Contribution,Annotation 1,Annotation 2
This paper describes a generic framework for generating comprehension questions from short edited texts using coherence relations.,Theory Proposal,Theory Proposal
"We present a simple, unsupervised but robust and accurate syntactic method for achieving the first objective and a modified hierarchical lexical method for the second objective.",New Algorithm/ Method,New Algorithm/ Method
we present a large-scale and indepth computational readability study for Arabic,Resources,Resources
we worked with an annotated corpus of human tutoring sessions from which we identified effective sessions based on human expert judgments,New Algorithm/ Method,New Algorithm/ Method
"we discuss one of the aspects of essay-writing, namely style, and how we can predict it automatically",Theory Proposal,Theory Proposal
"We describe the task definition, data preparation, performance metrics, and evaluation results.",Performance Evaluation,Performance Evaluation
This paper introduces our system at NLPTEA2018 Chinese Grammatical Error Diagnosis task. We will describe how to combine the knowledge that learned from large scale text data and handcraft heuristics with deep learning framework,New Algorithm/ Method,New Algorithm/ Method
"This paper introduces the DM NLP team’s system for NLPTEA 2018 shared task of Chinese Grammatical Error Diagnosis (CGED), which can be used to detect and correct grammatical errors in texts written by Chinese as a Foreign Language (CFL) learners",New Algorithm/ Method,New Algorithm/ Method
we employ the sequence to sequence learning to model the task of grammar error correction.,Model Proposal,Model Proposal
we propose a sequence labeling method based on the Policy Gradient LSTM model and apply it to this task to solve the above problems.,Model Optimization,Model Optimization
" In this paper, we report on a user study on language learners’ perceived usefulness of the application",Model Optimization,Model Optimization
"the domain of multi-perspective elaboration is used to illustrate that while Natural Language Processing (NLP) techniques are able to aid in the evaluation and implementation of key tool learning design objectives, that principled and critical analysis of learner impact is required in order to select appropriate techniques.",Algorithm/Method Optimization,Algorithm/Method Optimization
we present a qualitatively enhanced deep convolution recurrent neural network for computing the quality of a text in an automatic essay scoring task,Algorithm/Method Optimization,Algorithm/Method Optimization
This paper describes two models that employ word frequency embeddings to deal with the problem of readability assessment in multiple languages,Model Optimization,Model Optimization
provide a tool that enriches the traditional language learning setting in an enjoyable way and helps to avoid problems with learner motivation that can be encountered in language classes.,New Algorithm/ Method,New Algorithm/ Method
"This work presents an exploratory approach to the computational study of written language, oriented towards improving literacy acquisition in school-age children.",New Algorithm/ Method,New Algorithm/ Method
"This study assesses an index for measuring the pronunciation difficulty of sentences (henceforth, pronounceability) based on the normalized edit distance from a reference sentence to a transcription of learners’ pronunciation.",Theory Proposal,Theory Proposal
In this paper we report how we build a system and how to test it with a translated corpus from two publicly available English corpus,Theory Proposal,Theory Proposal
"This study explores the use of natural language processing techniques to enhance bilingual lexical access beyond simple equivalents, to enable translators to navigate along a wider cross-lingual lexical space and more examples showing different translation strategies, which is essential for them to learn to produce not only faithful but also fluent translations.",New Algorithm/ Method,New Algorithm/ Method
we propose methods to measure the bias and systematically remove its effects from a statistical model that learns the instructor’s intervention decision.,New Algorithm/ Method,New Algorithm/ Method
This paper studies how to integrate heterogeneous features such as a neural image feature generated from the image of the Web page by a variant of CNN (convolutional neural network) as well as text features extracted from the body text of the HTML file of the Web page.,Dataset Creation,Dataset Creation
"In this paper we formalize the problem automatic fill-in-the-blank question generation using two standard NLP machine learning schemes, proposing concrete deep learning models for each.",Algorithm/Method Optimization,Algorithm/Method Optimization
"this study aims to propose a proper short text clustering module for the IRS, and demonstrate our implemented techniques through real-world examples, so as to provide experiences and insights for further study.",Theory Proposal,Theory Proposal
"we use both a conventional linear CRF model (Lafferty et al., 2001) with specific feature engineering and a LSTM-CRF model to solve CGED task",Model Proposal,Model Proposal
"we regard CGED task as a sequence labeling problem(Zheng et al., 2016) and propose a CGED model with contextualized character representation.",Model Proposal,Model Proposal
we regarded the CGED 2018 shared task as a character-based sequence labeling task. We proposed a Bidirectional LSTM CRF(BiLSTM-CRF) neural network that combines LSTM and CRF for sequence labeling without any hand-craft features.,Resources,Resources
"This paper proposes a integrated approach of combining CRFs, statistical information from Google ngrams and rule-based expert knowledge to detect the four types of errors.",Model Optimization,Model Optimization
we build a Chinese Grammatical Error Diagnosis system in the NLPTEA2018 CGED shared task,Applications,Applications
The main goal of Chinese grammatical error diagnosis task is to detect word errors in the sentences written by Chinese-learning students.,Theory Proposal,Theory Proposal
"We present an approach for recursively splitting and rephrasing complex English sentences into a novel semantic hierarchy of simplified sentences, with each of them presenting a more regular structure that may facilitate a wide variety of artificial intelligence tasks, such as machine translation (MT) or information extraction (IE)",Theory Proposal,Algorithm/Method Optimization
" We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic.",Model Optimization,Model Proposal
"We present the zero-shot entity linking task, where mentions must be linked to unseen entities without in-domain labeled data.",Theory Proposal,Algorithm/Method Optimization
We propose a new neural transfer method termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER).,New Algorithm/ Method,New Algorithm/ Method
"we introduce an efficient knowledge distillation (KD) technique that transfers knowledge from a syntactic language model trained on a small corpus to an LSTM language model, hence enabling the LSTM to develop a more structurally sensitive representation of the larger training data it learns from",Performance Evaluation,Performance Evaluation
"we propose an imitation learning approach to unsupervised parsing, where we transfer the syntactic knowledge induced by the PRPN to a Tree-LSTM model with discrete parsing actions. Its policy is then refined by GumbelSoftmax training towards a semantically oriented objective.",Model Proposal,Model Optimization
" we annotate the Wall Street Journal part of the Penn Treebank with the gender information of the articles’ authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women.",Applications,Applications
"we study a broader range  of pre-training conditions and experiment over a variety of languages, both jointly and individually.
",Theory Proposal,Theory Proposal
We present a new method for sentiment lexicon induction that is designed to be applicable to the entire range of typological diversity of the world’s languages,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a tree communication model using graph convolutional neural network and graph recurrent neural network, which allows rich information exchange between phrases constituent tree.",Model Proposal,Model Optimization
"we design the gated unit networks to incorporate corresponding word representation into the decoder, and position-aware attention to pay more attention to the adjacent words of a target word.",Theory Proposal,Algorithm/Method Optimization
"In this paper, we propose a reinforced bidirectional attention network approach to tackle the above two challenges",Theory Proposal,Theory Proposal
"In this work, we present ELI5: a Long Form Question Answering dataset that emphasizes the dual challenges of isolating relevant information within long source documents and generating paragraph-length explanations in response to complex, diverse questions",Dataset Creation,Dataset Creation
"In this paper, we focus on the following two major characteristics of the TQA dataset. In this work, we introduce a novel algorithm
for solving the textbook question answering
(TQA) task which describes more realistic QA
problems compared to other recent tasks.",New Algorithm/ Method,New Algorithm/ Method
We present a novel approach to improve VQA performance that exploits this connection by jointly generating captions that are targeted to help answer a specific visual question.,Theory Proposal,Algorithm/Method Optimization
this paper proposes a multi-grained attention method. It learns explicit wordobject correspondence by two types of wordlevel attention complementary to the sentenceimage association.,New Algorithm/ Method,New Algorithm/ Method
"We investigate catastrophic forgetting in the context of multimodal models for Visual Question Answering (Antol et al., 2015) motivated by evidence from psycholinguistics.",Performance Evaluation,Performance Evaluation
"we propose a combined Visual and Textual Question Answering (VTQA) model which takes as input a paragraph caption as well as the corresponding image, and answers the given question based on both inputs.",Model Proposal,Model Optimization
"In this work, we aim to enhance the word representations and the interactions between the source and target words, while using even fewer parameters.",Theory Proposal,Model Optimization
In this work we present a new dataset of literary events—events that are depicted as taking place within the imagined space of a novel.,Dataset Creation,Dataset Creation
we propose a novel word reordering detection task to quantify how well the word order information learned by SAN and RNN.,Theory Proposal,Theory Proposal
In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP,Theory Proposal,Model Optimization
we provide novel support for this claim by performing a series of experiments to unpack the elements of English language structure learned by BERT.,Model Proposal,Model Proposal
"In this position paper, we argue that the community needs to make three substantive changes: (1) expanding our scope of problems to tackle both more subtle and more serious forms of abuse, (2) developing proactive technologies that counter or inhibit abuse before it harms, and (3) reframing our effort within a framework of justice to promote healthy communities.",Theory Proposal,Model Optimization
"we propose the self-feeding chatbot, a dialogue agent with the ability to extract new training examples from the conversations it participates in",Theory Proposal,Theory Proposal
"We propose an emotional dialogue system (EmoDS) that can generate the meaningful responses with a coherent structure for a post, and meanwhile express the desired emotion explicitly or implicitly within a unified framework",Theory Proposal,Theory Proposal
we propose a hierarchical graph representation by leveraging the structural property of dialog acts.,Theory Proposal,Theory Proposal
"we propose a novel incremental learning framework to design task-oriented dialogue systems, or for short Incremental Dialogue System (IDS),",Theory Proposal,Theory Proposal
"In this paper, we propose a new model, named ReCoSa, to tackle this problem. Firstly, a word level LSTM encoder is conducted to obtain the initial representation of each context.",Model Proposal,Model Optimization
"In this paper, we frame the consistency of dialogue agents as natural language inference (NLI) and create a new natural language inference dataset called Dialogue NLI. We propose a method which demonstrates that a model trained on Dialogue NLI can be used to improve the consistency of a dialogue model, and evaluate the method with human evaluation and with automatic metrics on a suite of evaluation sets designed to measure a dialogue model’s consistency.",Performance Evaluation,Performance Evaluation
"we measure budget in terms of the number of real user interactions. That is, we strive to optimize a dialogue agent via a fixed, small number of interactions with real users.",Theory Proposal,Theory Proposal
"In this work, we perform an extensive survey of decoding-time strategies for generating diverse outputs from conditional language models",Theory Proposal,New Algorithm/ Method
" In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation",New Algorithm/ Method,New Algorithm/ Method
we present a Vocabulary Pyramid Network (VPN) which is able to incorporate multi-pass encoding and decoding with multi-level vocabularies into response generation,Theory Proposal,Algorithm/Method Optimization
we propose an on-device neural network SGNN++ which dynamically learns compact projection vectors from raw text using structured and context-dependent partition projections,Theory Proposal,Theory Proposal
"In this paper, we take a radical step towards building a human-like conversational agent: endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic)",New Algorithm/ Method,Theory Proposal
"we propose a memory-augmented generative model, which learns to abstract from the training corpus and saves the useful information to the memory to assist the response generation. Our model clusters query-response samples, extracts characteristics of each cluster, and learns to utilize these characteristics for response generation",Model Proposal,Model Optimization
"In this paper, we propose to utilize the multiple references by considering the correlation of different valid responses and modeling the 1-to-n mapping with a novel two-step generation architecture",Model Proposal,Model Optimization
"This paper examines various unsupervised pretraining objectives for learning dialog context representations. Two novel methods of pretraining dialog context encoders are proposed, and a total of four methods are examined",New Algorithm/ Method,New Algorithm/ Method
" We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure.",Dataset Creation,Dataset Creation
"in this paper, we introduce a self-supervised learning task, inconsistent order detection, to explicitly capture the flow of conversation in dialogues.",New Algorithm/ Method,New Algorithm/ Method
"We explore the model’s behaviour on this task in detail, and conclude that its ability to model
humans is considerably weaker than K&C suggest.",Model Optimization,Model Proposal
"We propose an unsupervised approach for assessing conceptual complexity of texts, based on spreading activation.",Theory Proposal,Theory Proposal
"We propose two end-to-end metaphor identification models2 , detecting metaphors based on MIP and SPV, respectively",Model Proposal,Model Optimization
"this paper proposes a sense representation and tracking framework based on deep contextualized embeddings, aiming at answering not only what and when, but also how the word meaning changes",Theory Proposal,Theory Proposal
"We propose here a new task capturing crucial aspects of the human environment, such as natural object affordances, and of human conversation, such as full symmetry among the participants.",Theory Proposal,Theory Proposal
" We evaluate here an out-of-the-box CNN on the most challenging SCAN tasks, and we uncover the surprising fact that CNNs are dramatically better than RNNs at compositional generalization",Performance Evaluation,Performance Evaluation
" In this paper, we present a computational model which successfully identifies known universals, including Greenberg universals, but also uncovers new ones, worthy of further linguistic investigation",Theory Proposal,New Algorithm/ Method
"In this paper, we sought to fill this gap by employing a systematic approach that samples both over the space of algorithms and the space of human languages.",New Algorithm/ Method,New Algorithm/ Method
"we introduce a collection of large written corpora that we annotated using state-of-the-art parsers trained on Universal Dependencies (UD) treebanks (Nivre et al., 2018).",New Algorithm/ Method,New Algorithm/ Method
" In this paper, we present a novel approach
for incorporating external knowledge in Recurrent Neural Networks (RNNs).",Theory Proposal,New Algorithm/ Method
" We present a corpus of over 8,000 annotated text passages with ambiguous pronominal anaphora. These instances are both challenging and realistic",Theory Proposal,Algorithm/Method Optimization
. In this paper we propose Self Attentive Revision Encoder (StRE) which leverages orthographic similarity of lexical units toward predicting the quality of new edits.,Theory Proposal,Theory Proposal
"We propose an unsupervised method for collecting quantitative information from large amounts of web data, and use it to create a new, very large resource consisting of distributions over physical quantities associated with objects, adjectives, and verbs which we call Distribution over Quantities (DOQ)",New Algorithm/ Method,New Algorithm/ Method
"In our work, we target for the single-round non-task-oriented short-text conversation data collected from social media platforms",Dataset Creation,Dataset Creation
"we design a rubric for scoring an important, yet unexplored dimension of persuasive essay quality, thesis strength, and annotate a corpus of essays with thesis strength scores",Model Proposal,Model Proposal
"With this paper, we publish and analyze deISEAR, a German corpus of emotional event descriptions, and its English companion enISEAR, each containing 1001 instances",Theory Proposal,Theory Proposal
"This paper presents a multilingual corpus with semantic annotation of collocations in English, Portuguese, and Spanish.",Theory Proposal,Theory Proposal
"In this paper, we release a benchmark to directly test whether a system can differentiate natural language statements that make sense from those that do not make sense.",Theory Proposal,Theory Proposal
"We collected a dataset of jokes and funny dialogues in Russian from various online resources and complemented them carefully with unfunny texts with similar lexical properties. In this work we describe the creation of a large
dataset of funny short texts in Russian. ",Dataset Creation,Dataset Creation
"In this work, we present a method to decouple the language from the problem by learning language agnostic representations and therefore allowing training a model in one language and applying to a different one in a zero shot fashion.",New Algorithm/ Method,New Algorithm/ Method
we propose a generative model that aggregates short texts into clusters by leveraging the associated meta information.,Model Proposal,Model Proposal
we present two types of decoding functions whose inverse can be easily derived without expensive inverse calculation.,Model Proposal,Model Proposal
In this paper we introduce a new anomaly detection method—Context Vector Data Description (CVDD)—which builds upon word embedding models to learn multiple sentence representations that capture multiple semantic contexts via the self-attention mechanism,New Algorithm/ Method,New Algorithm/ Method
"This paper presents a new method for Bilingual Lexicon Induction (BLI), which we call Hubless Nearest Neighbor (HNN).",New Algorithm/ Method,New Algorithm/ Method
we introduce a noise detection component in our model: it lets the model detect and disregard examples which are likely to be noisy,Model Proposal,Model Proposal
"e, we introduce a new approach that learns an AL query strategy directly for the target problem of interest",New Algorithm/ Method,New Algorithm/ Method
"we propose a novel hierarchical attention-based architecture to serve as the neural regression function, with which the context information of a word is encoded and aggregated from K observations.",Theory Proposal,Theory Proposal
"this work, we propose a new method for constructing diachronic words embeddings, which we show to be competitive with prior approaches",New Algorithm/ Method,New Algorithm/ Method
We present a novel neural network architecture to simultaneously learn a two-part representation which is based on the principle of segregating source specific representation from the common representation,Algorithm/Method Optimization,Algorithm/Method Optimization
"In this study, we propose to use a block-regularized 3 × 2 CV (3 × 2 BCV) in model comparison because it could regularize the difference in certain frequency distributions over linguistic units between training and validation sets and yield stable estimators of P, R, and F1.",Model Optimization,Model Optimization
"In this paper, we propose an iterative inference algorithm based on gradient search, which is the first inference algorithm that can be broadly applied to any neural sequence generative models for text infilling tasks",Model Optimization,Model Optimization
We present here a general-purpose addition to the standard seq2seq framework that aims to simultaneously tackle all of the above issues,Algorithm/Method Optimization,Algorithm/Method Optimization
"In this paper, we propose the MINA algorithm for automatically extracting minimum spans to benefit from minimum span evaluation in all corpora",New Algorithm/ Method,New Algorithm/ Method
We propose a neural architecture for cross-document coreference resolution.,Theory Proposal,Theory Proposal
We propose an efficient neural framework for sentence-level discourse analysis in accordance with Rhetorical Structure Theory (RST).,Performance Evaluation,Performance Evaluation
"In this work, we explore this property in a multi-task learning framework for IDRR in which the relations and the connectives are simultaneously predicted, and the mapping is leveraged to transfer knowledge between the two prediction tasks via the embeddings of relations and connectives. We propose several techniques to enable such knowledge transfer that yield the state-of-the-art performance for IDRR on several settings of the benchmark dataset (i.e., the Penn Discourse Treebank dataset).",Theory Proposal,Theory Proposal
we explore the hypothesis that linguistic deficits drive the error patterns of speaker commitment models by analyzing the linguistic correlates of model errors on a challenging naturalistic dataset,Dataset Creation,Dataset Creation
"In this paper, we suggest to view learning event embedding as a multi-relational problem, which allows us to capture different aspects of event pairs",Theory Proposal,Theory Proposal
"In this paper, we propose a method for whyquestion answering (why-QA) that uses an adversarial learning framework.",New Algorithm/ Method,New Algorithm/ Method
"k, we propose a data augmentation technique by automatically generating relevant unanswerable questions according to an answerable question paired with its corresponding paragraph that contains the answer",Theory Proposal,Theory Proposal
we present a detailed analysis of why single-hop reasoning works so well,Model Proposal,Model Proposal
"We propose a new end-to-end question answering model, which learns to aggregate answer evidence from an incomplete knowledge base (KB) and a set of retrieved text snippets",Model Optimization,Model Optimization
we propose an adaptive decoding method to avoid such intermediate representations.,New Algorithm/ Method,New Algorithm/ Method
"This paper tackles this gap and performs an in-depth investigation of the characteristics of legal and illegal text in the Darknet, comparing it to a clear net website with similar content as a control condition.",Performance Evaluation,Performance Evaluation
" In this paper, we propose a weakly-supervised information extraction framework for automated CTA transcript parsing",Theory Proposal,Theory Proposal
"In this paper, we first build a novel boundary during searching for new concepts via external knowledge base and then utilize heterogeneous features to verify the highquality results.",New Algorithm/ Method,New Algorithm/ Method
"We show that the imperceptibility of several existing linguistic steganographic systems (Fang et al., 2017; Yang et al., 2018) relies on implicit assumptions on statistical behaviors of fluent text",Theory Proposal,Theory Proposal
"We evaluate a broad variety of neural models on the new dataset, establishing strong baselines that surpass previous feature-based models in three tasks: (1) binary violation classification; (2) multi-label classification; (3) case importance prediction",Performance Evaluation,Performance Evaluation
" We propose an approach to improving the robustness of NMT models, which consists of two parts: (1) attack the translation model with adversarial source examples; (2) defend the translation model with adversarial target inputs to improve its robustness against the adversarial source inputs.",Model Optimization,Model Optimization
"In this paper, we address these issues by sampling context words not only from the ground truth sequence but also from the predicted sequence by the model during training, where the predicted sequence is selected with a sentence-level optimum.",Model Proposal,Model Proposal
"In this paper, we introduce an alternative reward function for optimizing NMT systems that is based on recent work in semantic similarity",New Algorithm/ Method,New Algorithm/ Method
"This paper proposes a novel AutoML strategy based on probabilistic grammatical evolution, which is evaluated on the health domain by facing the knowledge discovery challenge in Spanish text documents",Performance Evaluation,Performance Evaluation
"this paper proposes a ∆-learning approach to distill discrimination and generalization knowledge by effectively decoupling, incrementally learning and adaptively fusing event representation",Theory Proposal,Theory Proposal
"In this paper, we proposed the multi-granularity lattice framework (MG lattice), a unified model comprehensively utilizes both internal information and external knowledge, to conduct the Chinese RE task.",Model Proposal,Model Proposal
"we propose A2N, an effective model (Section 2) which, conditioned on the query, uses a bi-linear attention on the graph neighborhood of an entity to generate an embedding representation of the entity.",Model Optimization,Model Optimization
"In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively.",Theory Proposal,Theory Proposal
"In this paper, we introduce a framework to infuse temporal awareness into such models by learning a pre-trained model to embed timexes.",Model Proposal,Model Proposal
"We consider a novel question answering (QA) task where the machine needs to read from large streaming data (long documents or videos) without knowing when the questions will be given, which is difficult to solve with existing QA methods due to their lack of scalability.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we introduce query-agnostic indexable representations of document phrases that can drastically speed up open-domain QA",Theory Proposal,Theory Proposal
"In this work, we propose neural variational language model (NVLM), which enables the sharing of grammar knowledge among different corpora.",Model Proposal,Model Proposal
"We present a new dataset with 1,390 examples from 7 application domains (e.g. a calendar or a file manager), each example consisting of a triplet: (a) the application’s initial state, (b) an instruction, to be carried out in the context of that state, and (c) the state of the application after carrying out the instruction",Dataset Creation,Dataset Creation
"We conduct the first large-scale systematic study of candidate pretraining tasks, comparing 19 different tasks both as alternatives and complements to language modeling",Resources,Resources
"In this work, we focus on complex question semantic parsing and propose a novel Hierarchical Semantic Parsing (HSP) method, which utilizes the decompositionality of complex questions for semantic parsing.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks.",New Algorithm/ Method,New Algorithm/ Method
We demonstrate that the automatically curated corpus allows a bidirectional LSTM sentence encoder to yield high quality sentence embeddings and can serve as a supervised fine-tuning dataset for larger models such as BERT,Dataset Creation,Dataset Creation
"we introduce SParC (cross-domain Semantic Parsing in Context), an expert-labeled dataset which contains 4,298 coherent question sequences (12k+ questions paired with SQL queries) querying 200 complex databases in 138 different domains",Dataset Creation,Dataset Creation
We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges: 1) the mismatch between intents expressed in natural language (NL) and the implementation details in SQL; 2) the challenge in predicting columns caused by the large number of outof-domain words,Model Proposal,Model Proposal
"we experiment with spectral methods of signal representation and summarization as mechanisms for constructing such word-sequence embeddings in an unsupervised fashion. In particular, we explore an algorithm rooted in fluid-dynamics, known as higher-order Dynamic Mode Decomposition, which is designed to capture the eigenfrequencies, and hence the fundamental transition dynamics, of periodic and quasi-periodic systems.",New Algorithm/ Method,New Algorithm/ Method
"We propose SEMBLEU, a robust metric that extends BLEU (Papineni et al., 2002) to AMRs",Theory Proposal,Theory Proposal
"We implement our reranker in a competitive neural semantic parser and test on four semantic parsing (GEO, ATIS) and Python code generation (DJANGO, CONALA) tasks, improving the strong baseline parser by up to 5.7% absolute in BLEU (CONALA) and 2.9% in accuracy (DJANGO), outperforming the best published neural parser results on all four datasets.",Dataset Creation,Dataset Creation
" In this paper, we present an encoder-decoder semantic parser, where the structure of the DB schema is encoded with a graph neural network, and this representation is later used at both encoding and decoding time.",Theory Proposal,Theory Proposal
This paper presents a conservative estimate of human performance to serve as a target for the GLUE sentence understanding benchmark.,Model Proposal,Model Proposal
"In this paper, we present a single semantic parser that does very well across all of DM, PAS, PSD, EDS and AMR (2015 and 2017).",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we show that combination of different methods makes a positive impact",New Algorithm/ Method,New Algorithm/ Method
"we present two novel contributions. First, we present an analysis that spans the common components of a traditional NLP pipeline. We show that the order in which specific abstractions are encoded reflects the traditional hierarchy of these tasks. Second, we qualitatively analyze how individual sentences are processed by the BERT network, layer-by-layer. We show that while the pipeline order holds in aggregate, the model can allow individual decisions to depend on each other in arbitrary ways, deferring ambiguous decisions or revising incorrect ones based on higher-level information",Algorithm/Method Optimization,Algorithm/Method Optimization
"We present a model and methodology for learning paraphrastic sentence embeddings directly from bitext, removing the timeconsuming intermediate step of creating paraphrase corpora",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a second-order semantic dependency parser, which takes into consideration not only individual dependency edges but also interactions between pairs of edges",Theory Proposal,Theory Proposal
"we propose a new sarcasm dataset, Multimodal Sarcasm Detection Dataset (MUStARD1 ), compiled from popular TV shows.",Theory Proposal,Theory Proposal
"In this paper, we tackle these tasks in the context of complex arguments on a diverse set of topics.",Theory Proposal,New Algorithm/ Method
", we investigate two formalisms with deep sentiment representations that capture sentiment subtype expressions by latent variables and Gaussian mixture vectors, respectively",Performance Evaluation,Performance Evaluation
In this work we focus on Japanese and show the potential use of transfer learning techniques in text classification.,Theory Proposal,Theory Proposal
We analyze the nature of these cues and demonstrate that a range of models all exploit them,Performance Evaluation,Performance Evaluation
We propose a reason comparing network (RCN) to leverage reason information for stance comparison.,Theory Proposal,Theory Proposal
"we conduct a task of human motive detection. We manually annotate 1,600 review texts in restaurant and laptop domains from existing ABSA datasets with the six motives. The annotation results reveal that people are driven by different motives in different domains. Finally, we report the performance of baseline methods on this new dataset.",New Algorithm/ Method,New Algorithm/ Method
we propose a novel method to refine the embeddings of targets and aspects. Such pivotal embedding refinement utilizes a sparse coefficient vector to adjust the embeddings of target and aspect from the context.,Performance Evaluation,Performance Evaluation
"We address this task in an empirical manner by annotating 39 political debates from the last 50 years of US presidential campaigns, creating a new corpus of 29k argument components, labeled as premises and claims. We then propose two tasks: (1) identifying the argumentative components in such debates, and (2) classifying them as premises and claims.",Theory Proposal,Theory Proposal
This study investigates (i) span representation originally developed for other NLP tasks and (ii) a simple task-dependent extension for ASP. Our extensive experiments and analysis show that these representations yield high performance for ASP and provide some challenging types of instances to be parsed,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present a fast and strong neural approach for general purpose text matching applications.",Model Proposal,Model Proposal
"We present a monolingual alignment system for long, sentence- or clause-level alignments, and demonstrate that systems designed for word- or short phrase-based alignment are illsuited for these longer alignments",Model Proposal,Algorithm/Method Optimization
"In this paper, we show that these two problems are actually complementary",Theory Proposal,Model Proposal
We present a latent variable model for predicting the relationship between a pair of text sequences,Model Proposal,Model Proposal
"We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017).",Model Proposal,Model Proposal
We present a supervised model for automatically identifying when one event is a subevent of another.,Model Proposal,Model Proposal
"In this paper, we show that commonsense inference still proves dicult for even stateof-the-art models, by presenting HellaSwag, a new challenge dataset.",Dataset Creation,Dataset Creation
we propose a novel framework to build a unified multi-domain enabled semantic parser trained only with weak supervision (denotations).,Theory Proposal,Theory Proposal
We introduce the use of Poincare embeddings ´ to improve existing state-of-the-art approaches to domain-specific taxonomy induction from text as a signal for both relocating wrong hyponym terms within a (pre-induced) taxonomy as well as for attaching disconnected terms in a taxonomy.,Theory Proposal,New Algorithm/ Method
"In this paper, we recast MNLI and JOCI as COPA-style plausibility tasks by sampling and constructing (p, h, h 0 ) triples from these two datasets. Each premise-hypothesis pair (p, h) is labeled with different levels of plausibility yp,h.",Dataset Creation,Dataset Creation
we propose a simple and effective method for fine-tuning distributional word vectors for LE. Our Generalized Lexical ENtailment model (GLEN) is decoupled from the word embedding model and applicable to any distributional vector space,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we describe a simple re-implementation of BERT for commonsense reasoning.",Theory Proposal,Theory Proposal
". In this paper, we show that the performance of three language models on WSC273 consistently and robustly improves when finetuned on a similar pronoun disambiguation problem dataset (denoted WSCR).",Dataset Creation,Dataset Creation
"In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph.",Model Proposal,Model Proposal
We propose an end-to-end neural model with coreference alignment and conversation flow modeling.,Model Proposal,Model Proposal
We propose a cross-lingual QG model which uses the following training regime: (i) Unsupervised pretraining of language models in both primary and secondary languages and (ii) joint supervised training for QG in both languages.,Model Optimization,Model Optimization
"we propose a hierarchical reinforced sequence operation method, named Point-Then-Operate (PTO), which consists of a high-level agent that proposes operation positions and a lowlevel agent that alters the sentence",New Algorithm/ Method,New Algorithm/ Method
"We propose a new metric, PARENT, which aligns n-grams from the reference and generated texts to the semi-structured data before computing their precision and recall.",Theory Proposal,Theory Proposal
"In this work, we explore to what extent high quality training data is actually required for Extractive QA, and investigate the possibility of unsupervised Extractive QA.",Theory Proposal,Theory Proposal
", we propose MULTIQA, a BERTbased model, trained on multiple RC datasets, which leads to state-of-the-art performance on five RC datasets",Model Optimization,Model Optimization
"We propose a curriculum learning (CL) based Pointer-Generator framework for reading/sampling over large documents, enabling diverse training of the neural model based on the notion of alternating contextual difficulty",Model Optimization,Model Optimization
We propose Commonsense Auto-Generated Explanations (CAGE) as a framework for generating explanations for CQA.,Theory Proposal,Theory Proposal
"In this work, we address the interpretability of ML based question answering (QA) models on a combination of knowledge bases (KB) and text documents",Model Proposal,Model Proposal
"We measure this characteristic using modularity, a network measurement that measures the strength of clusters in a graph",Theory Proposal,Theory Proposal
"In this paper, we present the first work on cross-lingual generalisation of GR-LE relation",Theory Proposal,Theory Proposal
"In this paper, we extend these earlier experiments to cover 69 languages from 13 language families using a multilingual Bible corpus",Theory Proposal,Theory Proposal
The goal of this paper is to shed light on this matter so as to better understand the nature and extension of these limitations.,Theory Proposal,Theory Proposal
"We provide implication for other domainrelated works where better representation of
domain terms is important, especially when
the data set is highly imbalanced.",Theory Proposal,Theory Proposal
"we propose a novel methodology to automatically
verify the presence of therapeutic factors in
social networking websites by using Natural
Language Processing (NLP) techniques",New Algorithm/ Method,New Algorithm/ Method
"To achieve this task, natural language processing techniques were used to predict whether
each Tweet from a given set of Tweets contains a
mention of an ADR and extract any mentions of
ADRs",Theory Proposal,Theory Proposal
"we describe the development of
TCL, a lexicon for Turkish discourse connectives,
which follows the format of DiMLex",Theory Proposal,Theory Proposal
"This paper proposes a novel representation of
event structure by separating verbal semantics and the meaning of argument structure
constructions that verbs occur in.",New Algorithm/ Method,New Algorithm/ Method
"we propose that natural language generation
systems describing emotions should take into account how emotions are expressed non-verbally",New Algorithm/ Method,New Algorithm/ Method
"we show that some emotions are more
likely to be expressed via a certain channel, and
this channel is also influenced by the presence or
non-presence of a communication partner",Theory Proposal,Theory Proposal
"Using the Recursive feature elimination with
cross-validation (RFECV) algorithm, we perform feature selection experiments on an exhaustive set of nineteen features (belonging
to all the classes mentioned above) extracted
from Brown corpus text",New Algorithm/ Method,New Algorithm/ Method
"we take advantage of
these characteristics to identify the highlights
of pre-scheduled events from tweet streams
and we demonstrate a method to summarize
these highlights",Theory Proposal,Theory Proposal
"To incorporate sentiment score in predicting
a movie’s success",Performance Evaluation,Performance Evaluation
"we explore the viability
of models for the preemptive toxic detection task.",Performance Evaluation,Performance Evaluation
"we adapt a CRF layer as a a top module over the
outputs of the BERT-based model and demonstrate
that it improves performance even further.",Model Optimization,Model Optimization
we increase precision by filtering these name candidates with automatically learnt inflection patterns derived from name occurrences in large news article collections.,Algorithm/Method Optimization,Algorithm/Method Optimization
we discuss possible methods for improving sentiment classification for Slovak language by using state-of-the-art methods.,Algorithm/Method Optimization,Algorithm/Method Optimization
"Examines bias in ELMo and BERT, taking advantage of their context-sensitivity to give better visualizations",Theory Proposal,Theory Proposal
"We propose a multi-head natural
language inference (NLI) encoder which resolves
co-reference though heuristic interaction and efficiently addresses the redundancy in BERT by applying dropout to inputs directly",New Algorithm/ Method,New Algorithm/ Method
we propose an extractive question answering (QA) formulation of pronoun resolution task that overcomes this limitation and shows much lower gender bias (0.99) on their dataset.,Theory Proposal,Theory Proposal
"we aim to support the annotation of argument schemes by combining a recently developed annotation method for one of
the leading typologies of argument schemes (Section 4) and a popular online software tool for
annotating argumentative discourse, OVA",New Algorithm/ Method,New Algorithm/ Method
we present a robust English corpus and annotation schema that allows us to explore the less straightforward examples of term-definition structures in free and semi-structured text,Dataset Creation,Dataset Creation
"it is essential to include a
justification method in similar annotation tasks as
a suitable way of checking the guidelines and improving the training and evaluation processes of
automatic systems towards explainable AI",New Algorithm/ Method,New Algorithm/ Method
"We introduce two novel automated metrics:
Semantic Similarity and Response Echo Index and we show that they correlate well with
human judgment",New Algorithm/ Method,New Algorithm/ Method
we propose a novel method to select an appropriate response from response candidates generated by NCMs.,New Algorithm/ Method,New Algorithm/ Method
"we outline the approach and key components through which our conversational agent, Ruuh is able to accommodate a wide range of social needs",Theory Proposal,Theory Proposal
"We present de-lexical segmentation, a linguistically motivated alternative to greedy or other unsupervised methods, requiring language specific knowledge, but no direct supervision.",New Algorithm/ Method,New Algorithm/ Method
We explore the use of data mining and NLP techniques for understanding the variability of tones in a large corpus of Mandarin newscast speech,Theory Proposal,Theory Proposal
k we investigate using a subtle yet robust signal to resolve such ambiguity: linguistic alignment.,Performance Evaluation,Performance Evaluation
we conduct a detailed study with human annotators to confirm that our selection of semantic roles is effective in determining the underlying rhetorical structure of existing biomedical articles in an extensive dataset.,Theory Proposal,Theory Proposal
we show that filtering for transitivity within pairwise annotations is more effective than filtering based on annotation confidence measures for individual examples.,Algorithm/Method Optimization,Algorithm/Method Optimization
"we take the novel approach of applying, for aggregation, a gradual argumentation semantics to bipolar argumentation frameworks mined using stance detection",New Algorithm/ Method,New Algorithm/ Method
we describe the the DipInfo-UniTo realizer (hencefort UniTO realizer) participating to the shallow track of the Surface Realization Shared Task 2018,Theory Proposal,Theory Proposal
we show that the internal representations of RNNs trained on a variety of NLP tasks encode these syntactic features without explicit supervision,Theory Proposal,Theory Proposal
We propose an efficient gradient-based optimization method to manipulate discrete text structure at its one-hot representation,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a method for obtaining high quality word embeddings that capture domain specific semantics and are suitable for tasks on the specific domain,New Algorithm/ Method,New Algorithm/ Method
"addresses the linguistic phenomenon of null-instantiated frame elements, i.e., implicit semantic roles, and their
representation in FrameNet (FN)",Theory Proposal,Theory Proposal
We develop an unsupervised pipeline to extract schemas and apply our method to Reddit posts to detect schematic structures that are characteristic of different subreddits.,New Algorithm/ Method,New Algorithm/ Method
"We developed a machine-learning-based
method to detect video game players that
harass teammates or opponents in chat earlier
in the conversation",New Algorithm/ Method,New Algorithm/ Method
"The
aim of these models is to identify abusive language that directly targets certain individuals or
groups, particularly people belonging to protected
categories",Theory Proposal,Theory Proposal
"focuses on using exclusively text-based input in the detection, in an optimised architecture combining Convolutional Neural Networks and Long ShortTerm Memory-networks.",New Algorithm/ Method,New Algorithm/ Method
"I
show how gender should be explored in
multiplicity in computational research
through clustering techniques, and layout
how this is being achieved in a study in
progress on gender hostility on Stack
Overflow.",Theory Proposal,Theory Proposal
"aims to fill this gap by applying
the WEAT bias detection method to four sets
of word embeddings trained on corpora from
four different domains: news, social networking, biomedical and a gender-balanced corpus extracted from Wikipedia (GAP).",Performance Evaluation,Performance Evaluation
Demonstrates the effectiveness of the debiasing conceptor on both traditional and contextualized word embeddings.,Theory Proposal,Theory Proposal
"we propose to make use of the
recent popular BERT tool (Devlin et al., 2018).
BERT is a model trained for masked language
modeling (LM) word prediction and sentence prediction using the transformer network",Model Proposal,Model Proposal
"Our work is the
first successful attempt of using R-GCN to boost
the performance of BERT contextual embeddings
without the need to fine tune BERT",Model Optimization,Model Optimization
"we apply a variant of the Structured Prediction Energy Network (SPEN) (Belanger and McCallum, 2016) to the Dialogue State Tracking Challenge (DSTC) 2 datase",Applications,Applications
"We leverage the pretrained multilingual
BERT cased model to encode input sentences and apply additional word-level and
character-level LSTM layers before jointly
decoding lemmas and morphology tags using
simple sequence tagging layers",Model Optimization,Model Optimization
We apply convolutional neural networks to the task of shallow morpheme segmentation using low-resource datasets for 5 different languages,New Algorithm/ Method,New Algorithm/ Method
"we apply modern language modeling techniques to a large-vocabulary icon set commonly used in AAC applications, but for which we have no in-domain training data.",Applications,Applications
"we define a meaning representation label set by adapting the English
schema and taking into account the specific
characteristics of Vietnamese.",Theory Proposal,Theory Proposal
"we propose the addition of a set of speech acts, tense and aspect information, and parameters that help specify spatial location",Theory Proposal,Theory Proposal
"We
propose using a neural encoder-decoder model to
extract story events and present empirical results
with significant improvements over the baseline.",Model Proposal,Model Proposal
"we present the results of a full end-to-end
story generation pipeline as originally proposed by
Martin et al. (2018) (Figure 1), showing how all of
the sub-systems can be integrated.",Theory Proposal,Theory Proposal
"We define the task of scenario detection
and introduce a benchmark dataset of
annotated narrative texts, with segments
labeled according to the scripts they in-stantiate.",Dataset Creation,Dataset Creation
To prepare a data set to define a movie’s success,Dataset Creation,Dataset Creation
"we introduce the first
publicly-available Levantine Hate Speech and
Abusive (L-HSAB) Twitter dataset with the
objective to be a benchmark dataset for automatic detection of online Levantine toxic contents",Dataset Creation,Dataset Creation
"using a large data set of conversations among
Wikipedia contributors, we compile and make publicly available a new dataset with complete discussion threads and with semi-automatically generated
toxicity labels",Dataset Creation,Dataset Creation
"We train a neural network
with an objective to label sentences as grammatical or ungrammatical, using a “simulated
learner corpus”: a dataset with correct text
and with artificial errors, generated automatically",New Algorithm/ Method,New Algorithm/ Method
"We present the first gold-standard dataset for
Russian annotated with compositionality information of noun compounds.",Dataset Creation,Dataset Creation
"We release
a new gender-balanced dataset1 of 800 sentences pertaining to specific professions and
propose a methodology for using it as a test
bench to evaluate sentiment analysis models",Dataset Creation,Dataset Creation
we use Strictly k-Piecewise languages to generate datasets with various propertiesto compute the characteristics of the LDDs in these datasets using mutual information and analyze the impact of factors,Dataset Creation,Dataset Creation
we introduce a dataset of 230 synthesis procedures annotated by domain experts with labeled graphs that express the semantics of the synthesis sentences.,Dataset Creation,Dataset Creation
"create and organize a collection of
lemmas that would serve as a “hub” point for different resources",Resources,Resources
"presents the annotation
of formulaic sequences in the reference corpus of
spoken Slovenian in terms of syntactic structure,
pragmatic function and semantic relevance",New Algorithm/ Method,New Algorithm/ Method
"we present a data set of HindiEnglish code-mixed tweets labelled with semantic
roles. These labels provide us with information of the role played by an argument with respect to a
verb in a given sentence",Dataset Creation,Dataset Creation
"We developed detailed
and explicit guidelines for human annotators, and
tested these on corpus data",New Algorithm/ Method,New Algorithm/ Method
"a recorded dataset of 400 speeches discussing 200 controversial topics, along with mined claims for each topic",Dataset Creation,Dataset Creation
"We release CompSent-19, a new corpus consisting of 7,199 sentences containing item pairs (27% of the sentences are tagged as comparative and annotated with a preference);",Dataset Creation,Dataset Creation
"we propose the Restricted RNTN (r-RNTN) which uses only K < |V | recurrence matrices. Given that |V | words must be assigned K matrices, we map the most frequent K − 1 words to the first K − 1 matrices, and share the K-th matrix among the remaining words.",Theory Proposal,Theory Proposal
"We enhance tweet representation with a language model and distinguish the importance of different words with
Multi-Head Self-Attention",Model Proposal,Model Proposal
"We propose that a lattice-like architecture of the annotation categories can adequately handle all four issues, and at the same
time remain both intuitive for annotators and
faithful to typological insights",New Algorithm/ Method,New Algorithm/ Method
"presents an annotation scheme for modality that employs a dependency structure. Events and sources (here, conceivers) are represented as nodes and epistemic strength relations characterize the edges.",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel way to combine a neural
story generation model with an explicit, symbolic text planning component; furthermore,
we show that the design reduces the demand
on training data",New Algorithm/ Method,New Algorithm/ Method
"We present an ensemble-based system for eventto-sentence that allows for guided language generation and demonstrate that this outperforms a
baseline sequence-to-sequence approach.",New Algorithm/ Method,New Algorithm/ Method
We propose a hybrid system combining a rule-based approach and light ML techniques. We use multilingual lexical resources such as JRC-NAMES and BABELNET together with a named entity guesser to recognise names.,New Algorithm/ Method,New Algorithm/ Method
I present a novel neural network model based on the pre-trained BERT for the gendered pronoun resolution task,Model Proposal,Model Proposal
"The model presented here draws upon
the strengths of state-of-the-art language and
coreference resolution models, and introduces
a novel evidence-based deep learning architecture.",Model Proposal,Model Proposal
"we started experimenting with machine
learning approaches for automating part of the annotation process",Model Proposal,Model Proposal
"we achieve
these features in a simple architecture integrating
existing methods on top of SEQ2SEQ in order to
make it easily reproducible in existing dialogue
systems",New Algorithm/ Method,New Algorithm/ Method
Our models combine sparse sequence-to-sequence models with a two-headed attention mechanism that learns separate attention distributions for the lemma and inflectional tags,Model Proposal,Model Proposal
We propose a merging strategy inspired by Byte-Pair-Encoding that reduces the space of valid operations by merging frequent adjacent operations,New Algorithm/ Method,New Algorithm/ Method
We present various models to tackle each task and evaluate performance.,Model Proposal,Model Proposal
We explore the potential of a transfer learning approach to improve the performance of an argument mining model trained with a small volume of data annotated with the proposed scheme.,New Algorithm/ Method,New Algorithm/ Method
we propose a neural network to evaluate the probability of there being a relation between ACs and to rank ACs using TextRank on the basis of probability,Performance Evaluation,Performance Evaluation
"we first introduce a variant of GloVe, in which there is an explicit connection between word vectors and PMI weighted co-occurrence vectors. We then show how relation vectors can be naturally embedded into the resulting vector space.",New Algorithm/ Method,New Algorithm/ Method
"we propose an approach to explicitly obscure important author characteristics at training time, such that representations learned are invariant to these attributes",New Algorithm/ Method,New Algorithm/ Method
"Our approach relied on a text processing pipeline for tweets, and training traditional machine learning and deep learning models",Theory Proposal,Theory Proposal
aims to detect tweets with Adverse Drug Reaction (ADR) mentions we used ELMo embeddings which is a deep contextualized word representation able to capture both syntactic and semantic characteristics,New Algorithm/ Method,New Algorithm/ Method
"We train ULMFit and BERT models for Tasks 1 and 4, and show that these models are agnostic to the effects of undersampling and oversampling, given a highly imbalanced dataset",Performance Evaluation,Performance Evaluation
"We propose
an end-to-end framework to automatically generate a sequence of pictures that represent major
2
events in a story text.",New Algorithm/ Method,New Algorithm/ Method
"We develop a story generation model that
generates globally coherent stories about
daily activities.",New Algorithm/ Method,New Algorithm/ Method
"we present a system to monitor cyberbullying phenomena by
combining message classification and social
network analysis.",New Algorithm/ Method,New Algorithm/ Method
"We propose
a structured annotation scheme that labels claim
verifiability, stance, and sentiment on news outlets.",New Algorithm/ Method,New Algorithm/ Method
"The goal is to develop a resource and
methods for distinguishing compositional compounds, which meaning could be split into parts,
from non-compositional ones that have a solid
meaning, and for which we would like to have a
dedicated embedding",Resources,Resources
"we build a neural (NMT) machine system on the publicly available clean out-of-domain news corpus, and a phrase-based (PBMT) system trained on the same data in order to compare the two approaches in this specific scenario.",New Algorithm/ Method,New Algorithm/ Method
The paper presents a generic approach to the supervised sentiment analysis of social media content in foreign languages,New Algorithm/ Method,New Algorithm/ Method
"presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health.",New Algorithm/ Method,New Algorithm/ Method
"Introduces debiasing conceptors along with
a formal definition and mathematical relation
to the Word Embedding Association Test",Theory Proposal,Theory Proposal
"we
describe our BERT-based approach to solving
the problem of gender-balanced pronoun resolution. We are able to reach 92% F1 score and
a much lower gender bias on the benchmark
dataset shared by Google AI Language team.",New Algorithm/ Method,New Algorithm/ Method
we propose an approach to extend biased single-output genderblind NLP systems with gender-specific alternative reinflections.,New Algorithm/ Method,New Algorithm/ Method
"we present the currently available
language processing systems similar to emtsv for
the sake of comparison.",Theory Proposal,Theory Proposal
"we show that representing the concept of word complexity in a continuous manner
results in higher inter-annotator agreement than
using binary labels.",New Algorithm/ Method,New Algorithm/ Method
"our
aim is to create a system that is actually capable
of formulating relevant questions about the text it
processes.",New Algorithm/ Method,New Algorithm/ Method
"we focus on goal-oriented dialog systems that have a
clear message they need to convey, such as a price
or available times, and the role of computational
creativity in encapsulating their message in a creative form",New Algorithm/ Method,New Algorithm/ Method
"We propose an adversarial learning approach
for generating multi-turn dialogue responses.
Our proposed framework, hredGAN, is based
on conditional generative adversarial networks",New Algorithm/ Method,New Algorithm/ Method
"we propose a response
generation model that outputs diverse words while
preserving relevance in response to the input utterance",Model Proposal,Model Proposal
We present a hierarchical neural model for contextual morphological analysis with a shared encoder and independent decoders for each coarse-grained feature.,Model Proposal,Model Proposal
", we present our approach of treating contextual morphological analysis as the generation of the correct sequence of MSD tag dimensions.",New Algorithm/ Method,New Algorithm/ Method
We propose a model to perform morphosyntactic annotation for any language with a translation of the Bible.,Model Proposal,Model Proposal
we present artificial phonology experiments that show that phone embeddings learn paradigmatic relationships such as phonemic and allophonic distribution quite well,Model Proposal,Model Proposal
"This paper demonstrates that there are regular functions that are not weakly deterministic, and, because all attested processes so far studied are weakly deterministic, supports the subregular hypothesis.",Performance Evaluation,Performance Evaluation
We propose and test an annotation scheme that we use to conduct a pilot annotation experiment in which we enrich a subset of the SciDTB corpus with an additional layer of argumentative structures.,New Algorithm/ Method,New Algorithm/ Method
We present an experimental study of supervised classifiers and a strong rule-based baseline from prior work.,Theory Proposal,Theory Proposal
"we present a large-scale and indepth computational readability study for Arabic. Arabic, being a relatively low-resource and morphologically complex language, presents numerous challenges to the task of automatic readability assessment.",Theory Proposal,Theory Proposal
"we propose a new method to study social media
content by characterizing disease-related correlations of language, by leveraging available demographic and disease information on the community level.",New Algorithm/ Method,New Algorithm/ Method
we describe our methods to automatically classify Twitter posts conveying events of adverse drug reaction (ADR). B,New Algorithm/ Method,New Algorithm/ Method
The best-performed model on the test sets were trained on a merged corpus consisting of the datasets released by SMM4H 2017 and 2019,New Algorithm/ Method,New Algorithm/ Method
We also show the use of combining pretrained BERT embeddings with Glove embeddings fed to a BLSTM text classifier for sub-task-1 and sub-task-4.,Performance Evaluation,Performance Evaluation
"we propose an extension to
Abstract Meaning Representations (AMRs) to
encode scope information of quantifiers and
negation, in a way that overcomes the semantic gaps of the schema while maintaining its
cognitive simplicity.",New Algorithm/ Method,New Algorithm/ Method
"We propose two extensions of GKR that
clearly show this division and empirically test
one of the proposals on an NLI dataset with
hard compositional pairs.",New Algorithm/ Method,New Algorithm/ Method
"We present a method of generating inferences
from ULFs from a small set of interpretable inference rules by first defining general semantic predicates over ULF clauses and tree transformations
that correspond to natural semantic operations in
ULF.",New Algorithm/ Method,New Algorithm/ Method
"We describe
how ULF can be used to generate natural language inferences that are grounded in the semantic and syntactic structure through a small
set of rules defined over interpretable predicates and transformations on ULFs",Theory Proposal,Theory Proposal
"This paper presents a new task-oriented meaning representation called meta-semantics, that
is designed to detect patients with early symptoms of Alzheimer’s disease by analyzing their
language beyond a syntactic or semantic level",New Algorithm/ Method,New Algorithm/ Method
"This paper proposes using a Bidirectional
LSTM-CRF model in order to identify the
tense and aspect of verbs",Model Proposal,Model Proposal
"we describe new semantic representations for the lexical resource VerbNet that
provide this sort of information for thousands of verb senses and introduce a means for automatically translating text to these representations.",Theory Proposal,Theory Proposal
"we describe an approach to overcome this
by getting labelled persona data from a different task and leveraging those annotations to
perform persona based story generation.",Theory Proposal,Theory Proposal
"We propose a novel take on understanding
narratives in social media, focusing on learning “functional story schemas”, which consist
of sets of stereotypical functional structures.",New Algorithm/ Method,New Algorithm/ Method
"We introduce a novel
partitioning approach for characterizing user
polarization based on their distribution of participation across interest subreddits",New Algorithm/ Method,New Algorithm/ Method
"we describe a workflow for the
data-driven acquisition and semantic scaling
of a lexicon that covers lexical items from the
lower end of the German language register—
terms typically considered as rough, vulgar or
obscene.",New Algorithm/ Method,New Algorithm/ Method
"we propose an approach
for semi-automatically creating a data-to-text
(D2T) corpus for Russian that can be used
to learn a D2T natural language generation
model.",New Algorithm/ Method,New Algorithm/ Method
"we propose a new method to quantify bias in BERT embeddings (§2). Since BERT embeddings use a masked language modelling objective, we directly query the model to measure the bias for a particular token",New Algorithm/ Method,New Algorithm/ Method
Construction of a corpus with template sentences that can check the preservation of gender-neutrality in KR-EN translation,Dataset Creation,Dataset Creation
"we have developed a method of acquiring hedge annotations through crowdsourcing, by
framing the hedge identification task as a simple
word sense disambiguation problem.",New Algorithm/ Method,New Algorithm/ Method
"a demonstration that the generalized method
is comparable in reliability of annotations to
the original more restricted crowd-sourcing
method proposed by (Scholman and Demberg, 2017a);",Model Proposal,Model Proposal
"we present a discourse annotation
study of Italian data, which uses the annotation
scheme and discourse-analytic method, the QUDtree framework",New Algorithm/ Method,New Algorithm/ Method
"Does controlling for the homogeneity of the
group of annotators with respect to their
age, education level and native language contribute to higher agreement",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel method for CMC based
on fine-tuning BERT by regarding the sequences of the questions and the answers as
independent inputs.",New Algorithm/ Method,New Algorithm/ Method
we contribute to the under-explored area of generating natural language explanations for general phenomena,Theory Proposal,Theory Proposal
"We introduce the use of multiple attention
mechanisms that selectively focus character and
word sequences in the sentence context.",New Algorithm/ Method,New Algorithm/ Method
We propose the input tier-based input strictly local (I-TISL) functions as a functional analogue of the generalized tierprojection mechanism of the IO-TSL languages,New Algorithm/ Method,New Algorithm/ Method
we adapt a graph-based approach to characterize the clusters (fuzzy types) of tone contour shapes observed in each tone n-gram category.,New Algorithm/ Method,New Algorithm/ Method
we will apply a hybrid approach for finding the correct splits of words and augmenting a morphological database,New Algorithm/ Method,New Algorithm/ Method
We propose an unsupervised approach for morphological segmentation of polysynthetic languages based on Adaptor Grammars,New Algorithm/ Method,New Algorithm/ Method
"We show that TSSL functions naturally describe rhythmic syncope while TIOSL functions cannot, and we argue that TSSL functions provide a more restricted characterization of rhythmic syncope than existing treatments within Optimality Theory.",Theory Proposal,Theory Proposal
"we have created a semantic graph that, together with named entity recognition and resolution (NER), should make it easier to establish connections between arguments in a given debate",New Algorithm/ Method,New Algorithm/ Method
We propose an attention mechanism to leverage lexicon information.,New Algorithm/ Method,New Algorithm/ Method
"We introduce a la carte embedding, a simple and general alternative to the usual word2vec-based approaches for building such representations that is based upon recent theoretical results for GloVe-like embeddings.",Model Proposal,Model Proposal
"We introduce a the DM NLP team’s system for NLPTEA 2018 shared task of Chinese Grammatical Error Diagnosis (CGED), which can be used to detect and correct grammatical errors in texts written by Chinese as a Foreign Language (CFL) learners.",New Algorithm/ Method,New Algorithm/ Method
"We describe an overview of the Dialogue Emotion Recognition Challenge, EmotionX, at the Sixth SocialNLP Workshop, which recognizes the emotion of each utterance in dialogues. This challenge offers the EmotionLines dataset as the experimental materials.",Theory Proposal,Theory Proposal
we propose a method to combine the breadth of generic embeddings with the specificity of domain specific embeddings,New Algorithm/ Method,New Algorithm/ Method
we propose a simple hyperparameter selection technique for active learning applied to semantic parsing,New Algorithm/ Method,New Algorithm/ Method
"we investigate whether SNACS
(Schneider et al., 2018b), an approach to semantic
disambiguation of adpositions and possessives, can
be adapted to cover syntactically core grammatical
relations (subjects and objects).",Theory Proposal,Theory Proposal
"we examine how narrative coherence is attained in the submissions
of NaNoGenMo 2018, an online text generation event where participants are challenged to
generate a 50,000 word novel.",Theory Proposal,Theory Proposal
"This study explores the relation between lexical concreteness and narrative text quality. We
present a methodology to quantitatively measure lexical concreteness of a text.",Theory Proposal,Theory Proposal
"we deploy a logistic regression
classifier to ascertain whether a given document belongs to the fiction or non-fiction
genre",Theory Proposal,Theory Proposal
"we will focus on the analysis of speech utterances in theatre scripts. Dialogues in theatre plays
are quite easy to collect (i.e. the characters are explicitly stated in the scripts) without the need of
lengthy and costly manual annotation.",Theory Proposal,Theory Proposal
"We evaluate our algorithm on
tweets collected around 2 episodes of a popular TV show, Game of Thrones, Season 7",Performance Evaluation,Performance Evaluation
"we
delineate and clarify the main challenges
and frontiers in the field, critically evaluate
their implications and discuss solutions",Theory Proposal,Theory Proposal
"We compare the effectiveness of end-to-end
character based models, with word + character embedding models, byte pair encoding and
subword models, to show which of the techniques perform better than pure word based
models.",Model Optimization,Model Optimization
"We also examine how preprocessing documents with byte pair encoding model pretrained on a large corpus, boost the performance of several word embedding based models massively.",Model Optimization,Model Optimization
"an investigation on the role
of populist themes and rhetoric in an Italian
Twitter corpus of hate speech against immigrants.",Theory Proposal,Theory Proposal
"contribution
of transfer learning technique to pronoun resolution systems is investigated and the gender
bias contained in classification models is evaluated.",Performance Evaluation,Performance Evaluation
Our work improves the snippetcontext baseline F1 score on Gendered Ambiguous Pronouns dataset from 66.9% to 80.3%.,Algorithm/Method Optimization,Algorithm/Method Optimization
"the development of a system-independent gender-awareness wrapper, and the building of a corpus for training and evaluating first-person-singular gender identification and reinflection in Arabic",New Algorithm/ Method,New Algorithm/ Method
A measure to evaluate and compare the performance of translation systems regarding the preservation of gender neutrality of pronouns,Performance Evaluation,Performance Evaluation
"we investigate RNN learning from the formal language
perspective using the WFA models, and we show
that adding more layers may not be sufficient if the
model has to deal with long-term dependencies.",Model Optimization,Model Optimization
"presents the annotation and evaluation of the Litkey Corpus, a longitudinal corpus of written texts in German from children in primary school between grades 2 to 4",Dataset Creation,Dataset Creation
"we explore corpus data of five Oceanic languages of Melanesia which are known to be mood-prominent (in the sense of Bhat, 1999). In order to find out more about tense, aspect, modality, and polarity, we tagged these categories in a subset of our corpora",Dataset Creation,Dataset Creation
we discover which linguistic phenomena are hard for humans to annotate and show that these do not always coincide with what is assumed to be difficult for automatic systems.,Theory Proposal,Theory Proposal
"we discuss whether the different distribution of discourse relations in each
setting reflects different strategies used to pursue a
communicative purpose (§6), and how these might
relate to audience design",Theory Proposal,Theory Proposal
"We found that the gold answer history contributed to the model performance most by
analyzing the effects of dialogue history",Model Optimization,Model Optimization
"We present the analysis of the application of
deep neural work for contextual resolution in dialogue, including both step-by-step and end-to-end
approaches",Applications,Applications
We provide a detailed analysis of the proposed models both on an internal benchmark and public dataset,Model Proposal,Model Proposal
"we propose and test the idea of performing cognate projection
to leverage high-resource training data for lowresource inflection generation.",New Algorithm/ Method,New Algorithm/ Method
We evaluate the effect of a variety of types of external embeddings for lemmatization and morphological tagging.,Performance Evaluation,Performance Evaluation
We evaluate the effect of combining annotated datasets from related languages for both tasks,Performance Evaluation,Performance Evaluation
"We analyze the dependencies among different morphological features to inform model choices, and find that adding POS information to the encoder significantly improves prediction accuracy by reducing errors across features, particularly Gender errors.",Model Optimization,Model Optimization
"We evaluate our proposed approach on 107 treebanks and achieve +14.76 (accuracy) average improvement over the shared task baseline (McCarthy et al., 2019) for morphological analysis.",Performance Evaluation,Performance Evaluation
"we examine whether a “CRFinspired” neural model without the hand-crafted features, can be applied to the task of argumentative unit segmentation at the clause level, and whether its performance is comparable to approaches exploiting such features",Model Proposal,Model Proposal
. We analyze challenges facing our computational methods and suggest future directions.,Theory Proposal,Theory Proposal
we investigate similarities between discourse and argumentation structures by aligning subtrees in a corpus containing both annotations,Theory Proposal,Theory Proposal
"In the face of the scarcity of argument lexicon, we explore several different types of lexicons to verify whether outside resources are useful for AM tasks.",Performance Evaluation,Performance Evaluation
we present and evaluate new attention-based architectures for the task of argumentative text segmentation.,New Algorithm/ Method,New Algorithm/ Method
we review the effectiveness of recently proposed contextualized word embedding approaches in regard to AM,Performance Evaluation,Performance Evaluation
"we run various discourse parsers (RST, PDTB) on the corpus, compare their results to the gold annotations (for RST) and then assess the contribution of automatically-derived discourse features for argumentation parsing",Performance Evaluation,Performance Evaluation
presents a first attempt at using Walton’s argumentation schemes for annotating arguments in Swedish political text and assessing the feasibility of using this particular set of schemes with two linguistically trained annotators.,New Algorithm/ Method,New Algorithm/ Method
"we study the possibility of combining short-term representations, stored in neural activations (hidden state), with medium-term representations encoded in a set of dynamical weights of the language model",Theory Proposal,Theory Proposal
we evaluate our approach which compares the use of “black-box” features (without ASR decoder information) and “glass-box” features which use internal information from the decoder,Performance Evaluation,Performance Evaluation
"We investigate the robustness of a classifier trained with adversarial examples, by studying its resilience to attacks and its accuracy on clean test data",Performance Evaluation,Performance Evaluation
"The solution presented
here features a bidirectional Long Shortterm Memory Network (bi-LSTM) for the
generation of character-level embeddings.",Theory Proposal,Theory Proposal
"we explore various aspects of sentiment detection
and their correlation to toxicity, and use our
results to implement a toxicity detection tool.",Theory Proposal,Theory Proposal
"we explore deep multimodal
fusion of text and photo for the task of hate
speech classification on social networks, where
hate speech posts frequently appear with images.",Theory Proposal,Theory Proposal
"we employ several wellestablished automated text analysis tools and
build on common practices for handling highly
imbalanced datasets and reducing sensitivity
to overfitting.",Dataset Creation,Dataset Creation
"The final model submitted is a multisource neural NER system with multilingual
BERT embeddings, trained on the concatenation of training data in various Slavic languages (as well as English)",Model Proposal,Model Proposal
"we use a
mixed model which combines multilingualcontextual and language-specific embeddings.",Model Proposal,Model Proposal
"Shows how heterogeneity in content and size of the ”target list” of gendered or racially marked terms interferes with debiasing, and how conceptors on contextual embeddings can be used to address such target list heterogeneity.",Theory Proposal,Theory Proposal
"For gender reinflection, we use a character-level neural MT (NMT) model in a single step (identify and reinflect, jointly), and as the second part of a twostep (identify then reinflect) system",Model Proposal,Model Proposal
"a “connective bank” consisting of 800 entries
including traditional connectives as well as
variations of connectives and alternative lexicalizations;",Dataset Creation,Dataset Creation
"we present a corpus annotated with
these relations and the analysis of these results where corpus contains 520 sentence pairs, annotated with these relations",Dataset Creation,Dataset Creation
"making
up for the scarcity of NLP resources in Turkish by
annotating a new corpus that has not been introduced to the UD project before, namely the TNC",Dataset Creation,Dataset Creation
"we describe three platforms that
constitute our annotation ecosystem, as background for a demonstration of their ability to work
in concert to provide easily usable means to adapt
NLP processes to specific domains",New Algorithm/ Method,New Algorithm/ Method
"we present
a repository of conversational datasets consisting of hundreds of millions of examples,
and a standardised evaluation procedure for
conversational response selection models using 1-of-100 accuracy.",Dataset Creation,Dataset Creation
"our model utilizes fine-tuning
to compensate for the training data scarcity, which
is essential because there is a limited amount of
domain-dependent and sentiment-rich dialogues",Model Proposal,Model Proposal
"We have developed a system based on LSTM neural networks inspired
by the excellent results obtained by deep learning classifiers",New Algorithm/ Method,New Algorithm/ Method
We study approaches based on machine learning and deep learning to extract adverse drug reaction mentions from highly informal texts in Twitter.,Theory Proposal,Model Proposal
This paper describes the system developed by team ASU-NLP for the Social Media Mining for Health Applications(SMM4H) shared task,New Algorithm/ Method,Model Proposal
"This paper describes the system that team MYTOMORROWS-TU DELFT developed for the 2019 Social Media Mining for Health Applications (SMM4H) Shared Task 3, for the end-to-end normalization of ADR tweet mentions to their corresponding MEDDRA codes.",New Algorithm/ Method,New Algorithm/ Method
We make an initial attempt in studying the effectiveness of transfer learning using ULMFit and BERT for the problems in the domain of health care pertaining to the shared tasks.,Theory Proposal,New Algorithm/ Method
"We employed a combination of three types of word representations as input to a LSTM model for detecting reportage of adverse drug reaction in tweets as part of the 2019 social media
mining for healthcare applications shared task.",Performance Evaluation,Performance Evaluation
"AMR concepts show a higher level of abstraction from surface forms, meaning that
AMR concepts bear less resemblance to the
word tokens in the original sentence.",Theory Proposal,Theory Proposal
"we consider neural network solution for multilingual named entity
recognition for Bulgarian, Czech, Polish and Russian languages for the BSNLP 2019 Shared Task
(Piskorski et al., 2019)",Theory Proposal,New Algorithm/ Method
"Present an approach to find one of the subtypes of gender bias, Gender Generalization",New Algorithm/ Method,Model Proposal
Provide a high-level definition of gender bias in text,Theory Proposal,Theory Proposal
"The main idea of our augmentation is to replace each name in the name-pronoun pair by a set of common placeholder names, in order to (1) diversify the idiosyncratic information embedded in individual names and leave only the contextual information",Theory Proposal,New Algorithm/ Method
"The main contribution of this study is providing progress on the recent detected problem which
is gender bias in MT",Theory Proposal,New Algorithm/ Method
aims to address such issues of interpretability by relating sequential neural networks to forms of computation that are more well understood.,Theory Proposal,Theory Proposal
"We address the nontrivial problem of evaluating the extractions
produced by systems against the reference tuples, and share our evaluation script",Theory Proposal,Theory Proposal
"we discuss how we tackle the challenges raised by harmonizing different lemmatization criteria in the LiLa: Linking Latin project,
which aims to make resources for Latin interoperable.1",Theory Proposal,Theory Proposal
"we first look at the use of discourse
connectives along two dimensions of variation and
show that there are systematic differences regarding the frequency of different forms of discourse
connectives",Theory Proposal,Theory Proposal
"While there is relevant
ongoing research on Semantic Role Labelling
(SRL) and on building tools for code-mixed
social media data, this is the first attempt at labelling semantic roles in Hindi-English codemixed data, to the best of our knowledge.",Dataset Creation,Dataset Creation
"We alleviated these problems
by developing WAT-SL 2.0, an open-source
web-based annotation tool for long-segment
labeling, hierarchically structured label sets
and built-ins for quality control.",Theory Proposal,Theory Proposal
"aims to 
create an annotated corpus where the annotation
contains all the features needed to generate questions concerning the text.",Dataset Creation,Dataset Creation
"we describe our system for
morphological analysis and lemmatization
in context, using a transformer-based
sequence to sequence model and a biaffine
attention based BiLSTM model",New Algorithm/ Method,New Algorithm/ Method
We use sequence-to-sequence networks trained on sequential phonetic encoding tasks to construct compositional phonological representations of words,New Algorithm/ Method,New Algorithm/ Method
we propose a three-way feature grouping: (i) features which access only the EAU span; (ii) features which access only the context of an EAU; (iii) features which access both EAU span and its context.,New Algorithm/ Method,New Algorithm/ Method
"to deploy a novel methodology for classifying different argumentative support (supporting evidences) in arguments, without considering the context",New Algorithm/ Method,New Algorithm/ Method
) the identification of the schemes for which available tools are readily available for use;,Theory Proposal,Theory Proposal
"This paper uses a novel framework to restore the elided elements in the sentence,
which is named Abstract Meaning Representation (AMR)(Banarescu et al., 2013). AMR represents the whole sentence meaning with concepts,
which are mainly abstracted from its corresponding words occurring in the sentence.",New Algorithm/ Method,New Algorithm/ Method
"Building a dataset for abusive language and
hate speech detection including detecting the
target, category, and level of hate speech in
Indonesian Twitter. We provide this research
dataset for public4
so that it can be used by
other researchers who are interested in doing
future work of this paper.",Dataset Creation,Dataset Creation
"Investigate what type of attention mechanism in deep learning architectures (contextual attention vs. self-attention) is better for
abusive language detection. We show that
contextual attention models outperform selfattention models on most cases (datasets and
architectures), and present a thorough error
analysis showing how contextual attention
works better than self-attention particularly
when it comes to modeling implicit abusive
content.",Algorithm/Method Optimization,Algorithm/Method Optimization
"Investigate whether stacked architectures are
better than simple architectures for abusive
language detection when using Biderectional
Long Short Term Memory (Bi-LSTM) networks. We show that stacked architectures are better than simple architectures
on all datasets. In addition, we discuss
the importance of pre-trained word embeddings for deep learning models.",Algorithm/Method Optimization,Algorithm/Method Optimization
"introduction of a novel
fine-grained hate speech typology that improves
on the common state-of-the-art used typologies,
which tend to disregard the existence of subtypes
of hate speech and either consider hate speech
recognition as a binary classification task, or take
into account only a few classes, such as ‘racism’
95
and ‘sexism’ (Waseem and Hovy, 2016) – despite
the fact that such broad distinctions unduly overgeneralize.",Algorithm/Method Optimization,Algorithm/Method Optimization
"This paper investigates the extent of the new
lexicon problem for different types of Ukrainian
corpora and further proposes and evaluates a
knowledge-light approach to extending lexical
coverage of morphological resources to neologisms (new words, meanings or usages) and new
single-word Named Entities (proper names) which
follow regular inflectional patterns",New Algorithm/ Method,Performance Evaluation
we pay special attention to the gapping resolution methods that were introduced within the shared task as well as an alternative test set that illustrates that our corpus is a diverse and representative subset of Russian language gapping sufficient for effective utilization of machine learning techniques.,New Algorithm/ Method,Algorithm/Method Optimization
"We provide an experimental evaluation of
models and methods for predicting compositionality of noun compounds. We show that
the methods from the previous work trained
on the proposed Russian-language resource
achieve the performance comparable with results on English corpora.",Performance Evaluation,Performance Evaluation
"describes the Second Shared Task on
multilingual NE recognition (NER), which aims
at addressing these problems in a systematic way.
The shared task was organized in the context of
the 7th Balto-Slavic Natural Language Processing
Workshop co-located with the ACL 2019 conference",Theory Proposal,Theory Proposal
"We propose a black-box approach for injecting the missing information to a pre-trained neural machine translation system, allowing to control the morphological variations in the generated translations without changing the underlying model or training data.",New Algorithm/ Method,New Algorithm/ Method
"we present an open-source, lightweight, easy-to-use graphical annotation tool that employs a statistical parser to create initial CCG derivations for sentences, and allows annotators to correct these annotations via lexical category constraints and span constraints",Resources,Resources
"we propose a corpus
generation strategy that only requires a machine translation system between English and
the target language in both directions, where
we filter the best translations by computing automatic translation metrics and the task performance score",New Algorithm/ Method,New Algorithm/ Method
"we present a new annotation
scheme for the Sejong part-of-speech tagged
corpus based on Universal Dependencies
style annotation. By using a new annotation
scheme, we can produce Sejong-style morphological analysis and part-of-speech tagging results which have been the de facto standard for
Korean language processing",Model Optimization,Model Optimization
"We formulate the problem
definition of context reconstruction in dialogue
into one detection problem and one ranking problem and present the difference between it and
traditional tasks such as pronoun and zero pronoun detection and mention candidate selection;",Theory Proposal,Theory Proposal
We improve upon the slot carryover model architecture in Naik et al. (2018) by introducing approaches for modeling slot interdependencies. We propose two neural network models based on pointer networks and transformer networks that can make joint predictions over slots.,Model Optimization,Model Optimization
"we computationally simulate two directions of verbal inflection in Japanese, Present 7→ Past and Past 7→ Present, with the rule-based computational model called Minimal Generalization Learner (MGL; Albright and Hayes, 2003) and experimentally evaluate the model with the bidirectional “wug” test where humans inflect novel verbs in two opposite directions.",Performance Evaluation,Performance Evaluation
"we propose Probabilistic FastText (PFT), which provides probabilistic characterlevel representations of words. The resulting word embeddings are highly expressive, yet straightforward and interpretable, with simple, efficient, and intuitive training procedures.",New Algorithm/ Method,New Algorithm/ Method
we transform external lexico-semantic relations into training examples which we use to learn an explicit retrofitting model (ER). The ER model allows us to learn a global specialization function and specialize the vectors of words unobserved in the training data as well.,New Algorithm/ Method,New Algorithm/ Method
"we introduce an extension by utilizing two independent encoders but sharing some partial weights which are responsible for extracting high-level representations of the input sentences.Besides, two different generative adversarial
networks (GANs), namely the local GAN
and global GAN, are proposed to enhance
the cross-language translation. With this
new approach, we achieve significant improvements on English-German, EnglishFrench and Chinese-to-English translation
tasks.",Model Optimization,Model Optimization
"We propose a novel triangular training architecture (TA-NMT) to effectively tackle the
data sparsity problem for rare languages in
NMT with an EM framework.Our method can exploit two additional bilingual datasets at both the model and data levels by introducing another rich language.Our method is a unified bidirectional EM algorithm, in which four translation models on
two low-resource pairs are trained jointly and
boost each other.",New Algorithm/ Method,New Algorithm/ Method
"We propose a unified model combining sentence-level and word-level attentions to
take advantage of both extractive and abstractive summarization approaches. We propose a novel inconsistency loss function to ensure our unified model to be mutually beneficial to both extractive and abstractive summarization. The unified model with
inconsistency loss achieves the best ROUGE
scores on CNN/Daily Mail dataset and outperforms recent state-of-the-art methods in
informativity and readability on human evaluation.",Model Proposal,Model Proposal
"We propose to introduce soft templates as additional input to improve the readability and stability of seq2seq summarization systems. Code and results can be found at http://www4.comp.polyu. edu.hk/˜cszqcao/. We extend the seq2seq framework to conduct template reranking and template-aware summary generation simultaneously. We fuse the popular IR-based and seq2seqbased summarization systems, which fully utilize the supervisions from both sides.",New Algorithm/ Method,New Algorithm/ Method
"We first to combine structural semantics and neural methods for TS, we propose an intermediate way for performing sentence splitting, presenting Direct Semantic Splitting (DSS), a simple and efficient algorithm based on a semantic parser which supports the direct decomposition of the sentence into its main semantic constituents.",Algorithm/Method Optimization,Algorithm/Method Optimization
We propose a method of combining Conditional Random Fields (CRFs) model with a post-processing layer using Google n-grams statistical information tailored to detect word selection and word order errors made by learners of Chinese as Foreign Language (CFL).,Model Optimization,Model Optimization
we report a short answer grading system in Chinese. We build a system based on standard machine learning approaches and test it with translated corpus from two publicly available corpus in English. The experiment results show similar results on two different corpus as in English.,New Algorithm/ Method,New Algorithm/ Method
"we present a qualitatively enhanced deep convolution recurrent neural network for computing the quality of a text in an automatic essay scoring task. The novelty of the work lies in the fact that instead of considering only the word and sentence representation of a text, we try to augment the different complex linguistic, cognitive and psychological features associated within a text document along with a hierarchical convolution recurrent neural network framework.",New Algorithm/ Method,New Algorithm/ Method
"we propose a new semi-supervised learning method with a feedback loop to leverage vast amounts of unlabeled data and feedback signals. In particular, we train two machine learning models iteratively. The main model, which is represented as M ain, performs the main task at runtime.",New Algorithm/ Method,New Algorithm/ Method
"We outline future directions in summarization to address all of these issues. By resolving the existing problems, we will make it easier for users of review-sites to make more informed decisions.",Model Optimization,Model Optimization
"We hypothesize that by training on higher information and more difficult training sentences, RNN language models can learn the language distribution more accurately and produce lower perplexities than models trained on similar-sized randomly sampled training sets",Theory Proposal,Theory Proposal
"We propose a learning-based framework to incorporate the scores of a set of lexical and semantic metrics as features, to capture the adequacy and fluency of captions at different linguistic levels. Our experimental results demonstrate that composite metrics draw upon the strengths of standalone measures to yield improved correlation and accuracy",Model Proposal,Model Proposal
"we propose a preordering method with a recursive neural network (RvNN). RvNN calculates reordering in a bottom-up manner (from the leaf nodes to the root) on a source syntax tree. Thus, preordering is performed considering the entire sub-trees.",New Algorithm/ Method,New Algorithm/ Method
"we aim to automatically generate description of medical images, to develop medical visual question answering system and to develop medical dialog agents that interact with patients to answer their queries based on their medical data.",Dataset Creation,Dataset Creation
"We review the existing methods which are revised to tackle complex entity mentions and categorize them as tokenlevel and sentence-level approaches. We then identify the research gap, and discuss some directions that we are exploring",Algorithm/Method Optimization,Algorithm/Method Optimization
"we attempt to contribute to LBD discipline outside of medical domain by automating crossdisciplinary knowledge discovery process. As a proof of concept, the proposed solution will be applied to different CS-related concepts.",Dataset Creation,Dataset Creation
"We compare our method with existing off-theshelf NER tools for social media content, and find that our systems outperforms the best baseline by 33.18 % (F1 score).",Algorithm/Method Optimization,Algorithm/Method Optimization
"We present ongoing work on data-driven parsing of German and French with Lexicalized Tree Adjoining Grammars. We use a supertagging approach combined with deep learning. We show the challenges of extracting LTAG supertags from the French Treebank, introduce the use of leftand right-sister-adjunction, present a neural architecture for the supertagger, and report experiments of n-best supertagging for French and German.",Model Proposal,Model Proposal
"we incorporate semantic supersensetags and syntactic supertag features into EN–FR and EN–DE factored NMT systems. In experiments on various test sets, we observe that such features (and particularly when combined) help the NMT model training to converge faster and improve the model quality according to the BLEU scores.",Performance Evaluation,Performance Evaluation
"we develop a novel pipeline for Semantic Abstractive Summarization (SAS). SAS, as introduced by Liu et al. (2015) first generates an AMR graph of an input story, through which it extracts a summary graph and finally, creates summary sentences from this summary graph. Compared to earlier approaches, we develop a more comprehensive method to generate the story AMR graph using state-ofthe-art co-reference resolution and Meta Nodes. Which we then use in a novel unsupervised algorithm based on how humans summarize a piece of text to extract the summary sub-graph. Our algorithm outperforms the state of the art SAS method by 1.7% F1 score in node prediction.",Resources,Resources
"we are focusing on biomedical document retrieval from literature for clinical decision support systems. We compare statistical and NLP based approaches of query reformulation for biomedical document retrieval. Also, we have modeled the biomedical document retrieval as a learning to rank problem. We report initial results for statistical and NLP based query reformulation approaches and learning to rank approach with future direction of research.",Model Optimization,Model Optimization
"we do not present direct quotes from any data, nor any identifying information. Anonymised data was collected from microblogging website Twitter - specifically, content containing self-classified suicidal ideation (i.e. text posts tagged with the word ’suicide) over the period of December 3, 2017 to January 31, 2018. The Twitter REST API2 was used for collection of tweets containing any of the following English words or phrases that are consistent with the vernacular of suicidal ideation (O’Dea et al., 2015",Dataset Creation,Dataset Creation
"we extracted 11,000 adjectives, 253 adverbs, 8483 verbs and sentiment annotation is being done by language experts. We discuss the methodology followed for the polarity annotations and validate the developed resource. This work aims at developing a benchmark corpus, as an extension to SentiWordNet, and baseline accuracy for a model where lexeme annotations are applied for sentiment predictions. The fundamental aim of this paper is to validate and study the possibility of utilizing machine learning algorithms, word-level sentiment annotations in the task of automated sentiment identification. Furthermore, accuracy is improved by annotating the bi-grams extracted from the target corpus.",New Algorithm/ Method,New Algorithm/ Method
"We investigate a new training paradigm for extractive summarization. Traditionally, human abstracts are used to derive goldstandard labels for extraction units. However, the labels are often inaccurate, because human abstracts and source documents cannot be easily aligned at the word level",Theory Proposal,Theory Proposal
"we capture using the HITS algorithm. We apply our proposed method to two tasks: machine translation and grammatical error correction. For Japanese-to-English translation, this method achieves a BLEU score that is 0.56 points more than that of a baseline. Furthermore, it outperforms the baseline method for English grammatical error correction, with an F0.5-measure that is 1.48 points higher",New Algorithm/ Method,New Algorithm/ Method
"we address the task of the generation of grammatical sentences in an isolated context given a partial bag-of-words which the generated sentence must contain. We view the task as a search problem (a problem of choice) involving combinations of smaller chunk based templates extracted from a training corpus to construct a complete sentence. To achieve that, we propose a fitness function which we use in conjunction with an evolutionary algorithm as the search procedure to arrive at a potentially grammatical sentence (modeled by the fitness score) which satisfies the input constraints.",Performance Evaluation,Performance Evaluation
"we develop an adversarial writing setting, where humans interact with trained models and try to break them. This annotation process yields a challenge set, which despite being easy for trivia players to answer, systematically stumps automated question answering systems. Diagnosing model errors on the evaluation data provides actionable insights to explore in developing robust and generalizable question answering systems",Resources,Resources
"we could predict a possible cognate from the given input. Our study shows that when language modelling smoothing methods are applied as the retrieval functions and used in conjunction with positional segmentation and error modelling gives better results than competing baselines, in both classification and prediction of cognates",Applications,Applications
we can demystify affect generation by reviewing psychological models which build on neuro-biological findings in regards to human emotion,Model Optimization,Model Optimization
"we show how to build an automatic spelling corrector for resourcescarce languages. We propose a sequenceto-sequence deep learning model which trains end-to-end. We perform experiments on synthetic datasets created for Indic languages, Hindi and Telugu, by incorporating the spelling mistakes committed at character level. A comparative evaluation shows that our model is competitive with the existing spell checking and correction techniques for Indic languages.",Model Proposal,Model Proposal
We reformulate the problem of encoding a multi-scale representation of a sequence in a language model by casting it in a continuous learning framework. We propose a hierarchical multi-scale language model in which short time-scale dependencies are encoded in the hidden state of a lower-level recurrent neural network while longer time-scale dependencies are encoded in the dynamic of the lower-level network by having a meta-learner update the weights of the lower-level neural network in an online meta-learning fashion. We use elastic weights consolidation as a higher-level to prevent catastrophic forgetting in our continuous learning framework,Model Optimization,Model Optimization
"we introduce restricted recurrent neural tensor networks (r-RNTN) which reserve distinct hidden layer weights for frequent vocabulary words while sharing a single set of weights for infrequent words. Perplexity evaluations show that for fixed hidden layer sizes, r-RNTNs improve language model performance over RNNs using only a small fraction of the parameters of unrestricted RNTNs. These results hold for r-RNTNs using Gated Recurrent Units and Long Short-Term Memory.",New Algorithm/ Method,New Algorithm/ Method
"We present a set of experiments to demonstrate that deep recurrent neural networks (RNNs) learn internal representations that capture soft hierarchical notions of syntax from highly varied supervision. We consider four syntax tasks at different depths of the parse tree; for each word, we predict its part of speech as well as the first (parent), second (grandparent) and third level (great-grandparent) constituent labels that appear above it. These predictions are made from representations produced at different depths in networks that are pretrained with one of four objectives: dependency parsing, semantic role labeling, machine translation, or language modeling. In every case, we find a correspondence between network depth and syntactic depth, suggesting that a soft syntactic hierarchy emerges. This effect is robust across all conditions, indicating that the models encode significant amounts of syntax even in the absence of an explicit syntactic training supervision",Model Proposal,Model Proposal
"we propose a novel approach to estimate WER, or e-WER, which does not require a gold-standard transcription of the test set. Our e-WER framework uses a comprehensive set of features: ASR recognised text, character recognition results to complement recognition output, and internal decoder features. We report results for the two features; black-box and glass-box using unseen 24 Arabic broadcast programs. Our system achieves 16.9% WER root mean squared error (RMSE) across 1,400 sentences. The estimated overall WER eWER was 25.3% for the three hours test set, while the actual WER was 28.5%",Theory Proposal,Theory Proposal
"we propose an approach to explicitly obscure important author characteristics at training time, such that representations learned are invariant to these attributes. Evaluating on two tasks, we show that this leads to increased privacy in the learned representations, as well as more robust models to varying evaluation conditions, including out-of-domain corpor",Theory Proposal,Theory Proposal
"We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier. We find that only a few manipulations are needed to greatly decrease the accuracy. Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the onehot input vectors. Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time. With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier.",Algorithm/Method Optimization,Algorithm/Method Optimization
We apply active learning to both traditional and “overnight” data collection approaches. We show that it is possible to obtain good training hyperparameters from seed data which is only a small fraction of the full dataset. We show that uncertainty sampling based on least confidence score is competitive in traditional data collection but not applicable for overnight collection. We evaluate several active learning strategies for overnight data collection and show that different example selected.,Dataset Creation,Dataset Creation
"we suggest to leverage the partition of articles into sections, in order to learn thematic similarity metric between sentences. We assume that a sentence is thematically closer to sentences within its section than to sentences from other sections. Based on this assumption, we use Wikipedia articles to automatically create a large dataset of weakly labeled sentence triplets, composed of a pivot sentence, one sentence from the same section and one from another section. We train a triplet network to embed sentences from the same section closer. To test the performance of the learned embeddings, we create and release a sentence clustering benchmark. We show that the triplet network learns useful thematic metrics, that significantly outperform state-of-theart semantic similarity methods and multipurpose embeddings on the task of thematic clustering of sentences. We also show that the learned embeddings perform well on the task of sentence semantic similarity prediction",Theory Proposal,Theory Proposal
"We use dependency triples automatically extracted from a Web-scale corpus to perform unsupervised semantic frame induction. We cast the frame induction problem as a triclustering problem that is a generalization of clustering for triadic data. Our replicable benchmarks demonstrate that the proposed graph-based approach, Triframes, shows state-of-the art results on this task on a FrameNet-derived dataset and performing on par with competitive methods on a verb class clustering task",Resources,Resources
We present a new architecture for named entity recognition. Our model employs multiple independent bidirectional LSTM units across the same input and promotes diversity among them by employing an inter-model regularization term. By distributing computation across multiple smaller LSTMs we find a reduction in the total number of parameters. We find our architecture achieves state-of-the-art performance on the CoNLL 2003 NER dataset.,Model Proposal,Model Proposal
"We observe that when they fail, they often make entity predictions that are incompatible with the type required by the relation. In response, we enhance each base factorization with two type-compatibility terms between entityrelation pairs, and combine the signals in a novel manner. Without explicit supervision from a type catalog, our proposed modification obtains up to 7% MRR gains over base models, and new state-of-the-art results on several datasets. Further analysis reveals that our models better represent the latent types of entities and their embeddings also predict supervised types better than the embeddings learned by baseline models",Performance Evaluation,Performance Evaluation
"We present a novel graph-based neural network model for relation extraction. Our model treats multiple pairs in a sentence simultaneously and considers interactions among them. All the entities in a sentence are placed as nodes in a fully-connected graph structure. The edges are represented with position-aware contexts around the entity pairs. In order to consider different relation paths between two entities, we construct up to l-length walks between each pair. The resulting walks are merged and iteratively used to update the edge representations into longer walks representations. We show that the model achieves performance comparable to the state-ofthe-art systems on the ACE 2005 dataset without using any external tools.",Model Proposal,Model Proposal
"We first point out that these tasks are related. Then, inspired by ranking relation instances and patterns computed by the HITS algorithm, and selecting cluster centroids using the K-means, LSA, or NMF method, we propose methods for selecting the initial seeds from an existing resource, or reducing the level of noise in the distantly labeled data. Experiments show that our proposed methods achieve a better performance than the baseline systems in both tasks",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose to improve the end-toend coreference resolution system by (1) using a biaffine attention model to get antecedent scores for each possible mention, and (2) jointly optimizing the mention detection accuracy and the mention clustering log-likelihood given the mention cluster labels. Our model achieves the stateof-the-art performance on the CoNLL2012 Shared Task English test set.",Dataset Creation,Dataset Creation
"We show that this update mechanism can be learned jointly with the semantic decoding and context modelling parts of the NBT model, eliminating the last rule-based module from this DST framework. We propose two different statistical update mechanisms and show that dialogue dynamics can be modelled with a very small number of additional model parameters. In our DST evaluation over three languages, we show that this model achieves competitive performance and provides a robust framework for building resource-light DST models.",Model Optimization,Model Optimization
"We study the role of linguistic context in predicting quantifiers (‘few’, ‘all’). We collect crowdsourced data from human participants and test various models in a local (single-sentence) and a global context (multi-sentence) condition. Models significantly out-perform humans in the former setting and are only slightly better in the latter. While human performance improves with more linguistic context (especially on proportional quantifiers), model performance suffers. Models are very effective in exploiting lexical and morpho-syntactic patterns; humans are better at genuinely understand",Model Optimization,Model Optimization
"We ask how to practically build a model for German named entity recognition (NER) that performs at the state of the art for both contemporary and historical texts, i.e., a big-data and a small-data scenario. The two best-performing model families are pitted against each other (linear-chain CRFs and BiLSTM) to observe the trade-off between expressiveness and data requirements. BiLSTM outperforms the CRF when large datasets are available and performs inferior for the smallest dataset.",Model Optimization,Model Optimization
"we analyze a novel dataset of more than one million code reviews for the Google Chromium project, from which we extract linguistic features of feedback that elicited responsive actions from coworkers. Using a manually-labeled subset of reviewer comments, we trained a highly accurate classifier to identify “acted-upon” comments (AUC = 0.85). Our results demonstrate the utility of our dataset, the feasibility of using NLP for this new task, and the potential of NLP to improve our understanding of how communications between colleagues can be authored to elicit positive, proactive responses",Dataset Creation,Dataset Creation
we describe a new multimodal dataset that consists of gaze measurements and spoken descriptions collected in parallel during an image inspection task. The task was performed by multiple participants on 100 general-domain images showing everyday objects and activities. We demonstrate the usefulness of the dataset by applying an existing visual-linguistic data fusion framework in order to label important image regions with appropriate linguistic labels,Dataset Creation,Dataset Creation
"we sketch 68 implicit morphological relations and 28 explicit semantic relations. A big and balanced dataset CA8 is then built for this task, including 17813 questions. Furthermore, we systematically explore the influences of vector representations, context features, and corpora on analogical reasoning. With the experiments, CA8 is proved to be a reliable benchmark for evaluating Chinese word embeddings.",Dataset Creation,Dataset Creation
"We therefore construct a significant new corpus on metaphor, with 5,605 manually annotated sentences in Chinese. We present an annotation scheme that contains annotations of linguistic metaphors, emotional categories (joy, anger, sadness, fear, love, disgust and surprise), and intensity. The annotation agreement analyses for multiple annotators are described. We also use the corpus to explore and analyze the emotionality of metaphors. To the best of our knowledge, this is the first relatively large metaphor corpus with an annotation of emotions in Chinese",Performance Evaluation,Performance Evaluation
we further develop automatic metrics that generalize a broad set of popular reference-based metrics and exhibit greatly improved correlations with human evaluations,Resources,Resources
"we propose a global encoding framework, which controls the information flow from the encoder to the decoder based on the global information of the source context. It consists of a convolutional gated unit to perform global encoding to improve the representations of the source-side information. Evaluations on the LCSTS and the English Gigaword both demonstrate that our model outperforms the baseline models, and the analysis shows that our model is capable of generating summary of higher quality and reducing repetition",Model Proposal,Model Proposal
"We herein present a language-modelbased evaluator for deletion-based sentence compression, and viewed this task as a series of deletion-and-evaluation operations using the evaluator. More specifically, the evaluator is a syntactic neural language model that is first built by learning the syntactic and structural collocation among words. Subsequently, a series of trial-and-error deletion operations are conducted on the source sentences via a reinforcement learning framework to obtain the best target compression. An empirical study shows that the proposed model can effectively generate more readable compression, comparable or superior to several strong baselines. Furthermore, we introduce a 200-sentence test set for a largescale dataset, setting a new baseline for the future research",Performance Evaluation,Performance Evaluation
"we seek to better understand how users react to trusted and deceptive news sources across two popular, and very different, social media platforms. To that end, (1) we develop a model to classify user reactions into one of nine types, such as answer, elaboration, and question, etc, and (2) we measure the speed and the type of reaction for trusted and deceptive news sources for 10.8M Twitter posts and 6.2M Reddit comments. We show that there are significant differences in the speed and the type of reactions between trusted and deceptive news sources on Twitter, but far smaller differences on Reddit",Model Proposal,Model Proposal
we model this task using CNN regression with an auxiliary ordinal regression objective. We demonstrate the effectiveness of our proposed approach using UK and US government petition datasets.1,Model Proposal,Model Proposal
"We introduce a new approach to tackle the problem of offensive language in online social media. Our approach uses unsupervised text style transfer to translate offensive sentences into non-offensive ones. We propose a new method for training encoderdecoders using non-parallel data that combines a collaborative classifier, attention and the cycle consistency loss. Experimental results on data from Twitter and Reddit show that our method outperforms a state-of-the-art text style transfer system in two out of three quantitative metrics and produces reliable non-offensive transferred sentences",New Algorithm/ Method,New Algorithm/ Method
"we address a research gap by exploring finer temporal granularity and using a more accessible language corpus. Twitter’s1 discourse is rather different from traditional English writing. So far, word embeddings trained on Twitter (Kulkarni et al., 2015; Mikolov et al., 2013) have considered it a static corpus, and have not used it to study short term changes in word connotations. It contributes with the following observations",Performance Evaluation,Performance Evaluation
"we make a move to build a dialogue system for automatic diagnosis. We first build a dataset collected from an online medical forum by extracting symptoms from both patients’ self-reports and conversational data between patients and doctors. Then we propose a taskoriented dialogue system framework to make the diagnosis for patients automatically, which can converse with patients to collect additional symptoms beyond their self-reports. Experimental results on our dataset show that additional symptoms extracted from conversation can greatly improve the accuracy for disease identification and our dialogue system is able to collect these symptoms automatically and make a better diagnosis",Theory Proposal,Theory Proposal
"we study transfer learning for multi-turn information seeking conversations in this paper. We first propose an efficient and effective multiturn conversation model based on convolutional neural networks. After that, we extend our model to adapt the knowledge learned from a resource-rich domain to enhance the performance. Finally, we deployed our model in an industrial chatbot called AliMe Assist 1 and observed a significant improvement over the existing online model.",Dataset Creation,Dataset Creation
"We present a novel multi-task modeling approach to learning multilingual distributed representations of text. Our system learns word and sentence embeddings jointly by training a multilingual skipgram model together with a cross-lingual sentence similarity model. Our architecture can transparently use both monolingual and sentence aligned bilingual corpora to learn multilingual embeddings, thus covering a vocabulary significantly larger than the vocabulary of the bilingual corpora alone. Our model shows competitive performance in a standard crosslingual document classification task. We also show the effectiveness of our method in a limited resource scenario",Model Proposal,Model Proposal
"We investigate the behavior of maps learned by machine translation methods. The maps translate words by projecting between word embedding spaces of different languages. We locally approximate these maps using linear maps, and find that they vary across the word embedding space. This demonstrates that the underlying maps are non-linear. Importantly, we show that the locally linear maps vary by an amount that is tightly correlated with the distance between the neighborhoods on which they are trained. Our results can be used to test non-linear methods, and to drive the design of more accurate maps for word translation",Theory Proposal,Theory Proposal
"We learn a joint multilingual sentence embedding and use the distance between sentences in different languages to filter noisy parallel data and to mine for parallel data in large news collections. We are able to improve a competitive baseline on the WMT’14 English to German task by 0.3 BLEU by filtering out 25% of the training data. The same approach is used to mine additional bitexts for the WMT’14 system and to obtain competitive results on the BUCC shared task to identify parallel sentences in comparable corpora. The approach is generic, it can be applied to many language pairs and it is independent of the architecture of the machine translation system",Resources,Resources
"we improve the existing SCRF methods by employing word-level and segment-level information simultaneously. First, word-level labels are utilized to derive the segment scores in SCRFs. Second, a CRF output layer and an SCRF output layer are integrated into an unified neural network and trained jointly. Experimental results on CoNLL 2003 named entity recognition (NER) shared task show that our model achieves state-of-the-art performance when no external knowledge is used",Algorithm/Method Optimization,Algorithm/Method Optimization
"we discuss the importance of external knowledge for performing Named Entity Recognition (NER). We present a novel modular framework that divides the knowledge into four categories according to the depth of knowledge they convey. Each category consists of a set of features automatically generated from different information sources, such as a knowledgebase, a list of names, or document-specific semantic annotations. Further, we show the effects on performance when incrementally adding deeper knowledge and discuss effectiveness/efficiency trade-of",Model Proposal,Model Proposal
"We consider the task of detecting contractual obligations and prohibitions. We show that a self-attention mechanism improves the performance of a BILSTM classifier, the previous state of the art for this task, by allowing it to focus on indicative tokens. We also introduce a hierarchical BILSTM, which converts each sentence to an embedding, and processes the sentence embeddings to classify each sentence. Apart from being faster to train, the hierarchical BILSTM outperforms the flat one, even when the latter considers surrounding sentences, because the hierarchical model has a broader discourse view.",Performance Evaluation,Performance Evaluation
"We present a paper abstract writing system based on an attentive neural sequenceto-sequence model that can take a title as input and automatically generate an abstract. We design a novel Writing-editing Network that can attend to both the title and the previously generated abstract drafts and then iteratively revise and polish the abstract. With two series of Turing tests, where the human judges are asked to distinguish the system-generated abstracts from human-written ones, our system passes Turing tests by junior domain experts at a rate up to 30% and by nonexpert at a rate up to 80%.",Model Proposal,Model Proposal
"We explore recently introduced definition modeling technique that provided the tool for evaluation of different distributed vector representations of words through modeling dictionary definitions of words. In this work, we study the problem of word ambiguities in definition modeling and propose a possible solution by employing latent variable modeling and soft attention mechanisms. Our quantitative and qualitative evaluation and analysis of the model shows that taking into account words ambiguity and polysemy leads to performance improveme",Model Optimization,Model Optimization
"we propose a Convolutional Neural Network (CNN) model for textbased multiple choice question answering where questions are based on a particular article. Given an article and a multiple choice question, our model assigns a score to each question-option tuple and chooses the final option accordingly. We test our model on Textbook Question Answering (TQA) and SciQ dataset. Our model outperforms several LSTM-based baseline models on the two datasets.",Dataset Creation,Dataset Creation
"we propose a novel method, tracking various semantic aspects with external neural memory chains while encouraging each to focus on a particular semantic aspect. Evaluated on the task of story ending prediction, our model demonstrates superior performance to a collection of competitive baselines, setting a new state of the art. 1",New Algorithm/ Method,New Algorithm/ Method
"we propose to inject structural representations in NNs by (i) learning an SVM model using Tree Kernels (TKs) on relatively few pairs of questions (few thousands) as gold standard (GS) training data is typically scarce, (ii) predicting labels on a very large corpus of question pairs, and (iii) pre-training NNs on such large corpus. The results on Quora and SemEval question similarity datasets show that NNs trained with our approach can learn more accurate models, especially after fine tuning on GS",Algorithm/Method Optimization,Algorithm/Method Optimization
"We offer a simple and effective method to seek a better balance between model confidence and length preference for Neural Machine Translation (NMT). Unlike the popular length normalization and coverage models, our model does not require training nor reranking the limited n-best outputs. Moreover, it is robust to large beam sizes, which is not well studied in previous work. On the Chinese-English and English-German translation tasks, our approach yields +0.4 ∼ 1.5 BLEU improvements over the state-of-the-art baselines.",Model Optimization,Model Optimization
"we propose an efficient method to dynamically sample the sentences in order to accelerate the NMT training. In this approach, a weight is assigned to each sentence based on the measured difference between the training costs of two iterations. Further, in each epoch, a certain percentage of sentences are dynamically sampled according to their weights. Empirical results based on the NIST Chinese-to-English and the WMT English-to-German tasks show that the proposed method can significantly accelerate the NMT training and improve the NMT performance.",New Algorithm/ Method,New Algorithm/ Method
"we propose to overcome this problem by replacing the source-language embedding layer of NMT with a bi-directional recurrent neural network that generates compositional representations of the input at any desired level of granularity. We test our approach in a low-resource setting with five languages from different morphological typologies, and under different composition assumptions. By training NMT to compose word representations from character trigrams, our approach consistently outperforms (from 1.71 to 2.48 BLEU points) NMT learning embeddings of statistically generated sub-word units.",Theory Proposal,Theory Proposal
"We explore strategies for incorporating target syntax into Neural Machine Translation. We specifically focus on syntax in ensembles containing multiple sentence representations. We formulate beam search over such ensembles using WFSTs, and describe a delayed SGD update training procedure that is especially effective for long representations like linearized syntax. Our approach gives state-of-the-art performance on a difficult Japanese-English task",Performance Evaluation,Performance Evaluation
"We empirically investigate learning from partial feedback in neural machine translation (NMT), when partial feedback is collected by asking users to highlight a correct chunk of a translation. We propose a simple and effective way of utilizing such feedback in NMT training. We demonstrate how the common machine translation problem of domain mismatch between training and deployment can be reduced solely based on chunk-level user feedback. We conduct a series of simulation experiments to test the effectiveness of the proposed method. Our results show that chunk-level feedback outperforms sentence based feedback by up to 2.61% BLEU absolute.",Theory Proposal,Theory Proposal
"We found such monotonicity forces the algorithm to sacrifice some decoding paths to explore new paths. As a result, the overall quality of the hypotheses selected by the algorithm is lower than expected. To mitigate this problem, we relax the monotonic constraint of the beam search by maintaining all found hypotheses in a single priority queue and using a universal score function for hypothesis selection. The proposed algorithm allows discarded hypotheses to be recovered in a later step. Despite its simplicity, we show that the proposed decoding algorithm enhances the quality of selected hypotheses and improve the translations even for highperformance models in English-Japanese translation task.",Theory Proposal,Theory Proposal
"we propose and evaluate models for classifying VNC usages as idiomatic or literal, based on a variety of approaches to forming distributed representations. Our results show that a model based on averaging word embeddings performs on par with, or better than, a previously-proposed approach based on skip-thoughts. Idiomatic usages of VNCs are known to exhibit lexico-syntactic fixedness. We further incorporate this information into our models, demonstrating that this rich linguistic knowledge is complementary to the information carried by distributed representations.",Model Optimization,Model Optimization
"we propose Pseudofit, a new method for specializing word embeddings according to semantic similarity without any external knowledge. Pseudofit exploits the notion of pseudo-sense for building several representations for each word and uses these representations for making the initial embeddings more generic. We illustrate the interest of Pseudofit for acquiring synonyms and study several variants of Pseudofit according to this perspective",New Algorithm/ Method,New Algorithm/ Method
we study the performance of both approaches on several hypernymy tasks and find that simple pattern-based methods consistently outperform distributional methods on common benchmark datasets. Our results show that pattern-based models provide important contextual constraints which are not yet captured in distributional methods.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We explore novel strategies to address the coverage problem that change only the attention transformation. Our approach allocates fertilities to source words, used to bound the attention each word can receive. We experiment with various sparse and constrained attention transformations and propose a new one, constrained sparsemax, shown to be differentiable and sparse. Empirical evaluation is provided in three languages pairs.",Performance Evaluation,Performance Evaluation
"We show that the divergence in the tag distributions of the common named entities between the primary and assisting languages can reduce the effectiveness of multilingual learning. To alleviate this problem, we propose a metric based on symmetric KL divergence to filter out the highly divergent training instances in the assisting language. We empirically show that our data selection strategy improves NER performance in many languages, including those with very limited training data.",Theory Proposal,Theory Proposal
"we propose a neural Open IE approach with an encoder-decoder framework. Distinct from existing methods, the neural Open IE approach learns highly confident arguments and relation tuples bootstrapped from a state-of-the-art Open IE system. An empirical study on a large benchmark dataset shows that the neural Open IE system significantly outperforms several baselines, while maintaining comparable computational efficiency.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose a novel Document Embedding Enhanced Bi-RNN model, called DEEB-RNN, to detect events in sentences. This model first learns event detection oriented embeddings of documents through a hierarchical and supervised attention based RNN, which pays word-level attention to event triggers and sentence-level attention to those sentences containing events. It then uses the learned document embedding to enhance another bidirectional RNN model to identify event triggers and their types in sentences. Through experiments on the ACE-2005 dataset, we demonstrate the effectiveness and merits of the proposed DEEB-RNN model via comparison with state-of-the-art methods",Model Proposal,Model Proposal
"We propose a method that can leverage unlabeled data to learn a matching model for response selection in retrieval-based chatbots. The method employs a sequence-tosequence architecture (Seq2Seq) model as a weak annotator to judge the matching degree of unlabeled pairs, and then performs learning with both the weak signals and the unlabeled data. Experimental results on two public data sets indicate that matching models get significant improvements when they are learned with the proposed method.",New Algorithm/ Method,New Algorithm/ Method
"We present a generative neural network model for slot filling based on a sequenceto-sequence (Seq2Seq) model together with a pointer network, in the situation where only sentence-level slot annotations are available in the spoken dialogue data. This model predicts slot values by jointly learning to copy a word which may be out-of-vocabulary (OOV) from an input utterance through a pointer network, or generate a word within the vocabulary through an attentional Seq2Seq model. Experimental results show the effectiveness of our slot filling model, especially at addressing the OOV problem. Additionally, we integrate the proposed model into a spoken language understanding system and achieve the state-of-the-art performance on the benchmark data.",Model Proposal,Model Proposal
"we propose a new transition-based discourse parser that makes use of memory networks to take discourse cohesion into account. The automatically captured discourse cohesion benefits discourse parsing, especially for long span scenarios. Experiments on the RST discourse treebank show that our method outperforms traditional featured based methods, and the memory based discourse cohesion can improve the overall parsing performance significantly 1 .",Theory Proposal,Theory Proposal
"we present SciDTB, a domainspecific discourse treebank annotated on scientific articles. Different from widelyused RST-DT and PDTB, SciDTB uses dependency trees to represent discourse structure, which is flexible and simplified to some extent but do not sacrifice structural integrity. We discuss the labeling framework, annotation workflow and some statistics about SciDTB. Furthermore, our treebank is made as a benchmark for evaluating discourse dependency parsers, on which we provide several baselines as fundamental work.",Model Proposal,Model Proposal
"we develop methods for predicting how much data is required to achieve a desired test accuracy by extrapolating results from systems trained on a small pilot training dataset. We model how accuracy varies as a function of training size on subsets of the pilot data, and use that model to predict how much training data would be required to achieve the desired accuracy. We introduce a new performance extrapolation task to evaluate how well different extrapolations predict system accuracy on larger training sets. We show that details of hyperparameter optimisation and the extrapolation models can have dramatic effects in a document classification task. We believe this is an important first step in developing methods for estimating the resources required to meet specific engineering performance targets.",Resources,Resources
"We investigate the influence that document context exerts on human acceptability judgements for English sentences, via two sets of experiments. The first compares ratings for sentences presented on their own with ratings for the same set of sentences given in their document contexts. The second assesses the accuracy with which two types of neural models — one that incorporates context during training and one that does not — predict these judgements. Our results indicate that: (1) context improves acceptability ratings for ill-formed sentences, but also reduces them for well-formed sentences; and (2) context helps unsupervised systems to model acceptability",Theory Proposal,Theory Proposal
"we propose a new similarity measure and two ad hoc experiments to shed light on this issue. In three cross-modal benchmarks we learn a large number of language-to-vision and visionto-language neural network mappings (up to five layers) using a rich diversity of image and text features and loss functions. Our results reveal that, surprisingly, the neighborhood structure of the predicted vectors consistently resembles more that of the input vectors than that of the target vectors. In a second experiment, we further show that untrained nets do not significantly disrupt the neighborhood (i.e., semantic) structure of the input vectors.",Theory Proposal,Theory Proposal
"We explore using a policy gradient method as a parser-agnostic alternative. In addition to directly optimizing for a tree-level metric such as F1, policy gradient has the potential to reduce exposure bias by allowing exploration during training; moreover, it does not require a dynamic oracle for supervision. On four constituency parsers in three languages, the method substantially outperforms static oracle likelihood training in almost all settings. For parsers where a dynamic oracle is available (including a novel oracle which we define for the transition system of Dyer et al. (2016)), policy gradient typically recaptures a substantial fraction of the performance gain afforded by the dynamic oracle.",Performance Evaluation,Performance Evaluation
"We propose a linear-time constituency parser with RNNs and dynamic programming using graph-structured stack and beam search, which runs in time O(nb2 ) where b is the beam size. We further speed this up to O(nb log b) by integrating cube pruning. Compared with chart parsing baselines, this linear-time parser is substantially faster for long sentences on the Penn Treebank and orders of magnitude faster for discourse parsing, and achieves the highest F1 accuracy on the Penn Treebank among single model end-to-end systems.",Model Proposal,Model Proposal
"We extend the LSTM-based syntactic parser of Dozat and Manning (2017) to train on and generate these graph structures. The resulting system on its own achieves stateof-the-art performance, beating the previous, substantially more complex stateof-the-art system by 0.6% labeled F1. Adding linguistically richer input representations pushes the margin even higher, allowing us to beat it by 1.9% labele",Performance Evaluation,Performance Evaluation
"We investigate the feasibility of recovering the original text written in an abugida after omitting subordinate diacritics and merging consonant letters with similar phonetic values. This is crucial for developing more efficient input methods by reducing the complexity in abugidas. Four abugidas in the southern Brahmic family, i.e., Thai, Burmese, Khmer, and Lao, were studied using a newswire 20, 000-sentence dataset",Theory Proposal,Theory Proposal
"we propose a novel task: automatic academic paper rating (AAPR), which automatically determine whether to accept academic papers. We build a new dataset for this task and propose a novel modularized hierarchical convolutional neural network to achieve automatic academic paper rating. Evaluation results show that the proposed model outperforms the baselines by a large margin",New Algorithm/ Method,New Algorithm/ Method
"we present an approach based on combining string kernels and word embeddings for automatic essay scoring. String kernels capture the similarity among strings based on counting common character ngrams, which are a low-level yet powerful type of feature, demonstrating state-of-theart results in various text classification tasks such as Arabic dialect identification or native language identification",Model Proposal,Model Proposal
"we aim to analyze structured time-series documents such as a collection of news articles and a series of scientific papers, wherein topics evolve along time depending on multiple topics in the past, and are also related to each other at each time.",Performance Evaluation,Performance Evaluation
" we propose a novel topic model PhraseCTM and a twostage method to find out the correlated topics at phrase level. In the first stage, we train PhraseCTM, which models the generation of words and phrases simultaneously by linking the phrases and component words within Markov Random Fields when they are semantically coheren",New Algorithm/ Method,New Algorithm/ Method
"we address the problem of finding a novel document descriptor based on the covariance matrix of the word vectors of a document. Our descriptor has a fixed length, which makes it easy to use in many supervised and unsupervised applications",Performance Evaluation,Performance Evaluation
"We report an empirical study on the task of negation scope extraction given the negation cue. Our key observation is that certain useful information such as features related to negation cue, long distance dependencies as well as some latent structural information can be exploited for such a task",Performance Evaluation,Performance Evaluation
We propose DEISTE (deep explorations of inter-sentence interactions for textual entailment) for this entailment task,Model Proposal,Model Proposal
"we focus on the task of pun location, which aims to identify the pun word in a given short text. We propose a sense-aware neural model to address this challenging task. Our model first obtains several WSD results for the text, and then leverages a bidirectional LSTM network to model each sequence of word senses.",Performance Evaluation,Performance Evaluation
"we report experiments with a rank-based metric for WE, which performs comparably to vector cosine in similarity estimation and outperforms it in the recently-introduced and challenging task of outlier detection, thus suggesting that rank-based measures can improve clustering quality",Performance Evaluation,Performance Evaluation
"We make three contributions to address this noise. First, we describe simple but effective adaptations to word embedding tools to maximize the informative content leveraged in each training sentence",Resources,Resources
"We hypothesize that taking into account global, corpuslevel information and generating a different noise distribution for each target word better satisfies the requirements of negative examples for each training word than the original frequency-based distribution",Theory Proposal,Theory Proposal
"We propose extending the continuous bag of words (CBOW) model (Mikolov et al., 2013a) to learn style-sensitive word vectors using a wider context window under the assumption that the style of all the words in an utterance is consistent",Dataset Creation,Dataset Creation
"we explore two approaches that transfer knowledge from documentlevel data, which is much less expensive to obtain, to improve the performance of aspect-level sentiment classification.",Performance Evaluation,Performance Evaluation
"We found that discourse relation, sentiment conflict and sentiment transition are effective indicators for humor recognition. On the perspective of using sentiment related features, sentiment association in discourse is more useful than counting the number of emotional words.",Theory Proposal,Theory Proposal
"we propose a double embeddings mechanism that is shown crucial for aspect extraction. The embedding layer is the very first layer, where all the information about each word is encoded.",Model Proposal,Model Proposal
"We propose a methodology to blend high quality but scarce labeled data with noisy but abundant weak labeled data during the training of neural networks. Experiments in the context of topic-dependent evidence detection with two forms of weak labeled data show the advantages of the blending scheme. In addition, we provide a manually annotated data set for the task of topicdependent evidence detection",New Algorithm/ Method,New Algorithm/ Method
"We propose a tri-modal architecture to predict Big Five personality trait scores from video clips with different channels for audio, text, and video data.",Model Proposal,Model Proposal
"We start by investigating previously suggested, but little evaluated, strategies for exploiting multiple treebanks based on concatenating training sets, with or without fine-tuning.",Theory Proposal,Theory Proposal
We generalize chart constraints to more expressive grammar formalisms and describe a neural tagger which predicts chart constraints at very high precision,Resources,Resources
we assess to what extent prominent sentence embedding methods exhibit select semantic properties,Resources,Resources
"We present the Supervised Directional Similarity Network (SDSN), a novel neural architecture for learning task-specific transformation functions on top of generalpurpose word embeddings",Model Proposal,Model Proposal
"We propose and assess methods for extracting one type of commonsense knowledge, object-property comparisons, from pretrained embeddings",Resources,Resources
We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge.,Theory Proposal,Theory Proposal
We propose the task of predicting simultaneous interpreter performance by building on existing methodology for quality estimation (QE) of machine translation output,Algorithm/Method Optimization,Algorithm/Method Optimization
"We experiment with a new approach where we combine resources from a pair of languages in the CoNLL 2009 shared task (Hajic et al. ˇ , 2009) to build a polyglot semantic role labeler. Notwithstanding the absence of parallel data, and the dissimilarity in annotations between languages, our approach results in an improvement in SRL performance on multiple languages over a monolingual baseline",Theory Proposal,Theory Proposal
we present a study to show how learning distributed representations of the logical forms from data annotated in different languages can be used for improving the performance of a monolingual semantic parser.,Model Proposal,Model Proposal
We propose a novel neural method to extract drug-drug interactions (DDIs) from texts using external drug molecular structure information,New Algorithm/ Method,New Algorithm/ Method
"we devise with these features can robustly cope with inputs 687 from diachronic corpora. We propose a new evaluation benchmark, based on the New York Times Archive, spanning more than 20 years, and the history collection historynet.com, spanning several centuries. Our experiments demonstrate that timeaware NED substantially outperforms some of the best standard NED tools",Theory Proposal,Theory Proposal
"We show experimentally that classification performance varies over time, and that performance can be improved by using a standard domain adaptation approach to adjust for changes in time.",Performance Evaluation,Performance Evaluation
We show how an adaptable language model can be used to generate personalized completions and how the model can use online updating to make predictions for users not seen during training. The personalized predictions are significantly better than a baseline that uses no user information,Resources,Resources
we focus on the problem of building assistive systems that can help users to write reviews.,Theory Proposal,Theory Proposal
We explore these two features of TS to build models tailored for specific grade levels. Our approach uses a standard sequenceto-sequence architecture where the original sequence is annotated with information about the target audience and/or the (predicted) type of simplification operation,Model Proposal,Model Proposal
"We show that while vanilla seq2seq models can reach high scores on the proposed benchmark (Narayan et al., 2017), they suffer from memorization of the training set which contains more than 89% of the unique simple sentences from the validation and test sets.",Performance Evaluation,Performance Evaluation
we supervise the learning of the representation of the source content with that of the summary,Theory Proposal,Theory Proposal
We present an alternative view to explain the success of LSTMs: the gates themselves are versatile recurrent models that provide more representational power than previously appreciated,Model Proposal,Model Proposal
"We consider the case of RNNs with finite precision whose computation time is linear in the input length. Under these limitations, we show that different RNN variants have different computational power.",Dataset Creation,Dataset Creation
we propose a new model to match a question-answer pair to a given passage. Our comatching approach explicitly treats the question and the candidate answer as two sequences and jointly matches them to the given passage,Model Proposal,Model Proposal
"we have performed various data analysis and analyzed a variety of top performing models presented for this task. Given the statistics we have aggregated, we have designed a new crowdsourcing scheme that creates a new SCT dataset, which overcomes some of the biases.",Model Optimization,Model Optimization
"we propose a Multi-sentiment-resource Enhanced Attention Network (MEAN) to alleviate the problem by integrating three kinds of sentiment linguistic knowledge (e.g., sentiment lexicon, negation words, intensity words) into the deep neural network via attention mechanisms",Model Proposal,Model Proposal
we address a sentiment classification task for a tweet analysis service as a case study and propose a pretraining strategy with unlabeled dialog data (tweet-reply pairs) via an encoder-decoder model.,Performance Evaluation,Performance Evaluation
"We analyze the ambiguity of hashtag usages and propose a novel neural networkbased model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection",Performance Evaluation,Performance Evaluation
"we explore the potential for generalizing classifiers between different targets, and propose a neural model that can apply what has been learned from a source target to a destination target",Theory Proposal,Theory Proposal
"we present SQUADRUN, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones",Dataset Creation,Dataset Creation
We propose a novel paradigm of grounding comparative adjectives within the realm of color descriptions.,New Algorithm/ Method,New Algorithm/ Method
"We introduce in this paper a novel method, that
we call Multi-Task Supervised Pre-training and Adaptation (MuTSPad)",New Algorithm/ Method,New Algorithm/ Method
"we pro-pose to build multi-task datasets for the News and
Tweets domains, by unifying the aforementioned
task-independent datasets.",Dataset Creation,Dataset Creation
"Hence our model can grasp
useful word-level semantic information and al-leviate the interference of segmentation error
cascading.",Model Optimization,Model Optimization
"The above operations provide a
wealth of resources to allow the model to in-
fer word-level deep characteristics, rather than
bluntly impose segmentation information.",Resources,Resources
"For document
level, we reused last year’s English-French data
for training and validation, but introduced a new
test set from the same corpus",Performance Evaluation,Performance Evaluation
"For QE as a metric we ran the evaluation jointly with the WMT19 metrics task, which meant applying the QE systems to news translation submissions and evaluating them against the human judgments collected this year",Performance Evaluation,Performance Evaluation
fair assessment of the progress in APE technology and for tests in more challenging conditions,Performance Evaluation,Performance Evaluation
"reusing the same test English-German set used last year, the evaluation framework allows us for a direct comparison with the last year’s outcomes at least on one language",Performance Evaluation,Performance Evaluation
"construction of training data and the official test sets, including statistics and an evalua- 31 tion of the quality of the test sets",Dataset Creation,Dataset Creation
a description of the three baselines that we developed for comparison,Theory Proposal,Theory Proposal
"an overview of the task, presents the results for the participating systems and provides analysis on additional subset sizes and the average sentence length of sub-selected data.",Performance Evaluation,Performance Evaluation
We obtain new results using referential translation machines with increased number of learning models in the set of results that are stacked to obtain a better mixture of experts prediction,Theory Proposal,Theory Proposal
We extend OpenKiwi with a Transformer predictor-estimator model,Model Optimization,Model Optimization
"We propose new ensembling techniques for combining word-level and sentence-level predictions, which outperform previously used stacking approaches",Model Optimization,Model Optimization
"We apply transfer learning techniques, finetuning BERT (Devlin et al., 2018) and XLM (Lample and Conneau, 2019) models in a predictor-estimator architecture",Applications,Applications
We build upon our BERT-based predictorestimator model to obtain document-level annotation and MQM predictions via a simple wordto-annotation conversion scheme,Model Optimization,Model Optimization
we propose a “bilingual” BERT using multi-task learning for translation quality estimation (called the QE BERT).,New Algorithm/ Method,New Algorithm/ Method
"we introduce our base model, which is a modified version of phrase-level Shef-bRNN (Ive et al., 2018), and further develop it by using different methods of extracting features from the input alongside the bi-RNN features",Model Optimization,Model Optimization
"we present two different approaches for the sentence-level QE task, which employ bi-directional translation knowledge and large-scale monolingual knowledge to the QE task, respectively",Theory Proposal,Theory Proposal
a simple ensemble of them can help to achieve better quality estimation performance in the sentence-level QE task,Performance Evaluation,Performance Evaluation
"we introduce a light-weight neural method with pre-trained embeddings, that means it does not require any pre-training",New Algorithm/ Method,New Algorithm/ Method
"to predict the required post-editing cost, measured in HTER",Performance Evaluation,Performance Evaluation
to rank all sentence pairs in descending translation quality,Performance Evaluation,Performance Evaluation
we propose a multisource APE model by extending Transformer to contain a joint multi-source encoder and a decoder that involves a multi-source attention layer to combine the outputs of the encoder.,New Algorithm/ Method,New Algorithm/ Method
"We also introduce the conservativeness penalty, a simple yet effective mechanism that controls the freedom of our APE in modifying the given MT output",New Algorithm/ Method,New Algorithm/ Method
we present a multi-source neural APE architecture model called transference,New Algorithm/ Method,New Algorithm/ Method
we explore the effect of adding tokens that identify partitions in the training data which may be relevant to guide the behaviour of the NPE system,Applications,Applications
"In order to tackle the over-correction problem and to induce a post-editing strategy that resembles the work of a human post-editor, we add a special token to the beginning of both the source text and the MT output indicating the amount of required post-editing",Performance Evaluation,Performance Evaluation
we re-implement a multi-source transformer model for the task,Model Optimization,Model Optimization
we designed a data preparation strategy for domainspecific translation systems to enrich data with terminology information without affecting the model architecture,Model Optimization,Model Optimization
we present an approach which aims at increasing the training corpus by mining similar in domain (Bio Med) sentences from out of domain data,Theory Proposal,Theory Proposal
"We have developed NMT system for English-French language pair, for translation in both directions",Theory Proposal,Theory Proposal
we present Huawei’s practices on adapting our NMT systems from general-domain to in-domain,New Algorithm/ Method,Model Proposal
"We apply transfer learning iteratively on datasets from different domains, obtaining strong models that cover two domains for both directions of the English-German language pair, and three domains for both directions of EnglishSpanish.",Applications,Applications
We therefore investigate applying Bayesian Interpolation for language-model based multi-domain ensemble weighting,Applications,Applications
"For that matter, we developed a machine translation (MT) system based on neural machine translation (NMT), using OpenNMT-py",New Algorithm/ Method,New Algorithm/ Method
This paper introduces a novel approach to translation modeling that is currently being developed,Model Proposal,Model Proposal
in this article we aimed to determine whether the neural or the statistical approach is a better one to solve the given problem.,Theory Proposal,Theory Proposal
We first briefly introduce the phenomenon of intercomprehension between Slavic languages and our idea how to take advantage of it for machine translation purposes,New Algorithm/ Method,Theory Proposal
The next section spreads out our plans on Czech-Polish translation by exploring the similarities and differences between the two languages,Theory Proposal,Theory Proposal
"The task focuses on improving machine translation results for three language pairs Czech-Polish
(Slavic languages), Hindi-Nepali (Indo-Aryan languages) and Spanish-Portuguese (Romance languages).",Model Optimization,Model Optimization
"To examine the efficiency of our NMT systems, the predicted translations exposed to automatic evaluation using the BLEU score",Performance Evaluation,Performance Evaluation
"For both translation directions, we trained supervised neural MT (NMT) and statistical MT (SMT) systems, and combined them through n-best list reranking using different informative features as proposed by Marie and Fujita (2018a)",Model Optimization,Model Optimization
"Keeping in view the recent results obtained in MT developments, we experimented with both PBSMT as well as NMT models and evaluated how different models perform in comparison to each other",Performance Evaluation,Performance Evaluation
we describe the UDS-DFKI system to the WMT 2019 Similar Language Translation task.,Theory Proposal,Theory Proposal
we assume that proper subword segmentation will be beneficial for neural machine translation (NMT) performance but we aim at consistent segmentation across both related languages,Performance Evaluation,Performance Evaluation
"We participated only in the Sinhala-English track, basing our system on that of JunczysDowmunt (2018) but extensively modified for the 2019 low-resource scenario",Resources,Resources
"we describe the 4 systems we submitted, which have three main components: pre-filtering rules, sentence pair scoring, and reranking to improve vocabulary coverage",Theory Proposal,Theory Proposal
"In our submission for this shared task, we use of multilingual sentence embeddings obtained from LASER2 which uses an encoder-decoder architecture to train a multilingual sentence representation model using a relatively small parallel corpus.",Resources,Resources
"we include a text quality metric in the subcorpus-building process, rather than combining it afterward.",Resources,Resources
describes the participation of Webinterpret in the shared task on parallel corpus filtering at the Fourth Conference on Machine Translation,Theory Proposal,Theory Proposal
"We present a method based on projecting word embeddings learned from a monolingual corpus in a highresource language, to the target low-resource language through whatever parallel text is available",New Algorithm/ Method,New Algorithm/ Method
we introduce a filtering method for noisy parallel corpora based mainly on generating hypotheses for each sentence pair from noisy data and scoring based on hypothesis and target sentence similarity,New Algorithm/ Method,New Algorithm/ Method
The aim of this shared task is to extract two smaller sets of high-quality parallel sentences from a very noisy parallel corpus,Dataset Creation,Dataset Creation
This methodology allowed us to build a simple and reliable system that is easily adaptable to other language pairs.,Model Proposal,Model Proposal
"In order to gain further insight into the performance of individual MT systems, we organized a call for dedicated “test suites”, each focussing on some particular aspect of translation quality",Performance Evaluation,Performance Evaluation
"QE developers were invited to perform the same scoring as standard metrics participants, with the exception that they refrain from using a reference translation in production of their scores. We then evaluate the QE submissions in exactly the same way as regular metrics are evaluated",Performance Evaluation,Performance Evaluation
"The goal of this shared task is to provide a testbed for improving MT models’ robustness to orthographic variations, grammatical errors, and other linguistic phenomena common in usergenerated content, via better modelling, training, adaptation techniques, or leveraging monolingual training data",Model Optimization,Model Optimization
we investigated character-based tokenisation vs. sub-word segmentation of Chinese text,Algorithm/Method Optimization,Algorithm/Method Optimization
"introduce the method of data filtering, mainly in the application of language model and describe the techniques on transformer architecture and show the conducted experiments in detail of all directions, including data preprocessing,
model architecture, back-translation and knowledge distillation",New Algorithm/ Method,New Algorithm/ Method
upperbounds on the translation performance using lowercased coverage to identify which models used data in addition to the parallel corpus,Model Optimization,Model Optimization
"we introduced two new translation directions involving two European languages, namely French and German",New Algorithm/ Method,New Algorithm/ Method
examine transfer learning for the Kazakh–English language pair using additional parallel data from Turkish–English.,Performance Evaluation,Performance Evaluation
We choose news translation task and focus on KazakhEnglish (and vice versa) language pair,Resources,Resources
Lingua Custodia’s submission to the WMT’19 news shared task for German-to-French on the topic of the EU elections,Resources,Resources
a self-attention model based on the decoder part of the Transformer architecture was trained on the two pseudoparallel corpora,Model Proposal,Model Proposal
"We focused on the new Germanto-French language direction, and mostly used current standard approaches to develop a Neural Machine Translation system",Theory Proposal,Theory Proposal
"we describe all the systems for Kazakh↔English, Gujarati↔English, Chinese↔English, and English→Finnish, that we developed and submitted for WMT 2019 under the team name “NICT.",Theory Proposal,Theory Proposal
we propose a novel augmentation method Cycle Translation and a data mixture strategy Big/Small parallel construction to entirely exploit the synthetic corpus,New Algorithm/ Method,New Algorithm/ Method
"Our system is based on the self-attentional Transformer networks, into which we integrated the most recent effective strategies from academic research (e.g., BPE, back translation, multi-features data selection, data augmentation, greedy model ensemble, reranking, ConMBR system combination, and postprocessing)",Model Optimization,Model Optimization
"describes the systems and experiments conducted to participate in the news translation tasks of WMT 2019 for Gujarati– English (gu–en, low-resourced language pair) and German–English (de–en, document-level evaluation).",Theory Proposal,Theory Proposal
"Our experiments show that Multilingual Neural Machine Translation leveraging parallel data from related language pairs helps in significant BLEU improvements upto 11.5, for low resource language pairs like Gujarati-English",Performance Evaluation,Performance Evaluation
We also proposed our own model architectures and applied them in the tasks.,Applications,Applications
"we refine our approach to training popular neural machine translation toolkits, experiment with a new domain adaptation technique and again measure improvements in performance on the Russian–English language pair",Model Optimization,Model Optimization
"We conduct an in-depth evaluation of the translation performance of different models, highlighting the trade-offs between methods of sharing decoder parameters",Performance Evaluation,Performance Evaluation
"In this edition, we have submitted systems for the German ↔ English and German ↔ French language pairs, participating in both directions of each pair",Theory Proposal,Theory Proposal
Our main focus is document-level neural machine translation with deep transformer models.,Model Proposal,Model Proposal
we describe our approach to low-resource NMT,Theory Proposal,Theory Proposal
This paper describes our submitted systems with embeddings pre-trained on monolingual corpora,Theory Proposal,New Algorithm/ Method
"We proposed four novel Deep-Transformer architectures based on (Wang et al., 2019) as our baseline, which outperformed the standard Transformer-Big significantly in terms of both translation quality and convergence speed.",Model Proposal,Model Proposal
Our submission is a multi-source NMT system taking both the original Kazakh sentence and its Russian translation as input for translating into English,Model Proposal,Model Proposal
"the systems we implement for the German-Czech language pair are built based on the previously proposed unsupervised MT systems, with some adaptations made to accommodate the morphologically rich characteristics of German and Czech",Algorithm/Method Optimization,Algorithm/Method Optimization
We created a News transalated Shared task system to to translate news text from Lithuanian to English.,Theory Proposal,Theory Proposal
We submitted systems for both directions of the EnglishGerman language pair,Theory Proposal,Theory Proposal
This paper describes the unsupervised neural (NMT) and statistical machine translation (SMT) systems built for the participation of the National Institute of Information and Communications Technology (NICT) to the WMT19 shared News Translation Task,Model Proposal,Model Proposal
"we participate with neural MT systems for two language pairs and in three directions: English-Russian, EnglishGerman and German-English",Model Proposal,Model Proposal
we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for English–Gujarati language pair within the translation task subtrack,Theory Proposal,Theory Proposal
"We participate with the methods for shared news translation task in four language
directions, English ↔ German and English
↔ Russian in both directions",Resources,Model Proposal
"The systems have been developed with the aim of identifying and following rather than establishing best practices, under the constraints imposed by a low resource training and decoding environment normally used for our production system",Model Proposal,Model Proposal
"The systems have been developed with the aim of identifying and following rather than establishing best practices, under the constraints imposed by a low resource training and decoding environment normally used for our production system",Algorithm/Method Optimization,Algorithm/Method Optimization
"I describe a rule-based, bidirectional machine translation system for the Finnish—English language pair.",Theory Proposal,Theory Proposal
We describe our NMT systems submitted to the WMT19 shared task in English→Czech news translation.,Theory Proposal,Theory Proposal
"describes the neural machine translation systems developed at the RWTH Aachen University for the De→En, Zh→En and Kk→En news translation tasks",Theory Proposal,Theory Proposal
"Our two new news translation tasks address the low-resource
English-to-Kazakh language pair, for which only
a few thousand in-domain parallel sentences are
available",Theory Proposal,Theory Proposal
"Elastic weight consolidation (Kirkpatrick et al., 2017, EWC) is a domain adaptation technique that aims to avoid degradation in performance on the original domain",Model Proposal,Model Proposal
"To incorporate document-level context in a light-weight fashion, we propose a modification to the Transformer (Vaswani et al., 2017) that has separate attention layers for inter- and intra-sentential context.",New Algorithm/ Method,Model Proposal
"Even though the performance gap between NMT and traditional statistical machine translation (SMT) is growing rapidly on the task at hand, SMT can still improve very strong NMT ensembles",Performance Evaluation,Performance Evaluation
"we focus on the improvement of single system, and propose three novel Transformer variants",New Algorithm/ Method,New Algorithm/ Method
we trained a single multilingual translation system using the constrained parallel and monolingual data for several language pairs.,Model Optimization,Model Optimization
"neural machine translation (NMT) systems for English↔Kazakh
(henceforth referred to as EN↔KK) constrained
tasks.",Theory Proposal,Theory Proposal
we describe the system we developed at the LMU Munich Center for Information and Language Processing,New Algorithm/ Method,Theory Proposal
"We submit constrained systems, i.e, we rely on the data provided for this language pair and do not use any external data.",Resources,Resources
"we present the University of Helsinki submissions to the WMT 2019 shared task on news translation in three language pairs: English–German, English–Finnish and Finnish–English",Resources,Resources
"Neural architecture optimization (NAO), our newly proposed method (Luo et al., 2018), leverages the power of a gradient-based method to conduct optimization and guide the creation of better neural architecture in a continuous and more compact space given the historically observed architectures and their performances",New Algorithm/ Method,New Algorithm/ Method
"This paper is based on Transformer, a neural machine translation network structure, to develop a two-way evaluation task between Russian and English.",Performance Evaluation,Theory Proposal
This paper describes the DFKI-NMT submission to the WMT19 News translation task for both English-to-German and German-toEnglish directions,Model Proposal,Model Proposal
"we use the DFKI test suite for German→English MT (Burchardt et al., 2017) in order to analyze the performance of the 16 MT Systems that took part at the translation task",Model Proposal,Model Proposal
We provide a test suite for WMT19 aimed at assessing discourse phenomena of MT systems participating in the News Translation Task.,Performance Evaluation,Performance Evaluation
We present a test set for evaluating an MT system’s capability to translate ambiguous conjunctions depending on the sentence structure,New Algorithm/ Method,New Algorithm/ Method
we present a languageindependent method for automatically building ContraWSD-style test suites,New Algorithm/ Method,New Algorithm/ Method
"a machine translation test set of documents from the auditing domain and its use as one of the “test suites” in the WMT19 News Translation Task for translation directions involving Czech, English and German.",Performance Evaluation,Performance Evaluation
we propose WMDO (metric) – an extension to WMD that incorporates word order,Performance Evaluation,Performance Evaluation
we seek to directly address the problem mentioned before by adopting a syntactic-level language resource into Meteor.,Theory Proposal,Theory Proposal
"We present YiSi, a unified automatic semantic machine translation quality evaluation and estimation metric for languages with different levels of available resources",New Algorithm/ Method,New Algorithm/ Method
" introduces a new MT metric: Extended Edit Distance (EED), based on an extension of the Levenshtein distance",Dataset Creation,Dataset Creation
We propose a method to filter pseudo-references by paraphrasing for automatic evaluation of machine translation (MT),New Algorithm/ Method,New Algorithm/ Method
We proposed one single and one ensemble system for each translation direction,New Algorithm/ Method,New Algorithm/ Method
we describe our neural machine translation (NMT) systems for Japanese↔English translation which we submitted to the translation robustness task,Theory Proposal,Theory Proposal
"describes the systems of Fraunhofer FOKUS for the WMT 2019 machine translation robustness task on EN-FR, FR-EN, and JA-EN language pairs",Theory Proposal,Theory Proposal
We further improved the performance of our model by fine-tuning on the in-domain noisy data without influencing the translation quality on the news domain,Model Optimization,Model Optimization
"Our submission combined techniques including utilization of a synthetic corpus, domain adaptation, and a placeholder mechanism, which significantly improved over the previous baseline",Algorithm/Method Optimization,Algorithm/Method Optimization
we built straightforward 6-layer Transformer models and experimented with a handful of variables including subword processing (FR–EN) and a handful of hyperparameters settings (JA↔EN),Model Proposal,Model Proposal
We illustrated that adding a domain symbol in source sentence improves the robustness of the model,Model Optimization,Model Optimization
We found that “social-media-style” sentences can be generated by training a translation model with different “start-of-sentence” symbols for sentences in different domains in the decoder side,Model Proposal,Model Proposal
we propose a multitask learning algorithm for transformer-based MT systems that is more resilient to this noise.,New Algorithm/ Method,New Algorithm/ Method
"We propose a series of such methods that are model-agnostic, are able to be applied either offline or online, and do not require parameter update or architectural change",New Algorithm/ Method,New Algorithm/ Method
Our work here focuses on the zero-shot translation aspect of universal multilingual NMT,Theory Proposal,Theory Proposal
This is one of the first attempts at using syntax to improve Transformer-based NMT,Model Optimization,Model Optimization
We introduce two methods for adding syntax to NMT that are straightforward to incorporate in practice,New Algorithm/ Method,New Algorithm/ Method
"We empirically evaluate both methods on translation from English into 21 diverse target languages, finding that the multi-task method improves consistently over a nonsyntactic baseline",Performance Evaluation,Performance Evaluation
We introduce an APE model trained only on synthetic data generated with RTT for fixing typical translation errors from NMT output and investigate its scalability,Model Proposal,Model Proposal
We improve the BLEU of top submissions of the recent WMT evaluation campaigns,Algorithm/Method Optimization,Model Optimization
"We propose separately reporting scores on test sets whose source sentences are translated and whose target sentences are translated, and call for higher-quality test sets",Performance Evaluation,Performance Evaluation
we focus on investigating why sampling creates better training data by re-writing the loss criterion of an NMT model to include a model-based data generator,Dataset Creation,Dataset Creation
"We propose a simpler alternative to noising techniques, consisting of tagging back-translated source sentences with an extra token.",Algorithm/Method Optimization,Algorithm/Method Optimization
We introduce and explore different approaches for using document embeddings in parallel document mining,New Algorithm/ Method,New Algorithm/ Method
We adapt the previous work on hierarchical networks to introduce a simple hierarchical document encoder trained on document pairs for this task.,Dataset Creation,Dataset Creation
Empirical results show our best document embedding model leads to state-of-the-art results on the document-level bitext retrieval task on two different datasets,Performance Evaluation,Performance Evaluation
"We study in depth the effect of translationese on test data, using the test sets from the last three editions of WMT’s news shared task, containing 17 translation directions.",Performance Evaluation,Performance Evaluation
"we present a customized NMT system for subtitling, with focus on the entertainment domain",New Algorithm/ Method,New Algorithm/ Method
"We introduce our work, which to the best of our knowledge is the first of its kind, on integrating synchrony constraints into the machine translation paradigm",Model Proposal,Model Proposal
We propose the use of lexical shortcuts as a simple strategy for alleviating the representation bottleneck in NMT models,New Algorithm/ Method,New Algorithm/ Method
We demonstrate significant improvements in translation quality across multiple language pairs as a result of equipping the transformer with lexical shortcut connections,Performance Evaluation,Performance Evaluation
We report a positive impact of our modification on the model’s ability to perform word sense disambiguation,Model Optimization,Model Optimization
This paper presents a high-quality multilingual dataset for the documentation domain to advance research on localization of structured text,Dataset Creation,Dataset Creation
"In this talk I will give an overview of advances on the identification and treatment of multiword expressions, in particular concentrating on techniques for identifying their degree of idiomaticity.",Theory Proposal,Theory Proposal
" we present the types of VMWEs existing in each language, as they are reflected in the respective corpora created within PARSEME",Model Proposal,Model Proposal
This paper reports on the Romanian journalistic corpus annotated with verbal multiword expressions following the PARSEME guidelines.,Theory Proposal,Theory Proposal
"We show how the Multiword Expressions (MWEs) contained in OdeNet can be morphologically specified by the use of the lexical representation and linking features of OntoLex-Lemon, which also support the formulation of restrictions in the usage of such expressions.",Resources,Resources
introduction of a new task in NLP that sheds light on the basic mechanisms underlying conceptual creativity; an automatic way of evaluating newly generated language; a temporally-aware neural model that learns what are plausible new conceptual combinations by generalising over attested combinations and corrupted instances thereof.,New Algorithm/ Method,New Algorithm/ Method
this unsupervised method to a bilingual vector space so as to model translation as a process of compositional contextualization.,Algorithm/Method Optimization,Algorithm/Method Optimization
this paper also contributes with a new freely available dataset of 273 EnglishSpanish compound equivalents,Dataset Creation,Dataset Creation
This paper presents a systematic evaluation of twelve AMs —both symmetric and directional— which have been proposed for collocation extraction.,Theory Proposal,Theory Proposal
we aimed to replicate the MWS frequency effects found for adult native language speakers based on evidence from self-paced reading and sentence recall tasks in an ecologically more valid eye-tracking study,Model Optimization,Model Optimization
we present the distribution and treatment of MultiWord Expressions (MWEs) within BTB-WN — a data-driven Bulgarian WordNet.,Model Proposal,Model Proposal
We focus on modeling compositionality of MWEs as reflected in their morphosyntactic and semantic properties.,Performance Evaluation,Performance Evaluation
We propose a scenario for coupling MWEI with MWE discovery via syntactic MWE lexicons,Theory Proposal,Theory Proposal
This paper is a position statement based on an analysis of the state of the art in MWEI,Theory Proposal,Theory Proposal
"we test the quality of noun compound representations produced by different methods, including distributional representations, composition functions, and paraphrase-based phrase embeddings",Performance Evaluation,Performance Evaluation
"our own proposal of how to deal with semantics of collocations; we argue that the notion of a semantic frame in the sense of FrameNet (Ruppenhofer et al., 2016) provides a suitably general semantic framework that is applicable to a wide range of semantic fields",Applications,Applications
We propose to tackle the problem of verbal multiword expression (VMWE) identification using a neural graph parsing-based approach.,New Algorithm/ Method,New Algorithm/ Method
this paper aims to determine whether the sentiment of the component words of an idiom is related to the sentiment of that idiom.,Theory Proposal,Theory Proposal
"We report on the ongoing development of IDION, a web resource of richly documented multiword expressions (MWEs) of Modern Greek addressed to the human user and to NLP",New Algorithm/ Method,New Algorithm/ Method
describe how we created a dataset for noun-adjective neologisms and in particular how we constructed a weak negative set for evaluation,Dataset Creation,Dataset Creation
describe our baseline methodologies and how we used pretrained language models in order to identify adjective-noun neologism with increased accuracy,Applications,Applications
"we propose a deep encoderdecoder architecture generating for every MWE word its corresponding part in the lemma, based on the internal context of the MWE",Model Proposal,Model Proposal
we aim to close this gap and present an evaluation study that considers both corpus- and documentlevel ATE.,Performance Evaluation,Performance Evaluation
we propose a neural model that improves MWE identification by jointly learning MWE and dependency parse labels,Model Proposal,Model Proposal
"we propose, to the best of our knowledge for the first time, a cross-lingual transfer learning method for processing MWEs",New Algorithm/ Method,New Algorithm/ Method
"We show that MWE identification models, when multitasked with dependency parsing, outperform the models which naively add dependency parse information as additional features",Resources,Resources
"Our work aims to compile a comprehensive lexicon of Irish MWEs (Ilfhocail) for the purposes of NLP, by leveraging both existing monolingual and bilingual lexical resources and generating new MWE entries through methods of semiautomatic discovery",New Algorithm/ Method,New Algorithm/ Method
"Our goal is to study the impact of word representations on verbal MWE (VMWE) identification, comparing lemmas, surface forms, traditional word embeddings and subword representations.",Performance Evaluation,Performance Evaluation
We explore a variety of methods for the novel task of classifying four types of assertions about activity performance,Model Optimization,Model Optimization
"We propose a neural network model, which is a combination of a convolutional neural network (CNN) (LeCun et al., 1989), a recurrent neural network (RNN) (Elman, 1990), and a residual network (He et al., 2016) inspired by their recent successes in multiple tasks",New Algorithm/ Method,Model Proposal
Application of VAE in context to clinical paraphrasing task,Applications,Applications
"In this work, we build a unifying framework for RE, applying this on three highly used datasets (from the general, biomedical and clinical domains) with the ability to be extendable to new datasets",New Algorithm/ Method,Theory Proposal
we develop a simple measure of sentence importance and demonstrate its effectiveness in interpreting a complex LSTM model’s decision making process,New Algorithm/ Method,New Algorithm/ Method
we discover clusters in the high-dimensional space of the sentence embedding model and test their correlation with feature importance scores for a given diagnosis class,Performance Evaluation,Performance Evaluation
We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results,Performance Evaluation,Performance Evaluation
"We present a deep learning approach to combining in real time available diagnosis codes (ICD codes) and free-text notes: Patient Context Vectors. Patient Context Vectors are created by averaging ICD code embeddings, and by predicting the same from free-text notes via a Convolutional Neural Network",New Algorithm/ Method,New Algorithm/ Method
to present the construction of a biomedical gold standard corpus annotated both with part-of-speech tags and named entities,New Algorithm/ Method,New Algorithm/ Method
"Two different approaches for domain adaptation of SRL for biological processes, with our code and models publicly available",Model Optimization,Model Optimization
Analysis of the model performance when the target corpus is annotated with event-event relationships to the SRL corpus,Performance Evaluation,Performance Evaluation
We present DEep Contextualized Biomedical Abbreviation Expansion (DECBAE) model,Model Proposal,Model Proposal
we will tackle the word categorization task and compare the performance of classification model on different feature sets: standard linguistic and non-linguistic features,Performance Evaluation,Performance Evaluation
we propose to apply deep learning techniques to improve identification of readability and understandability of medical words by nonexpert users,Algorithm/Method Optimization,Algorithm/Method Optimization
"Construct a dataset for training machine learning models to identify and extract data from full-text articles on diagnostic test accuracy. We focus on the target condition, index test, and reference standard.",Dataset Creation,Dataset Creation
"a discriminative model for automatically constructing high-coverage and domain-specific corpora for information extraction,",Model Proposal,Model Proposal
"an approach for automatically selecting queries using index terms as candidates,",New Algorithm/ Method,New Algorithm/ Method
an automated method to evaluate queries based on a sample corpus,Model Optimization,Model Optimization
We present a simple and computationally efficient approach using a widely-available “off-theshelf” retrofitting algorithm to align pretrained embeddings according to semantic verb clusters,Model Optimization,Model Optimization
"we show that by using semantic clusters for verbs, a large lexicon of verb classes derived from biomedical literature, we are able to improve the performance of common pretrained embeddings in downstream tasks by retrofitting them to verb classes",Model Optimization,Model Optimization
We compare wordbased and context-based representations for the three classification problems.,Performance Evaluation,Performance Evaluation
We propose a number of methods for extracting patterns from a sentence in which two eligible entities co-occur; different types of patterns have different trade-offs between expressive power and coverage,New Algorithm/ Method,New Algorithm/ Method
we propose a method which utilises these seed pairs to rank newly discovered patterns in terms of their compatibility with the existing data.,New Algorithm/ Method,New Algorithm/ Method
"We provide a resource to be distributed for research purposes in the BioNLP community. MedLexSp includes inflected forms (singular/plural, masculine/feminine) and conjugated verb forms of term lemmas, which are mapped to UMLS Concept Unique Identifiers",Resources,Resources
We present a novel multichannel TextCNN model for MeSH term indexing.,Model Proposal,Model Proposal
Experimental results show that incorporating figure and table information improves the performance of automatic MeSH indexing,Performance Evaluation,Performance Evaluation
We make available a labeled full text biomedical document dataset,Dataset Creation,Dataset Creation
We publish a dataset of 2010 sentences with complete annotations of biological entities and binding interactions between the entities,Dataset Creation,Dataset Creation
"We propose a benchmark task with a welldefined evaluation system, which follows the best practices of machine learning research",Theory Proposal,Theory Proposal
We perform extensive evaluation of several competing methods on the dataset and report the results.,Performance Evaluation,Performance Evaluation
The first NLP method to focus specifically on drug information for nursing mothers.,Model Proposal,Model Proposal
"Application of a deep learning-based system on two separate lactation information sources, drug labels and LactMed.",Applications,Applications
Evaluation of cross-corpus similarity in terms of important lactation information,Performance Evaluation,Performance Evaluation
"we investigated how temporal information is documented in clinical text by annotating a corpus of medical reports with time expressions (TIMEXes), based on TimeML",Model Proposal,Model Proposal
we propose a novel annotation schema that could be useful for timeline reconstruction: CALendar EXpression (CALEX).,New Algorithm/ Method,New Algorithm/ Method
We present a method for the semantic categorization of clinical terms based on their surface form.,New Algorithm/ Method,Algorithm/Method Optimization
"we build a dataset of PIO elements by improving the methodology found in (Jin and Szolovits, 2018)",Dataset Creation,Dataset Creation
"we built a multi-label PIO classifier, along with a boosting framework, based on the state of the art text embedding, BERT",Model Proposal,Model Proposal
A collection of Portuguese clinical texts with manuallylabelled named entities,Dataset Creation,Dataset Creation
"A model of word embeddings learned from a larger collection of Portuguese clinical text (i.e., Neurology clinical case descriptions)",Model Optimization,Model Optimization
"An analysis of the performance of state-of-the-art models in Portuguese clinical NER, namely BiLSTM-CRF neural networks (Lample et al., 2016), tested on the labelled collection, either using the previous word embeddings or general-language word embeddings",Performance Evaluation,Performance evaluation
We present two models for combining word and character embeddings for cause-of-death classification of verbal autopsy reports using the text of the narrative,Model Proposal,Model Proposal
a single methodology to generate medical text for a series of downstream NLP tasks,New Algorithm/ Method,New Algorithm/ Method
an assessment of the utility of the generated data as complementary training data in two important biomedical NLP tasks: text classification (phenotype classification) and temporal relation evaluation,Performance Evaluation,Performance Evaluation
"we introduce our work on building a Chinese medical QA corpus named ChiMed
by crawling data from a big Chinese medical forum",Applications,Applications
Our goal in this paper is to maximize the predictive power of clinical notes by bridging the gap between information extraction and deep learning models,Theory Proposal,Theory Proposal
we present the semantic annotations we made on a corpus of clinical cases written in French by domain experts,Theory Proposal,Theory Proposal
"We develop a two-stage federated natural language processing method that enables utilization of clinical notes from different hospitals or clinics without moving the data, and demonstrate its performance using obesity and comorbities phenotyping as medical task",Model Optimization,Model Optimization
"focus on causal sentence detection as a binary classification task and  to consider causal sentence detection in
both generic and biomedical texts",Model Proposal,Model Proposal
We propose a new NE method that leverages the strengths of both structure and content-oriented approaches.,New Algorithm/ Method,New Algorithm/ Method
Our objective is to propose methods and material for the creation of transformation rules from a small set of parallel sentences differentiated by their technicity,New Algorithm/ Method,New Algorithm/ Method
We also propose a typology of transformations and quantify them,Theory Proposal,Theory Proposal
We detail the performance of two packages of models released in scispaCy and demonstrate their robustness on several tasks and datasets,Performance Evaluation,Performance Evaluation
this paper will focus on presenting the best NER performance achieved to date on full chemical patent corpus,Resources,Resources
"Our main research contribution is a new neural model that detects ADRs by firstly learning to classify sentiment, using a publicly available corpus of Tweets that is annotated with sentiment information and then using transfer learning to adapt this classifier to the detection of ADRs in social media postings",Theory Proposal,Theory Proposal
This work instead examines the evolution in biomedical knowledge over time using scientific literature in terms of diachronic change.,Performance Evaluation,Performance Evaluation
"we present our approach towards extracting outcomes, significance levels and relations between them, that can be incorporated into a spin detection pipeline",Algorithm/Method Optimization,Algorithm/Method Optimization
"In this paper, we describe the tasks, the datasets, and the participants’ approaches and results of shared task.",Theory Proposal,Theory Proposal
"we demonstrate that we can achieve significant performance gains over traditional deep learning models like ESIM by adapting pre-trained language
models into the medical domain",Model Proposal,Model Proposal
"we introduce an end-to-end system, trained in a multi-task setting, to filter
and re-rank answers in medical domain",Theory Proposal,Theory Proposal
we investigate different methods to combine and transfer the knowledge from the two different sources and illustrate our results on the MEDIQA shared task,Performance Evaluation,Performance Evaluation
We apply the transfer learning method with two general domain NLI datasets and show that a source task in a domain can benefit learning a target task in a different domain,Model Optimization,Model Optimization
We show the independent strengths of the proposed approaches in quantitative and qualitative manners,Performance Evaluation,Performance Evaluation
"we propose a hybrid approach to biomedical NLI, which includes three main components",Model Proposal,New Algorithm/ Method
"To enhance our model, we also use model ensemble and conflict resolution strategies",Model Optimization,Model Optimization
we specialize our model on the MedNLI dataset.,Model Optimization,Model Optimization
"In this paper, we propose a novel model called Adversarial Multi-Task Network (AMTN) for jointly modeling Recognizing Question Entailment (RQE) and medical Question Answering (QA) tasks.",Model Proposal,Model Proposal
"Our approach for both task 1 and task 2 is based on the state-of-the-art natural language understanding model MT-DNN (Liu et al., 2019), which combines the strength of multi-task learning (MTL) and language model pre-training. MTL in deep networks has shown performance gains when related tasks are trained together resulting in better generalization to new domains",Theory Proposal,Theory Proposal
This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain,Theory Proposal,Theory Proposal
we present our novel approach to detect question entailment by determining the type of question asked rather than focusing on the type of the ailment given,Model Proposal,Model Proposal
"we detail our approach in MEDIQA which addresses some of the problems with biomedical text such as utilising deep contextual relationships between words within a sentence for semantic understanding and ambiguity associated with esoteric terminology, abbreviations, and patient colloquialism",Model Proposal,Model Proposal
we present Biomedical MultiTask Deep Neural Network (Bio-MTDNN) on the NLI task of MediQA 2019 challenge,Applications,Applications
we describe our proposed model and the implementation details for both tasks,Model Proposal,Model Proposal
"This paper describes our approach to the Natural Language Inference (NLI) subtask of the MEDIQA 2019 shared task (Ben Abacha et al., 2019)",Theory Proposal,Theory Proposal
This paper explores the use of Bidirectional Encoder Representation from Transformer (BERT) for solving MedNLI,New Algorithm/ Method,Theory Proposal
" Our proposed systems produce
encouraging results",Performance Evaluation,Performance Evaluation
Our approach explored a common Transformer-based architecture that could be applied to each task.,Performance Evaluation,Performance Evaluation
"Our solution explores a BERT-based model, in which the BiLSTM network with attention mechanism is integrated for textual inference",Performance Evaluation,Performance Evaluation
"We discuss the Proposed Architecture for NLI, RQE and QA and  the results,
performance of the various models for each task,
followed by error analysis, conclusion and references",Performance Evaluation,Performance Evaluation
"we propose a new component
that aims to address this particular weakness of
seq2seq models",New Algorithm/ Method,New Algorithm/ Method
"we propose a new testing paradigm based on overgeneralization, that can be used to gain more insights in the biases of a model which cannot be inferred from task success alone",New Algorithm/ Method,New Algorithm/ Method
the creation of a challenging sentiment dataset from previously available data,Dataset Creation,Dataset Creation
finally presenting a practical use-case demonstrating how the dataset can be used to probe the particular types of errors made by a new model.,Applications,Applications
We create an artificial data set with target words displaying context overlap in different orders of co-occurrence and show that SGNS behaves similarly to SVD in capturing second-order co-occurrence information,Dataset Creation,Dataset Creation
we present a new evaluation dataset1 that covers a wide range of monotonicity reasoning that was created by crowdsourcing and collected from linguistics publications,Dataset Creation,Dataset Creation
we study what the meaningful units to highlight are  so that all highlighted symptoms can be directly used for explaining the model.,New Algorithm/ Method,New Algorithm/ Method
Our aim is to identify what strategy deep learning models for visual question answering learn when trained on such questions,New Algorithm/ Method,Model Proposal
we compare the explanations from the two models through human evaluation on Mechanical Turk and find that the model trained with human rationales is judged to generate explanations that better support its decisions,Performance Evaluation,Performance Evaluation
visualizing attention in the Transformer at three levels of granularity,Model Optimization,Model Optimization
"The proposal of a neural network architecture, the Headline Attention Network that is designed to capture the important parts of news article causing political bias by paying headline attention",New Algorithm/ Method,New Algorithm/ Method
"we show that, contrary to our expectations, most models fail to generalize across the different datasets.",Performance Evaluation,Performance Evaluation
we examine the behavior of POS taggers across languages from the perspective of individual hidden units within the character LSTM,Performance Evaluation,Performance Evaluation
"One approach to explainable VQA is to generate visual explanations, which highlight image regions that most contributed to the system’s answer, as determined by attention mechanisms or gradient analysis",Theory Proposal,Theory Proposal
"we evaluate and compare the aforementioned methods, using two different experimental setups, thereby we assess basic properties and differences between the explanation methods",Algorithm/Method Optimization,Algorithm/Method Optimization
"we explore how word relevances can be used to build sentence-level representations, and demonstrate how the relevance visualization can help to understand the (mis-)classification of selected samples w.r.t. semantic composition.",Algorithm/Method Optimization,Algorithm/Method Optimization
We present a detailed comparison of two types of sequence to sequence models trained to conduct a compositional task,Performance Evaluation,Performance Evaluation
"we show that a seq2seq model with attention mechanism not only solves the tagging task, but also generalizes well over unseen depths",Performance Evaluation,Performance Evaluation
"we propose a new KBC model, the Context Path Model (CPM), which provides a path-based explanation for newly proposed facts.",Model Proposal,Model Proposal
we extend previous work on longdistance dependencies to tease apart the potential grounds for the different outcomes by making previous work more comparable,Resources,Resources
"we examine whether the word embeddings (trained on the whole words, not using any subword units or individual characters) capture derivational relations",Performance Evaluation,Performance Evaluation
we present a suite of experiments probing whether neural language models trained on linguistic data induce these stack-like data structures and deploy them while incrementally predicting words,Performance Evaluation,Performance Evaluation
"we define and apply representational stability analysis (ReStA), an intuitive way of analyzing neural language models.",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel approach to the study of how artificial neural network perceive the distinction between grammatical and ungrammatical sentences, a crucial task in the growing field of synthetic linguistics",New Algorithm/ Method,New Algorithm/ Method
"We propose a method for robustness evaluation without goldstandard translation references, and perform experiments and extensive analysis on all available English Grammar Error Correction (GEC) corpora",New Algorithm/ Method,New Algorithm/ Method
we introduce a visualization technique for performing further analysis,New Algorithm/ Method,New Algorithm/ Method
we attempt to detect the presence of latent representations of hierarchical structure through an exploration of the unsupervised learning of constituency structure,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a white-box attack algorithm called “Global Search” method and compare it with a simple misspelling noise and a more sophisticated and common white-box attack approach called “Greedy Search,New Algorithm/ Method,New Algorithm/ Method
We propose a simple attention-based metric called the confusion score that captures BERT’s response to syntactic distortions in an input sentence,New Algorithm/ Method,New Algorithm/ Method
"This paper presents a simple but general and effective method to debug the output of machine learning (ML) supervised models, including neural networks",Theory Proposal,Theory Proposal
"We propose a transparent deterministic method of quantifying the amount of syntactic information present in the self-attentions, based on automatically building and evaluating phrasestructure trees from the phrase-like sequences.",New Algorithm/ Method,New Algorithm/ Method
we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention,Model Proposal,Model Proposal
"We introduce novel computational models for modeling semantic bleaching, a widespread category of change in which words become more abstract or lose elements of meaning, like the development of arrive from its earlier meaning ‘become at shore.’",Model Proposal,Model Proposal
"This paper is an attempt to understand what has changed in poetry over the last 150 years within the age of mechanical reproduction of art, named so by Benjamin and Underwood",Theory Proposal,Theory Proposal
"The present study employs Word2Vec models (Mikolov et al., 2013) to investigate two questions about the FOOD>MEAT>FLESH chain.",Performance Evaluation,Performance Evaluation
The paper focuses on diachronic evaluation of semantic changes of harm-related concepts in psychology.,Performance Evaluation,Performance Evaluation
"We propose a novel, attentional, diachronic word embedding model that derives inductive biases from several contextualized, sociodemographic, features to fit the data accurately",Model Proposal,Model Proposal
"our work is also the first to estimate the usefulness of the diachronic word embeddings
for downstream task like tweet classification.",Theory Proposal,Theory Proposal
I discuss how evolutionary approaches to language change allow the modeling of cognate evolution,Theory Proposal,Theory Proposal
This paper introduces a novel method to track collocational variations in diachronic corpora that can identify several changes undergone by these phraseological combinations and to propose alternative solutions found in later periods.,New Algorithm/ Method,New Algorithm/ Method
We propose an accurate and interpretable model for identifying the era of authorship of old Thai prose,Model Proposal,Model Proposal
"We are the first to provide statistical evidence that Traiphumikatha and Pumratchatham might be both written in the Sukhothai era, contrary to previous hypotheses",Applications,Applications
we conclude that grammaticalized words and polyfunctionalized words are the strongest distinguishing indicators of prose from the Sukhothai era,Theory Proposal,Theory Proposal
we propose a data-driven methodology for identifying temporal trends in a corpus of medieval charters,New Algorithm/ Method,New Algorithm/ Method
This paper examines gender bias in historical newspapers,Resources,Resources
The paper at hand presents a computational method based on deep neural networks to predict phonetic features of historical sounds where the exact quality is unknown and to test the overall coherence of reconstructed historical phonetic features,Model Proposal,Model Proposal
"we introduce ParHistVis: a novel, free, easy-to-use, interactive visualization tool for parallel, multilingual, diachronic and synchronic linguistic data.",Theory Proposal,Theory Proposal
"We collected a large corpus for this purpose, composed of thousands of books and newspapers published in France between 1789 and 1914",Dataset Creation,Dataset Creation
"we present DiaHClust, a new approach which can be used to identify stages in diachronic change based on quantitative corpusderived data",New Algorithm/ Method,New Algorithm/ Method
"we propose an approach that fits additional, theoretically informative parameters to configure a mixture of embeddings",New Algorithm/ Method,New Algorithm/ Method
We propose a novel method to investigate the pace of language change based on the entire embedding matrix,New Algorithm/ Method,New Algorithm/ Method
"I propose that as words immigrate to new syntactic environments over time, they tend to push out words that populated these environments prior to immigration",New Algorithm/ Method,New Algorithm/ Method
we investigate semantic change across languages by measuring the semantic distance of cognate words in multiple languages,Performance Evaluation,Performance Evaluation
Verify that the represented temporal change reflects syntax rather than simply word frequency.,Theory Proposal,Theory Proposal
"The paper showcases the application of word embeddings to change in language use in the domain of science, focusing on the Late Modern English period",Theory Proposal,Theory Proposal
we model the contact possibility based on two of the most important factors in sociolinguistics to be affecting language change: age and distance,Model Optimization,Model Optimization
We reformulate the well-known word analogy task such that multiple correct answers or no correct answer at all become possible,Theory Proposal,Theory Proposal
We process historical armed conflicts data and present it as a ready-to-use evaluation set,Dataset Creation,Dataset Creation
we show that our learned cosine threshold approach can significantly improve the temporal one-to-X analogies performance by filtering out false positives.,Algorithm/Method Optimization,Model Optimization
"we investigate on is there a general trend in human languages which makes evaluative adjectives change
more intensely over time",Performance Evaluation,Performance Evaluation
we investigate to what extent diachronic semantic change occurs in the Hansard record by examining the contexts in which words appear during two different periods in the corpus,Performance Evaluation,Performance Evaluation
"we illustrate this importance and propose methods that take these risks into account
when investigating conceptual change using word
embeddings.",New Algorithm/ Method,New Algorithm/ Method
we present the first study on the compositionality of compounds over time.,Theory Proposal,Theory Proposal
we introduce a linguistic classification that allows to better characterize the variants than edit operations,Model Proposal,Model Proposal
we propose to focus on a specific concept—that of Circular Economy (CE).,Theory Proposal,Theory Proposal
This paper proposes a Gaussian Process model of sound change targeted toward questions in Indo-Aryan dialectology,Model Proposal,Model Proposal
"we apply computational methods, to the extent that it is possible, to gain insight into the nature of language change that occurred in historical West-Frisian, a lesser-used language spoken in the Dutch province of Fryslan",New Algorithm/ Method,New Algorithm/ Method
"This paper presents a significant extension of HistoBankVis, a multilayer visualization system which allows a fast and interactive exploration of complex linguistic data",Model Proposal,Model Proposal
we implement a new query strategy for selecting “unlabeled” instances from a target domain and investigate its effect on fine-tuning a generic NMT model,Dataset Creation,Dataset Creation
This paper compares morphologyaware DA word segmentation to other word segmentation approaches like Byte Pair Encoding (BPE) and Sub-word Regularization (SR).,Theory Proposal,Theory Proposal
we investigate the possibility of using POS tagging to improve word-level language identification for diglossic Arabic in a deep-learning system,Performance Evaluation,Performance Evaluation
we present syntax-ignorant n-gram embeddings to be used in sentiment analysis of several Arabic dialects,New Algorithm/ Method,New Algorithm/ Method
we propose six Arabic-English cross-lingual word embedding models,Model Proposal,Model Proposal
We introduce automatic selective diacritization as a viable step in lexical disambiguation and provide an encouraging baseline for future developments towards optimal diacritization,New Algorithm/ Method,New Algorithm/ Method
We propose several unsupervised data-driven methods for the automatic identification of ambiguous words,New Algorithm/ Method,New Algorithm/ Method
We evaluate and analyze the impact of partial sense disambiguation (i.e. selective diacritic restoration of identified homographs) in downstream applications for MSA.,New Algorithm/ Method,New Algorithm/ Method
" The proposed model
integrates various tailored techniques together,
including representation learning, feature engineering, sequence labeling, and ensemble
learning.",Model Proposal,Model Proposal
we aim at advancing performance and generalization capabilities of Arabic NLP tasks by developing new ULMs for Arabic,Resources,Resources
"We develop the first Arabic specific ULM model, called hULMonA",Resources,Resources
We introduce a newly built (small) ALG dataset for STS.,Model Proposal,Model Proposal
"We compare the performance of different DNN configurations on this dataset, namely: various combinations of Recurrent Neural NetworksConvolutional Neural Networks (CNNs),
pre-training of embeddings, including a replication of two new state-of-the art attention models.",Performance Evaluation,Performance Evaluation
we propose to leverage this sequential substructure to improve the root extraction process and morphological decomposition,Model Optimization,Model Optimization
"we investigate the effect of different Arabic segmentation schemes, sentence length and embedding sizes on learning Arabic-English (Ar-En) Bilingual word embeddings",Model Optimization,Model Optimization
"Crowdsourced Arabic Reading Comprehension Dataset (ARCD) of 1,395 questions, and translated Arabic-SQuAD: 48k translated questions",Dataset Creation,Dataset Creation
"End-toend system for open domain Arabic questions using a hierarchical TF-IDF retriever, BERT and linear answer ranking",Resources,Resources
"we show how NLP applications
can scale up their performance on dialectal data by
integrating a basic and simple preprocessing step,
i.e. segmentation",Performance Evaluation,Performance Evaluation
"we propose a semi-supervised deep learning approach, which we refer to as deep co-learning.",New Algorithm/ Method,New Algorithm/ Method
"We present a collection of morphologically annotated corpora for seven Arabic
dialects",Theory Proposal,Theory Proposal
This paper reports on the construction and annotation of a comprehensive 100-million-word corpus of contemporary Arabic,New Algorithm/ Method,New Algorithm/ Method
our goal is building an ArabicTurkish machine translation on the news domain,Theory Proposal,Theory Proposal
we propose the use of domain adaptation to address this challenge while considering the task of sentiment analysis (SA) also referred to as Opinion Mining (OM).,New Algorithm/ Method,New Algorithm/ Method
This paper presents the first version of the Open Source International Arabic News (OSIAN) corpus.,Theory Proposal,Theory Proposal
we proposed speech act classification for asynchronous conversations on Twitter using multiple machine learning methods including SVM and deep neural networks,New Algorithm/ Method,New Algorithm/ Method
"we present Mazajak , an Online Arabic sentiment analysis system that utilises deep learning and massive Arabic word embeddings",Resources,Resources
we present the results and findings of the MADAR Shared Task on Arabic Fine Grained Dialect Identification,Applications,Applications
We propose a simple classification approach that only utilizes word and character n-grams using Na¨ıve Bayes learning model.,Model Proposal,Model Proposal
the relationships between entities in an image by utilizing only image captions and object locations as the source of supervision,New Algorithm/ Method,New Algorithm/ Method
"we study multimodal summarization with various methods to summarize the intent of open-domain instructional videos stating the exclusive and unique features of the video, irrespective of modality",Model Optimization,Model Optimization
"we (i) collect human edits for machine-generated stories from two different state-of-the-art models, (ii) analyze what people edited, and (iii) advance the task of visual story post-editing",Performance Evaluation,Performance Evaluation
This technique can greatly reduce the workload of radiologists for interpreting CXR images and writing corresponding reports.,Algorithm/Method Optimization,Algorithm/Method Optimization
"an end-to-end model that extends the standard Transformer network (Vaswani et al., 2017) to learn representations directly from unaligned multimodal streams",Model Proposal,Model Proposal
"we introduce a high-level object-based visual representation to ground language into visual context in a more generalizable way, using the symbolic output of a pretrained object detection system",New Algorithm/ Method,New Algorithm/ Method
"This is done by building on the Word Mover’s Distance (WMD) metric, which measures the distance between two texts in a word embeddings space. Another contribution is the extension of WMD to allow for multiple references to be used to model object importance",Performance Evaluation,Performance Evaluation
: (i) a novel approach to MMT based on deliberation networks and structured visual information which gives state of the art results (Sections 3.2 and 5.1); (ii) a frequency bias-free investigation on the need for visual context in MMT (Sections 4.2 and 5.2); and (iii) a thorough investigation on different visual sual representations for transformer-based architectures,New Algorithm/ Method,New Algorithm/ Method
we propose to construct an imagegrounded vocabulary as a way to leverage the image semantics for image captioning,New Algorithm/ Method,New Algorithm/ Method
"the Collaborative Drawing (CoDraw) task, which combines grounded language understanding and learning effective goal-driven communication into a single, unified testbed",New Algorithm/ Method,New Algorithm/ Method
"leveraging upstream models that are capable of producing fine-grained entity names, and integrating them in a controlled manner to produce captions that are both fluent and highly informative",Model Optimization,Model Optimization
"a novel attention mechanism that consumes a word lattice and the probability scores from the ASR system. ii) The proposed approach is naturally applied to both the encoder self-attention and encoder-decoder attention. iii) Another appealing feature is that the lattice transformer can be reduced to standard latticeto-sequence model without probability scores, fitting the text translation task. iv) Extensive experiments on speech translation datasets demonstrate that our method outperforms the previous transformer and Lattice-LSTMs",Algorithm/Method Optimization,Algorithm/Method Optimization
(i) We propose a ReDAN framework that supports multi-step reasoning for visual dialog. (ii) We introduce a simple rank aggregation method to combine the ranking results of discriminative and generative models to further boost the performance. (iii) Comprehensive evaluation and visualization analysis demonstrate the effectiveness of our model in inferring answers progressively through iterative reasoning steps,New Algorithm/ Method,New Algorithm/ Method
"to encourage the model to learn speech representations which are correlated with the encoding of spoken language as a sequence of characters. Additionally, and for completeness, we also consider a second auxiliary task matching text to images.",Model Proposal,Model Proposal
• An end-to-end architecture for goal-oriented visual dialogue combining Information Gain with Reinforcement Learning. • A novel reward function for goal-oriented visual question generation to model long-term dependencies in dialogue. • Both versions of our model outperform the current baselines on the GuessWhat?! dataset for the task of identifying an undisclosed object in an image by asking a series of questions.,New Algorithm/ Method,Model Proposal
"generating text as a sequence of segments, where each segment is generated either character-by-character from a sequence model or as a single draw from a lexical memory of multi-character units. The segmentation decisions and decisions about how to generate words are not observed in the training data and marginalized during learning using a dynamic programming algorithm",Model Optimization,Model Optimization
"(1) a procedure for collecting visually rich images paired with semantically-diverse language descriptions; (2) NLVR2, which contains 107,292 examples of captions and image pairs, including 29,680 unique sentences and 127,502 images ",New Algorithm/ Method,New Algorithm/ Method
we use an implicit data gathering approach to label human activities in videos.,New Algorithm/ Method,New Algorithm/ Method
"our latent variable MMT formulation improves considerably over strong baselines, and compares favourably to the state-of-the-art. • we exploit correlations between both modalities at training time through a joint generative approach and do not require images at prediction time.",Theory Proposal,Theory Proposal
"1. We propose a model fusing transcript of narrated instructional video during procedure extraction and captioning. 2. We employ the pre-trained BERT(Devlin et al., 2018) and self-attention(Vaswani et al., 2017) layer to embed transcript, and then integrate them to visual encoding during procedure extraction. 3. We adopt the sequence-to-sequence model to generate captions by merging tokens of the transcript with the aligned video frames.",Model Proposal,Model Proposal
"We introduce a uniqueness measure to evaluate topic quality more wholistically. • W-LDA produces significantly better quality topics than existing topic models in terms of topic coherence and uniqueness. • We experiment with both the WAE-GAN and WAE-MMD variants (Tolstikhin et al., 2017) for distribution matching and demonstrate key performance advantage of the latter with a carefully chosen kernel, especially in high dimensional settings. • We discover a novel technique of adding noise to W-LDA to significantly boost topic coherence. This technique can potentially be applied to WAE in general and is of independent interest.",Performance Evaluation,Performance Evaluation
". Using a qualitative analysis, we further show that RAT works as a regularizer and prohibits NMT to overfit to TC vocabulary",Performance Evaluation,Performance Evaluation
We explore possible explanations for the finding that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks and provide a set of adaptation guidelines for the NLP practitioner.,Theory Proposal,Theory Proposal
"We propose a novel approach to handle the discrete nature of text, during training, using word embeddings.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we explore a multilingual translation model with a cross-lingually shared layer that can be used as fixed-size sentence representation in different downstream tasks.",Model Proposal,Model Proposal
we present a multilingual translation system that efficiently tackles the task of learning language-agnostic sentence representations,New Algorithm/ Method,New Algorithm/ Method
In this article we propose an adaptation of Doubly Stochastic Variational Inference for Automatic Relevance Determination (DSVIARD) for neural networks compression.,Performance Evaluation,Performance Evaluation
"We introduce a simple yet effective, self-supervised post-processing method that constructs task-specialized word representations by picking from a menu of reconstructing transformations to yield improved end-task performance (MORTY)",New Algorithm/ Method,New Algorithm/ Method
"we compile several key pitfalls of evaluation of sentence embeddings, a currently very popular NLP paradigm",Performance Evaluation,Performance Evaluation
We propose a novel model architecture and training algorithm to learn bilingual sentence embeddings from a combination of parallel and monolingual data,New Algorithm/ Method,New Algorithm/ Method
"In this work, we present POSTLE, an all-words post-specialization model for the asymmetric LE relation",New Algorithm/ Method,Model Proposal
we propose two novel constraints for composing linguistically informed and intuitively explainable noun phrase representations and show how these approaches could benefit future composition methods.,New Algorithm/ Method,Model Proposal
We apply pre-trained language models to low-resource named entity recognition for Historic German.,New Algorithm/ Method,New Algorithm/ Method
"We propose a simple entity-pair ranking (PR) protocol (PR), which is more suitable to assess model performance for KBC.",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel supertagger based on the Transformer architecture (Vaswani et al., 2017) that is capable of constructing categories inductively, bypassing the aforementioned limitations.",Algorithm/Method Optimization,Algorithm/Method Optimization
"In this work, we introduce a deep generative model that generates source and target sentences jointly from a shared latent representation",New Algorithm/ Method,Model Proposal
"In this paper, we propose BilLex (Bilingual Word Embeddings Based on Lexical Definitions) to learn bilingual word embeddings.",New Algorithm/ Method,New Algorithm/ Method
We empirically study how pre-trained embeddings and language models perform when used to analyze text from social media.,New Algorithm/ Method,Theory Proposal
This paper extends the task of probing sentence representations for linguistic insight in a multilingual domain.,Resources,Resources
We develop a fine-grained entity typing model that embeds both entity types and entity mentions in hyperbolic space.,New Algorithm/ Method,Theory Proposal
We propose to generate multilingual metarepresentations from pre-trained monolingual word embeddings. The model can learn how to construct the best word representation by mixing multiple sources without explicit language identification.,New Algorithm/ Method,Model Proposal
"we explore and evaluate several sub-word unit based embedding strategies – character n-grams, lemmatization provided by an NLP-pipeline, and segments obtained in unsupervised learning (morfessor) – to boost semantic consistency in Hungarian word vectors.",Algorithm/Method Optimization,Performance Evaluation
"The method we propose, learns discriminative features from both an autoencoder and a sentence embedding, then uses assignments from a clustering algorithm as supervision to update weights of the encoder network",Model Proposal,Algorithm/Method Optimization
"In this paper, we introduce a new approach to warm-start embedding models with morphological information, in order to reduce training time and enhance their performance.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we aim to gain a better insight into the inner workings of recurrent models with respect to incrementality while taking inspiration from and drawing parallels to this psycholinguistic perspective.",New Algorithm/ Method,Model Proposal
In this paper we investigate how representing adversarial training models as committees can be used to effectively improve the performance of QuestionAnswer (QA) Ranking.,Performance Evaluation,Model Proposal
"We propose to consider lifelong relation extraction as a metalearning challenge, to which the machinery of current optimization-based meta-learning algorithms can be applied",New Algorithm/ Method,Theory Proposal
"In this paper, we investigate the best practices for constructing the seed dictionary for a specific domain.",Algorithm/Method Optimization,Performance Evaluation
"we present a novel technique that efficiently combines PCA based dimensionality reduction with a recently proposed post-processing algorithm (Mu and Viswanath, 2018), to construct effective word embeddings of lower dimensions",Algorithm/Method Optimization,Theory Proposal
We present a modified skip-gram negative sampling algorithm that produces related word and context vectors.,New Algorithm/ Method,New Algorithm/ Method
"We present a novel approach for cross-lingual representation learning that combines methods for multi-task learning of monolingual sentence representations (Cer et al., 2018; Subramanian et al., 2018) with recent work on dual encoder methods for obtaining multilingual sentence representations for bi-text retrieval (Guo et al., 2018; Yang et al., 2019).",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel method, Modality-based Redundancy Reduction Fusion (MRRF), for understanding and modulating the relative contribution of each modality in multimodal inference tasks",New Algorithm/ Method,New Algorithm/ Method
we present the results of our experiments on learning a simple multi-task neural network model for partof-speech and semantic tagging for Welsh using a pre-trained embedding model from FastText.,Performance Evaluation,Model Proposal
In this paper we discuss different definitions of fairness and possible ways to apply them to educational applications.,Applications,Applications
"we propose a method for estimating the difficulty of MCQs from a high-stakes medical exam, where all questions were deliberately written to a common reading level.",New Algorithm/ Method,New Algorithm/ Method
we propose a novel testing strategy by combining automatic item generation (AIG) and computerized adaptive testing (CAT) in vocabulary assessment for Chinese L2 learners.,Performance Evaluation,Performance Evaluation
"we  explore the use of computational linguistic methods to investigate how taskappropriate complexity and accuracy relate to the grading of overall performance, content performance, and language performance as assigned by teachers.",Algorithm/Method Optimization,Performance Evaluation
In this paper we present a model for automatic scoring of summaries based on analysing a rhetorical structure of a student’s summary compared to that of reference summaries.,New Algorithm/ Method,Model Proposal
This paper reports on the BEA-2019 Shared Task on Grammatical Error Correction (GEC).,Resources,Resources
This paper addresses automatic correction of spelling errors where the misspelled string is not a valid word in the language.,Resources,Performance Evaluation
The present study explores how fluency filtering can affect the quality of artificial errors.,Resources,Performance Evaluation
In this paper we present first results for automated essay scoring of Norwegian learner language.,Theory Proposal,Performance Evaluation
"In this paper, we perform a systematic comparison of ELMo, BERT and Flair embeddings on a range of public GED datasets, and propose an approach to effectively integrate such representations in current methods, achieving a new state of the art on GED.",Performance Evaluation,Performance Evaluation
We formulate precise hypotheses about the possible effects of adding character representations to word-based models and test these hypotheses on large-scale real-world content scoring datasets.,Model Optimization,Performance Evaluation
"In this paper, we up the ante by exploring the potential of more sophisticated language models in GEC and offer some key insights on their strengths and weaknesses.",Model Optimization,Model Optimization
We introduce unsupervised techniques based on phrase-based statistical machine translation for grammatical error correction (GEC) trained on a pseudo learner corpus created by Google Translation.,New Algorithm/ Method,Model Proposal
"We propose a new method for combining systems (§4) that can combine many systems and relies solely on their output, i.e., it uses systems as a black-box.",New Algorithm/ Method,New Algorithm/ Method
"In this work, we investigate a similar approach by systematically generating parallel data for pretraining.",Dataset Creation,Dataset Creation
This paper describes our two systems for the three tracks in the BEA-2019 GEC Shared Task,Algorithm/Method Optimization,Algorithm/Method Optimization
This paper presents the contributions from the Cambridge University Engineering Department to the latest GEC competition at the BEA 2019 workshop.,Resources,Resources
We introduce the AIP-Tohoku grammatical error correction (GEC) system for the BEA2019 shared task in Track 1 (Restricted Track) and Track 2 (Unrestricted Track) using the same system architecture,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present our models and their results in the restricted, unrestricted, and lowresource tracks.",New Algorithm/ Method,Model Proposal
"In the following, we present our low-resource approach to GEC, which ranked as the 6th best performing system in the low-resource 192 track of the BEA 2019 shared task.",New Algorithm/ Method,Model Proposal
"In this paper, we describe the submissions from the group of Beijing Language and Culture University (BLCU) in the first two tracks.",Applications,Applications
we propose to finetune BERT on learner corpora with grammatical errors for re-ranking.,Theory Proposal,New Algorithm/ Method
"In this paper, we introduce a neural GEC system that combines the power of pre-training and transfer learning.",New Algorithm/ Method,Model Proposal
We present a system pipeline that utilises both error detection and correction models.,New Algorithm/ Method,New Algorithm/ Method
we explore two approaches of generating error-focused phrases and examine whether these phrases can lead to better performance in grammatical error correction for the restricted track of BEA 2019 Shared Task on GEC.,Algorithm/Method Optimization,Algorithm/Method Optimization
we suggest an alternative approach for GEC with “Multi-headed” architecture that uses BERT as Encoder and specialized “Heads” networks enabling additional text processing based on particular error types.,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a simple and surprisingly effective unsupervised synthetic error generation method based on confusion sets extracted from a spellchecker to increase the amount of training data,New Algorithm/ Method,New Algorithm/ Method
"This paper compares three end-to-end resources for collocation learning, all of which used the same corpus but different methods",Resources,Resources
The experiments presented in this paper aim to analyze how much each of these phenomena reveal about the L2 speaker’s native language,New Algorithm/ Method,Theory Proposal
we present a novel method based on deep learning applied to the task of automatic prerequisite relations identification between concepts to automatically create pedagogically motivated sequences of LOs.,New Algorithm/ Method,New Algorithm/ Method
our study develops an example sentence retrieval system with grammatical error detection using the large-scale Lang-8 dataset for JSL by focusing on the usability of automatic incorrect example retrieval.,New Algorithm/ Method,Model Proposal
we propose an automated algorithm which provides feedback about the specific content of non-native English speakers’ spoken responses.,New Algorithm/ Method,Resources
This paper provides an analytical assessment of student short answer responses with a view to potential benefits in pedagogical contexts.,New Algorithm/ Method,Theory Proposal
we discuss leveraging this observation in our efforts to build audio-visual content for young learners’ vocabulary learning.,Algorithm/Method Optimization,Algorithm/Method Optimization
"we discuss our system, Curio SmartChat for self-paced K-12 learning through Question Answering as a mode",New Algorithm/ Method,Model Proposal
This paper proposes a support tool for evaluating student summaries in terms of their contents by suggesting the links between the ideas of a source text and its summary.,New Algorithm/ Method,Theory Proposal
"we take first steps towards understanding the relation between expert annotations, reader proficiency and comprehension for automatic readability assessment research by conducting a web-based reading study with over 100 participants in a natural reading environment.",Performance Evaluation,Performance Evaluation
we assess the effectiveness of an automatic classification tool for the evaluation of text complexity in Italian,Performance Evaluation,Performance Evaluation
"Our goal is to create a machine teacher that can detect and exploit situations where incidental learning can occur in narrative text (stories, articles etc.).",New Algorithm/ Method,Theory Proposal
We track the development of writing complexity and accuracy in German students’ early academic language development from first to eighth grade.,Applications,Applications
We developed an automated oral proficiency scoring system for non-native English speakers’ spontaneous speech,New Algorithm/ Method,New Algorithm/ Method
"we build a system that learns relationships between LOs, and we achieve up to human-level performance in the LO relationship extraction task.",New Algorithm/ Method,New Algorithm/ Method
"we study several simplistic machine understanding systems, described in § 2.4 and empirically examine the correlation between their performance and the actual complexity of texts, measured by humans (see § 3).",Algorithm/Method Optimization,Algorithm/Method Optimization
In this paper we investigate metaphors in the context of news texts simplification.,Model Optimization,Model Optimization
"This paper presents a roadmap for now incorporating equity into the design, evaluation, and implementation of those systems",Performance Evaluation,Performance Evaluation
" In this paper, we go one step further, assisting students to learn to use confusing words appropriately in a productive task: sentence translation.",New Algorithm/ Method,Theory Proposal
"we propose a tool, Dexter, that extracts a subjectspecific corpus from a heterogeneous corpus, such as Wikipedia, by relying on a small seed corpus and distributed document representations.",Resources,Resources
"we investigate how effective are different model architectures in generating artificial, parallel data to improve a GEC model.",Model Optimization,Model Optimization
"This paper explores network structures, contextualized embeddings and pre-training strategies aimed at capturing discourse characteristics of essays",Resources,Resources
"we present a simple and effective method for assessing the proficiency of language learners, as well as the difficulty of linguistic concepts, by utilizing the Elo formula, (Elo, 1978)— in an unsupervised fashion.",New Algorithm/ Method,New Algorithm/ Method
"We present a unique dataset of student sourcebased argument essays to facilitate research on the relations between content, argumentation skills, and assessment",Dataset Creation,Dataset Creation
"we designed a principled framework of boosting response generation,
based on the recently developed theory of boosting generative models",New Algorithm/ Method,New Algorithm/ Method
"we propose an adversarial training algorithm to learn two sets
of better word weights which contribute to
two emotion dimensions in two attention layers.",New Algorithm/ Method,New Algorithm/ Method
"Two auxiliary tasks are designed to enhance
the labeling of ATE and ASC, and an extra
RNN cell ReGU is proposed to improve the
capability of feature extraction.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose an approach that provides an
entity-level representation in a simple and intuitive
manner, and also facilitates end-to-end optimization.",New Algorithm/ Method,New Algorithm/ Method
"We analyze the discriminative features that
help the best performing method, string kernels, in (i) distinguishing the Moldavian and
the Romanian dialects and in (ii) categorizing the text samples by topic.",Algorithm/Method Optimization,Algorithm/Method Optimization
we focus on the transferability of our methods from biased datasets to ones having different or no biases.,New Algorithm/ Method,New Algorithm/ Method
We propose a Siamese neural network architecture shown to outperform several baselines on both a prior convincingness data set and our own.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose a new task: emotion-cause pair extraction (ECPE). It solves the shortcomings of the traditional ECE task that depends on the annotation of emotion before extracting cause, and allows emotion cause analysis to be applied to real-world scenarios.",New Algorithm/ Method,New Algorithm/ Method
"we introduce a new word replacement order determined by both the word saliency and the classification probability, and propose a greedy algorithm called probability weighted word saliency (PWWS) for text adversarial attack.",New Algorithm/ Method,New Algorithm/ Method
we propose a strong unsupervised system for parallel sentence mining and show that the mined data improves the performance of unsupervised MT systems.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose a simple algorithm on top of these parses that allows us to control the average chunk size, which in turn limits the number of autoregressive decoding steps we have to perform.",New Algorithm/ Method,New Algorithm/ Method
"We introduce a “Co-curricular learning”, for transfer learning across data quality. It extends the single curriculum learning work in NMT and makes
the existing domain-data selection method
work better with noisy data.",Theory Proposal,Theory Proposal
"we propose an imitation learning framework for nonautoregressive machine translation, which still enjoys the fast translation speed but gives comparable translation performance compared to its auto-regressive counterpart.",New Algorithm/ Method,New Algorithm/ Method
"We extend the recently-proposed Average Lagging latency metric, making it differentiable and calculable in expectation, which allows it to be used as a training objective.",New Algorithm/ Method,New Algorithm/ Method
"Our ARNOR framework achieves significant improvement over state-of-the-art noise reduction methods, in terms of both RC performance and noise reduction effect.",Algorithm/Method Optimization,Algorithm/Method Optimization
"We evaluate our method even with contextual embeddings. The relative performance of
the adaptation alternatives remain fairly stable whether the adapted embeddings are used
on their own, or concatenated with contextsensitive embeddings",Performance Evaluation,Performance Evaluation
Our aim in this paper is to integrate the advantages of TMs into NMT systems in order to improve MT quality by utilizing existing translations for highly similar source sentences in a given TM,Applications,Applications
"we attempt to obtain diverse translations by using sentence codes to condition the sentence generation. We describe two methods to extract the codes, either with or without the help of syntax information.",Theory Proposal,Algorithm/Method Optimization
"we propose a method to distill the important domain signal as part of a multi-domain learning system, using a latent variable model in which parts of a neural model are stochastically gated based on the inferred domain.",New Algorithm/ Method,New Algorithm/ Method
"we propose a new head-modifier templatebased method to improve the readability and data fidelity of generating type descriptions, which is also the first attempt of integrating head-modifier rule into neural generative models",New Algorithm/ Method,New Algorithm/ Method
"We propose a syntax-infused VAE that integrates syntactic trees with sentences, to grammatically improve the generated sentences. i",New Algorithm/ Method,New Algorithm/ Method
"We propose a simple domain embedding approach to merge the sourceand target-domain training data, which is shown to be more effective than both direct corpus concatenation and multi-task learning.",Theory Proposal,Theory Proposal
We propose a domain adaptive dialog generation method based on meta-learning (DAML). DAML is an end-to-end trainable dialog system model that learns from multiple rich-resource tasks and then adapts to new domains with minimal training samples.,New Algorithm/ Method,New Algorithm/ Method
Our goal is to design a counter-argument generation system to address the above challenges and produce paragraph-level arguments with rich-yetcoherent content.,Theory Proposal,Theory Proposal
we propose a sequence-level training method based on a novel reinforcement algorithm for NAT to reduce the variance and stabilize the training procedure,New Algorithm/ Method,New Algorithm/ Method
"We propose SynGCN, a Graph Convolution based method for learning word embeddings. Unlike previous methods, SynGCN utilizes syntactic context for learning word representations without increasing vocabulary size.",New Algorithm/ Method,New Algorithm/ Method
"we demonstrate that our proposed methods obtain substantial improvement over state-of-the-art approaches, and also yield an advantage when used in conjunction with
methods",Algorithm/Method Optimization,Algorithm/Method Optimization
"Based on BERT, we introduce target word embedding dropout for helping substitute candidate proposal, and a substitute candidate validation method based on the substitution’s influence on the global contexts.",New Algorithm/ Method,New Algorithm/ Method
a method for assessing the credibility of claims derived from medical usergenerated content.,New Algorithm/ Method,New Algorithm/ Method
we propose a noise-added strategy to add noise samples into the training set in the form of pseudo data,Theory Proposal,Theory Proposal
"we investigate the potential of using MT methods to normalize non-canonical texts in Turkish, a morphologically-rich, agglutinative language, allowing for a very large number of common word forms.",Performance Evaluation,Performance Evaluation
", we present an improved and effective methodology to classify domain-specific freeform speech commands while utilizing this direct classification and transfer learning approaches.",Algorithm/Method Optimization,Algorithm/Method Optimization
We introduce a hybrid Convolutional Neural Network (CNN) and Long Short Term Memory Network (LSTM) approach to dementia detection that takes advantage of both targeted and implicitly learned features to perform classification.,New Algorithm/ Method,New Algorithm/ Method
propose a method that uses graph embeddings for integrating structured information from the knowledge base with unstructured information from text-based representations,New Algorithm/ Method,New Algorithm/ Method
"we introduce a demo system of
our in-house OL framework, in which we integrated our translation servers with the translators
user-friendly interface SDL Trados Studio",New Algorithm/ Method,New Algorithm/ Method
"we address these limitations
by introducing a tool that provides a flexible
and efficient way to query the Semantic Scholar
knowledge base, a semi-automatically constructed
knowledge base of scientific literature",New Algorithm/ Method,New Algorithm/ Method
"We present TARGER, an open source neural argument mining framework for tagging arguments in free input texts and for keyword-based retrieval of arguments from an argument-tagged web-scale corpus",New Algorithm/ Method,New Algorithm/ Method
we have described a method to merge multiple medical terminologies into a single network preserving both terminology-specific and cross-terminology relations.,New Algorithm/ Method,New Algorithm/ Method
"developed two systems based on bidirectional encoder representations from transformers (BERT) (Devlin, Chang, Lee, & Toutanova, 2018) for the two subtasks respectively",New Algorithm/ Method,New Algorithm/ Method
We propose an iterative algorithm to form a single representation for up-to l-length walks between the entities of a pair,New Algorithm/ Method,New Algorithm/ Method
we propose to improve the end-toend coreference resolution system by using a biaffine attention model to get antecedent scores for each possible mention,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose the HSCRF architecture which employs both word-level and segment-level labels for segment score calculation,New Algorithm/ Method,New Algorithm/ Method
we propose a joint CRF-HSCRF training framework and a naive joint decoding algorithm for neural sequence labeling,New Algorithm/ Method,New Algorithm/ Method
"We have devised a simple but effective strategy to deal with questions having options like none of the above, two of the above, all of the above, both (a) and (b) etc",Theory Proposal,Theory Proposal
we propose a method of dynamic sentence sampling (DSS) to improve the NMT training efficiency,Algorithm/Method Optimization,Algorithm/Method Optimization
we design a memory network method to capture discourse cohesion implicitly in order to improve discourse parsing,New Algorithm/ Method,New Algorithm/ Method
we apply a simple policy gradient method to train four different state-of-theart transition-based constituency parsers to maximize expected F1,Applications,Applications
"We investigated the impact of a specific
set of grammatical roles on coherence, we instead investigate a large set
of GR types, and train the model to predict the
type of role dependents participate in.",Performance Evaluation,Performance Evaluation
"We perform an extensive analysis of ways to represent the conversational-context in terms of the number of utterance history, and sampling strategy considering to use the generated sentences or the true preceding utterance.",Theory Proposal,Theory Proposal
"We present a universal representor to replace encoder and decoder, leading to a compact translation model, which fully explores the commonality between languages.",Model Optimization,Model Optimization
"we propose a new solution that can complete the multiple entityrelations extraction task with only one-pass encoding on the input corpus, and achieve a new state-of-the-art accuracy performance, as demonstrated in the ACE 2005 benchmark.",New Algorithm/ Method,New Algorithm/ Method
"We propose an entmax sparse output layer, together with a natural loss function. In largevocabulary settings, sparse outputs avoid wasting probability mass on unlikely outputs, substantially improving accuracy.",New Algorithm/ Method,New Algorithm/ Method
"we use adversarial training across tasks, to “softcode” shared and private spaces, to avoid the shared space gets too sparse.",Theory Proposal,Theory Proposal
"We note that our approach differs from other applications in the NLP literature in using the mean reward as our baseline, and in comparing different reward functions",Theory Proposal,Theory Proposal
"we aim not to merely study this phenomenon qualitatively, but instead to quantify the degree to which the language used to describe men and women is different and, moreover, different in a positive or negative way.",Theory Proposal,Theory Proposal
"It application of a well-studied graphical model to a
novel domain, outperforming previous approaches
on word and sentence-level translation retrieval tasks.",Applications,Applications
The proposed reordering mechanism can be easily integrated into the Transformer to learn reordering-aware sentence representation for machine translation.,Applications,Applications
we extend the architecture search approach to an important paradigm of transfer learning across multiple data sources: continual learning. The major problem in continual learning is catastrophic forgetting,New Algorithm/ Method,New Algorithm/ Method
"In order to adapt to non-parallel data, we design a cycle reinforcement learning algorithm CycleRL to guide the model training in an unsupervised way.",New Algorithm/ Method,New Algorithm/ Method
"We propose a new and effective framework for CQG, which is equipped with a dynamic reasoning component to generate a conversational question and is further fine-tuned via a reinforcement learning mechanism.",New Algorithm/ Method,New Algorithm/ Method
"We show the effectiveness of our method using the recent CoQA dataset. Moreover, we
show its wide applicability by using it to create multi-turn QA conversations for passages
in SQuAD",Performance Evaluation,Performance Evaluation
we propose to train the decoder in a sequence of steps that encourages the source and target embedding spaces to remain aligned during adaptation,Theory Proposal,Theory Proposal
"We introduce and experiment with various self-supervised approaches for extractive summarization, one of which achieves the new state-ofthe-art results with a basic hierarchical model.",Theory Proposal,Theory Proposal
Token-level cross-passage information interaction is implemented through the application of the proposed DynSA at relatively less computational costs.,New Algorithm/ Method,New Algorithm/ Method
QFE adaptively determines the number of evidence sentences by considering the dependency among the evidence sentences and the coverage of the question.,New Algorithm/ Method,New Algorithm/ Method
"we show that policy gradient fine-tuning learns an easy-first strategy, which reduces error propagation",Performance Evaluation,Performance Evaluation
We present the first ever application of this formalism to the task of realistic wide-coverage parsing.,Theory Proposal,Theory Proposal
"we survey the state of the art in constructing author profiling corpora for the first time, compiling a taxonomy of construction strategies applied.",Theory Proposal,Theory Proposal
"we show that in the multihop HotpotQA dataset, the examples often contain reasoning shortcuts through which models can directly locate the answer by word-matching the question with a sentence in the context.",Performance Evaluation,Performance Evaluation
"we perform a replication and a series of reproductions. These techniques were until recently quite rare in this field, despite the inherently repeatable nature of most natural language processing experiments.",Theory Proposal,Theory Proposal
We propose alternative evaluation metrics based on example difficulty and provide a reference implementation.,New Algorithm/ Method,New Algorithm/ Method
we apply a different analysis based on intermediate representation erasure to assess whether attention weights can instead be relied upon to explain the relative importance of the inputs to the attention layer itself.,New Algorithm/ Method,New Algorithm/ Method
"we propose to apply RSA to neural representations of strings from a language on one side, and to structured symbolic representations of these strings on the other side.",Theory Proposal,Theory Proposal
"we empirically show that our approach is competitive with previous work and that HardKuma has further applications,",New Algorithm/ Method,New Algorithm/ Method
We show how pre-trained BERT models can also be used and fine-tuned as the decoder in a language generation task.,Theory Proposal,Theory Proposal
we focus on the multilingual transfer setting where training data in multiple source languages is leveraged to further boost target language performance.,New Algorithm/ Method,New Algorithm/ Method
we investigate the problem of biomedical name embedding and its applications. We pay attention to the similarity between semantically related names as well as the names of the same concept.,Theory Proposal,Theory Proposal
we have manually annotated 100 sentences from the Turkish translation of the novel “The Little Prince” with AMRs to describe the differences between these annotations and their English counterparts,Theory Proposal,Theory Proposal
Our goal is to develop robust ASR systems for pathological speech and incorporate the ASR technology to detect their speech intelligibility problems.,New Algorithm/ Method,New Algorithm/ Method
The first is to provide a formal definition of the notion of informativeness applied to both sentential context (as a whole) and context words (taken individually).,Theory Proposal,Theory Proposal
"we show that ELMo models can be successfully fine-tuned on a small in-domain corpus, bringing significant improvements to strategies involving contextual embeddings.",Model Optimization,Model Optimization
"we apply and compare simple shallow capsule networks for hierarchical multi-label text classification and show that they can perform superior to other neural networks, such as CNNs and LSTMs, and non-neural network architectures such as SVMs.",Theory Proposal,Theory Proposal
"we characterize the available datasets as capturing various phenomena related to abusive language, and investigate this characterization in cross-domain classification.",New Algorithm/ Method,New Algorithm/ Method
This paper presents a new annotation tool that is designed to fill the niche of a lightweight interface for users with a terminal-based workflow.,New Algorithm/ Method,New Algorithm/ Method
"The entire operable SARAL system itself, an end-to-end CLIR and summarization system that combines SEARCHER and traditional IR techniques and applies them to text and speech documents in low-resource languages",New Algorithm/ Method,New Algorithm/ Method
We demonstrate the practical utility of our approach by applying it on a set of 67 novel event types.,Performance Evaluation,Performance Evaluation
", the system is designed to
make it easy to port to other application domains (e.g., the dialogue component factors
out domain-specific execution from domaingeneral actions such as requesting and updating slot values).",New Algorithm/ Method,New Algorithm/ Method
"we show that crossturn dependencies can be learned automatically, this eliminates the rule-based NBT component and effectively yields a fully statistical dialogue state tracker",Algorithm/Method Optimization,Algorithm/Method Optimization
we demonstrate the feasibility of using NLP for this task in the form of a highaccuracy classifier of actionable feedback,Model Optimization,Model Optimization
we apply our model to label 10.8M Twitter posts and 6.2M Reddit comments in order to evaluate the speed and type of user reactions to various news sources,Model Proposal,Model Proposal
we aim to give transparency and user-comprehensible explainability,Theory Proposal,Theory Proposal
we investigate the empirical hypothesis that NMT is able to learn from the good chunks of a noisy sentence and describe a simple way of utilizing such chunk-level feedback in NMT training,Theory Proposal,Theory Proposal
"We provide a detailed empirical comparison of various attention transformations, including softmax, sparsemax",Performance Evaluation,Performance Evaluation
We demonstrate the benefits of multilingual Neural NER on low-resource languages,Theory Proposal,Theory Proposal
"we provide a large number of highquality training examples which can be bootstrapped from state-of-the-art Open IE systems, which is released for future research",Dataset Creation,Dataset Creation
we conduct comprehensive experiments on a large benchmark dataset to compare different Open IE systems to show the neural approach’s promising potential,Performance Evaluation,Performance Evaluation
"We devise a new formulation of graphstructured stack (Tomita, 1991) which requires no extra bookkeeping, proving a new theorem that gives deep insight into GSS",New Algorithm/ Method,New Algorithm/ Method
"our parser is substantially faster for long sentences on the Penn Treebank, and orders of magnitude faster for end-to-end discourse parsing",Algorithm/Method Optimization,Algorithm/Method Optimization
"We evaluate the proposed model over two
real-world datasets. We adapt distant supervision with co-reference resolution and paraphrase detection to obtain high-quality training
data.",Model Optimization,Model Optimization
"We introduce the task of email subject line generation
(SLG) and build a benchmark dataset AESLC",New Algorithm/ Method,New Algorithm/ Method
"We propose the Multimodal EmotionLines Dataset (MELD), which includes not only
textual dialogues, but also their corresponding visual and audio counterparts.",Dataset Creation,Dataset Creation
"we extend, improve, and further develop the EmotionLines dataset for the multimodal
scenario.",Dataset Creation,Dataset Creation
"introduce a
new color-grid reference task and data set consisting of higher dimensional objects and more complex speaker language",Dataset Creation,Dataset Creation
"We propose a set of cross-domain coherence
datasets with increasingly difficult evaluation
protocols.",Dataset Creation,Dataset Creation
"We introduce a novel large corpus containing
33564 text samples written in the Moldavian
and the Romanian dialects",Dataset Creation,Dataset Creation
"We propose OneSeC (One Sense per Category), a novel fully-automatic method
that produces multilingual sense-annotated
datasets on a large scale by mapping
Wikipedia categories to word senses.",New Algorithm/ Method,New Algorithm/ Method
"we present SP-10K, which is unprecedented in both size and the number of SP
relations. It contains 10,000 selectional triplets
consisting of 2,500 frequent verbs, nouns, and
adjectives in American English.",Dataset Creation,Dataset Creation
"We propose a new dataset, ChID, for clozestyle reading comprehension in Chinese language. ChID contains 581K passages and
729K blanks from three domains",Dataset Creation,Dataset Creation
we explore the use of noisy counseling data obtained from public sources for the analysis of counseling quality,Performance Evaluation,Performance Evaluation
we obtain substantial improvement over prior models for both entities and negations on the 2010 i2b2/VA challenge task as well as a proprietary de-identified clinical note dataset for medical conditions,Model Optimization,Model Optimization
"we present a new data set, IBMEviConv, of pairs of evidence labeled for convincingness, designed to be more challenging than existing alternatives.",Dataset Creation,Dataset Creation
"Based on a benchmark ECE corpus, we construct a corpus suitable for the ECPE task. The experimental results prove the feasibility of the ECPE task as well as the effectiveness of our approach.",Dataset Creation,Dataset Creation
We introduce the first large-scale multi-document summarization datasets in the news domain.,Dataset Creation,Dataset Creation
"To learn such an embedding, we create the largest distant supervision dataset by linking the entire English ClueWeb09 corpus to Freebase. The dataset is publicly available",Dataset Creation,Dataset Creation
"We extend the GPT to handle bag-level, multi-instance training and prediction for distantly supervised datasets, by aggregating sentence-level information with selective attention to produce bag-level predictions",New Algorithm/ Method,New Algorithm/ Method
"We perform extensive experiments on five publicly available datasets for entity alignment tasks, and achieve significant improvements of 5% Hits@1 on average. Further ablation study demonstrates the effectiveness of our key components.",Dataset Creation,Dataset Creation
"We propose new formulations for training topicspecific embeddings on a limited target corpus DT by adapting generic pre-trained word embeddings E, and/or selecting from any available broad-coverage corpus DS",New Algorithm/ Method,New Algorithm/ Method
We also show that the existing paths in the dataset are not ideal for evaluating instruction following because they are direct-to-goal shortest paths. We join existing short paths to form more challenging extended paths to create a new data set,Performance Evaluation,Performance Evaluation
We create a novel human language guided image editing dataset to boost the study in describing visual relationships,New Algorithm/ Method,New Algorithm/ Method
"We contribute a new dataset, named as VID-sentence, to serve as a benchmark for the novel WSSTG task",Dataset Creation,Dataset Creation
we propose a data-collection task formulated as a collaborative game prompting two online participants to refer to images utilising both their visual context as well as previously established referring expressions.,Dataset Creation,Dataset Creation
"we propose a new dataset with two new automatic metrics for this task, and experiments show that our method achieves stateof-the-art performance on both datasets.",Dataset Creation,Dataset Creation
"We propose a method to construct a pseudo parallel dataset for the surface realization model, without the need of labeled data.",New Algorithm/ Method,New Algorithm/ Method
"we create a new dataset, that contains 1716 summaries for papers from several computer science conferences, that can be used as training data",Dataset Creation,Dataset Creation
the new state-of-the-art performance on five real-world datasets in a setting where a model is able to determine the number of keyphrases to generate.,New Algorithm/ Method,New Algorithm/ Method
"we present a novel dataset, BIGPATENT, consisting of 1.3 million records of U.S. patent documents along with human written abstractive summaries.",Dataset Creation,Dataset Creation
a large-scale multi-sentence compression corpus is introduced along with a manually created test set for future research. We release source code and data here,Dataset Creation,Dataset Creation
"we introduce a cross-lingual OpenQA dataset called XQA. It consists of a training set in English, and development and test sets in English, French, German, Portuguese, Polish,Chinese, Russian, Ukrainian, and Tamil.",Dataset Creation,Dataset Creation
We create a new dataset for multi-modal Twitter sarcasm detection and release it,Dataset Creation,Dataset Creation
we explore the task of predicting human activities from user-generated content. We collect a dataset containing instances of social media users writing about a range of everyday activities.,Dataset Creation,Dataset Creation
"We propose a silver dataset containing user-generated reviews labelled with a approximation of the socio-economic status of their author, based on the price range of restaurants",Dataset Creation,Dataset Creation
"To address real-world, large-scale application scenarios and to facilitate the possibility of adopting modern ‘data-hungry’ language models in this domain, we collect a new largescale book review dataset from goodreads.com.",Dataset Creation,Dataset Creation
"we report on the construction of the first large-scale corpus of celebrity profiles, describing our acquisition approach based on a reliable matching of Twitter accounts to Wikidata items.",Theory Proposal,Theory Proposal
"We create a dataset for ranking constructive comments including 100K+ Japanese comments with constructiveness scores, in collaboration with Yahoo! News. Our dataset will be publicly available.",Dataset Creation,Dataset Creation
We propose the task of cross-modal automatic commenting (CMAC) and construct a large-scale dataset.,Dataset Creation,Dataset Creation
We introduce a novel data set of tweets posted by U.S. politicians who self-reported their tweets using a signature.,Dataset Creation,Dataset Creation
We use a back-translation procedure that generates pseudo source sentences paired with the true summaries to build a training corpus for the cross-lingual ASSUM.,New Algorithm/ Method,New Algorithm/ Method
A massive collection of parallel texts for over 300 diverse languages is our main contribution to facilitate multilingual NLP,Dataset Creation,Dataset Creation
We propose the creation of a dataset to learn the QAR strategy with weak supervision.,Dataset Creation,Dataset Creation
we build a corpus of New Zealand English tweets containing Maori loan- ¯ words,Theory Proposal,Theory Proposal
We present a Telugu-English code-mixed corpus with the corresponding named entity tags.,Theory Proposal,Theory Proposal
", we introduce the French
CASS dataset, composed of judgments from
the French Court of cassation and their corresponding summaries.",Dataset Creation,Dataset Creation
"we introduce manually verified corpus of compelling fake and questionable news articles on the USA politics, containing around 700 articles from Aug-Nov, 2016",Theory Proposal,Theory Proposal
we visualize probably the first job posting data set with labels from domain experts showing the intensity of PhD-level research skills,Dataset Creation,Dataset Creation
"we present a ranking-based model that has been successfully applied to predicting PhD skills intensity from job postings, with empirical performance evaluation.",Model Proposal,Model Proposal
we use a generic and simple frame-slots data-structure with pre-defined dialogue policies that allows for fast design and implementation at the price of some flexibility reduction.,New Algorithm/ Method,New Algorithm/ Method
"We benchmark OpenKiwi on two datasets from WMT 2018 (English-German SMT and NMT), yielding state-of-the-art performance on the word-level tasks and near state-of-the-art in the sentencelevel tasks",Performance Evaluation,Performance Evaluation
"we provide an annotated dataset of 5,727 partwhole relations , which contains 8 subtypes for the bootstrapping RE system",Dataset Creation,Dataset Creation
we study how to automatically extract such relationship through a sentence-level relation classifier and aggregating the scores of entity pairs from a large corpus,Theory Proposal,Theory Proposal
we propose a large structured dataset of automatically linguistically annotated software developer conversations for feature exploration,Dataset Creation,Dataset Creation
we propose a smaller manually-labeled subset of that dataset for hypothesis testing,Dataset Creation,Dataset Creation
We demonstrate the usefulness of this general-domain dataset by applying an existing visual-linguistic annotation framework that successfully annotates image regions by combining gaze and language data,Theory Proposal,Theory Proposal
"we study the performance of plagdet, the main measure for Plagiarism Detection Systems evaluation, on manually paraphrased plagiarism datasets (such as PAN Summary)",Performance Evaluation,Performance Evaluation
we design a large scale news dataset with 1.02 million sentence compression pairs are compiled for this task in addition to 200 manually created sentences.,Dataset Creation,Dataset Creation
"We annotate the first medical dataset for dialogue system that consists of two parts, one is self-reports from patients and the other is conversational data between patients and doctors",Dataset Creation,Dataset Creation
we incorporate knowledge of the lexico-syntactic fixedness of VNCs — automatically acquired from corpora using the method of Fazly et al. (2009) — into our various embedding-based approaches,Theory Proposal,Theory Proposal
we verified the effectiveness of the method on public data sets,Performance Evaluation,Performance Evaluation
"we construct the discourse dependency corpus SciDTB1 . based on scientific abstracts, with the reference to the discourse dependency representation in Li et al. (2014)",Dataset Creation,Dataset Creation
"we show that metadata is crucial for modeling voting outcomes in new contexts, as changes between sessions lead to changes in the underlying data generation process",Model Optimization,Model Optimization
"We introduce pivot translation into unsupervised NMT to improve the accuracy of distant
languages.",Model Optimization,Model Optimization
"We propose an n-gram based attention model
to effectively map the multi-word mentions of
entities and their relationships into uniquely
identified entities and predicates.",Model Proposal,Model Proposal
"we empirically show that multimodal learning with audio and text can indeed reduce prediction error, compared to previous work that relies
on text only.",Performance Evaluation,Performance Evaluation
"we try to model the multidimensional learning task as a multi-task learning
task through adversarial learning.",Model Proposal,Model Proposal
"We propose global fusion to obtain an overall view of multimodal embeddings via a specifically designed ABS-LSTM, in which we integrate two levels of attention mechanism: Regional Interdependence Attention and Global Interaction Attention.",New Algorithm/ Method,New Algorithm/ Method
"We propose the factored tensor network FTN
to model the complex semantic interactions,
and it has the advantage of significantly reducing the complexity of the original model",Model Optimization,Model Optimization
"This paper codifies model and task agnostic principles for
informative error analysis, and presents Errudite, an interactive tool for better supporting this process.",Model Proposal,Model Proposal
"we propose a new fully-trainable, language-independent mention detectors that outperform the Stanford CORE mention detector in a variety of genres.",Algorithm/Method Optimization,Algorithm/Method Optimization
introduce a constrained decoding approach for Seq2Seq models that leverages this representation to improve semantic correctness,New Algorithm/ Method,New Algorithm/ Method
"We show that the proposed approaches outperform baselines in both indomain and cross-domain evaluation, demonstrating that the model learns domain-agnostic walking
patterns that are generalizable for unseen domains.",Model Optimization,Model Optimization
we propose a graph-based evidence aggregating and reasoning (GEAR) framework which enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multievidence information.,New Algorithm/ Method,New Algorithm/ Method
our goal is to induce semantic information from the proposed multimodal model into an acoustic model. We study a more challenging scenario where we establish that lexical information is available during,Model Proposal,Model Proposal
"We introduce a multi-task learning framework based on the neural network model, transformer",New Algorithm/ Method,New Algorithm/ Method
"we present a novel approach to CWI based on sequence modelling. Our system is capable of performing CWI in context, does not require extensive feature engineering and outperforms state-of-the-art systems on this task",New Algorithm/ Method,New Algorithm/ Method
we incorporate the global lattice structure into the model through reachability masks that mimic the pairwise conditioning structure of previous recurrent approaches.,Model Optimization,Model Optimization
"we introduce a model suitable for this scenario, and demonstrate that it is effective on our new benchmarks without sacrificing performance as measured with BLEU.",Model Proposal,Model Proposal
"We extend a novel graph neural network model with generated parameters, to enable relational message-passing with rich text information, which could be applied to process relational reasoning on unstructured inputs such as natural language.",Model Proposal,Model Proposal
"We incorporate the embeddings of characterwise/word-wise BIO tag from NER task to enrich the input representation, which proves to be very effective not only for our model but for other models as well.",Model Optimization,Model Optimization
"We propose a novel neural framework named MGNER for Multi-Grained Named Entity Recognition, aiming to detect both nested and non-overlapping named entities effectively in a single model",New Algorithm/ Method,New Algorithm/ Method
"MGNER is highly modularized. Each module
in MGNER can adopt a wide range of neural network designs. Moreover, MGNER can
be easily extended to many other related information extraction tasks.",Applications,Applications
we show experimental results show that our model significantly outperforms previous methods of using gazetteers and the state-of-the-art Chinese NER models,Model Optimization,Model Optimization
"we propose an alternative approach to address this limitation, and in particular, to train models by marginalizing over the set of segmentations",Model Optimization,Model Optimization
We propose a phrase prediction model that improves the performance of state-of-the-art word-level language models,Model Optimization,Model Optimization
We introduce an adaptive optimizer to selfadjust the number of iterations for each example in order to improve instance-level convergence and enhance the reliability of routing processes.,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a neural P2C conversion model augmented by an online updated vocabulary with a sampling mechanism to support open vocabulary learning during IME working.,Model Proposal,Model Proposal
we propose a method to simultaneously learn tokenization and text classification to address these problems. Our model incorporates a language model for unsupervised tokenization into a text classifier and then trains both models simultaneously,New Algorithm/ Method,New Algorithm/ Method
"we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others.",Performance Evaluation,Performance Evaluation
"We introduce LSTMEmbed, an RNN model based on a bidirectional LSTM for learning word and sense embeddings in the same semantic space, which – in contrast to the most popular approaches to the task – takes word ordering into account.",Model Proposal,Model Proposal
The proposed translation models outperform the state-of-the-art NMT baselines systems with a similar number of parameters and achieve comparable results compared to NMT systems with much more parameters.,Applications,Applications
"we analyze the performance of different models on different types of constituents, and find that our model shows substantial improvement on noun phrases and prepositional phrases which are common in captions",Performance Evaluation,Performance Evaluation
"We design novel relationalspeaker models, including a dynamic relational
attention module, to handle the problem of twoimage captioning by focusing on all their visual
relationships",Model Proposal,Model Proposal
We conduct extensive experiments showing that our model outperforms the state-of-theart both in automated and human evaluations.,Performance Evaluation,Performance Evaluation
"We propose a sentiment intensity controlled generative model Seq2SentiSeq, in which a sentiment intensity value is introduced via a Gaussian kernel layer to achieve fine-grained sentiment control of the generated sentence.",Model Proposal,Model Proposal
"We propose to break up the table-to-text generation into two stages with two separate models, so that the model can be trained with fewer annotated data.",Model Proposal,Model Proposal
"We redesign the ELBO of the joint log likelihood, to accommodate two separate latent spaces in one VAE framework, for two SIVAE model variants based on different intuitions, which can be further used for other applications.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we utilize a multi-level decoder structure to capture the coherent long-term structure inherent in long-form texts, by generating intermediate sentence representations as highlevel plan vectors.",New Algorithm/ Method,New Algorithm/ Method
"we extend supervised DIM to semi-supervision setup (SEMIDIM), where unsupervised learning objectives based on unlabeled data are also optimized",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose that the rich multi-modal data from recording the meeting environment, especially cameras facing each participant, can provide speaker interaction and participant feedback to discover salient utterances.",Theory Proposal,Theory Proposal
We introduce multi-style learning that enables our model to control answer styles and improves RC for all styles involved.,New Algorithm/ Method,New Algorithm/ Method
We use a co-attention mechanism to model sentence coherence and integrate the coherenceand entailment-based attentions into our proposed hierarchical attention framework for better evidence embedding,New Algorithm/ Method,New Algorithm/ Method
we analyze the usefulness of a user’s network information over the user’s tweets for predicting its occupational group. We extend the existing dataset for occupation classification by introducing the network information about a user,Theory Proposal,Theory Proposal
we propose the WMM2Seq for dialog generation which separates the storage of dialog history and KB information by using the episodic and semantic memories and then leverages the working memory to interact with them,Theory Proposal,Theory Proposal
"we consider an extension to the FC scenario, where a practitioner has the computational capacity to fit multiple models in parallel.",New Algorithm/ Method,New Algorithm/ Method
It seamlessly integrates implicit anticipation and translation in a single model that directly predicts target words without explictly hallucinating source ones.,Model Proposal,Model Proposal
Our prefix-to-prefix framework is tailored to simultaneous translation and trained from scratch without using full-sentence models.,New Algorithm/ Method,New Algorithm/ Method
"We combine the ability of BERT to handle sentence pair inputs together with its pre-trained multilingual model, to use both the src and mt in a cross-lingual encoder, that takes a multilingual sentence pair as input",New Algorithm/ Method,New Algorithm/ Method
"we propose a framework, which
we call LANGRANK, to empirically answer the
question posed above: given a particular task lowresource language and NLP task, how can we determine which languages we should be performing
transfer",New Algorithm/ Method,New Algorithm/ Method
"We propose a morphology-aware alignment model for unsupervised bilingual lexicon induction, which aims to alleviate the adverse effect of morphological variation by introducing grammatical information learned from pre-trained language model.",Model Proposal,Model Proposal
"We demonstrate a speed-up of several orders of magnitude when predicting word similarity by vector operations on our embeddings as opposed to directly computing the respective path-based measures, while outperforming various other graph embeddings",New Algorithm/ Method,New Algorithm/ Method
"we design an NPI-based model that simulates the editing process by a programmer and an interpreter, which outperforms the state-of-the-art neural MT-based TS models by large margins in terms of SARI and is judged by humans as simpler and overall better",Model Proposal,Model Proposal
"It proposes the use of a unique combination of lexical, sentiment, durational and further derivative features of adjacency pairs to train traditional classification models",Dataset Creation,Dataset Creation
"r aims to improve existing document
embedding models (Le and Mikolov, 2014; Li
et al., 2016a) by training document embeddings
using cosine similarity instead of dot product",Model Optimization,Model Optimization
r presents an alternative to the current morpheme-based scheme for Japanese word segmentation,Theory Proposal,Theory Proposal
"we propose a joint neural model to simultaneously extract names and kinships from obituaries, which combines a two-layer bidirectional Long Short-Term Memory (bi-LSTM) (Hochreiter and Schmidhuber, 1997) and a unique tagging scheme",Model Proposal,Model Proposal
"we exploited ensembles based on a pretrained language representation with a neural transformer architecture (BERT) (Tasks 1
and 4) and a CNN-BiLSTM(-CRF) network
within a multi-task learning scenario",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel architecture that encodes
locally stored domain information into sentence representation.",New Algorithm/ Method,New Algorithm/ Method
"we propose a new approach for learning thematic relatedness between sentences, formulating the related TDC task and creating a thematic clustering benchmark",New Algorithm/ Method,New Algorithm/ Method
"we propose a new approach to triclustering, achieving state-of-the-art performance on the frame induction task",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose an approach based on linguistic knowledge for identification of aliases mentioned using proper nouns, pronouns or noun phrases with common noun headword",New Algorithm/ Method,New Algorithm/ Method
we propose a new parallel recurrent neural network model for entity recognition,Model Proposal,Model Proposal
we use named entities as domain-specific terms for newscentric content and present a new weighting model for Latent Dirichlet Allocation,Model Proposal,Model Proposal
we study the problem of word ambiguities in definition modeling and propose a possible solution by employing latent variable modeling and soft attention mechanisms,Theory Proposal,Theory Proposal
The proposed CNN model performs comparatively or better than LSTM-based baselines on two different datasets,Model Proposal,Model Proposal
we extend the beam search to introduce more flexibility,Algorithm/Method Optimization,Algorithm/Method Optimization
"we analized the the encoder-decoder framework learns the sequence-to-sequence task directly, bypassing other hand-crafted patterns and alleviating error propagation",Performance Evaluation,Performance Evaluation
"we model the response
selection problem as a multi-class classification
problem with sequences as input, where the label of the true response is set to one and the
other candidates are set to zero.",Model Proposal,Model Proposal
"we introduce a different way to
handle reentrancy, and propose an attention-based model that treats AMR parsing as sequence-tograph transduction.",Model Proposal,Model Proposal
"we propose a novel
reliability-aware name tagging model to tackle
this issue. We design a set of word frequencybased reliability signals to indicate the quality
of each word embedding.",Model Proposal,Model Proposal
"We propose an end-to-end model for extract-
ing and canonicalizing triples to enrich a KB.
The model reduces error propagation between
relation extraction and NED, which existing
approaches are prone to.",Model Proposal,Model Proposal
"We propose the novel AGGCNs that learn a
“soft pruning” strategy in an end-to-end fashion, which learns how to select and discard
information. Combining with dense connections, our AGGCN model is able to learn a
better graph representation",Model Proposal,Model Proposal
"we proposed DihEdral to model
the relation in KG with the representation of dihedral group. The elements in a dihedral group are
constructed by rotation and reflection operations
over a 2D symmetric polygon.",Model Proposal,Model Proposal
we propose a novel recursive neural network architecture consisting of a decomposable attention framework in every branch,New Algorithm/ Method,New Algorithm/ Method
"It proposes a probabilistic model,
JELTA, which jointly estimates the credibility of
claims and the trustworthiness of sources, when
claims are made by sources directly, indirectly, or
both",Model Proposal,Model Proposal
"Our framework incorporates a TE model
as part of the global inference framework as a way
to link evidence (and thus, sources) to claims.",Model Proposal,Model Proposal
"We propose
a novel model to generate email subjects. Our automatic and human evaluations demonstrate that
our model outperforms competitive baselines and
approaches human-level quality.",Model Proposal,Model Proposal
"We propose a generic hierarchical fusion strategy, termed ‘divide, conquer and combine’, to explore both local and global interactions in multiple stages each focusing on
different dynamics.",New Algorithm/ Method,New Algorithm/ Method
"we propose an interactive multitask learning network (IMN), which solves both
tasks simultaneously, enabling the interactions between both tasks to be better exploited.",Model Proposal,Model Proposal
"we propose a novel Transfer
Capsule Network (TransCap) model to transfer
sentence-level semantic knowledge from DSC to
ASC.",Model Proposal,Model Proposal
"we
propose a progressive self-supervised attention learning approach for neural ASC models, which automatically mines useful attention supervision information from a training
corpus to refine attention mechanisms.",Model Optimization,Model Optimization
"A novel framework DOER is proposed to address the aspect term-polarity co-extraction
problem in an end-to-end fashion. A crossshared unit (CSU) is designed to leverage the
interaction of the two tasks",Model Proposal,Model Proposal
"We propose a MTL approach to coherence assessment
and compare it against a number of baselines",New Algorithm/ Method,New Algorithm/ Method
"we
designed a novel discourse relation identification pipeline specifically tuned for opendomain dialogue systems.",New Algorithm/ Method,New Algorithm/ Method
"we introduce Word Injection to LSC, a modeling idea drawn from term extraction, that overcomes the problem of vector space alignment.",Model Proposal,Model Proposal
"We introduce unified models for multi-task learning that learn three sets of features: task, task group, and task universe features;",Model Proposal,Model Proposal
"We propose a knowledge attention module,
which helps to select the most related and helpful knowledge from different KGs",Theory Proposal,Theory Proposal
we propose An end-to-end hierarchical neural model consisting of a shared encoder and different decoding schemes to jointly extract entities and negations.,Model Proposal,Model Proposal
"we present a novel method inspired by the determinantal point process for multi-document summarization. The method includes a diversity measure assessing the redundancy between sentences, and a quality measure that indicates the importance of sentences",New Algorithm/ Method,New Algorithm/ Method
we propose to learn topic-aware news representations by jointly training the news encoder with an auxiliary topic classification task,New Algorithm/ Method,New Algorithm/ Method
Proposing a novel end-toend sequence labeling architecture utilizing LDL to model the emphasis words in a given text.,New Algorithm/ Method,New Algorithm/ Method
"We propose a classifier by integrating multiple text feature sets, including the publicly available pre-trained textual language model Bi-directional Encoder Representation from transformers (BERT)",New Algorithm/ Method,New Algorithm/ Method
we propose the use of lattice positional embeddings to model positioning and ordering of lattice nodes.,Model Proposal,Model Proposal
"We propose the novel task of learning general-purpose embedding of textual relations, which has the potential to facilitate a wide range of relational understanding tasks",New Algorithm/ Method,New Algorithm/ Method
We present a novel and concise joint model to handle the joint type inference problem based on graph convolutional network,Model Proposal,Model Proposal
"We introduce a binary relation classification
task to explore the structure of entity-relation bipartite graph in a more efficient and interpretable way",New Algorithm/ Method,New Algorithm/ Method
"we propose GraphRel, a neural end-to-end joint model for entity recognition and relation extraction that is the first to handle all three key aspects in relation extraction",Model Proposal,Model Proposal
"we propose a neural pattern diagnosis framework, DIAG-NRE, that can automatically summarize and refine highquality relational patterns from noise data with human experts in the loop.",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel Multi-channel GNN model MuGNN that learns alignmentoriented embeddings by encoding graphs from different perspectives: completion and pruning, so as to be robust to structural differences.",Model Proposal,Model Proposal
"we propose a lightweight recurrent network (LRN), which combines the strengths of ATR and SRU. The structure of LRN is simple: an input gate and a forget gate are applied to weight the current input and previous hidden state, respectively",Model Proposal,Model Proposal
we focus on perfectly decodable encoding of sentences which will be very useful in designing good generative models that can generate longer sentences.,Theory Proposal,Theory Proposal
"we present a new approach to counterfactual data augmentation 
for mitigating gender stereotypes associated with
animate nouns for morphologically rich languages.",New Algorithm/ Method,New Algorithm/ Method
"we introduce a generative latent-variable model that jointly represents adjective choice, with its sentiment, given the natural gender of a head noun.",Model Proposal,Model Proposal
we first propose a relation-aware semantic projection model to estimate probabilistic distributions of lexical relations over unlabeled data.,Model Proposal,Model Proposal
"we introduce a novel ‘continual architecture search’ (CAS) approach, where the model parameters evolves and adapts when trained sequentially on a new task while maintaining the performance on the previously learned tasks.",New Algorithm/ Method,New Algorithm/ Method
we propose a novel aspect-aware coarse-tofine decoder for generating product reviews. We first utilize unsupervised topic models to extract aspects and tag review sentences with aspect labels.,New Algorithm/ Method,New Algorithm/ Method
We propose a novel metaphor and personification generation model with a rhetorically controlled encoder-decoder.,New Algorithm/ Method,New Algorithm/ Method
We propose a memory-augmented neural model with adversarial training to integrate external commonsense knowledge into topicto-essay generation.,Model Proposal,Model Proposal
"we propose various multi-level network structures for the VAE model (ml-VAE), to address coherency and repetitiveness challenges associated with long-form text generation.",Theory Proposal,Theory Proposal
"we propose a novel data-totext generation model with two modules, one for saliency tracking and another for text generation.",Model Proposal,Model Proposal
"we propose the Extended Transformer model for Abstractive Document Summarization (ETADS) to tackle the above issues. Specifically, we design a novel focusattention mechanism and saliency-selection network equipped in the encoder and decoder",Model Proposal,Model Proposal
We propose a novel unsupervised end-to-end model to generate an abstractive summary of a single product review while inducing a latent discourse tree,Model Proposal,Model Proposal
We propose an RL approach with a novel adaptive reward function that explicitly encourages the model to generate both sufficient and accurate keyphrases,New Algorithm/ Method,New Algorithm/ Method
a new evaluation method that considers name variations of the keyphrase labels,Performance Evaluation,Performance Evaluation
"we propose a multi-modal hierarchical attention mechanism across topic segments, utterances, and words. We learn topic segmentation as an auxiliary task and limit the attention within each segment.",New Algorithm/ Method,New Algorithm/ Method
"we propose an end-to-end MRC model named as Knowledge Aided Reader (KAR), which explicitly uses the above extracted general knowledge to assist its attention mechanisms.",Model Proposal,Model Proposal
"we propose RE3QA, a neural question answering model that conducts the full retrieve-read-rerank process for multi-document RC tasks.",Model Proposal,Model Proposal
We propose QFE for explainable multi-hop QA. We use the multi-task learning of the QA model for answer selection and QFE for evidence extraction.,New Algorithm/ Method,New Algorithm/ Method
"We devise a new approach KTNET to MRC. It outperforms competitive baselines, ranks the 1st place on the ReCoRD leaderboard, and is also the best single model on the SQuAD",Model Optimization,Model Optimization
We propose two novel methods to handle the simplified HPSG parsing.,New Algorithm/ Method,New Algorithm/ Method
"We are the first to introduce the deep transition architecture for sequence labeling, and further enhance it with the global contextual representation at the sentence level, named GCDT",Theory Proposal,Theory Proposal
"We conduct elaborate investigations of global contextual representation, model complexity and effects of various components in GCDT.",Performance Evaluation,Performance Evaluation
We propose a novel claim verification framework based on hierarchical attention neural networks to learn sentence-level evidence embeddings to obtain claim-specific representation,New Algorithm/ Method,New Algorithm/ Method
"we propose a simple, automatic recipe towards reducing hallucination for neural surface realisers by enhancing the semantic equivalence between pairs of MRs and utterances.",Theory Proposal,Theory Proposal
"We present a novel co-attention model, which aims at capturing intrinsic interactions between multiple modal contents.",Model Proposal,Model Proposal
We Propose a novel path-based reasoning approach for multi-hop QA over text that produces explanations in the form of explicit paths,New Algorithm/ Method,New Algorithm/ Method
"We design A model, PathNet, which aims to extract implicit relations from text and compose them",Model Proposal,Model Proposal
We define author context as the embedded representation of their historical posts on Twitter and suggest neural models that extract these representations.,Theory Proposal,Theory Proposal
we develop a novel framework for temporal relation representation that puts event duration front and center.,New Algorithm/ Method,New Algorithm/ Method
We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence.,New Algorithm/ Method,New Algorithm/ Method
we propose a novel model namely Reference Network that incorporates the referring process into translation decoding of NMT.,Model Proposal,Model Proposal
we propose a hard-attention based NMT model which selects a subset of source tokens for each target token to effectively handle long sequence translation.,Model Proposal,Model Proposal
we propose a sentencelevel agreement module to directly minimize the difference between the representation of source and target sentence.,New Algorithm/ Method,New Algorithm/ Method
"we introduce the topic entity graph, a local sub-graph of an entity, to represent entities with their contextual information in KG.",Theory Proposal,Theory Proposal
we focus on methods for cross-lingual transfer to distant languages and propose to learn a generative model with a structured prior that utilizes labeled source data and unlabeled target data jointly,Theory Proposal,Theory Proposal
"we propose to encode relational knowledge in a separate word embedding, which is aimed to be complementary to a given standard word embedding.",New Algorithm/ Method,New Algorithm/ Method
we propose a word embedding model which explicitly aims to learn context vectors that are organised in clusters.,Model Proposal,Model Proposal
"We propose a BERT-based end-to-end lexical substitution approach without relying on
any annotated data and external linguistic resources.",New Algorithm/ Method,New Algorithm/ Method
We propose a novel Seq2Seq model that decomposes the paraphrase generation into learning paraphrase patterns at different granularity levels separately,Model Proposal,Model Proposal
a methodology for testing existing models and proposed extensions.,New Algorithm/ Method,New Algorithm/ Method
proposing the use of Inverted Softmax and Cross-modal Local Scaling to replace naive nearest neighbor search (for inference).,Theory Proposal,Theory Proposal
"we present a recurrent neural model to detect ad hominem attack in a paragraph, and we experiment with various other models to compare them",Model Proposal,Model Proposal
We put forward a shared Bi-LSTM-CRF model for efficiently integrating multiple embeddings and sharing useful linguistic features;,Model Proposal,Model Proposal
"we propose a
new training schedule that allows the system
to scale to more languages without modification of the previous components based on
joint training and language-independent encoder/decoder modules allowing for zero-shot
translation.",New Algorithm/ Method,New Algorithm/ Method
we develop a neural model based on a CNN-LSTM architecture that learns to detect AD and related dementias using targeted and implicitly-learned features from conversational transcripts,Model Proposal,Model Proposal
we build the NMT systems for both EN-ID and ID-EN directions using the Transformer model,New Algorithm/ Method,New Algorithm/ Method
"We propose a new strategy for using scheduled sampling in Transformer models by
making two passes through the decoder in
training time.",New Algorithm/ Method,New Algorithm/ Method
"we propose an approach
of using semantic similarity between the output
sequence and the ground-truth sequence to train
the generation model.",Theory Proposal,Theory Proposal
"We present a modular framework for the rapidprototyping of linguistic, web-based, visual
analytics applications.",New Algorithm/ Method,New Algorithm/ Method
We present a demonstration of a neural interactive-predictive system for tackling multimodal sequence to sequence tasks,Theory Proposal,Theory Proposal
provides pretrained conversational models that can be either used directly or loaded for fine-tuning or bootstrapping other models; these models power an online demo of our framework.,Model Proposal,Model Proposal
"we present PERSPECTROSCOPE, a web-based system which lets users query a discussion-worthy natural language claim, and extract and visualize various perspectives in support or against the claim, along with evidence supporting each perspective",New Algorithm/ Method,New Algorithm/ Method
"We demonstrate HEIDL, a prototype HITLML system that exposes the machine-learned model through high-level, explainable linguistic expressions formed of predicates representing semantic structure of text",New Algorithm/ Method,New Algorithm/ Method
"We describe My Turn
To Read, an app that uses interleaved reading
to help developing and struggling readers improve reading skills while reading for meaning
and pleasure.",New Algorithm/ Method,New Algorithm/ Method
"we present ClaimPortal, a webbased platform for monitoring, searching, checking, and analytics of factual claims on Twitter. ClaimPortal is available at https://idir.
uta.edu/claimportal",New Algorithm/ Method,New Algorithm/ Method
We propose a graph walk based neural model that considers multiple entity pairs in relation extraction from a sentence,Model Proposal,Model Proposal
we develop a linguistically-infused neural network model to classify reactions in social media posts,Model Proposal,Model Proposal
we model this task using CNN regression with an auxiliary ordinal regression objective,Model Proposal,Model Proposal
we propose an unified approach to filter noisy bitexts and to mine bitexts in huge monolingual texts,New Algorithm/ Method,New Algorithm/ Method
Our model takes question-option tuple to generate a score for the concerned option,Model Proposal,Model Proposal
"we gauge human ability to perform cross-lingual gender detection, an angle of analysis which has not been studied thus far",Theory Proposal,Theory Proposal
we propose an entity-centric neural crosslingual coreference model,Model Proposal,Model Proposal
"we propose a novel Document Embedding Enhanced Bi-RNN model, called DEEB-RNN, for ED at sentence level",Model Proposal,Model Proposal
we propose a model that jointly identifies the domain and tracks the belief states corresponding to that domain,Model Proposal,Model Proposal
We propose the task of automatically rating academic papers and build a new dataset for this task,New Algorithm/ Method,New Algorithm/ Method
"proposal of a novel interaction-over-interaction
network which enables deep-level matching with
carefully designed interaction block chains",New Algorithm/ Method,New Algorithm/ Method
"we propose a novel method for
zero-shot multilingual transfer, inspired by research in truth inference in crowd-sourcing, a related problem, in which the ‘ground truth’ must be
inferred from the outputs of several unreliable annotators",New Algorithm/ Method,New Algorithm/ Method
"We propose the learning to route
(LTR) method to automatically select the good
translation path",New Algorithm/ Method,New Algorithm/ Method
"We propose a machine learning algorithm that
uses self-regulation in order to balance the cost
and effect of learning from different types of feedback.",New Algorithm/ Method,New Algorithm/ Method
"We propose a systematic
and principled method of injecting semantic
change in a controlled fashion.",New Algorithm/ Method,New Algorithm/ Method
"We introduce a novel corpus on aspect-based
argument similarity and demonstrate how contextualized word embeddings help to improve clustering similar arguments in a supervised fashion with
little training data.",Dataset Creation,Dataset Creation
"We introduce the simplified topic model STM
to infer the latent topic-level representations
and employ such topic-level relevance to recognize Chinese implicit discourse relations.",Model Proposal,Model Proposal
we design a computational methodology to quantitatively track systematic changes along the two dimensions of within- and between-counselor linguistic diversification.,New Algorithm/ Method,New Algorithm/ Method
We present algorithms for finding both consistent and contrastive expansions and demonstrate their effectiveness empirically.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose a multimodal method that is inspired by the way humans process emotions in a conversation. That is, lexical and acoustic information is simultaneously perceived at every word step.",New Algorithm/ Method,New Algorithm/ Method
"We propose a two-step framework to address the ECPE task, which first performs individual emotion extraction and cause extraction and then conduct emotion-cause pairing and filtering.",New Algorithm/ Method,New Algorithm/ Method
We propose an end-to-end method to incorporate MMR into pointer-generator networks.,New Algorithm/ Method,New Algorithm/ Method
We propose a method for text categorization that complements implicit representation by leveraging a predominant sense of a word.,New Algorithm/ Method,New Algorithm/ Method
we propose a new multi-task learning approach for rumor detection and stance classification tasks.,New Algorithm/ Method,New Algorithm/ Method
It systematically studies word alignment from NMT and proposes two approaches to induce word alignment which are agnostic to specific NMT models,Model Proposal,Model Proposal
"We present MILk attention, which allows us to build the first simultaneous MT system to learn an adaptive schedule jointly with an NMT model that attends over all source tokens read thus far",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel attention regularization method for reducing the noise in DS. Our method forces the model to clearly explain the relation patterns in terms of attention, and selects trustable instances if they can be explained by the model.",New Algorithm/ Method,New Algorithm/ Method
We propose novel algorithms to generate more natural adversarial examples that both preserve the semantics and mislead the classifiers.,New Algorithm/ Method,New Algorithm/ Method
"we present our method for learning representations from imperfect human language across the language, visual, and acoustic modalities.",New Algorithm/ Method,New Algorithm/ Method
we propose a near lossless method for encoding long sequences of texts as well as all of their sub-sequences into feature rich representations.,New Algorithm/ Method,New Algorithm/ Method
"We propose a debiasing method that preserves the genderrelated information in feminine and masculine
words",New Algorithm/ Method,New Algorithm/ Method
We propose a simple method for TM-NMT integration that is based on augmenting the source data with retrieved fuzzy TM targets by means of concatenation.,New Algorithm/ Method,New Algorithm/ Method
we propose an approach based on dynamic linear combination of layers (DLCL) to memorizing the features extracted from all preceding layers.,Theory Proposal,Theory Proposal
"we propose a new and simpler method without a priori parallel corpora. Our premise is that NMT systems —either sequence to sequence models with RNNs, transformers, or any architecture based on encoder–decoder models",New Algorithm/ Method,New Algorithm/ Method
we introduce a novel constraint-driven approach to learning a document-level (‘global’) co-reference model without using any document-level annotation;,Model Proposal,Model Proposal
we propose a reinforcement learning (RL) framework that synchronously searches for training instances relevant to the target domain and learns better representations for them.,New Algorithm/ Method,New Algorithm/ Method
"We introduce a new task of Conversational Question Generation (CQG), which is crucial for developing intelligent agents to drive question-answering style conversations and can potentially provide valuable datasets for future relevant research.",New Algorithm/ Method,New Algorithm/ Method
We propose a novel bi-directional selective mechanism with two gates to mutually select important information from both article and template to assist with summary generation,New Algorithm/ Method,New Algorithm/ Method
We develop a Fast Rerank method to automatically select high-quality templates from training corpus.,Dataset Creation,Dataset Creation
"we propose a method to learn to select sentence singletons and pairs, which then serve as the basis for an abstractive summarizer to compose a summary sentence-by-sentence, where singletons are shortened and pairs are merged",New Algorithm/ Method,New Algorithm/ Method
We design a new network that can answer inferential question by recursively deducing the evidence chain from the text,New Algorithm/ Method,New Algorithm/ Method
We propose an effective termination mechanism which can dynamically determine the uncertain reasoning depth,New Algorithm/ Method,New Algorithm/ Method
"we propose a data enrichment method, which uses WordNet to extract inter-word semantic connections as general knowledge from each given passage-question pair",New Algorithm/ Method,New Algorithm/ Method
"We propose A novel text generation task (SQUASH), which converts documents into specificity-based hierarchies of QA pairs.",Theory Proposal,Theory Proposal
We proposed a novel PU learning algorithm to perform the NER task using only unlabeled data and named entity dictionaries.,New Algorithm/ Method,New Algorithm/ Method
"To make the above assumption hold as far as possible, we propose an adapted method, motivated by the AdaSampling algorithm, to enrich the dictionary.",New Algorithm/ Method,New Algorithm/ Method
we propose a new parsing algorithm for semantic dependency parsing (SDP) that combines transition-based and graph-based approaches,New Algorithm/ Method,New Algorithm/ Method
"we consider using cross-domain LM as a bridge cross-domains for NER domain adaptation, performing crossdomain and cross-task knowledge transfer by designing a novel parameter generation network.",Theory Proposal,Theory Proposal
"we propose a sequence-to-sequence (seq2seq) based neural keyphrase generation framework, enabling absent keyphrases to be created",New Algorithm/ Method,New Algorithm/ Method
A multi-task learning method that uses different sets of features to handle different types of hashtags,New Algorithm/ Method,New Algorithm/ Method
We propose a novel method for analyzing entities in a narrative that is both interpretable and generalizable,New Algorithm/ Method,New Algorithm/ Method
We propose the novel CogQA framework for multi-hop reading comprehension QA at scale according to human cognition,New Algorithm/ Method,New Algorithm/ Method
we propose a new method to solve the multi-hop RC problem across multiple documents.,New Algorithm/ Method,New Algorithm/ Method
We introduce methods based on sentence mover’s similarity; our automatic metrics evaluate text in a continuous space using word and sentence embeddings.,New Algorithm/ Method,New Algorithm/ Method
To propose a multi-level matching and aggregation network is proposed to encode query instances and class prototypes in an interactive fashion,New Algorithm/ Method,New Algorithm/ Method
"we introduce an adaptive and general framework for measuring similarity of the pairs of relations these distributions are
parameterized by a very simple neural network",New Algorithm/ Method,New Algorithm/ Method
we propose an unsupervised adaptation method which finetunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus.,New Algorithm/ Method,New Algorithm/ Method
we propose a two step pipeline for building a rapid neural MT system for many languages. The pipeline does not require parallel data or parameter fine-tuning when adapting to new source languages.,New Algorithm/ Method,New Algorithm/ Method
"We propose a general method to detect cognates from multilingual lexical resources, with precision and recall parametrable according to usage needs",New Algorithm/ Method,New Algorithm/ Method
we introduce a neural decipherment algorithm that delivers strong performances across several languages with distinct linguistic characteristics.,New Algorithm/ Method,New Algorithm/ Method
we propose a new method for this task based on multilingual sentence embeddings,New Algorithm/ Method,New Algorithm/ Method
"we propose to generate, without supervision, synthetic parallel sentences that can be directly exploited to jointly train BWE with existing algorithms",Applications,Applications
we define and distinguish three aspects constituting to quality of biomedical name representations. We propose a novel encoding framework that considers all these aspects in the representation learning.,New Algorithm/ Method,New Algorithm/ Method
"We also present SemGCN, a framework for incorporating diverse semantic knowledge in learned word embeddings, without requiring relation-specific special handling as in previous methods.",New Algorithm/ Method,New Algorithm/ Method
"we propose delta embedding learning, a novel method that aims to address the above problems together: using regularization to find the optimal fine-tuning of word embeddings.",New Algorithm/ Method,New Algorithm/ Method
"We investigate how an LSTM language model deals with lexical ambiguity in English, designing a method to probe its hidden representations for lexical and contextual information about words.",New Algorithm/ Method,New Algorithm/ Method
We propose a Method for mapping entities from a graphical representation to the space in which a pretrained embedding lies,New Algorithm/ Method,New Algorithm/ Method
"Based on the proposed model, we develop a simple yet effective method for unsupervised domain adaptation.",Applications,Applications
Our goal is to present a patient biomedical QA system that can address the gaps in biomedical research and allows a patient to query their symptoms,Theory Proposal,Theory Proposal
methods for extracting of aggregated knowledge from patient experiences on online fora,New Algorithm/ Method,New Algorithm/ Method
"a method for cross-linking curated knowledge and complementary patient knowledge, and",New Algorithm/ Method,New Algorithm/ Method
"we propose a general approach for permuting the words in an input sentence based on the notion of simplification,",New Algorithm/ Method,New Algorithm/ Method
we present an unsupervised pretraining method for NMT models using Elastic Weight Consolidation,New Algorithm/ Method,New Algorithm/ Method
we propose a method for neural grammar error correction (GEC) that can control the degree of correction,New Algorithm/ Method,New Algorithm/ Method
we propose a method to predict a DA of the next response based on the history of previous utterances and their DAs.,New Algorithm/ Method,New Algorithm/ Method
", we propose a novel task, automatically generating personalized comment based on
user profile.",New Algorithm/ Method,New Algorithm/ Method
", we propose an inexpensive, scalable, CPUtrainable and efficient method of extractive text
summarization based on the use of sentence embeddings.",New Algorithm/ Method,New Algorithm/ Method
"we propose a method for add weights to a training loss according to levels of words on top of (Scarton and Specia, 2018), and thus output only words under the desired level.",New Algorithm/ Method,New Algorithm/ Method
we present a hybrid architecture for the task of Sentiment Analysis of EnglishHindi code-mixed data,New Algorithm/ Method,New Algorithm/ Method
"we propose an unsupervised
method to capture discourse structure in terms
of cohesion and coherence for document embedding.",New Algorithm/ Method,New Algorithm/ Method
". SEARCHER, a novel CLIR approach designed
for low-resource conditions that relies on the
construction of a shared semantic space learned
from bitext and monolingual corpora",New Algorithm/ Method,New Algorithm/ Method
"We present an approach to rapidly gather event trigger examples for new event types, with minimal human effort.",New Algorithm/ Method,New Algorithm/ Method
We develop a User Interface (UI) to further expedite and improve the time efficiency of our approach,New Algorithm/ Method,New Algorithm/ Method
", we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism",New Algorithm/ Method,New Algorithm/ Method
"We introduce an open-source web-based data
annotation framework (AlpacaTag) for sequence tagging tasks such as named-entity
recognition (NER)",New Algorithm/ Method,New Algorithm/ Method
"we introduce a Knowledge-Constraint Typing Annotation Tool (KCAT1 ), which is efficient for fine-grained entity typing annotation",New Algorithm/ Method,New Algorithm/ Method
"We develop GLTR, a tool to support humans in detecting whether a text was generated by a model",New Algorithm/ Method,New Algorithm/ Method
"we develop and evaluate a multilabel, multidimensional deep neural network designed to predict PHQ-4 scores based on individuals written text",New Algorithm/ Method,New Algorithm/ Method
we propose a new method for the evaluation of frame induction enabling straightforward comparison of approaches,New Algorithm/ Method,New Algorithm/ Method
we propose methods for automatic seed selection for bootstrapping RE and noise reduction for distant supervised RE,New Algorithm/ Method,New Algorithm/ Method
"we propose the new task of automatic article commenting, and introduces a large-scale Chinese dataset1 with millions of real comments and a humanannotated subset characterizing the comments’ varying quality",New Algorithm/ Method,New Algorithm/ Method
"we design an effective syntaxbased evaluator is built as a post-hoc checker, yielding compression with better quality based upon the evaluation metrics",Algorithm/Method Optimization,Algorithm/Method Optimization
we learn word and sentence embeddings jointly by training a multilingual skip-gram model together with a cross-lingual sentence similarity model,Model Optimization,Model Optimization
"we propose an approach that aims at injecting syntactic information in NNs, still keeping them simple",New Algorithm/ Method,New Algorithm/ Method
we present a simple and effective approach by introducing a coverage-based feature into NMT,New Algorithm/ Method,New Algorithm/ Method
"we propose an approach that uses both the sentences and the bag-of-words as targets in the training stage, in order to encourage the model to generate the potentially correct sentences that are not appeared in the training se",New Algorithm/ Method,New Algorithm/ Method
"we propose Pseudofit, a method that improves word embeddings without external knowledge and focuses on semantic similarity and synonym extraction",Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them",New Algorithm/ Method,New Algorithm/ Method
We formulate constrained sparsemax and derive efficient linear and sublinear-time algorithms for running forward and backward propagation,Algorithm/Method Optimization,Algorithm/Method Optimization
We present a simple approach to select assisting language sentences based on symmetric KLDivergence of overlapping entities,New Algorithm/ Method,New Algorithm/ Method
"We devise a novel loss function which penalizes wrong spans that cross gold-tree spans, and employ max-violation update (Huang et al., 2012) to train this parser with structured SVM and beam search",New Algorithm/ Method,New Algorithm/ Method
we propose a new method that can leverage unlabeled data to learn matching models for retrieval-based chatbots,New Algorithm/ Method,New Algorithm/ Method
"we show that there are relations
between sentences and semantic representations
which can be described by compositional mechanisms which are bounded and non-projective, but
not by ones which are bounded and projective.",Theory Proposal,Theory Proposal
"more importantly, we demonstrate, on several sentence-matching datasets, that simply evaluating the Hamming distance over binary representations performs on par or even better than calculating the cosine similarity between their continuous counterparts",Performance Evaluation,Performance Evaluation
"We propose a
technique to quantitatively estimate this assumption of the isometry between two embedding spaces and empirically show that this assumption weakens as the languages in question become increasingly etymologically distant.",Performance Evaluation,Performance Evaluation
We present a large-scale evaluation of multilingual subword representations on two sequence tagging tasks,Performance Evaluation,Performance Evaluation
"We evaluate our approach on three different
NLP tasks: machine comprehension, textual
entailment, and text chunking. We show that
augmented models lead to large performance
gains in the low training data regimes",Performance Evaluation,Performance Evaluation
"We frame the problem of open-domain argument search as a combination of topic-dependent
argument classification and clustering and discuss how contextualized word embeddings can
help to improve these tasks across four different
datasets.",Model Optimization,Model Optimization
"After
training a supervised deep learning algorithm to
predict attachments on the STAC corpus1
, we then
constructed a weakly supervised learning system
in which we used 10% of the corpus as a development set.",New Algorithm/ Method,New Algorithm/ Method
"we frame zero-shot learning as
a challenge for pragmatic modeling and explore
zero-shot reference games, where a speaker needs
to describe a novel-category object in an image to
an addressee who may or may not know the category",Theory Proposal,Theory Proposal
"Our new method outperforms previous methods by a significant margin on both the previous closed domain WSJ dataset as well as on
all open-domain ones, setting the new stateof-the-art for coherence modelling.",Algorithm/Method Optimization,Algorithm/Method Optimization
"Even with the simplest sentence encoder, averaged GloVe, our method frequently outperforms previous methods, while it can gain
further accuracy by using stronger encoders.",Algorithm/Method Optimization,Algorithm/Method Optimization
"We provide a comprehensive
comparative evaluation of a wide range of stateof-the-art—both supervised and unsupervised—
projection-based CLE models.",Performance Evaluation,Performance Evaluation
"We unify
evaluation protocols for all models and conduct experiments over 28 language pairs spanning diverse
language types.",Performance Evaluation,Performance Evaluation
"provides a benchmark to evaluate the ability of understanding idioms, a unique yet common language phenomenon in Chinese.",Theory Proposal,Theory Proposal
"We conduct extensive experiments on the design of candidate idioms and the idiom representation methods, and compare state-ofthe-art models.",Performance Evaluation,Performance Evaluation
evaluates token-level topic assignment quality to understand which topic models produce meaningful local topics for individual documents and proposes metrics that correlate with human judgment of the quality of these assignments.,Performance Evaluation,Performance Evaluation
"we evaluate the proposed models to perform
multi-domain joint learning of slot filling and
intent classification on both public datasets
and a real-world dataset from the Alexa virtual assistant;+99:116",Performance Evaluation,Performance Evaluation
"We explore how to resolve pronoun coreferences with KGs, which outperforms all existing models by a large margin on datasets from two different domains.",Model Optimization,Model Optimization
We evaluate the performance of different pronoun coreference models in a cross-domain setting and show that our model has better generalization ability than state-of-the-art baselines.,Model Optimization,Model Optimization
We evaluate a large number of baselines on SherLIiC. The best-performing baseline makes use of typing,Performance Evaluation,Performance Evaluation
analysis of the performance of the models that provides meaningful insights for further improvements,Performance Evaluation,Performance Evaluation
"We test models for open-domain and multi-choice QA, showing the complexity of the dataset and its utility to encourage progress in QA",Performance Evaluation,Performance Evaluation
"We compared GOLC with two optimization methods, a maximum log-likelihood and a minimum risk training, on CNN/Daily Mail and a Japanese single document summarization data set of The Mainichi Shimbun Newspapers.",Performance Evaluation,Performance Evaluation
"We perform two tasks, a classification and a regression one.
The evaluation shows that our proposed model
successfully outperforms the earlier reported results in PeerRead",Model Optimization,Model Optimization
Defining evaluation metrics and providing comparisons with several baselines to assess the model performance.,Performance Evaluation,Performance Evaluation
we consider a novel and realistic set-up where a much larger amount of sentencelevel data is available compared to that aligned at the document level,Theory Proposal,Theory Proposal
"We verify our GP-GNNs on the task of relation extraction from text, which demonstrates its ability on multi-hop relational reasoning as compared to those models which extract relationships separately.",Performance Evaluation,Performance Evaluation
"We evaluate our fine-tuned language model
on the NYT10 dataset and show that it achieves a state-of-the-art AUC compared
to RESIDE 2018 and
PCNN+ATT in held-out
evaluation",Performance Evaluation,Performance Evaluation
"We publish a better manually labeled sentence-level test set1 for evaluating the performance of RC models. This test set contains 1,024 sentences and 4,543 entity pairs, and is carefully annotated to ensure accuracy.",Dataset Creation,Dataset Creation
"We evaluate our Quaternion NLP models on
a wide range of diverse NLP tasks such as
pairwise text classification, neural
machine translation (NMT), sentiment analysis, mathematical language understanding
(MLU), and subject-verb agreement",Performance Evaluation,Performance Evaluation
"We formulate routing processes as a proxy problem minimizing a total negative agreement score in order to evaluate how routing processes perform at instance level, which will be discussed more in depth later",New Algorithm/ Method,New Algorithm/ Method
We show that training with delayed rewards achieves better performance than maximum likelihood training across six different historical text normalization benchmarks,Theory Proposal,Theory Proposal
we present a transparent framework and metric for evaluating discrimination across protected groups with respect to their word embedding bias,New Algorithm/ Method,New Algorithm/ Method
"we aim to combine the power of neural networks with the dataefficiency of logical forms by pre-learning abstractions in a semi-supervised way, satiating part of the network’s data hunger on cheaper unlabeled data from the environment.",Theory Proposal,Theory Proposal
We develop a series of automatic evaluation metrics to comprehensively assess the quality of the generated essay.,Performance Evaluation,Performance Evaluation
"We evaluate our models on data with humanconstituted trees or parsed trees, and yield promising results in generating sentences with better reconstruction loss and less grammatical errors, compared to other baseline methods.",Performance Evaluation,Performance Evaluation
We propose DIM to capture the duality and adopt variational approximation to maximize the dual information,New Algorithm/ Method,New Algorithm/ Method
"The experimental results demonstrate that our model is competitive with or outperforms other unsupervised models. In particular, for long reviews, it achieves a competitive or better performance than the supervised models.",Performance Evaluation,Performance Evaluation
We propose Empirical evaluations on the benchmark dataset show our model has achieved a new state of the art.,Performance Evaluation,Performance Evaluation
"we show that our model improves performance over ADA and an expanded vocabulary alone and further, that a limited amount of labeled target data can achieve performance close to training on all labeled target data.",Performance Evaluation,Performance Evaluation
we compare different NLI models regarding their ability to rank more correct summaries above incorrect alternatives.,Performance Evaluation,Performance Evaluation
"we present a neural rewriter for multi-sentence compression without any parallel data. This rewriter significantly improves the grammaticality and novel word rate, while maintaining the information coverage according to automatic evaluation",New Algorithm/ Method,New Algorithm/ Method
"Our Dynamic Self-attention Network (DynSAN) achieves new state-of-the-art performance compared with previously published results on SearchQA, Quasar-T and WikiHop benchmarks.",Performance Evaluation,Performance Evaluation
"We show the effectiveness of our approach, which achieves state-of-the-art results in both single- and multi-hop open-domain QA benchmarks.",Performance Evaluation,Performance Evaluation
We correlate several linguistically- and psycholinguisticallymotivated predictors to parsing accuracy on a large multilingual grammar induction evaluation data set.,Performance Evaluation,Performance Evaluation
"Framing the problem as pairwise ranking using novel neural approaches, in contrast to previous work which ignored the relative order of candidate segmentations",Theory Proposal,Theory Proposal
"We experimentally confirm that our method is much more effective than several state-of-theart claim verification models using three public benchmark datasets collected from snopes.com, politifact.com and Wikipedia.",Performance Evaluation,Performance Evaluation
We explore a neural model of stylistic variation that can predict socioeconomic status with good performance,Model Proposal,Model Proposal
We investigate how to label comments for ranking and clarify that the performance of pairwise ranking models tends to be more enhanced by the variation in comments than that in articles,Performance Evaluation,Performance Evaluation
"The experiments show that our approach can achieve better performance than competitive baselines. With multiple modal information and co-attention, the generated comments are more diverse and informative.",Algorithm/Method Optimization,Algorithm/Method Optimization
"To evaluate model performance, we collect and annotate a large-scale dataset from Google Business News1 with diverse event types and explainable event schemas.",Performance Evaluation,Performance Evaluation
"we argue that this is a dual effect of the highly lexicalized nature of NMT, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words.",Theory Proposal,Theory Proposal
"We propose to improve the robustness of NMT to homophone noises by jointly embedding both textual and phonetic information of source sentences,",New Algorithm/ Method,New Algorithm/ Method
"We make a thorough empirical evaluation of different ways of coupling BERT models in an APE system, comparing different options of parameter sharing, initialization, and fine-tuning.",Theory Proposal,Theory Proposal
we propose to boost lowresource cross-lingual document retrieval performance with deep bilingual query-document representations.,Algorithm/Method Optimization,Algorithm/Method Optimization
"Extensive experimental results show that our approach achieves better performance than several state-of-the-art unsupervised systems, and even achieves competitive performance compared to supervised methods",New Algorithm/ Method,New Algorithm/ Method
"we evaluate the proposed encoder in biomedical synonym retrieval, name normalization, and semantic similarity and relatedness benchmarks.",Performance Evaluation,Performance Evaluation
"We evaluate our corpus by using it to train supervised classifiers to automatically assign aspectual categories to verbs in context, permitting favourable comparisons to previous work.",New Algorithm/ Method,New Algorithm/ Method
"we propose a novel approach for manual evaluation, HIGHlight-based Referenceless Evaluation of document Summarization",New Algorithm/ Method,New Algorithm/ Method
We demonstrate that the model achieves more interpretable and controllable generation of paraphrases.,Performance Evaluation,Performance Evaluation
"adding paraphrases with additional multilingual data yields mixed performance; its performance is better than training on language families alone, but is worse than training on both the source and target paraphrases without language families.",Theory Proposal,Theory Proposal
"A system that jointly performs NER and EL, with competitive results in both tasks.",Theory Proposal,Theory Proposal
A empirical qualitative analysis of the advantage of doing joint learning vs using separate models and of the influence of the different components to the result obtained.,Theory Proposal,Theory Proposal
we do an in-depth analysis of how adding community features may enhance the performance of classification models that detect religious hate speech in Arabic.,Theory Proposal,Theory Proposal
we define two ways of combining contextual and static embeddings and conclude that the naive concatenation of vectors is consistently outperformed by the addition of the static representation directly into the internal linear combination of ELMo;,Theory Proposal,Theory Proposal
"we perform an analytic comparison of these methods, and introduce our own results. By fine-tuning Google’s
recently published transformer-based architecture, BERT, on the fake review detection task",Theory Proposal,Theory Proposal
". A configuration format that natively enables
searching over hyperparameters and running
remote multistage experiments at scale.",Theory Proposal,Theory Proposal
"critical examinations of different training conditions and requirements under which unsupervised
algorithms can and cannot work effectively",Performance Evaluation,Performance Evaluation
the first corpus for evaluating mistake detection and correction in a medical patient forum,New Algorithm/ Method,New Algorithm/ Method
"We investigate the use of a
language representation model BERT trained
to obtain semantic representations of social
media texts",Performance Evaluation,Performance Evaluation
"we evaluate the linguistic differences between temporal cohorts, e.g. 20-year-olds in 2011 vs. 20-year-olds in 2015",Performance Evaluation,Performance Evaluation
we achieve state-of-the-art performance in CoNLL 2003 NER shared task,Algorithm/Method Optimization,Algorithm/Method Optimization
"We adopt the pointer network to handle the OOV problem in slot value prediction, which achieves good performance without any manually-designed rules or features",Algorithm/Method Optimization,Algorithm/Method Optimization
"we investigate how to simplify and recover abugidas, with the aim of developing a more efficient method of encoding abugidas for input",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose a conceptually simpler
approach to the issue, which is agnostic on any
parser architecture, namely, automatic generation
of CCGbanks (i.e., CCG treebanks)1
for new domains, by exploiting cheaper resources of dependency trees.",New Algorithm/ Method,New Algorithm/ Method
we present the first study exploiting capsule networks for determining sentence similarity for summarization purpose. It is important to recognize that summarization places particular emphasis on measuring redundancy between sentences,Theory Proposal,Theory Proposal
we formulate properties required from a useful notion of Importance as the quantity unifying these concepts. We provide intuitions to interpret the proposed quantities.,Theory Proposal,Theory Proposal
"We introduce a contextual gating mechanism to incorporate multiple types of embeddings, word, speech, and conversationalcontext embeddings.",New Algorithm/ Method,New Algorithm/ Method
we address the degeneracy problem due to capturing spurious correlations by quantitatively analyzing the mutual information between language IDs of the source and decoded sentences,Theory Proposal,Theory Proposal
"We demonstrate favorable trade-offs to those of wait-k strategies at many latency values, and provide evidence that MILk’s advantage extends from its ability to adapt based on source content",Theory Proposal,Theory Proposal
"We write and enabling the quick generalization to new relation types by only requiring a small number
of human annotations",Theory Proposal,Theory Proposal
"We propose to perform KG inference and alignment jointly, so that the heterogeneity of KGs are explicitly reconciled through completion by rule inference and transfer, and pruning via cross-KG attention.",Resources,Resources
"We construct entmax sparse attention, improving interpretability at no cost in accuracy.
We show that the entmax gradient has a simple
form revealing an insightful
missing link between softmax and sparsemax.",New Algorithm/ Method,New Algorithm/ Method
"We conduct comprehensive experiments to examine the robustness of RNN, Transformer, and BERT. Our results show that both
self-attentive models, whether pre-trained or
not, are more robust than recurrent models.",Performance Evaluation,Performance Evaluation
"We critically discuss issues with current debiasing methods with the purpose of identifying optimizations, knowledge gaps, and directions for future research.",Theory Proposal,Theory Proposal
"we first empirically characterize the racial bias present in several widely used Twitter corpora annotated for toxic content, and quantify the propagation of this bias through models trained on them",Applications,Applications
We present an innovative idea for taking advantage of pretrained embeddings by using them as an objective during training.,Theory Proposal,Theory Proposal
we offer a holistic quantification of the systematicity of the sign using mutual information and recurrent neural networks.,Theory Proposal,Theory Proposal
we explore the use of multitask learning and adversarial training to address morphological richness and dialectal variations in the context of full morphological tagging.,Theory Proposal,Theory Proposal
we show how Wikipedia and unlabeled data can be used to construct an accurate linker which rivals linkers constructed using expensive human supervision,New Algorithm/ Method,New Algorithm/ Method
"We Propose a novel entity-aware model for data-to-text generation which is linguistically motivated, yet resource lean (no preprocessing is required",Model Proposal,Model Proposal
"we note some writer-specific patterns and characteristics: how data records are selected to be mentioned; and how data records are expressed as text, e.g., the order of data records and the word usages.",New Algorithm/ Method,New Algorithm/ Method
we propose a new approach to automatically generate summaries for scientific papers based on video talks,New Algorithm/ Method,New Algorithm/ Method
we investigate the factors involved in representing sentence singletons and pairs. We perform extensive experiments and report findings on sentence selection and abstraction.,Theory Proposal,Theory Proposal
we propose the use of artificial titles for unlabeled target documents to train a decoder to learn the grammatical style of titles in the new domain,Theory Proposal,Theory Proposal
we present a detailed error analysis and discuss potential areas of improvements for consumer health question summarization.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We also propose using sentence-level representations for retrieval, and show the possible benefits of this approach over paragraph-level representations.",Theory Proposal,Theory Proposal
"We investigate and demonstrate the feasibility of enhancing pre-trained LMs with rich knowledge for MRC. To our knowledge, this is the first study of its kind, indicating a potential direction for future research.",Theory Proposal,Theory Proposal
investigating new configurations of GNNs for handling direct edges and nodes with multiple representations.,Theory Proposal,Theory Proposal
"We quantitatively show the significance of each modality in Twitter sarcasm detection. We further show that to fully unleash the potential of images, we would need to consider image attributes",Theory Proposal,Theory Proposal
Our study aims to help this body of research grow by automating the process of collection of tweets containing recollections of sexual harassment.,Theory Proposal,Theory Proposal
"we highlight the importance of contextualizing social information, capturing how this information is disseminated in social networks",Theory Proposal,Theory Proposal
we investigate novel decompositions of the story generation process that break down the problem into a series of easier coarse-tofine generation problems.,Theory Proposal,Theory Proposal
We show that the cognitive graph structure in our framework offers ordered and entitylevel explainability and suits for relational reasoning.,Performance Evaluation,Performance Evaluation
We learn incremental suggestion models for little data scenarios through continuous adjustments of the suggestion model and discuss suitable setups.,Model Optimization,Model Optimization
We propose a criterion to distinguish between obvious and non-obvious examples in text pair similarity datasets,Theory Proposal,Theory Proposal
We define the types of relationships between the text and the image of a social media post,Theory Proposal,Theory Proposal
"we build on extensions of Harris’ distributional hypothesis to relations, as well as recent advances in learning text representations to build task agnostic relation representations solely from entity-linked text.",New Algorithm/ Method,New Algorithm/ Method
we present a differentiable approach to extractive rationales including an objective that allows for specifying how much text is to be extracted,New Algorithm/ Method,New Algorithm/ Method
The pipeline only requires a comprehensive source to target dictionary. We show that this dictionary can be easily obtained using offthe shelf tools within a few hours.,Performance Evaluation,Performance Evaluation
we empirically show that jointly training multiple languages improves separately trained bilingual models,Performance Evaluation,Performance Evaluation
We also show how simple techniques over our data yield competitive results in building crosslingual word embeddings and annotation projection for part-of-speech tagger induction.,Theory Proposal,Theory Proposal
we ask the fundamental question of whether Chinese word segmentation (CWS) is necessary for deep learning-based Chinese Natural Language Processing.,Theory Proposal,Theory Proposal
we study the benefits of hybrid strategies of hypernymy via a hybrid of extremely simple models of pattern-based and distributional hypernym discovery.,Theory Proposal,Theory Proposal
we describe the commonly used approaches in a subarea of interest and specify their features which could improve or deteriorate the performance of these models,Theory Proposal,Theory Proposal
We focus on the NLG approaches based on semantic representations and discuss their advantages and limitations.,Theory Proposal,Theory Proposal
"analyzing the shortcomings of sum and maxmargin loss, proposing a kNN-margin loss as a trade-off (for training);",Theory Proposal,Theory Proposal
we define a hop as a computational step which could be performed for an output symbol many times,Theory Proposal,Theory Proposal
"we propose a fullyautomated, context-aware machine translation approach with fewer stages of processing.",New Algorithm/ Method,New Algorithm/ Method
"We compare several approaches for conditioning on the model predictions when they
are used instead of the gold target.",Theory Proposal,Theory Proposal
"we report on our shared framework and infrastructure that drives a multitude
of linguistic visualization projects,",Performance Evaluation,Performance Evaluation
"ConvLab provides a rich set of tools and recipes to develop dialog systems of different types, enabling researchers to compare widely different approaches under the same condition.",New Algorithm/ Method,New Algorithm/ Method
"an unsupervised datadriven spelling correction method that works well
on specialized domains with many OOV terms
without the need for a specialized dictionary",New Algorithm/ Method,New Algorithm/ Method
"we analyze the role of linguistic context in both humans and the models, with implications for cognitive plausibility and future modeling work",Theory Proposal,Theory Proposal
"we use petitions from the official UK and US government websites, whereby citizens can directly appeal to the government for action on an issue",Dataset Creation,Dataset Creation
"we allow for an underlying mapping function that is non-linear, but assume that it can be approximated by linear maps at least in small enough neighborhoods",Applications,Applications
"we extend the research to investigate the impact of context on human acceptability judgements, where context is defined as the full document environment surrounding a sentence",New Algorithm/ Method,New Algorithm/ Method
"our research aims to develop a distributed knowledge-based clinical autocoding system that would leverage on NLP and ML techniques, where a human coders will give their queries to the coding system and in revert the system will suggest a set of clinical codes.",Model Proposal,Model Proposal
"we take a step in that direction and
confirm some of these speculations, showing that
models do not make use of a lot of the information available to it, by subjecting the dialog history to a variety of synthetic perturbations.",Model Optimization,Model Optimization
"We perform systematic analyses on nine languages using two different architectures (transition-based and graph-based) across
two dimensions: with and without BiLSTM representations, and with and without features drawn
from structural context.",Performance Evaluation,Performance Evaluation
"we investigate
words classified by L&M as negative, litigious and
uncertain that our embedding classifier classifies
otherwise",Theory Proposal,Theory Proposal
"we examine analysts’ decision making behavior as it pertains to the
language content of earnings calls.",Performance Evaluation,Performance Evaluation
"We provide a general
modular framework for sequence learning tasks.
While we focus on sentiment analysis task, the
framework is broadly applicable to many other
tagging tasks",New Algorithm/ Method,New Algorithm/ Method
"several principled model changes
to produce better structures but that still do not resemble the structure of discourse.",Model Optimization,Model Optimization
comprehensive performance results on existing and additional tasks and datasets showing document-level structured attention is largely unhelpful,Performance Evaluation,Performance Evaluation
"We eliminate the dependency on the structure of a semantic network by relying only on
the association between Wikipedia pages and
categories and on a sparse vector representation of concepts",Theory Proposal,Theory Proposal
"we provide the first large-scale
evaluation of an extensive number of approaches.",Performance Evaluation,Performance Evaluation
approach to mention detection for large-scale coreference annotation projects in which the output of mention detectors is corrected using a Gamewith-a-Purpose,Algorithm/Method Optimization,Algorithm/Method Optimization
"To overcome the multi-turn mapping problem,
TRADE leverages its context-enhanced slot
gate and copy mechanism to properly track slot values mentioned anywhere in dialogue history",New Algorithm/ Method,New Algorithm/ Method
we demonstrate experimentally the superiority of introducing group-level features and learning features in both parallel and serial ways.,Theory Proposal,Theory Proposal
"we define the task, including the annotation scheme for labeling the clinical conversations and the evaluation metrics to measure model performance",New Algorithm/ Method,New Algorithm/ Method
"we address this knowledge gap by examining how individuals change their conversational language in a domain with profound societal importance, where conversations play a primary role: mental health counseling.",Theory Proposal,Theory Proposal
"we describe the process of acquiring, anonymizing and filtering the dataset, deduplicating the answer set, and our first attempts towards automating the answering of questions.",Dataset Creation,Dataset Creation
"We present HEAD-QA, a multichoice testbed of graduate-level questions about medicine, nursing, biology, chemistry, psychology, and pharmacology",Dataset Creation,Dataset Creation
"we take a step towards closing this gap, by introducing the task of Debate Topic Expansion – finding related topics that can enrich our arguments and strengthen our case when debating a given topic.",Theory Proposal,Theory Proposal
"we aim to explicitly define a taxonomy of such principled recurring arguments, and, given a controversial topic, to automatically identify which of these arguments are relevant to the topic",Theory Proposal,Theory Proposal
"we seek to better understand how neural extractive summarization systems could benefit from different types of model architectures, transferable knowledge and learning schemas",Theory Proposal,Theory Proposal
we find an effective way to improve current frameworks and achieve the state-ofthe-art result on CNN/DailyMail by a large margin based on our observations and analyses.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We define several concepts intuitively connected to summarization: Redundancy, Relevance and Informativeness. These concepts have been used extensively in previous summarization works and we discuss along the way how our framework generalizes them",Theory Proposal,Theory Proposal
"we focus on the problem of generating valid adversarial examples for text classification, which could inspire more works for NLP attack and defense.",Theory Proposal,Theory Proposal
We introduce an approach that models writing style difference as the Jensen-Shannon distance between the character n-gram distributions of texts,New Algorithm/ Method,New Algorithm/ Method
we use neural sequence generation models for automatic conversion of poetry to prose. Lack of sufficient poetry-prose parallel data is an impediment in framing the problem as a seq2seq task,Model Proposal,Model Proposal
"We introduce language-sensitive embedding, attention, and discriminator which augment the ability of Multi-NMT model in distinguishing different languages.",Model Proposal,Model Proposal
"We understand NMT from the viewpoint of
word alignment and investigates the effect
of alignment errors on translation errors via
quantitative analysis over many testing examples.",Theory Proposal,Theory Proposal
"we utilize both large-scale textual corpora and KGs to train an enhanced language
representation model, which can
take full advantage of lexical, syntactic, and
knowledge information simultaneously.",Model Optimization,Model Optimization
we firstly recognize named entity mentions in text and then align these mentions to their corresponding entities in KGs,New Algorithm/ Method,New Algorithm/ Method
we hypothesize that the underperformance of monotonic models stems from the lack of joint training of the alignments with the transduction.,Performance Evaluation,Performance Evaluation
"We 
summarize recent studies of algorithmic bias in
NLP under a unified framework for the ease of future discussion.",Dataset Creation,Dataset Creation
We perform a systematic comparison of our and several recent methods on three tasks spanning ten topics and offer many insights.,Performance Evaluation,Performance Evaluation
We show that the proper use of layer normalization is the key to learning deep encoders. The deep network of the encoder can be optimized smoothly by relocating the layer normalization unit.,Applications,Applications
"we generate phoneme labels for speech frames and average consecutive frames with the same label to create shorter, higher-level source sequences for translation.",New Algorithm/ Method,New Algorithm/ Method
"We tackle a novel task, namely weakly-supervised spatio-temporally video grounding (WSSTG), which localizes a spatiotemporal tube in a given video that semantically corresponds to a given natural sentence, in a weakly-supervised manner",New Algorithm/ Method,New Algorithm/ Method
we provide evidence that fully-annotated documents may not be as beneficial as previously believed.,Performance Evaluation,Performance Evaluation
"We present the first work to generate modern Chinese poetry while controlling for the use of metaphor and personification, which play an essential role in enhancing the aesthetics of poetry",New Algorithm/ Method,New Algorithm/ Method
"we report correctness estimates for summaries generated by three recent abstractive summarization systems, showing that even recent state-of-the-art
models have errors in 25% of their summaries",Performance Evaluation,Performance Evaluation
"To the best of our knowledge, we are the first to consider using the whole document to learn contextualized sentence representations with selfsupervision and without any human annotations.",Theory Proposal,Theory Proposal
"we explore data augmentation techniques, including semantic selection from open-domain datasets, and study the behavior of state-of-the-art neural abstractive models on the original and augmented datasets",Performance Evaluation,Performance Evaluation
We propose Dynamic Self-attention (DynSA) for information interaction in a long sequence.,New Algorithm/ Method,New Algorithm/ Method
"We introduce the pointer-generator mechanism for generating an abstractive answer from the question and multiple passages, which covers various answer styles",New Algorithm/ Method,New Algorithm/ Method
"Our model achieves state-of-the-art results on
PTB and CTB for both constituent and dependency parsing",Model Proposal,Model Proposal
"We proved that the proposed algorithm can unbiasedly and consistently estimate the task loss as if there is fully labeled data, under the assumption that the entities found out by the dictionary can reveal the distribution of entities.",Performance Evaluation,Performance Evaluation
we show that multitask learning of state representations for this parsing algorithm is superior to single-task training,Performance Evaluation,Performance Evaluation
"introducing graph neural networks to dependency parsing, which aims to efficiently encode high order information in dependency tree node representations.",Theory Proposal,Theory Proposal
We show an assessment of how well contextualized word embeddings capture affect information,Performance Evaluation,Performance Evaluation
We show empirical evidence that constructiveness scores are not always related to positive user feedback such as “Like”-button clicks,Theory Proposal,Theory Proposal
we propose to exploit social media and natural language processing techniques to enhance air quality prediction.,Theory Proposal,Theory Proposal
We study the effects of automatically suggesting annotations to expert annotators across two domains for a hard discourse-level sequence labelling task.,Performance Evaluation,Performance Evaluation
"We propose a solution that meets our three criteria. Particularly, we adapt to our problem the recently presented concept of Almost Stochastic Order (ASO) between two distributions",Theory Proposal,Theory Proposal
"we would like to focus on the joint effects of conversation context and user history, ignoring other information.",Theory Proposal,Theory Proposal
To analyse into the author’s demographic traits that are related to usage preference of textimage relationship types,Theory Proposal,Theory Proposal
To analyze manually annotated corpus of claims from debates about migration found in German newspaper reports,Theory Proposal,Theory Proposal
"we introduce HardKuma, which gives support to binary outcomes and allows for reparameterized gradient estimates",New Algorithm/ Method,New Algorithm/ Method
we approach the problem by training a neural MT system to learn how to use custom terminology when provided with the input. C,New Algorithm/ Method,New Algorithm/ Method
we propose a strategy to train multilingual unsupervised NMT for one source to many targets and many targets to one source translations,Theory Proposal,Theory Proposal
"we also show that without training the network for many-to-many translations, the network can translate between all the languages participating in the training",Theory Proposal,Theory Proposal
We propose teaching both summary word generation distribution and attention weights in the cross-lingual ASSUM networks by using the monolingual ASSUM networks.,Theory Proposal,Theory Proposal
We demonstrate consistent and significant improvements on benchmark datasets in unsupervised and supervised settings.,Algorithm/Method Optimization,Algorithm/Method Optimization
We devise a straightforward and efficient approach for combining distributional and hypernymy information for the task of noun phrase compositionality prediction.,New Algorithm/ Method,New Algorithm/ Method
"we claim that vector space models, despite giving close representations for synonyms and antonyms, contain subtle differences that allow to discriminate antonymy.",Theory Proposal,Theory Proposal
We propose An approach to constructing graphical representations of entities in a knowledge base in an unsupervised manner.,New Algorithm/ Method,New Algorithm/ Method
"we
show that existing embedding models are inadequate at constructing representations that
capture salient aspects of mathematical meaning for numbers, which is important for language understanding.",Theory Proposal,Theory Proposal
How is personal recovery discussed online by individuals meeting criteria for BD?,Theory Proposal,Theory Proposal
What new insights do we get about personal recovery and factors that facilitate or hinder it?,Theory Proposal,Theory Proposal
"This research proposal consequently explores this question in the context of a neural morphological analyzer for a polysynthetic language, St",Theory Proposal,Model Proposal
"we find that over the past few decades, gender stereotypes in writings by males have decreased.",Theory Proposal,Theory Proposal
"Our paraphrase-exploiting NMT uses only two languages, the source and the target languages, and achieves higher BLEUs than the multi-source and multi-target NMT that incorporates more languages",New Algorithm/ Method,Algorithm/Method Optimization
a system for ranking explicit and implicit questions by their appropriateness in a dialogue is presented,New Algorithm/ Method,New Algorithm/ Method
we investigate the effect of the textual information of the tweets that target users liked/retweeted.,Theory Proposal,Theory Proposal
"we present a machine learning approach for information extraction, which has a recall of 80% for a social media data source.",New Algorithm/ Method,New Algorithm/ Method
", we investigate the efficacy
of bias reduction during training by introducing a
new loss function which encourages the language
model to equalize the probabilities of predicting
gendered word pairs like he and she.",New Algorithm/ Method,Algorithm/Method Optimization
"Our proposed approach, which uses community-based graph information to augment hand-crafted features based on topic modeling and emotion detection on debate transcripts currently surpasses the benchmark results on the same dataset.",New Algorithm/ Method,New Algorithm/ Method
we propose an artificial neural network (ANN) solution which does not use a lexicon or any other manually labeled source.,Theory Proposal,Theory Proposal
"we explored the use of a domain-independent, multilingual lexicon of abusive words called HurtLex (Bassignana et al., 2018) in both cross-domain and cross-lingual settings",Theory Proposal,Theory Proposal
"we use logic-based representations as
unified meaning representations for texts and
images and present an unsupervised multimodal logical inference system that can effectively prove entailment relations between
them",New Algorithm/ Method,New Algorithm/ Method
"we focus on
extraction information of adverse drug reactions from various sources of biomedical textbased information, including biomedical literature and social media",Theory Proposal,Theory Proposal
"Our system shows the incorrect sentences and
the corresponding sentence as corrected by
a native speaker. Thus, learners can rectify
their mistakes during composition.",Theory Proposal,Resources
". An intuitive snippet extraction and presentation design which has been shown in human studies to provide readers with sufficient evidence to filter out erroneous query matches and preserve good ones, even in low-resource conditions",Theory Proposal,Theory Proposal
to provide a highly flexible research framework not only for technique oriented developers but also for non-technical oriented developers such as linguists,New Algorithm/ Method,New Algorithm/ Method
"Modular machine learning components to develop replicable, state of the art research
results. This includes: neural network
components (pretrained or not), benchmark
datasets, and standardized training and evaluation modules.",Theory Proposal,Theory Proposal
"an overview of linguistic structures and corresponding discourse analysis tasks that discourse researchers are generally interested in,
as well as key applications on which these discourse structures have an impact",Theory Proposal,Theory Proposal
"We aim to provide a gentle, all-round
introduction to methods and tasks related to computational analysis of political texts",Theory Proposal,Theory Proposal
"addresses the fundamentals
of statistical models and neural networks, and focus on a series of advanced Bayesian models and
deep models",Theory Proposal,Theory Proposal
we present a new task and results for training models to learn semantically-rich function words,Model Proposal,Model Proposal
we introduce a new way to deal with the problem of offensive language on social media,Theory Proposal,Theory Proposal
"we propose a simple and parameter-efficient adaptation technique that only requires adapting the bias of the output softmax to each particular user of the MT system, either directly or through a factored approximation",New Algorithm/ Method,New Algorithm/ Method
"we aim to compare the performance of attention-based models to another baseline, namely, neural hidden Markov models",Performance Evaluation,Performance Evaluation
We design the first neural parser that is both linear time and capable of searching over exponentially large space,New Algorithm/ Method,New Algorithm/ Method
We propose a modularized hierarchical convolutional neural network model that considers the overall information of the source paper,Model Proposal,Model Proposal
we propose to combine string kernels (low-level character n-gram features) and word embeddings (high-level semantic features) to obtain state-of-the-art AES results,Model Optimization,Model Optimization
"we develop a more principled approach to unsupervised SMT, addressing several
deficiencies of previous systems by incorporating subword information, applying a theoretically
well founded unsupervised tuning method, and developing a joint refinement procedure.",New Algorithm/ Method,New Algorithm/ Method
"Our model achieves new state-of-the-art results without additional computational over
Implementation is based on Pytorch (Paszke et al., 2017).
head when compared with previous GCNs.
Unlike tree-structured models (e.g., TreeLSTM (Tai et al., 2015)), it can be efficiently
applied over dependency trees in parallel.",Model Optimization,Model Optimization
"We find that different methods have different strengths: Monolingual BPEmb works
best in medium- and high-resource settings,
multilingual non-contextual subword embeddings are best in low-resource languages,
while multilingual BERT gives good or best
results across languages.",Performance Evaluation,Performance Evaluation
"we propose a span-based
extract-then-classify framework, where multiple opinion targets are directly extracted from
the sentence under the supervision of target
span boundaries, and corresponding polarities
are then classified using their span representations.",New Algorithm/ Method,New Algorithm/ Method
"We create SherLIiC, a new resource for LIiC, consisting of 3985 manually annotated InfCands. Additionally, we provide ~960k unlabeled InfCands (SherLIiC-InfCands), and the typed event graph SherLIiC-TEG, containing ~190k typed textual binary relations between Freebase entities.",Resources,Resources
"we conduct extensive analyses on conversational aspects such as turn-by-turn interaction, the sentiment expressed during the interaction, linguistic alignment, and salient topics during the conversation to obtain insights into what are the patterns of high-quality counseling.",Performance Evaluation,Performance Evaluation
"we propose a new paradigm to handle the task of entity-relation extraction. We formalize the task as a multi-turn question answering task: each entity type and relation type is characterized by a question answering template, and entities and relations are extracted by answering template questions",New Algorithm/ Method,New Algorithm/ Method
"We propose a multi-task architecture which jointly trains a model to perform relation identification with cross-entropy loss and relation classification task with ranking loss, which can successfully mitigate the negative effect of having too many negative instances.",New Algorithm/ Method,New Algorithm/ Method
"We propose two RelDist losses: a skewness
loss, which encourages the classifier to predict a class with confidence for a single sentence, and a distribution distance loss, which
encourages the classifier to scatter a set of
sentences into different classes",Theory Proposal,Theory Proposal
"we propose a novel multi-digraph model to learn how to combine the gazetteer information and to resolve conflicting matches in learning with contexts. To the best of our knowledge, we are the first neural approach to NER that models the gazetteer information with a graph structure",Model Proposal,Model Proposal
"we propose a regularization technique that exploits a symmetry in language models. A unique aspect of language modeling using
LSTMs (or any RNN) is that at each time step t,
the model takes as input a particular token xt from
a vocabulary W and using the hidden state of the
LSTM predicts a probability distribution on the next
token over the same vocabulary as output",Model Proposal,Model Proposal
"We propose Quaternion neural models for NLP. More concretely, we propose a novel Quaternion attention model and Quaternion Transformer for a wide range of NLP tasks. To the best of our knowledge, this is the first formulation of hypercomplex Attention and Quaternion models for NLP.",Model Optimization,Model Optimization
"we add morphology supervision to character language modeling and show that, across two benchmark datasets, multitasking morphology with CLMs improves bits-per-character (BPC) performance on twentyfour languages, even when the annotated morphology features and language modeling data do not
overlap",Model Optimization,Model Optimization
"we conduct the first large-scale multilingual evaluation of gender-bias in machine translation (MT), following recent small-scale qualitative studies which observed that online MT services, such as Google Translate or Microsoft Translator, also exhibit biases",Performance Evaluation,Performance Evaluation
"we answer several of these open questions. We begin by proving that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc via subspace projection is, under certain conditions, equivalent to training on an unbiased corpus without reconstruction error.",Theory Proposal,Theory Proposal
"we address both issues simultaneously: leveraging the high accuracy of English taggers and parsers, we project morphological information onto translations of the Bible in 26 varied test languages. Using an iterative discovery, constraint, and training process, we build inflectional lexica in the target languages.",Theory Proposal,Theory Proposal
"We propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information, and thus these learned reordering embeddings are added to the sentence representation for archiving reordering of words. To the best of our knowledge, this is the first work to introduce the reordering information to the Transformer translation system.",New Algorithm/ Method,Resources
We propose a novel attentive interactor to exploit fine-grained relationships between instances and the sentence to characterize their matching behaviors. A diversity loss is proposed to strengthen the matching behaviors between reliable instance-sentence pairs and penalize the unreliable ones during training,New Algorithm/ Method,Performance Evaluation
"We propose a new dataset for data-to-text generation which we hope will encourage further work in this area a comprehensive evaluation and
comparison study which highlights the merits and
shortcomings of various recently proposed datato-text generation models on two datasets.",Dataset Creation,Dataset Creation
"we show both automatic and human evaluations for our approach. We make our dataset and related code publicly available . To our knowledge, this is the first approach to automatically create extractive summaries for scientific papers by utilizing the videos of conference talks",Theory Proposal,Theory Proposal
"we define Question Summarization as generating a condensed question expressing the minimum information required to find correct answers to the original question, and we create a new corpus1 of 1K consumer health questions and their summaries based on this definition",Theory Proposal,Theory Proposal
"We propose a novel hierarchical fusion model
to address the challenging multi-modal sarcasm detection task in Twitter. To the best
of our knowledge, we are the first to deeply
fuse the three modalities of image, attribute
and text, rather than na¨ıve concatenation, for
Twitter sarcasm detection",Model Proposal,Model Proposal
"We aim to improve over existing MT evaluation methods, through developing a series of new metrics based on contextual word embeddings a technique which captures rich and portable representations of words in context, which have been shown to provide important signal to many other NLP tasks.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we describe the creation of the first large-scale, multilingual, expert-based dataset of hate speech/counternarrative pairs. This dataset has been built with the effort of more than 100 operators from three different NGOs that applied their training and expertise to the task",Dataset Creation,Dataset Creation
"we propose a hybrid attention mechanism to dynamically leverage both of the local and global information. Specifically, our approach uses a gating scalar for integrating both sources of the information, which is also convenient for quantifying their contributions.",Algorithm/Method Optimization,Algorithm/Method Optimization
We propose a new unsupervised multilingual word embedding method that overcomes the limitations of the existing methods. Our approach can successfully obtain multilingual word embeddings under the challenging conditions when only small monolingual corpora are available,Algorithm/Method Optimization,Algorithm/Method Optimization
"Extensive experimental results on two benchmark datasets show that our proposed method is able to perform better than several baselines and related works, and significantly reduce the performance gap between the crosslingual ASSUM and the monolingual ASSUM.",New Algorithm/ Method,New Algorithm/ Method
"we propose to model the edit operations explicitly for sentence simplification in an end-to-end fashion, rather than relying on MT-based models to learn the simplification mappings implicitly, which often generates outputs by blindly repeating the source sentences",Model Optimization,Model Optimization
"our research aims to develop a distributed knowledge-based clinical autocoding system that would leverage on NLP and ML techniques, where a human coders will give their queries to the coding system and in revert the system will suggest a set of clinical codes",Theory Proposal,Theory Proposal
"we describe a simple yet effective approach to merge lexicon information with
an attention LSTM model for ABSA in order to
leverage both the power of deep neural networks
and existing linguistic resources, so that the framework becomes more flexible and robust without
requiring additional labeled data",Model Optimization,Model Optimization
a better way is to utilize the system to assist human creation. The human-machine collaboration mechanism in Jiuge system can not only improve the emotions and semantics of generated poems but also guide and teach beginners to understand the poetic creation process.,Performance Evaluation,Performance Evaluation
"we design and construct a real-world online platform that offers PhD graduates a dedicated job search functionality, as well as helps governments, universities, and employers in increasing the understanding of different industries’ absorption of PhD graduates.",New Algorithm/ Method,New Algorithm/ Method
"We introduce Texar, a general-purpose text generation toolkit aiming to support popular and
emerging applications in the field, by providing researchers and practitioners a unified and flexible framework for building their models.
Texar has two versions, building upon TensorFlow
(tensorflow.org) and PyTorch (pytorch.
org), respectively, with the same uniform design",New Algorithm/ Method,New Algorithm/ Method
"we present an open source modular tool dedicated to automatic summarization. Written in Java, it is designed to first answer the lack of such a tool and so provide the community with an easy-to-use summarization tool, to allow a straightforward maintenance of existing modules and development of new modules, and to allow methods comparison in a unified framework.",New Algorithm/ Method,New Algorithm/ Method
"We present a prototype vocabulary
learning system, Linggle Booster, that applies
the method to corpora and web pages. Evaluation on a set of target words shows that the
method has reasonably good performance in
terms of generating useful and correct information for vocabulary learning.",New Algorithm/ Method,New Algorithm/ Method
"We will introduce researchers to state-of-theart methods for constructing resource-light crosslingual word representations and discuss their applicability in a broad range of downstream NLP
applications, covering bilingual lexicon induction,
machine translation (both neural and phrase-based),
dialogue, and information retrieval tasks",Model Optimization,Model Optimization
"Classification models that can generalize to different health contexts would be greatly beneficial to researchers in these fields (e.g., (Payam and Eugene, 2018)), as this would allow researchers to more easily apply existing tools and resources to new problems",Algorithm/Method Optimization,Algorithm/Method Optimization
"we present a MedNorm corpus consisting of 27,979 textual descriptions (phrases) simultaneously mapped to both MedDRA and SNOMED-CT, that have been sourced from five publicly available datasets across biomedical and social media domains. To combine them, we designed a data harmonisation pipeline that can be re-used in the future to integrate new datasets into the corpus or applied in relevant annotation and data processing tasks.",Dataset Creation,Dataset Creation
"We provide the language and vision communities with a unique multimodal dataset comprised of co-captured gaze and audio data, and transcriptions. This dataset was collected via an image-inspection task with 100 general-domain images and American English speakers",Dataset Creation,Dataset Creation
"we propose to improve the quality of input (source language) representations of rare words in NMT by augmenting its embedding layer with a bi-directional recurrent neural network (biRNN), which can learn compositional input representations at different levels of granularity",Model Optimization,Model Optimization
"We choose bidirectional long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) with an attention mechanism to represent EDUs directly from embeddings, and use simple position features to capture shallow discourse structures, without relying on off-the-shelf tools or resources",Resources,Resources
"we propose an approach based on linguistic knowledge for identification of aliases mentioned using proper nouns, pronouns or noun phrases with common noun headword. We use Markov Logic Network (MLN) to encode the linguistic knowledge for identification of aliases. We evaluate on four diverse history narratives of varying complexity as well as newswire subset of ACE 2005 dataset. Our approach performs better than the state-of-the-art.",Theory Proposal,Theory Proposal
"we study how to automatically extract such relationship through a sentence-level relation classifier and aggregating the scores of entity pairs from a large corpus. Also, we release two benchmark datasets for evaluation and future research.",Dataset Creation,Dataset Creation
"we study the performance of plagdet, the main measure for Plagiarism Detection Systems evaluation, on manually paraphrased plagiarism datasets (such as PAN Summary). We reveal its fallibility under certain conditions and propose an evaluation framework with normalization of inner terms, which is resilient to the dataset imbalance. We conclude with the experimental justification of the proposed measure. The implementation of the new framework is made publicly available as a Github repository",Dataset Creation,Dataset Creation
"we use named entities as domain-specific terms for newscentric content and present a new weighting model for Latent Dirichlet Allocation. Our experimental results indicate that involving more named entities in topic descriptors positively influences the overall quality of topics, improving their interpretability, specificity and diversity.",Resources,Resources
"we propose a simple and parameter-efficient adaptation technique that only requires adapting the bias of the output softmax to each particular user of the MT system, either directly or through a factored approximation. Experiments on TED talks in three languages demonstrate improvements in translation accuracy, and better reflection of speaker traits in the target text.",Theory Proposal,Theory Proposal
"we propose an approach that uses both the sentences and the bag-of-words as targets in the training stage, in order to encourage the model to generate the potentially correct sentences that are not appeared in the training set. We evaluate our model on a Chinese-English translation dataset, and experiments show our model outperforms the strong baselines by the BLEU score of 4.55.1",Model Proposal,Model Proposal
"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them. The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision. Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.1",Dataset Creation,Dataset Creation
"we aim to compare the performance of attention-based models to another baseline, namely, neural hidden Markov models. The neural HMM has been successfully applied in the literature on top of conventional phrasebased systems (Wang et al., 2017). In this work, our purpose is to explore its application in standalone decoding, i.e. the model is used to generate and score candidates without assistance from a phrase-based system. Because translation is done standalone using only neural models, we still refer to this as NMT. In addition, while Wang et al. (2017) applied feedforward networks to model alignment and translation, the recurrent structures proposed in this work surpass the feedforward variants by up to 1.3% in BLEU.",Performance Evaluation,Performance Evaluation
"we propose a model that jointly identifies the domain and tracks the belief states corresponding to that domain. It uses semantic similarity between ontology terms and turn utterances to allow for parameter sharing between different slots across domains and within a single domain. In addition, the model parameters are independent of the ontology/belief states, thus the dimensionality of the parameters does not increase with the size of the ontology, making the model practically feasible to deploy in multidomain environments without any modifications. Finally, we introduce a new, large-scale corpora of natural, human-human conversations providing new possibilities to train complex, neural-based models",Model Proposal,Model Proposal
Crowdsourcing a large paraphrasing corpus of questions which are answerable using the data from EHR,Applications,Applications
The creation and annotation of a newspaper dataset for political bias detection,Dataset Creation,Dataset Creation
this paper puts forward a new thinking direction of enriching training dataset for the CGED task.,New Algorithm/ Method,New Algorithm/ Method
"We conduct a comparison and evaluation of our findings with other URE techniques, to ascertain the important features in URE. We conclude that entity types provide a strong inductive bias for URE",Performance Evaluation,Performance Evaluation
"we address the task of machine reading the time of historical events, compile datasets for the task, and develop a model for tackling it.",Theory Proposal,Theory Proposal
"we explore the implicit event argument detection task, which studies event arguments beyond sentence boundaries",Algorithm/Method Optimization,Algorithm/Method Optimization
We demonstrate the effectiveness of our approach with state-of-the-art accuracy on the unsupervised Story Cloze task and with promising results on larger-scale next sentence prediction tasks,New Algorithm/ Method,New Algorithm/ Method
"In this paper we explore the use of synthetic data for the English shallow task. We analyse the effects of synthetic data, and
we argue that its use should be encouraged
rather than prohibited so that future research
efforts continue to explore systems that can
take advantage of such data.",Applications,Applications
"In this paper, we present a novel image captioning architecture to better explore semantics available in captions and leverage that to enhance both image representation and caption generation",New Algorithm/ Method,New Algorithm/ Method
"In this paper, I take a broad linguistic perspective, looking at how well current models can deal with various semantic challenges.",New Algorithm/ Method,Theory Proposal
"we outline several lessons that transfer to QA research: removing ambiguity, identifying better QA agents, and adjudicating disputes.",Performance Evaluation,Performance Evaluation
"In this paper, we will attempt to uncover potential reasons for this.",Theory Proposal,Theory Proposal
"Here we reflect on parsing MRLs in that decade, highlight the solutions and lessons learned for the architectural, modeling and lexical challenges in the pre-neural era, and argue that similar challenges re-emerge in neural architectures for MRLs",Theory Proposal,Theory Proposal
we compare the structural probe to a more traditional parser with an identical lightweight parameterisation,Performance Evaluation,Performance Evaluation
"We review motivations, definition, approaches, and methodology for unsupervised crosslingual learning and call for a more rigorous position in each of them.",Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose an approach to solve this task as a link prediction problem, using Deep Convolutional Graph Neural Networks. This paper also analyses how different baselines perform in this task and shows that a graph structure can provide higher F1-score, especially when considering multi-hop premise selection",New Algorithm/ Method,New Algorithm/ Method
"This paper provides the first study of how these explanations can be generated automatically based on available claim context, and how this task can be modelled jointly with veracity prediction",Theory Proposal,Theory Proposal
"This paper presents Kernel Graph Attention Network (KGAT), which conducts more finegrained fact verification with kernel-based attentions",Theory Proposal,Model Proposal
we propose a multi-source meta transfer (MMT) for low-resource MCQA.,Model Proposal,Model Proposal
We evaluate stateof-the-art cross-lingual models and machinetranslation-based baselines on MLQA.,Performance Evaluation,Performance Evaluation
"In this paper we present DoQA, a task and associated dataset for accessing domain-specific FAQs via conversational QA",New Algorithm/ Method,New Algorithm/ Method
we devise a novel bootstrapping framework based on self-supervision to obtain a dataset of clarification questions from various domains of stackexchange,Model Proposal,Model Proposal
"In this paper, we develop simple approaches to semi-supervised contextualized text normalization",New Algorithm/ Method,New Algorithm/ Method
We create a ten-year Reddit corpus as a benchmark for MFEP and evaluate a number of baselines on this benchmark,New Algorithm/ Method,New Algorithm/ Method
we propose a model that can disambiguate between mappings and convert between the two scripts.,Model Proposal,Model Proposal
"Our method is based on repeated training of linear classifiers that predict a certain property we aim to remove, followed by projection of the representations on their null-space",Algorithm/Method Optimization,Algorithm/Method Optimization
"This paper contributes a sober view of the problem, a survey of techniques to address it, novel techniques, and extensions to the model. To establish a ranking of techniques, we perform a systematic comparison using Bayesian optimisation and find that many techniques perform reasonably similar, given enough resources",Theory Proposal,Theory Proposal
"In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks",Performance Evaluation,Performance Evaluation
"We propose a novel large-scale referring expression recognition dataset, Refer360°, consisting of 17,137 instruction sequences and ground-truth actions for completing these instructions in 360° scenes.",Dataset Creation,Dataset Creation
"This paper proposes a new neural network architecture for VQA based on the recent Graph Network (GN) (Battaglia et al., 2018).",New Algorithm/ Method,New Algorithm/ Method
we propose a novel dual channel graph convolutional network (DC-GCN) for better combining visual and textual advantages.,Model Proposal,Theory Proposal
we propose to explicitly segment target text into fragment units and align them with their data correspondences,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose the Heterogeneous Graph Transformer to independently model the different relations in the individual subgraphs of the original graph, including direct relations, indirect relations and multiple possible relations between nodes.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a novel attentional sequence-to-sequence(Seq2seq) model that dynamically exploits the relevance of each output word to the target stylefor unsupervised style transfer.",Model Proposal,Model Proposal
we propose a neural co-generation model that generates dialogue acts and responses concurrently,Model Proposal,Model Proposal
we propose a multi-task learning model with a simple yet effective utterance tagging technique and a bidirectional language model as an auxiliary task for task-oriented dialogue state generation.,Model Proposal,Model Proposal
"In this paper, we propose a Meta-Reinforced MultiDomain State Generator (MERET). Our first contribution is to improve the DST accuracy. We enhance a neural model based DST generator with a reward manager, which is built on policy gradient reinforcement learning (RL) to fine-tune the generator",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs",Dataset Creation,Dataset Creation
"In this paper, we propose a new perspective to diversify dialogue generation by leveraging non-conversational text",New Algorithm/ Method,New Algorithm/ Method
"we aim to identify, from among a set of speeches on the same topic and with an opposing stance, the ones that directly counter it. We provide a large dataset of 3685 such speeches (in English), annotated for this relation, which hopefully would be of general interest to the NLP community.",Performance Evaluation,Performance Evaluation
"In this paper, we model debaters’ prior beliefs, interests, and personality traits based on their previous activity, without dependence on explicit user profiles or questionnaires. Using a dataset of over 60,000 argumentative discussions, comprising more than three million individual posts collected from the subreddit r/ChangeMyView, we demonstrate that our modeling of debater’s characteristics enhances the prediction of argument persuasiveness as well as of debaters’ resistance to persuasion.",Model Optimization,Model Optimization
"In this paper, we formulate the data augmentation as a conditional generation task: generating a new sentence while preserving the original opinion targets and labels. We propose a masked sequence-to-sequence method for conditional augmentation of aspect term extraction.",Model Optimization,Model Optimization
"In order to further test the capabilities of these powerful neural networks on a harder NLP problem, we propose a transition system that, thanks to Pointer Networks, can straightforwardly produce labelled directed acyclic graphs and perform semantic dependency parsing.",Algorithm/Method Optimization,Algorithm/Method Optimization
"We apply, extend and evaluate different meta-embedding methods from the word embedding literature at the sentence level, including dimensionality reduction (Yin and Schutze ¨ , 2016), generalized Canonical Correlation Analysis (Rastogi et al., 2015) and cross-view auto-encoders (Bollegala and Bao, 2018).",Applications,Applications
"In this paper, we present an improved crowdsourcing protocol for complex semantic annotation, involving worker selection and training, and a data consolidation phase.",Dataset Creation,Dataset Creation
" In this paper, we propose N 3 (Neural Networks from Natural Language) - a new paradigm of synthesizing task-specific neural networks from language descriptions and a generic pre-trained model.",New Algorithm/ Method,New Algorithm/ Method
"We therefore present a novel domain-agnostic Human-In-The-Loop annotation approach: we use recommenders that suggest potential concepts and adaptive candidate ranking, thereby speeding up the overall annotation process and making it less tedious for users. We evaluate our ranking approach in a simulation on difficult texts and show that it greatly outperforms a strong baseline in ranking accuracy.",Model Proposal,Model Proposal
"We present a method for incorporating model and data uncertainty estimates into natural language processing models for automatic rumour verification. We show that these estimates can be used to filter out model predictions likely to be erroneous, so that these difficult instances can be prioritised by a human fact-checker. We propose two methods for uncertainty-based instance rejection, supervised and unsupervised. We also show how uncertainty estimates can be used to interpret model performance as a rumour unfolds.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present CorefQA, an accurate and extensible approach for the coreference resolution task. We formulate the problem as a span prediction task",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we close this gap by reporting concept extraction performance on automatically anonymized data and investigating joint models for de-identification and concept extraction.",Performance Evaluation,Performance Evaluation
" We propose uncertainty-aware curriculum learning, which is motivated by the intuition that: 1) the higher the uncertainty in a translation pair, the more complex and rarer the information it contains; and 2) the end of the decline in model uncertainty indicates the completeness of current training stage. Specifically, we serve cross-entropy of an example as its data difficulty and exploit the variance of distributions over the weights of the network to present the model uncertainty",Model Proposal,Model Proposal
"We present the first thorough investigation of gender bias in speech translation, contributing with: i) the release of a benchmark useful for future studies, and ii) the comparison of different technologies (cascade and end-to-end) on two language directions (English-Italian/French).",Performance Evaluation,Performance Evaluation
"In this work, we present CLASSYMAP, a classification-based approach to self-learning, yielding a more robust and a more effective induction of projection-based CLWEs. Unlike prior self-learning methods, our approach allows for integration of diverse features into the iterative process. We show the benefits of CLASSYMAP for bilingual lexicon induction: we report consistent improvements in a weakly supervised setup (500 seed translation pairs) on a benchmark with 28 language pairs.",New Algorithm/ Method,New Algorithm/ Method
"In this work, we introduce a class of hyperbolic KG embedding models that simultaneously capture hierarchical and logical patterns.",New Algorithm/ Method,New Algorithm/ Method
we introduce a gated component self-dependency units (SDU) that incorporates LSTM-styled gating units to replenish internal semantic importance within the multi-dimensional latent space of individual representations.,New Algorithm/ Method,New Algorithm/ Method
"We introduce a parametric family of entropy regularizers, which includes label smoothing as a special case, and use it to gain a better understanding of the relationship between the entropy of a trained model and its performance on language generation tasks.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we develop a deep, endto-end model that learns to effectively classify mismatches and to generate hard mismatched examples to improve the classifier. We train the model end-to-end by introducing a latent variable into the cross-entropy loss that alternates between using the real and generated samples.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we compare the performance of both QT and DT using the traditional SMT and state-of-the-art NMT methods trained on the same data to make the comparison as fair as possible. We present a novel approach for NMT model selection that is optimized towards CLIR performance and investigate the effect of morphological pre- and post-processing on the performance on CLIR.",Performance Evaluation,Performance Evaluation
"In this paper, we propose a method FGS2EE to inject fine-grained semantic information into entity embeddings to reduce the distinctiveness and facilitate the learning of contextual commonality.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose FLAT: Flat-LAttice Transformer for Chinese NER, which converts the lattice structure into a flat structure consisting of spans.",New Algorithm/ Method,New Algorithm/ Method
"We present an effective TSE method which is based on querying large, pre-trained masked language models (MLMs).",New Algorithm/ Method,New Algorithm/ Method
"In this work, we propose a structural-aware model at both the encoder and decoder phase to integrate the structural information, where graph attention network (GAT) is exploited for effectively modeling.",Model Proposal,Model Proposal
"we propose a two-stage semantic parsing framework, where the first stage utilizes an unsupervised paraphrase model to convert an unlabeled natural language utterance into the canonical utterance.",Model Proposal,Model Proposal
We propose an approach to semi-supervised learning of semantic dependency parsers based on the CRF autoencoder framework.,New Algorithm/ Method,New Algorithm/ Method
" we formulate the task based on the divergence between literal and intended meanings. We combine the complementary strengths of English Resource Grammar, a linguistically-precise hand-crafted deep grammar, and TLE, an existing manually annotated ESL UD-TreeBank with a novel reranking model.",New Algorithm/ Method,New Algorithm/ Method
We demonstrate the effectiveness of this new perspective by developing a new state-of-the-art semantic parser for Minimal Recursion Semantics.,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we introduce a new model, called RikiNet, which reads Wikipedia pages for natural question answering.",Model Proposal,Model Proposal
"In this paper, we study machine reading comprehension (MRC) on long texts, where a model takes as inputs a lengthy document and a question and then extracts a text span from the document as an answer",Theory Proposal,Theory Proposal
"We present a reliable, crowdsourced framework for scalably annotating RC datasets with derivations. We create and publicly release the R4C dataset, the first, quality-assured dataset consisting of 4.6k questions, each of which is annotated with 3 reference derivations (i.e. 13.8k derivations).",Dataset Creation,Dataset Creation
we propose to learn the model with the help of a large scale of unlabeled data that is much easier to obtain.,Theory Proposal,Theory Proposal
"In this work, we introduce two approaches to improve unsupervised QA. First, we harvest lexically and syntactically divergent questions from Wikipedia to automatically construct a corpus of question-answer pairs (named as REFQA)",New Algorithm/ Method,New Algorithm/ Method
"we present a novel multi-grained machine reading comprehension framework that focuses on modeling documents at their hierarchical nature, which are different levels of granularity: documents, paragraphs, sentences, and tokens. We utilize graph attention networks to obtain different levels of representations so that they can be learned simultaneously",Model Proposal,Model Proposal
"We propose the task of unsupervised morphological paradigm completion. Given only raw text and a lemma list, the task consists of generating the morphological paradigms, i.e., all inflected forms, of the lemmas",New Algorithm/ Method,New Algorithm/ Method
"Here, we investigate the strength of those clues. More specifically, we operationalize “strength” as measuring how much information, in bits, we can glean about declension class from knowing the form and meaning of nouns",Performance Evaluation,Performance Evaluation
"In this paper, we propose a new framework that incorporates typological awareness by explicitly modeling different morphological patterns including suffixation, prefixation, infixation, and reduplication.",Model Proposal,Model Proposal
we develop a sentence-level training procedure to perform noise reduction and maximum utilization of the source domain information.,New Algorithm/ Method,New Algorithm/ Method
"We generate data from a finite state transducer to train an encoderdecoder model. We improve the model by “hallucinating” missing linguistic structure into the training data, and by resampling from a Zipf distribution to simulate a more natural distribution of morphemes.",Dataset Creation,Dataset Creation
"we propose a modification to contextual representation fine-tuning which, during inference, allows for an early (and fast) “exit” from neural network calculations for simple instances, and late (and accurate) exit for hard instances.",Algorithm/Method Optimization,Algorithm/Method Optimization
we present a general approach to learn both intra-cell and inter-cell architectures (call it ESS).,Theory Proposal,Theory Proposal
"In this paper, we make use of a multi-task objective, i.e., the models simultaneously predict words as well as ground truth parse trees in a form called “syntactic distances”, where information between these two separate objectives shares the same intermediate representation",Model Optimization,Model Optimization
"we show that adversarial examples also exist in dependency parsing: we propose two approaches to study where and how parsers make mistakes by searching over perturbations to existing texts at sentence and phrase levels, and design algorithms to construct such examples in both of the black-box and white-box settings",Performance Evaluation,Performance Evaluation
"We propose Differentiable Window, a new neural module and general purpose component for dynamic window selection. While universally applicable, we demonstrate a compelling use case of utilizing Differentiable Window to improve standard attention modules by enabling more focused attentions over the input regions. We propose two variants of Differentiable Window, and integrate them within the Transformer architecture in two novel ways. We evaluate our proposed approach on a myriad of NLP tasks, including machine translation, sentiment analysis, subject-verb agreement and language modeling. Our experimental results demonstrate consistent and sizable improvements across all tasks.",New Algorithm/ Method,New Algorithm/ Method
we propose a dependency graph enhanced dual-transformer network (named DGEDT) by jointly considering the flat representations learnt from Transformer and graphbased representations learnt from the corresponding dependency graph in an iterative interaction manner.,New Algorithm/ Method,New Algorithm/ Method
we propose the mixture of attentive experts model (MAE). MAE is trained using a block coordinate descent algorithm that alternates between updating (1) the responsibilities of the experts and (2) their parameters,Performance Evaluation,Performance Evaluation
"We critically examine RefCOCOg, a standard benchmark for this task, using a human study and show that 83.7% of test instances do not require reasoning on linguistic structure, i.e., words are enough to identify the target object, the word order doesn’t matter",Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose a video span localizing network (VSLNet), on top of the standard span-based QA framework, to address NLVL. The proposed VSLNet tackles the differences between NLVL and span-based QA through a simple and yet effective query-guided highlighting (QGH) strategy",Performance Evaluation,Performance Evaluation
We present a simple experiment on language grounding that highlights the great potential of top-down processing even for very common words with a lot of visual instances: we learn to ground colour terms in visual representations of real-world objects and show that model predictions improve strongly when incorporating prior knowledge and assumptions about the object itself.,Model Proposal,Model Proposal
"In this paper, we propose to tackle this issue of large-scale image-caption consistency using a coherence-aware approach inspired by the framework of discourse coherence theory (Hobbs, 1978; Phillips, 1977).",Resources,Resources
"In this paper, we explore AspectOpinion Pair Extraction (AOPE) task, which aims at extracting aspects and opinion expressions in pairs",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a teacher-student learning method to address such limitations, where NER models in the source languages are used as teachers to train a student model on unlabeled data in the target language",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present a novel approach to the task of extracting structured information from formlike documents using a learned representation of an extraction candidate.",New Algorithm/ Method,New Algorithm/ Method
In this work we annotate a test set with ground-truth sentence-level explanations to evaluate the quality of explanations afforded by the relation extraction models. We demonstrate that replacing the entity mentions in the sentences with their fine-grained entity types not only enhances extraction accuracy but also improves explanation. We also propose to automatically generate “distractor” sentences to augment the bags and train the model to ignore the distractors.,Performance Evaluation,Performance Evaluation
"We present Neighborhood Matching Network (NMN), a novel sampling-based entity alignment framework. NMN aims to capture the most informative neighbors and accurately estimate the similarities of neighborhoods between entities in different KGs",Model Proposal,Model Proposal
"In this paper, we use ideas from graph-based dependency parsing to provide our model a global view on the input via a biaffine model (Dozat and Manning, 2017).",Model Optimization,Model Optimization
We then propose a Medical Information Extractor (MIE) towards medical dialogues.,New Algorithm/ Method,New Algorithm/ Method
"In this study, we develop models possessing interpretable inference process for structured prediction. Specifically, we present a method of instance-based learning that learns similarities between spans.",Model Proposal,Model Proposal
"In this paper, we refer this phenomenon particularly to rare entity problem. It is different from other types of data sparsity problems such as the lack of training data for lowresource language (Lin et al., 2018), as this rare entity problem is more related to a mismatch of entity distributions between training and test, rather than the size of training data. We present an example of the problem in Table",Theory Proposal,Theory Proposal
we introduce episodic memory activation and reconsolidation (EMAR) to continual relation learning in this paper,Theory Proposal,Theory Proposal
"In this paper, we propose a novel approach for KG entity typing which is trained by jointly utilizing local typing knowledge from existing entity type assertions and global triple knowledge from KGs.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a novel bipartite flatgraph network (BiFlaG) for nested named entity recognition (NER), which contains two subgraph modules: a flat NER module for outermost entities and a graph module for all the entities located in inner layers.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we argue that incorporation of multimodal cues can improve the automatic identification of PPI",Theory Proposal,Theory Proposal
"In this paper, we justify from both computational and perceptive points-of-view that the top-down architecture is more suitable for textlevel DRS parsing. On the basis, we propose a top-down neural architecture toward text-level DRS parsing.",Performance Evaluation,Performance Evaluation
"In this paper, we propose an automatic evaluation model based on that idea and learn the model parameters from an unlabeled conversation corpus.",Model Proposal,Model Proposal
We propose a Dialogue State Tracker with Slot Attention and Slot Information Sharing (SAS) to reduce redundant information’s interference and improve long dialogue context tracking.,Model Optimization,Model Optimization
"In this paper, we present that efficiently learns dialogue policy from demonstrations through policy shaping and reward shaping.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose a novel Dynamic Fusion Network (DFNet) which automatically exploit the relevance between the target domain and each domain. Results show that our model outperforms existing methods on multi-domain dialogue, giving the state-of-the-art in the literature",Model Optimization,Model Optimization
"In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose to enhance the DST through employing a contextual hierarchical attention network to not only discern relevant information at both word level and turn level but also learn contextual representations",Algorithm/Method Optimization,Algorithm/Method Optimization
"In this paper we intend to give a thorough chronology of the major interplay between corpus progression and query tool evolution, with a strong focus on the latter",Theory Proposal,Theory Proposal
"In this paper, we trace the history of neural networks applied to natural language understanding tasks, and identify key contributions which the nature of language has made to the development of neural network architectures.",Theory Proposal,Theory Proposal
"In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time.",Theory Proposal,Theory Proposal
"This work proposes an approach to representation and learning based on the tenets of embodied cognitive linguistics (ECL). According to ECL, natural language is inherently executable (like programming languages), driven by mental simulation and metaphoric mappings over hierarchical compositions of structures and schemata learned through embodied interaction",Theory Proposal,Theory Proposal
"In this paper, we analyze three different instances of sample bias that are prevalent in QE datasets, which affect the generalization that models trained on them can achieve.",Performance Evaluation,Performance Evaluation
" we propose an algorithm that reduces parsing to tagging, where all tags are predicted in parallel using a standard model architecture such as BERT (Devlin et al., 2019).",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a multi-granularity interaction network for extractive and abstractive multi-document summarization, which jointly learn semantic representations for words, sentences, and documents.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we develop a neural abstractive multidocument summarization (MDS) model which can leverage well-known graph representations of documents such as similarity graph and discourse graph, to more effectively process multiple input documents and produce abstractive summaries.",Model Optimization,Model Optimization
"In this paper, we propose to ease the cross-lingual summarization training by jointly learning to align and summarize. We design relevant loss functions to train this framework and propose several methods to enhance the isomorphism and cross-lingual transfer between languages.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present a heterogeneous graph-based neural network for extractive summarization (HETERSUMGRAPH), which contains semantic nodes of different granularity levels apart from sentences.",Model Proposal,Model Proposal
"In this paper, we focus on extractive summarization since it usually generates semantically and grammatically correct sentences (Dong et al., 2018; Nallapati et al., 2017) and computes faster.",Theory Proposal,Theory Proposal
"In this paper, we argue that elementary discourse unit (EDU) is a more appropriate textual unit of content selection than the sentence unit in abstractive summarization",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we study the challenging problem of automatic generation of citation texts in scholarly papers",New Algorithm/ Method,New Algorithm/ Method
we present a method suitable for reasoning about the semantic-level structure of evidence.,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose two efficient neural mixed counting models, i.e., the Negative BinomialNeural Topic Model (NB-NTM) and the Gamma Negative Binomial-Neural Topic Model (GNB-NTM) for dispersed topic discovery.",Model Proposal,Model Proposal
"we propose neural graph matching networks, a novel sentence matching framework capable of dealing with multi-granular input information",New Algorithm/ Method,New Algorithm/ Method
"we propose a neural network model, called NeuInfer, to conduct both simple and flexible knowledge inference on n-ary facts",Model Proposal,Model Proposal
"we propose to incorporate paraphrase knowledge into question generation(QG) to generate human-like questions. Specifically, we present a two-hand hybrid model leveraging a self-built paraphrase resource, which is automatically conducted by a simple back-translation method.",Applications,Applications
" we propose an approach that automatically finds evidence for an event from a large text corpus, and leverages the evidence to guide the generation of inferential texts",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we introduce a method for evaluating whether neural models can learn systematicity of monotonicity inference in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition",New Algorithm/ Method,Performance Evaluation
"In this paper, we draw inspiration from similar ideas, and propose our approach 6096 for arranging a curriculum when learning NLU tasks",Theory Proposal,Theory Proposal
we propose a novel decoding algorithm that integrates constrained decoding using positive/negative examples during inference: this demonstrates the potential of our dataset to enable work at the intersection of NLP and program synthesis.,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a novel attack model, which incorporates the sememebased word substitution method and particle swarm optimization-based search algorithm to solve the two problems separately.",Model Proposal,Model Proposal
"we propose LogicalFactChecker, a neural network approach capable of leveraging logical operations for fact checking",New Algorithm/ Method,New Algorithm/ Method
we explore the effectiveness of incorporating two varieties of external knowledge into NL-to-code generation: automatically mined NL-code pairs from the online programming QA forum StackOverflow and programming language API documentation.,Performance Evaluation,Performance Evaluation
we propose a novel speed-tunable FastBERT with adaptive inference time.,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present the first detailed empirical study of the effects of different masked lan- guage modeling (MLM) pretraining regimes on cross-lingual transfer. Our first set of experiments is a detailed ablation study on a range of zero-shot cross-lingual transfer tasks",Algorithm/Method Optimization,Algorithm/Method Optimization
"In this paper, we present an effective retrievalbased approach to paraphrase generation by proposing a novel editor module.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we use both frequency changes and word semantic shifts to measure document influence by developing a neural network based framework",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we apply pre-trained word embedding as the intermediate level in the multitask ST model. We propose to constrain the hidden states of the decoder of the recognition part to be close to the pre-trained word embedding",Model Proposal,Model Proposal
"In this paper, we show that neural machine translation (NMT) systems trained on large back-translated data overfit some of the characteristics of machine-translated texts",Theory Proposal,Theory Proposal
we propose to use extracted templates from tree structures as soft target templates to guide the translation procedure.,Theory Proposal,Theory Proposal
"In this work, we investigate the effect of future sentences as context by comparing the performance of a contextual NMT model trained with the future context to the one trained with the past context.",Performance Evaluation,Performance Evaluation
"In this paper, we propose a new adversarial augmentation method for Neural Machine Translation (NMT).",New Algorithm/ Method,New Algorithm/ Method
"In this work, we propose a simple but effective method for incorporating the word lexicon into the character representations.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we consider the problem of shifted label distribution, which is caused by the inconsistency between the noisy-labeled training set subject to external knowledge graph and the human-annotated test set, and exacerbated by the pipelined entity-then-relation extraction manner with noise propagation",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we take the benefits of ConvE and KBGAT together and propose a Relation-aware Inception network with joint local-global structural information for knowledge graph Embedding (ReInceptionE). Specifically, we first explore the Inception network to learn query embedding, which aims to further increase the interactions between head and relation embeddings",Model Proposal,Model Proposal
"In this paper, we propose a novel layered model called Pyramid for nested NER. The model consists of a stack of inter-connected layers. Each layer l predicts whether a text region of certain length l, i.e. an l-gram, is a complete entity mention",Model Optimization,Model Optimization
We investigate a multi-cell compositional LSTM structure to deal with the above challenges by separately and simultaneously considering the possibilities of all entity types for each word when processing a sentence.,Performance Evaluation,Performance Evaluation
"In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. We present a joint
model that supports multi-class classification
and introduce a simple variant of self-attention
that allows the model to learn scaling factors.",Model Optimization,Model Optimization
"In the paper, we empower the model with external knowledge called Open-Domain Trigger Knowledge to provides extra semantic support on unseen/sparsely labeled trigger words and improve trigger identification",Model Optimization,Model Optimization
"We present IMOJIE, an extension to CopyAttention, which produces the next extraction conditioned on all previously extracted tuples. we design the first neural OpenIE
system that uses sequential decoding of tuples conditioned on previous tuples.",Resources,Resources
"We propose a simple, effective transition-based model with generic neural encoding for discontinuous NER.We propose an end-to-end
transition-based model with generic neural
encoding that allows us to leverage specialized
actions and attention mechanism to determine
whether a span is the component of a discontinuous
mention or not.",Model Proposal,Model Proposal
"In this paper, we propose a unified framework that is capable of handling both flat and nested NER tasks",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we leverage the power of pre-trained language models for improving video-grounded dialogue, which is very challenging and involves complex features of different dynamics: (1) Video features which can extend across both spatial and temporal dimensions; and (2) Dialogue features which involve semantic dependencies over multiple dialogue turns. We propose a framework by extending GPT-2 models to tackle these challenges by formulating videogrounded dialogue tasks as a sequence-tosequence task, combining both visual and textual representation into a structured sequence, and fine-tuning a large pre-trained GPT-2 network.",Algorithm/Method Optimization,Algorithm/Method Optimization
"In this paper, we propose an algorithm that can customize a unique dialogue model for each task in the few-shot setting",New Algorithm/ Method,New Algorithm/ Method
"In this work, we introduce a three-stage framework that employs a generate-delete-rewrite mechanism to delete inconsistent words from a generated response prototype and further rewrite it to a personality-consistent one. We carry out evaluations by both human and automatic metrics. Experiments on the Persona-Chat dataset show that our approach achieves good performance",Model Optimization,Model Optimization
"this paper proposes a novel commonsense knowledge-aware dialogue generation model, ConKADI. We design a Felicitous Fact mechanism to help the model focus on the knowledge facts that are highly relevant to the context; furthermore, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion are proposed to facilitate the integration of the knowledge in the ConKADI",Performance Evaluation,Performance Evaluation
"We investigate the following research questions: (i) what is the effect of integrating preprocessing techniques earlier into word embedding models, instead of later on in a downstream classification models? (ii) which preprocessing techniques yield the most benefit in affective tasks? (iii) does preprocessing of word embeddings provide any improvement over stateof-the-art pretrained word embeddings? and if yes, how much?",Performance Evaluation,Performance Evaluation
"We present OPINIONDIGEST, an abstractive opinion summarization framework, which does not rely on gold-standard summaries for training",Theory Proposal,Theory Proposal
we propose a novel Entity-aware Dependencybased Deep Graph Attention Network (ED-GAT) for comparative preference classification. We represent a sentence by its dependency graph,Model Proposal,Model Proposal
"We present an efficient annotation framework for argument quality, a feature difficult to be measured reliably as per previous work.",Model Optimization,Model Optimization
"In this paper, we investigate an extreme scenario of cross-lingual sentiment classification, in which the low-resource language does not have any labels or parallel corpus. We propose an unsupervised cross-lingual sentiment classification model named multi-view encoder-classifier (MVEC) that leverages an unsupervised machine translation (UMT) system and a language discriminator",Performance Evaluation,Performance Evaluation
"in this paper, we introduce a new research problem, stance polarity and intensity prediction in a responsive relationship between posts, which aims to predict a text’s stance polarity and intensity which we combine into a single continuous agreement value",Performance Evaluation,Performance Evaluation
"In this paper, we present the first comprehensive categorization of essential commonsense knowledge for answering the Winograd Schema Challenge (WSC).",New Algorithm/ Method,New Algorithm/ Method
. In this paper we demonstrate that the combination of a consistent answer structure with span annotations opens the door for new approaches to automatic verification of annotations and enables new types of analyses for reading comprehension.,Theory Proposal,Theory Proposal
"we provide best practices and guidelines tailored towards NLP research, as well as an easy-to-use package called HyBayes for Bayesian assessment of hypotheses,1 complementing existing tools.",Theory Proposal,Theory Proposal
We introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue.,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we introduce the Cascade Transformer, a simple yet effective technique to adapt transformer-based models into a cascade of rankers.",New Algorithm/ Method,New Algorithm/ Method
"we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy",Performance Evaluation,Performance Evaluation
"In this paper, we present SCDE, a dataset of sentence-level cloze questions sourced from public school examinations.",Model Proposal,Model Proposal
"In this paper, we demonstrated that the choice of probability space and interpretation of the distant supervision signal for document-level QA have a large impact, and that they interact.",Performance Evaluation,Performance Evaluation
"we show that diversity-promoting QG indeed provides better QA training than likelihood maximization approaches such as beam search. We also show that standard QG evaluation metrics such as BLEU, ROUGE and METEOR are inversely correlated with diversity, and propose a diversity-aware intrinsic measure of overall QG quality that correlates well with extrinsic evaluation on QA.",Performance Evaluation,Performance Evaluation
"In this paper, we address the task of producing globally consistent and accurate predictions for comparison questions leveraging logical and symbolic knowledge for data augmentation and training regularization",Model Optimization,Model Optimization
"In this work, we propose to cross variational auto-encoders by generating questions with aligned answers and generating answers with aligned questions.",New Algorithm/ Method,New Algorithm/ Method
"In this work, we study the benefits of collecting intermediate reasoning supervision along with the answer during data collection.",Theory Proposal,Theory Proposal
"In this work, we extend this selective rationalization approach to text matching, where the goal is to jointly select and align text pieces, such as tokens or sentences, as a justification for the downstream prediction",New Algorithm/ Method,New Algorithm/ Method
" we propose and conduct a systematic evaluation of the intermediate outputs of NMNs on NLVR2 and DROP, two datasets which require composing multiple reasoning steps.",Algorithm/Method Optimization,Algorithm/Method Optimization
we build hierarchical explanations by detecting feature interactions.,New Algorithm/ Method,New Algorithm/ Method
"we present an unsupervised analysis method that provides evidence mBERT learns representations of syntactic dependency labels, in the form of clusters which largely agree with the Universal Dependencies taxonomy.",New Algorithm/ Method,New Algorithm/ Method
we develop a new quantitative measure based on influence functions that can reveal artifacts in training data,Theory Proposal,Theory Proposal
"In this paper, we evaluated five explanation methods through simulation tests with text and tabular data.",Performance Evaluation,Performance Evaluation
"In this paper, we introduce the Cross-Linguistic Assessment of Models on Syntax (CLAMS) data set, which extends the subject-verb agreement component of the Marvin and Linzen (2018) challenge set to French, German, Hebrew and Russian",Dataset Creation,Dataset Creation
"In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem.",Theory Proposal,Theory Proposal
"In this paper, we investigate the presence of social biases in sentence-level representations and propose a new method, SENTDEBIAS, to reduce these biases",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present evidence of such undesirable biases towards mentions of disability in two different English language models: toxicity prediction and sentiment analysis",Theory Proposal,Model Proposal
"We introduce SOCIAL BIAS FRAMES, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others",New Algorithm/ Method,New Algorithm/ Method
"We survey 146 papers analyzing “bias” in NLP systems, fnding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing",Theory Proposal,Theory Proposal
"We propose a simple but effective technique, Double-Hard Debias, which purifies the word embeddings against such corpus regularities prior to inferring and removing the gender subspace.",New Algorithm/ Method,New Algorithm/ Method
we propose a novel regularization technique based on these explanations that encourages models to learn from the context of group identifiers in addition to the identifiers themselves.,New Algorithm/ Method,New Algorithm/ Method
"We propose to better explore their interaction by solving both tasks together, while the previous work treats them separately",Model Optimization,Model Optimization
"We propose PeTra, a memory-augmented neural network designed to track entities in its memory slots. PeTra is trained using sparse annotation from the GAP pronoun resolution dataset and outperforms a prior memory model on the task while using a simpler architecture",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we revisit prior work to explicate the inconsistencies and propose an improved evaluation protocol to promote experimental rigor in future work.",Model Optimization,Model Optimization
we explore to what extent neural network sentence encoders can learn to predict the strength of scalar inferences,Theory Proposal,Theory Proposal
"we apply an existing theory of functional discourse structure for news articles that revolves around the main event and create a human-annotated corpus of 802 documents spanning over four domains and three media sources, we propose several documentlevel neural-network models to automatically construct news content structures",Applications,Applications
we present a new task and corpus for learning alignments between machine and human preferences,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we take the first step towards a better understanding of these processes and the underlying dynamics that shape them, using data-driven methods. We build a new large-scale dataset, from multiple data sources, connecting state bills and legislator information, geographical information about their districts, and donations and donors’ information",Performance Evaluation,Performance Evaluation
"In this paper, we introduce the text-based ideal point model (tbip), an unsupervised probabilistic topic model that analyzes texts to quantify the political positions of its authors. We demonstrate the tbip with two types of politicized text data: U.S. Senate speeches and senator tweets.",Model Proposal,Model Proposal
"we collect and categorize applications with text as a causal confounder (Table 1 and §2), and we provide a flowchart of analysts’ decisions for this problem setting,we highlight recent work in representation learning in NLP (§4) and caution that this is still an open research area with questions of the sensitivity of effects to choices in representation,we summarize some of the most-used causal estimators that condition on confounders:matching, propensity score weighting, regression adjustment, doubly-robust methods, and causally-driven representation learning .",New Algorithm/ Method,New Algorithm/ Method
In this paper we explore connections between the language people use to describe their predictions and their forecasting skill.,Algorithm/Method Optimization,Algorithm/Method Optimization
" In this paper, we present a novel model that uses message-level attention to learn the relative weight of users’ social media posts for assessing their five factor personality traits. We demonstrate that models with message-level attention outperform those with word-level attention, and ultimately yield stateof-the-art accuracies for all five traits by using both word and message attention in combination with past approaches (an average increase in Pearson r of 2.5%).",New Algorithm/ Method,Model Proposal
"In this paper, we introduce HURRICANEEMO, an emotion dataset of 15,000 English tweets spanning three hurricanes: Harvey, Irma, and Maria. We present a comprehensive study of fine-grained emotions and propose classification tasks to discriminate between coarsegrained emotion groups.",Dataset Creation,Dataset Creation
we develop an unsupervised methodology to quantify how counselors manage this balance.,Theory Proposal,Theory Proposal
we demonstrate that certain attention heads of a visually grounded language model actively ground elements of language to image regions.,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias.",New Algorithm/ Method,New Algorithm/ Method
we perform a large-scale study on the pretrained RoBERTa model with 110 intermediate–target task combinations,Model Proposal,Model Proposal
"In this paper, we describe the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an indepth analysis of the advantages and disadvantages of existing works to explore possible future directions.",Theory Proposal,Theory Proposal
We advocate for supplementing or replacing PAID with paradigms that reward architectures that generalize as quickly and robustly as humans.,Model Optimization,Model Optimization
"In this paper, we describe work on examining the papers and their citations to identify broad trends within NLP research—overall, across paper types, across publication venues, over time, and across research areas within NLP. Notably, we explored questions such as: how well cited are papers of different types (journal articles, conference papers, demo papers, etc.)? how well cited are papers published in different time spans? how well cited are papers from different areas of research within NLP? etc",Theory Proposal,Theory Proposal
"In this position paper, we argue that a system trained only on form has a priori no way to learn meaning,We argue in this paper that genuine progress in our field — climbing the right hill,
not just the hill on whose slope we currently sit—
depends on maintaining clarity around big picture
notions such as meaning and understanding in task
design and reporting of experimental results.",Theory Proposal,Theory Proposal
"In this paper, we engage with an idea largely absent from discussions of meaning in natural language understanding—namely, that the way something is expressed reflects different ways of conceptualizing or construing the information being conveyed",New Algorithm/ Method,New Algorithm/ Method
"We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the “amount of novelty” going into the new review or, equivalently, vary the extent to which it deviates from the input.",Model Proposal,Model Proposal
"This paper presents a novel unsupervised abstractive summarization method that generates summaries directly from source documents, without the aid of example summaries.",New Algorithm/ Method,New Algorithm/ Method
"This paper describes the Critical Role Dungeons and Dragons Dataset (CRD3) and related analyses. Critical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons, an openended role-playing game.",Resources,Resources
we develop a general framework where we evaluate the factual correctness of a generated summary by factchecking it automatically against its reference using an information extraction module,Performance Evaluation,Performance Evaluation
"We propose the use of dual encoders—a sequential document encoder and a graphstructured encoder—to maintain the global context and local characteristics of entities, complementing each other.",New Algorithm/ Method,New Algorithm/ Method
We present Deep Generalized Canonical Correlation Analysis (DGCCA).,New Algorithm/ Method,New Algorithm/ Method
we investigate a variety of features for automatically detecting plagiarized spoken responses in the context of a standardized assessment of English speaking proficiency.,Model Optimization,Model Optimization
"we recorded 2 hours of Chinese voice data from a female speaker, and Xiaomingbot learnt to speak in English and Japanese with the same voice.",Resources,Resources
"We propose an end-to-end, data-driven model for predicting depression from interview transcripts that leverages the contextual information provided by interviewer prompts",Model Proposal,Model Optimization
We conduct robust experiments to show that our model outperforms competitive baselines,Resources,Resources
"Our proposal rests on A light-weight query language that does not require in-depth familiarity with the underlying syntactic representation scheme, and instead lets the user specify their intent via a natural language example and lightweight markup.",Theory Proposal,Theory Proposal
"Our proposal rests on A fast, near-real-time response time due to efficient indexing, allowing for rapid experimentation",Performance Evaluation,Performance Evaluation
We describe how the cards were generated where each card corresponds to a Wikipedia page,Theory Proposal,Theory Proposal
"we adapted MRS techniques to create a conversational search portal that enable users to ask natural language questions to find precise answers and extract insights from the last 3 year papers published in top-tier NLP conferences, including ACL, NAACL, EMNLP and etc.",Applications,Applications
We developed a collaborative annotation toolkit that enable any researcher to contribute to this dataset so that more potential answers from these papers can be annotated.,Dataset Creation,Dataset Creation
we provided further evidence that the nature of LKBs impacts on system performance: the injection of syntagmatic relations – in the form of disambiguated pairs of co-occurring words – into an existing LKB biased towards paradigmatic knowledge enables knowledge-based systems to rival their supervised counterparts,Model Optimization,Model Optimization
"we introduce a Web interface and a RESTful API for SyntagRank, our multilingual WSD system, which applies the Personalized PageRank (PPR) algorithm (Haveliwala, 2002) to an LKB made up of WordNet, the Princeton WordNet Gloss Corpus (PWNG) and the lexical-semantic syntagmatic combinations available in the SyntagNet resource",New Algorithm/ Method,New Algorithm/ Method
"We introduce a broad-coverage, datadriven and linguistically sound set of transformations, that makes event-structure and many lexical relations explicit",Dataset Creation,Dataset Creation
"We present pyBART, an easy-to-use open-source Python library for converting English UD trees either to Enhanced UD graphs or to our representation",Theory Proposal,Model Optimization
"We build EVIDENCEMINER, a web-based system for textual evidence discovery for life sciences. EVIDENCEMINER is supported by novel methods for distantly supervised named entity recognition and pattern-based open information extraction.",New Algorithm/ Method,New Algorithm/ Method
"we describe a prototype system that facilitates interactive exploration and mapping of the evidence base, with an emphasis on answering the above questions",Theory Proposal,Theory Proposal
we introduce SyntaxGym: an online platform and open-source framework that makes targeted syntactic evaluations more accessible to experts in NLP and linguistics,Theory Proposal,New Algorithm/ Method
"Our system, GAIA enables seamless search of complex graph queries, and retrieves multimedia evidence including text, images and videos.",Theory Proposal,Theory Proposal
"We present easy-to-use retrieval focused multilingual sentence embedding models, made available on TensorFlow Hub",Theory Proposal,Model Optimization
"we developed a user-friendly workflow management platform, 96 BiomEdical Nlp TOolkits (BENTO), to facilitate the process of building and applying of clinical NLP pipelines.",Applications,Model Proposal
"we present BENTO, a workflow management platform with a graphic user interface (GUI) that is built on top of CodaLab, to facilitate the process of building clinical NLP pipelines",Theory Proposal,Model Optimization
"We introduce Stanza , a Python natural language processing toolkit supporting many human languages",Theory Proposal,New Algorithm/ Method
"We demonstrate that jiant reproduces published performance on a variety of tasks and models, including BERT and RoBERTa.",New Algorithm/ Method,Performance Evaluation
"We introduce MT-DNN, a comprehensive and easily-configurable open-source toolkit for building robust and transferable natural language understanding models.",Model Proposal,Model Optimization
we developed a web-based system LinggleWrite (f.linggle.com) with many assistive writing functions.,New Algorithm/ Method,New Algorithm/ Method
"We release CLIReval, 1 an open-source toolkit that evaluates the quality of MT outputs in the context of a CLIR system, without the need for any actual CLIR dataset.",Performance Evaluation,Performance Evaluation
"We demonstrate that CLIReval can perform as well as popular intrinsic MT metrics on recent WMT metrics shared task, without supervision from external datasets and domain-basedparameter tuning",Dataset Creation,Dataset Creation
we have developed an analysis tool and an interactive tool to assist researchers in diagnosing dialogue systems.,New Algorithm/ Method,New Algorithm/ Method
"We present a framework for bitext cleaning, OpusFilter, focusing on processing data collected in OPUS (Tiedemann, 2012), the world’s largest resource of openly available parallel corpora",Theory Proposal,Model Optimization
"We propose the Label Noise in Context system, or LNIC, which uses the neighborhood surrounding a suspicious example in the training set to improve both precision and explainability.",Theory Proposal,Theory Proposal
We describe LNIC’s nearest-neighbors-based algorithm to improve precision and explainability of automatically detected label noise,New Algorithm/ Method,New Algorithm/ Method
"we developed EXBERT, a tool that combines the advantages of static analyses with a dynamic and intuitive view into both the attentions and internal representations of the underlying model.",New Algorithm/ Method,Model Proposal
We demonstrate that EXBERT can replicate insights from the analysis by Clark et al. (2019) and easily extend it to other models,Performance Evaluation,Performance Evaluation
"We present a web-based system for diacritization of Hebrew text, which caters to both casual and expert users",Theory Proposal,Model Optimization
We provide a web interface for the user to input a text for diacritization and refine the resulting diacritized text,Model Optimization,Model Optimization
"We aim to provide a tool that is useful to casual users and language enthusiasts, but also to experts and professionals who may use it to set scientific editions of historical Hebrew texts.",Model Optimization,Model Optimization
"we present PHOTON, a modular, cross-domain NLIDB that adopts deep learning in its core components",Theory Proposal,Model Optimization
we present the prototype of a new task automation agent named SUGILITE,Theory Proposal,Model Optimization
"we unified the models of different implementation in a single codebase, implemented demos as top-level managers to access different models, and provide strategies to allow more organic integration across the models, including token probability interpolation, cross-mode scoring, latent interpolation, and unified hypothesis ranking",Model Optimization,Model Optimization
"We describe how we built an interactive visual explorer for this unified data, which we refer to as NLP Scholar",Theory Proposal,Theory Proposal
"we introduce Funlines1 , an online game for generating funny news headlines for humor research.",Theory Proposal,New Algorithm/ Method
"We explore and evaluate this fun, competitive way of motivating people to contribute creative text, addressing some of the special challenges of generating humor data mentioned above.",Performance Evaluation,Performance Evaluation
we optimize for efficiency with features that collapse common patterns observed in user testing and components designed for the iterative tuning of the semantic parser exemplars.,Performance Evaluation,Performance Evaluation
"We introduce DIALOGPT, a tunable gigawordscale neural network model for generation of conversational reponses, trained on Reddit data.",Model Proposal,Model Optimization
"we introduce a new version of ADVISER - previously a text-based, multi-domain dialog system toolkit (Ortega et al., 2019) - that supports multi-modal dialogs, including speech, text and vision information processing",Algorithm/Method Optimization,Algorithm/Method Optimization
we present Prta —the PRopaganda persuasion Techniques Analyzer.,Theory Proposal,Model Optimization
"we exploit dilated convolution and n-gram matching mechanism to extract implicit semantic features and explicit semantic features, respectively.",Theory Proposal,Theory Proposal
we develop a system to assist the professional coders in assigning the correct codes.,New Algorithm/ Method,New Algorithm/ Method
"We present ESPnet-ST, a toolkit that implements many of the recent models for E2E-ST, as well as the ASR and MT modules for Cascade-ST.",Theory Proposal,Model Optimization
", we extend ESPnet to ST tasks, providing code for building translation systems and recipes (i.e., scripts that encapsulate the entire training/inference procedure for reproducibility purposes) for a wide range of ST benchmarks.",Theory Proposal,Theory Proposal
"We describe and demonstrate Penman, a Python library and command-line utility for working with AMR data at both the tree and graph levels and for encoding and decoding these structures using PENMAN notation",Theory Proposal,Theory Proposal
"We introduce a web application for writing scientific text with integrated literature discovery, paper reading, and bibliography management capabilities.",Theory Proposal,New Algorithm/ Method
"we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT.",Theory Proposal,Model Optimization
"We present MMPE, the first translation environment combining standard mouse & keyboard input with touch, pen, and speech interactions for PE of MT",Theory Proposal,Model Optimization
"We introduce Torch-Struct, a library for structured prediction designed to take advantage of and integrate with vectorized, auto-differentiation based frameworks",Theory Proposal,New Algorithm/ Method
we also include a number of general-purpose optimizations to provide cross-algorithm efficiency.,Performance Evaluation,Performance Evaluation
we present a novel approach to building dialog managers (DMs).,Theory Proposal,Model Optimization
"we showcase Conversation Learner, a machine teaching tool for building dialog managers",Theory Proposal,Theory Proposal
"We tackle the challenges involved with consuming vast quantities of news by leveraging modern techniques to semantically cluster stories, as well as innovative summarization methods to extract succinct, informational summaries for each cluster",New Algorithm/ Method,New Algorithm/ Method
"We leverage labeled datasets for DDI identification for supervision, and train a model that transfers to the related task of identifying supplement interactions.",Model Optimization,Dataset Creation
we design task specific architectures to incorporate the now captured explanations into training,Model Proposal,Model Proposal
"We designed, built, and evaluated a fully automated news chatbot that bases its content on a stream of news articles from a diverse set of English news sources",Performance Evaluation,Performance Evaluation
We perform interpretability analysis to learn how these approaches can enhance our understanding of attention behavior and adaptive approaches,Applications,Applications
We provide experimental results on the recent adaptive approaches for the multi-modal input sequences.,Model Optimization,Model Optimization
we propose methods to transfer text style on the story level.,New Algorithm/ Method,New Algorithm/ Method
we define style as the setting of the story which reveals time background and geographical information,Theory Proposal,Theory Proposal
"we describe our novel unsupervised method, which can be implemented without the need for labeled paraphasia data",New Algorithm/ Method,New Algorithm/ Method
We demonstrate the utility of our method as an essential first step in developing augmentative and alternative communication (AAC) devices for patients suffering from aphasia in any language.,New Algorithm/ Method,New Algorithm/ Method
"we propose a novel GCN (Kipf and Welling, 2016)-based MeSH term index model, HGCN4MeSH, which learns the co-occurrence representation of tags via a GCN-based mapping function",Model Proposal,Model Optimization
we design a novel data-driven adjacency matrix to guide the information propagation between nodes.,Model Proposal,Model Proposal
We confirm that selecting training data similar to the learners’ corpus instead of using randomly selected monolingual data improves the performance of the GEC model.,Applications,Applications
We show the effect of realistic pseudo errors by considering the types of errors typically made by language learners for the Russian GEC task.,Theory Proposal,Theory Proposal
"we study the relations among several popular embedding methods, including GloVe (Pennington et al., 2014), SGNS1 (Mikolov et al., 2013), Singular Value Decomposition (SVD) factorization of PMI matrix, and SVD factorization of log count (LC) matrix.",New Algorithm/ Method,New Algorithm/ Method
"we analyze the influence of training processes, i.e. hyperparameters (negative sampling), random initialization; and the influence of corpora towards word embeddings.",Resources,Resources
We propose a word attribute transfer method that obtains a vector with an inverted binary attribute without explicit knowledge.,New Algorithm/ Method,New Algorithm/ Method
The proposed method demonstrates more accurate word attribute transfer for words that have target attributes than other baselines without changing the words that do not have the target attributes.,New Algorithm/ Method,New Algorithm/ Method
"we propose a balancing procedure, based on the a priori ratio between topic capacities.",Theory Proposal,Theory Proposal
"We propose to modify the Transformer architecture (Vaswani et al., 2017) to combine the learned subword representations into word representations in the encoder block.",Theory Proposal,Theory Proposal
We demonstrate that the North KoreanEnglish translation model can be trained effectively on bilingual South Korean-English data by character-level tokenization and phonemelevel decomposition.,Performance Evaluation,Performance Evaluation
"we propose a method to tokenize South Korean input sentences at the character level and decompose them into phonemes to mitigate the grammatical differences between South Korean and North Korean, and demonstrate that the translation model from North Korean to English can be effectively learned using bilingual South Korean-English data.",Model Proposal,New Algorithm/ Method
we present an unsupervised deep learning framework (SCAR) for deletion-based sentence compression,New Algorithm/ Method,Model Optimization
We introduce a novel linkage loss that ties together the compressor and the reconstructor.,New Algorithm/ Method,Theory Proposal
"we propose a model that can identify and focus on abnormal findings more specifically and precisely, similar to the way that physicians would typically read, interpret, and write chest x-ray reports.",Model Proposal,Model Optimization
we investigate a method to exploit the monolingual data of the agglutinative language to enhance the representation ability of the encoder.,New Algorithm/ Method,New Algorithm/ Method
We experimentally compare the relevances produced by our method to those of other black-box and gradient-based explanation approaches.,New Algorithm/ Method,New Algorithm/ Method
We introduce the class zero-sum axiom for explanation methods.,New Algorithm/ Method,New Algorithm/ Method
We introduce NTUs as a novel research object that is capable of advancing our understanding of the interactive and rational aspects of social talk.,New Algorithm/ Method,Theory Proposal
We propose an annotation strategy for exploring NTUs in naturally occurring dialogues.,Theory Proposal,Theory Proposal
We propose to replace the rich linguistic feature templates used in the past approaches with a minimal feature function using contextual vector representations,Theory Proposal,Theory Proposal
We train a BERT model on the Telugu Wikipedia data and use vector representations from this model to train the parser.,New Algorithm/ Method,Model Optimization
we understand how models which perform well under pointwise evaluation may fail in practice and find better methods for evaluating paraphrase identification models,New Algorithm/ Method,New Algorithm/ Method
we present our efforts towards building efficient NMT systems between Indian languages (specifically Indo-Aryan languages) and English by exploiting parallel data from related languages,Performance Evaluation,Performance Evaluation
we propose an interpretable approach for event extraction (EE) that mitigates the tension between generalization and interpretability through multitask learning (MTL).,Theory Proposal,Theory Proposal
"We extend a subset of the BioNLP 2013 GENIA event extraction (Kim et al., 2013) dataset with a
set of rules designed to extract and explain three
of the GENIA biomedical events: protein phosphorylation, localization, and gene expression",Dataset Creation,Dataset Creation
We propose a dataset which maintains a broad scope but which addresses subjectivity,Theory Proposal,Theory Proposal
We propose an effective unsupervised alignment method to tackle the alignment problem.,New Algorithm/ Method,New Algorithm/ Method
we propose a strategy to supplement state-of-theart models with automatically extracted information using basic NLP tools to effectively handle rich morphology.,Model Proposal,Model Optimization
"We describe the first effort at establishing points of correspondence between disparate sentences. Without a clear understanding of points of correspondence, sentence fusion remains a daunting challenge that is only sparsely and sometimes incorrectly performed by abstractive summarizers.",Theory Proposal,Theory Proposal
We present a sizable dataset for sentence fusion containing human-annotated corresponding regions between pairs of sentences,Dataset Creation,Dataset Creation
We developed an uncertainty-aware automatic evaluation method for dialogue systems. Our method automates the human ratings required in ∆BLEU while keeping the performance.,New Algorithm/ Method,New Algorithm/ Method
We showed that integrating υBLEU into RUBER greatly improves RUBER’s performance by providing the robustness to evaluate responses with uncertainty,Performance Evaluation,Performance Evaluation
we present a preliminary morphological analyser for verbs in Nen,New Algorithm/ Method,Model Optimization
we outline a computational approach for modelling the linguistic phenomenon of distributed exponence.,Model Proposal,Model Proposal
"We propose a novel end-to-end Arabic document classification framework, Arabic document imagebased classifier (AraDIC), inspired by the work on image-based character embeddings. AraDIC consists of an image-based character encoder and a classifier",Theory Proposal,Theory Proposal
We propose to integrate label component information as embeddings into models. This procedure consists of two steps: (i) label decomposition and (ii) label embedding calculation.,Model Proposal,Model Optimization
we build a Japanese Wikipedia typo dataset (JWTD) from Japanese Wikipedia’s revision history.,Dataset Creation,Dataset Creation
We introduce a new task formulation of SAS that matches the actual usage,New Algorithm/ Method,Theory Proposal
we seek to develop models that bridge the gap between biological plausibility and linguistic competence,New Algorithm/ Method,Model Optimization
We propose a method to further align representations from such models into the cross-lingual space and use them to derive sentence embeddings.,Model Proposal,New Algorithm/ Method
we present a compositional semantics that maps various comparative constructions in English to semantic representations via Combinatory Categorial Grammar (CCG) parsers and combine it with an inference system based on automated theorem proving,New Algorithm/ Method,Model Optimization
"We introduce a set of new linguistic constraints (i.e. synonyms and antonyms) created with BabelNet for three languages: English, German and Italian.",New Algorithm/ Method,Theory Proposal
"We introduce an improved post-specialization method (dubbed WGAN-postspec), which demonstrates improved performance as compared to state-of-the-art DFFN (Vulic et al. ´ , 2018) and AuxGAN (Ponti et al., 2018) models",New Algorithm/ Method,New Algorithm/ Method
We show that the proposed approach achieves performance improvements on an intrinsic task (word similarity) as well as on a downstream task (dialog state tracking),Theory Proposal,Theory Proposal
We give a novel study of leveraging monolingual corpora of related and unrelated languages for NMT pre-training.,Model Proposal,Model Proposal
We make a comparison of existing and proposed techniques in a variety of corpora settings to verify our hypotheses,Theory Proposal,Theory Proposal
We propose a method that selects a better hypothesis giving high importance to distinct words generated from decoder without the usage of any language model or data,Model Proposal,New Algorithm/ Method
"We aggregate existing datasets into a large disaster dataset using a new annotation scheme. Furthermore, by utilizing a class-mask (elaborated in Section 4.1), we make use of both binary-classification data and multi-class classification data in the same training phase.",Dataset Creation,Dataset Creation
"We explore Manifold Mixup (Verma et al., 2019) in the natural language-based disaster domain. Manifold Mixup is a regularization technique originally introduced in computer vision tasks.",New Algorithm/ Method,Theory Proposal
"we evaluate the syntactic difference between the generated trees, randomly generated trees and gold reference trees produced by constituency parsers;",Performance Evaluation,Performance Evaluation
"we introduce a new dataset containing questions in tweets paired with their prior tweets to provide context. We create classification models to assess the difficulty of distinguishing rhetorical and information-seeking questions, and experiment with different properties of the prior context.",Dataset Creation,Model Optimization
We propose a single step transfer learning based classification method that identifies victim blaming language and labels it.,New Algorithm/ Method,New Algorithm/ Method
"we present various interactive visualization methods such as neuron activations (Karpathy et al., 2015; Dalvi et al., 2019), attention mechanisms (Bahdanau et al., 2014; Strobelt et al., 2018), and saliency measures (Li et al., 2016; Murdoch et al., 2018; Arras et al., 2017), including a walkthrough on how to build a simple attention visualization",New Algorithm/ Method,New Algorithm/ Method
"we learn how to anticipate how a developed technology could be repurposed for harmful or negative results, and designing systems so that they do not inadvertently cause harm.",New Algorithm/ Method,New Algorithm/ Method
"we focus on three main topic areas: 1) grounding in human-human communication; 2) grounding in dialogue systems; and 3) grounding in multi-modal interactive systems, including image-oriented conversations and humanrobot interactions",Theory Proposal,Theory Proposal
"we propose this tutorial on reviewing natural language processing research, focusing on conference submissions and various review forms used in the NLP community.",Theory Proposal,Theory Proposal
"we will introduce evaluation methods for style-conditioned text generation. We will present the current practice in the literature, involving both human evaluation and automatic metrics.",New Algorithm/ Method,New Algorithm/ Method
"we present approaches for information extraction (IE) from Web data that can be differentiated along two key dimensions: 1) the diversity in data modality that is leveraged, e.g. text, visual, XML/HTML, and 2) the thrust to develop scalable approaches with zero to limited human supervision",New Algorithm/ Method,Model Optimization
"we will (1) outline the various types of commonsense (e.g., physical, social), and (2) discuss techniques to gather and represent commonsense knowledge, while highlighting the challenges specific to this type of knowledge (e.g., reporting bias). We will also (3) discuss the types of commonsense knowledge captured by modern NLP systems (e.g., large pretrained language models), (4) review ways to incorporate commonsense knowledge into downstream task models, and (5) present various benchmarks used to measure systems’ commonsense reasoning abilities.",Resources,Resources
"We discuss two-stage retriever-reader frameworks for open-domain QA, pioneered by Chen et al. (2017): a retriever component finding documents that (might) contain an answer from a large collection of documents, followed by a reader component finding the answer in a given paragraph or a document.",Theory Proposal,Theory Proposal
"we investigate the effectiveness of extending ImageNet to Arabic using Arabic WordNet (AWN) by searching in AWN for all the synsets used in ImageNet. AWN was originally developed in 2006 (Black et al., 2006).",New Algorithm/ Method,Model Optimization
"we propose Entity Synset Alignment(ESA), which is a method to create a general scene graph by aligning various semantic knowledge efficiently to solve this bias problem.",Performance Evaluation,Performance Evaluation
"we introduce VQGR, a VQG system that is able to generate natural language questions when shown radiology images",New Algorithm/ Method,Theory Proposal
we propose two new metrics that evaluate how each question contributes to the goal,Performance Evaluation,Performance Evaluation
"We propose a novel alignment mechanism to deal with procedural reasoning on a newly released multimodal QA dataset, named RecipeQA",Theory Proposal,Theory Proposal
we propose a novel method for sentence boundary detection that takes it as a multi-class classification task under the endto-end pre-training framework.,New Algorithm/ Method,New Algorithm/ Method
we proposed a new adversarial training method to leverage target monolingual data to relieve the lowresource shortcoming of speech translation.,New Algorithm/ Method,New Algorithm/ Method
we propose a method to handle the two problems so as to generate robust translation to ASR errors.,New Algorithm/ Method,New Algorithm/ Method
"we propose a novel and effective Encoder-NAD-AD framework for NMT, in which the newly added non-autoregressive decoder (NAD) can provide target-side global information when autoregressive decoder (AD) translates, as illustrated in Figure 1. Briefly speaking, the encoder is first used to encode the source sequence into a sequence of vector representations.",Theory Proposal,Theory Proposal
"We propose a novel and efficient approach to explicitly exploit discourse structure information for documentlevel NMT. Particularly, our approach is applicable for any other context encoder of document-level NMT;",Performance Evaluation,Performance Evaluation
This paper describes our machine translation systems for the streaming Chinese-toEnglish translation task of AutoSimTrans 2020. We present a sentence length based method and a sentence boundary detection model based method for the streaming input segmentation,New Algorithm/ Method,New Algorithm/ Method
we evaluate the joint use of linguistic features and deep learning models. We achieve this fusion by simply taking the output of deep learning models as features themselves.,Performance Evaluation,Performance Evaluation
"we use simulated data to demonstrate that the rate of human-human agreement has a substantial effect on estimates of system performance, making it difficult to compare systems that are evaluated on different datasets",Performance Evaluation,Performance Evaluation
"we are interested in providing feedback specialized to the content of the essay, and specifically for the content areas required by the rubric. A key objective is that the feedback should be localized alongside the relevant essay text.",Resources,Resources
This paper examines one form of spoken language assessment; whether the response from the candidate is relevant to the prompt provided. This will be referred to as off-topic spoken response detection.,Model Optimization,Model Optimization
We propose a novel method for creating a tutoring dialogue collection that exhibits many of the properties needed for training a conversational tutor.,New Algorithm/ Method,New Algorithm/ Method
we employ a novel approach to advancing our understanding of the development of writing in English and German children across school grades using classification tasks.,Algorithm/Method Optimization,Model Optimization
We introduce an annotation scheme to capture the nature of sentence-level revisions of evidence use and reasoning (the ‘RER’ scheme) and apply it to 5th- and 6th-grade students’ argumentative essays.,New Algorithm/ Method,Applications
"we show how a deep-learning based system can outperform feature-based machine learning systems, as well as a string kernel system in scoring essay traits",Applications,Applications
we present an NLP-based approach for tracking the evolution of written language competence in L2 Spanish learners using a wide range of linguistic features automatically extracted from students’ written productions.,New Algorithm/ Method,Model Optimization
we build two datasets of MCQs for second-language learners with distractor selections annotated manually by human experts.,Dataset Creation,Dataset Creation
We develop and train models for automatic distractor selection that combine simple features with representations from pretrained models like BERT and ELMo,Algorithm/Method Optimization,Model Optimization
We annotate a small corpus of methodology sections drawn from Spanish information technology theses for the presence of steps and their logical order.,New Algorithm/ Method,New Algorithm/ Method
"We design a model to detect sentences that represent methodological steps, incorporating language model and verb taxonomy features, achieving 0.939 f-measure.",New Algorithm/ Method,New Algorithm/ Method
we set out methodological considerations of using automated speech recognition to build a corpus of teacher speech in an Indonesian language classroom,New Algorithm/ Method,New Algorithm/ Method
we describe a set of CR formative assessment items that call for students to express and integrate ideas across multiple dimensions of the NGSS.,Theory Proposal,Theory Proposal
"we present a novel learning-andassessment context where middle school students were asked to criticize an argument presented in the prompt, focusing on identifying and explaining the reasoning flaws.",New Algorithm/ Method,Model Optimization
"we investigate whether, in automated essay scoring (AES) research, deep neural models are an appropriate technological choice. We find that fine-tuning BERT produces similar performance to classical models at significant additional cost.",Performance Evaluation,Performance Evaluation
We develop custom g-transformations: token-level edits to perform (g)rammatical error corrections. Predicting g-transformations instead of regular tokens improves the generalization of our GEC sequence tagging system.,New Algorithm/ Method,New Algorithm/ Method
"We decompose the fine-tuning stage into two stages: fine-tuning on errorful-only sentences and further fine-tuning on a small, high-quality dataset containing both errorful and error-free sentences.",Dataset Creation,Dataset Creation
"We achieve superior performance by incorporating a pre-trained Transformer encoder in our GEC sequence tagging system. In our experiments, encoders from XLNet and RoBERTa outperform three other cutting-edge Transformer encoders (ALBERT, BERT, and GPT-2)",Applications,Applications
we propose a method for interpreting the weights of personalized neural CWI models.,Model Proposal,New Algorithm/ Method
"we propose an approach for automatically evaluating their appropriateness. Using neural machine translation, we generate correct-incorrect sentence pairs to serve as synthetic data in order to increase the amount and diversity of training data for our scoring model",Model Proposal,Model Optimization
we present work on automatically scoring student responses to constructed-response mathematics items where the response should contain both text and mathematical equations or expressions.,New Algorithm/ Method,Model Optimization
we explore whether approaches from the field of transfer learning may be useful for improving item parameter modeling.,Model Proposal,Model Proposal
"we provide a fair comparison of two methods for generating synthetic parallel data for GEC, using two evaluation datasets;",New Algorithm/ Method,New Algorithm/ Method
we look at the temporal change of gender bias in biomedical research.,Theory Proposal,Theory Proposal
"We answer the question; How has the usage of gender stereotypes changed in the last 60 years of biomedical research? Specifically, we look at the change in well-known gender stereotypes (e.g., Math vs Arts, Career vs Family, Intelligence vs Appearance, and occupations) in biomedical literature from 1960 to 2020.",Theory Proposal,Theory Proposal
"we are the first to employ a novel, completely unsupervised end-to-end neural attention-based document representation learning approach, using no external labels, in order to achieve the most meaningful term transfer between related documents, i.e. semantic tagging of documents, in a “pseudorelevance feedback”–based (Xu and Croft, 2000) setting for unsupervised query expansion.",New Algorithm/ Method,Model Optimization
"We present a search system that works in a paradigm which we call Extractive Search, and which allows rapid information seeking queries that are aimed at extracting facts, rather than documents.",New Algorithm/ Method,Model Proposal
"we adapt ESP to encode dependency paths, an approach we call Embedding of Structural Dependencies (ESD).",Applications,Applications
"We compare two methods for learning biomedical concept embeddings, the skip-gram with negative sampling (SGNS) algorithm (Mikolov et al., 2013a) and Embedding of Semantic Predications (ESP) (Cohen and Widdows, 2017), which adapts SGNS to encode concept-predicate-concept triples.",New Algorithm/ Method,New Algorithm/ Method
"we introduce in more detail the notion of spin, the types of spin that we address, and the information that is required to assess an article for spin",New Algorithm/ Method,Theory Proposal
"we describe our current algorithms, methods employed and provide their evaluation.",New Algorithm/ Method,New Algorithm/ Method
"we introduce construction of RadVisDial - the first publicly available dataset for visual dialog in radiology, derived from the MIMIC-CXR (Johnson et al., 2019) dataset",Dataset Creation,Dataset Creation
we compare several state-of-the-art models for VQA and VisDial applied to these images,Model Proposal,Model Proposal
"our model operates in the relation extraction setting, meaning it must distinguish between relations and nonrelations, as well as classifying by relation type.",Model Proposal,Model Proposal
"We introduce a pooled embedding for relational classification across long distances. Wang et al. (2019) focused on short-distance relations, but clinical CONTAINS relations often span multiple sentences, so a sequence-level embedding is necessary for such long-distance inference.",New Algorithm/ Method,Theory Proposal
we present an experimental evaluation of coding coverage in the MIMIC-III discharge summaries.,New Algorithm/ Method,Model Proposal
"we further propose to combine reinforcement learning (RL) to automatically extract out task-specific noisy text from the long documents, as we observe that many text segments do not contain predictive information such that removing these noise can potentially improve the performance.",Theory Proposal,Theory Proposal
"We model the noise extraction process as a sequential decision problem, which also aligns with the fact that clinical documents are received in time-sequential order",Model Proposal,Model Proposal
"we study the impact of a number of model design choices. First, following Reimers and Gurevych (2019), we study the impact of various pooling methods on STS, and find that convolution filters coupled with max and mean pooling outperform a number of alternative approaches",New Algorithm/ Method,New Algorithm/ Method
"We establish state-of-the-art benchmarks for EMR QA on a large clinical question answering dataset, emrQA",Dataset Creation,Dataset Creation
"We introduce and evaluate new models, achieving SOTA performance for this task.",Performance Evaluation,Performance Evaluation
we show that machine learningbased unsupervised clustering of and anomaly detection with linguistic biomarkers are promising approaches for intuitive visualization and personalized early stage detection of Alzheimer’s disease.,Theory Proposal,Theory Proposal
"we introduce BIOMRC, a new dataset for biomedical MRC that can be viewed as an improved version of BIOREAD.",Dataset Creation,Dataset Creation
"we propose a simple and intuitive neural model to reinstate migrating words that transpire in letter position dyslexia, a visual analysis deficit to the encoding of character order within a word",Model Proposal,Model Optimization
"We propose a document classification approach to determine the reason for administration of a given drug, with particular focus on domain adaptation from one drug to another, and instance selection to minimize annotation effort.",Theory Proposal,Theory Proposal
our work explores methods to improve the performance of classifying the indication for an antibiotic administration in veterinary records of dogs and cats.,New Algorithm/ Method,New Algorithm/ Method
"We make the embeddings, code, and other materials publicly available and outline several avenues of future work to facilitate progress in the field.",Performance Evaluation,Performance Evaluation
"We train five recent KGE models on SNOMED-CT and demonstrate their advantages over previous methods, making a case for the importance of leveraging the multirelational nature of knowledge graphs for biomedical knowledge representation.",New Algorithm/ Method,New Algorithm/ Method
"We investigate different types of errors that are penalized by exact F-score and identify a specific error type where there is high degrees of disagreement between the human user experience and what exact F-score measures: namely, errors where the extracted entity is correctly labeled, but the span only overlaps with the annotated entity rather than matching perfectly",Performance Evaluation,Performance Evaluation
"We demonstrate that the simple applications of this model under-perform and require knowledge base order-sensitive markings, ktag, to achieve state-of-the-art performance. This data encoding scheme captures the latent relation direction and provides a simple way to reduce noise in distant supervision.",Model Optimization,Model Optimization
we propose a new neural network model that combines multi-head attention mechanisms with a set of convolutions to provide global locality in biomedical event and relation extraction,Model Proposal,Model Optimization
we investigate the use of MTL with transformer-based models (BERT) on multiple biomedical and clinical NLP tasks,Performance Evaluation,Performance Evaluation
we present the dataset used for our experiments and their respective results,Dataset Creation,Dataset Creation
our paper introduces a multi-modal approach for fine-grained opinion mining,New Algorithm/ Method,Theory Proposal
"Our proposed model, at the time of writing, out-performs the state of the art on a benchmark dataset on a variety of accuracy and regression metrics",Model Proposal,Model Optimization
"we combine ideas from (Tsai et al., 2019) and (Liu et al., 2018) and explore the use of Transformer (Vaswani et al., 2017) based models for both aligned and unaligned signals without extensive over-parameterization of the models by using multiple modality-specific transformers.",Model Proposal,Model Proposal
"a cross-situational learning based grounding framework is proposed that allows grounding of words and phrases through corresponding percepts without human supervision and online, i.e. it does not require any explicit training phase, but instead updates the obtained mappings for every new encountered situation.",Theory Proposal,Theory Proposal
"We propose a multimodal analytical framework that analyzes the candidate in an interview scenario and provides feedback for predefined labels such as engagement, speaking rate, eye contact, etc.",Theory Proposal,Theory Proposal
"we discuss the benefits of a multimodal understanding of in-cabin utterances by incorporating verbal/language input together with the non-verbal/acoustic and visual cues, both from inside and outside the vehicle (e.g., passenger gestures and gaze from in-cabin video stream, referred objects outside of the vehicle from the road view camera stream).",Theory Proposal,Theory Proposal
"we recommend an AI sensing system that can semantically interpret the environmental conditions, objects, relations and activity carried out from the visual feed.",Resources,Resources
We analyze popular VQA models through the lens of attribution (input’s influence on predictions) to gain valuable insights,Resources,Resources
"We adopt the PU algorithm of Peng et al. (2019) to the domain of consumer electronic product descriptions, and evaluate its effectiveness on four entity types: Product, Component, Brand and Attribute",Performance Evaluation,Performance Evaluation
"we present SessionPath, a novel neural network model that improves facet suggestions on two counts: first, the model is able to leverage session embeddings to provide scalable personalization; second, SessionPath predicts facets by explicitly producing a probability distribution at each node in the taxonomy path.",New Algorithm/ Method,Model Proposal
we formulate the recommendation problem into a supervised product embedding learning process,Theory Proposal,Theory Proposal
"we target and use real-world data - service calls, which poses additional challenges with respect to the artificial datasets that have been typically used in the past in multimodal sentiment researches (Cambria et al., 2017), such as variability and noises.",Dataset Creation,Dataset Creation
We demonstrate the success of XLNet on finding product specifications that can help answering product related queries. It beats the baseline Siamese method by 0.14 − 0.31 points in HIT@1.,New Algorithm/ Method,New Algorithm/ Method
we present our work to improve the intent classification in the shopping assistant of Walmart company by using inter-utterance context. Our work also reduces the contextual disambiguation burden from the dialog manager,New Algorithm/ Method,Model Proposal
We propose a semi-supervised iterative approach to collect user complaints about a service from social media platforms,Theory Proposal,Theory Proposal
We evaluate the proposed approach for the problem of complaint detection for transportation services on Twitter.,Performance Evaluation,Performance Evaluation
"we propose a novel approach for item-based collaborative filtering, by leveraging the BERT model (Devlin et al., 2018) to understand item titles and model relevance between different items",Model Proposal,Model Optimization
"We proposed a semisupervised method, and successfully applied it to product reviews from different categories in the ecommerce platform",New Algorithm/ Method,New Algorithm/ Method
"We propose a Deep Hierarchical Classification framework, which incorporates the multi-scale hierarchical information in neural networks and introduces a representation sharing strategy according to the category tree.",Theory Proposal,Theory Proposal
we introduced SimsterQ - a clustering based system for answering questions that makes use of word vectors. Clustering was performed using cosine similarity scores between sentence vectors of reviews and questions,New Algorithm/ Method,Theory Proposal
"We propose a novel use of sentiment analysis by examining a key section of the quarterly and annual reports submitted to the SEC in two states: first, the unaltered report as filed with the SEC (X 0 ), and second, the report without selected NGMs (X). We then calculated the change in the tone or sentiment (as we use these terms interchangeable) as (X - X0 ) for each report and used it as an input to our prediction model",Model Proposal,Model Optimization
we study the applicability of Bayesian Parametric and Non-parametric methods for user clustering in an E-commerce search setting.,New Algorithm/ Method,New Algorithm/ Method
We propose a joint training setup in which sentence selection and claim verification are tackled by a single neural sequence matching model.,Model Proposal,Model Optimization
we simplify the training procedure and increase training efficiency for sentence selection and claim verification by merging redundant components and computation that exist when training the two tasks separately.,Performance Evaluation,Performance Evaluation
We describe the methodology for creating the corpus and the annotation process.,New Algorithm/ Method,New Algorithm/ Method
we propose a probabilistic graphical model which formulates fact extraction in a generative process.,Model Proposal,Model Optimization
"we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components",Model Proposal,Model Proposal
We propose two measures for measuring the quality of constructed claims in the FEVER task. Annotating data for this task involves the creation of supporting and refuting claims over a set of evidence,Theory Proposal,Theory Proposal
"We propose, instead, a model-agnostic framework that consists of two modules: (1) a span extractor, which identifies the crucial information connecting claim and evidence; and (2) a classifier that combines claim, evidence, and the extracted spans to predict the veracity of the claim",Model Proposal,Model Optimization
"we report on the shared task on sarcasm detection that we conducted as part of the2nd Workshop on Figurative Language Processing
(FigLang 2020) at ACL 2020. The task aims to
study the role of conversation context for sarcasm
detection.",Resources,Resources
"We propose a new data augmentation technique that can successfully leverage the structural patterns of the conversational dataset. Our technique, called CRA(Contextual Response Augmentation), utilizes the conversational context of the unlabeled dataset to generate new training samples.",Theory Proposal,Theory Proposal
"We propose an architecture where the Transformer Encoder is stacked with BiLSTM (Schuster and Paliwal, 1997) and NeXtVLAD (Lin et al., 2018). We observe that NeXtVLAD, a differentiable pooling layer, proves more effective than simple nonparametric mean/max pooling methods.",New Algorithm/ Method,New Algorithm/ Method
"We present the shared task and provide a brief description of each of the participating systems, a comparative evaluation of the systems, and our observations about trends in designs and performance of the systems that participated in the shared task",New Algorithm/ Method,Model Proposal
we propose an end-to-end neural based method named DeepMet for detecting metaphor by transforming the token-level metaphor detection task into the reading comprehension task.,New Algorithm/ Method,New Algorithm/ Method
"We propose a novel approach (as detailed in Figure 1) wherein we first construct a dataset of realworld context–satirical headline pairs in which the context is constructed by procedurally retrieving and ranking real-world stories, events and information related to the entities that appear in the original satirical headline.",Theory Proposal,Theory Proposal
"we introduce a novel approach for modeling satirical news headlines as conditioned on a real-world context, and an information retrieval pipeline for constructing the real-world context for a given real satirical headline",Model Proposal,Model Optimization
"we explore the use of contextualized word embeddings for detecting sarcasm in the responses sampled from Reddit as well as Twitter. We outline the effect of adding contextual information, from previous dialogue turns, to the response, for both the datasets.",Algorithm/Method Optimization,Algorithm/Method Optimization
we propose using machine learning techniques with BERT and GloVe embeddings to detect sarcasm in tweets.,Theory Proposal,Theory Proposal
we present our study on the effectiveness of contextual information to decide if anutterance is sarcastic or not.,Theory Proposal,Model Proposal
"we propose to employ bidirectional encoder representations transformers (BERT), and aspect-based sentiment analysis approaches in order to extract the relation between context dialogue sequence and response and determine whether or not the response is sarcastic.",Theory Proposal,Theory Proposal
"we present traditional Machine learning approaches, Deep learning approach (RNN-LSTM) and BERT (Bidirectional Encoder Representations from Transformers) for identifying sarcasm.",Theory Proposal,Model Proposal
we present a deep neural architecture for sarcasm detection.,Theory Proposal,Model Proposal
"We investigate various pre-trained language representation models (PLRMs) like BERT, RoBERTa, etc. and fine-tune it on the Twitter dataset1",Model Optimization,Dataset Creation
we describe the work we performed for context aware sarcasm detection for both the data sets.,Dataset Creation,Dataset Creation
"We present different techniques and models, mostly based on transformer for Sarcasm Detection with Context.",Theory Proposal,Model Proposal
we propose a novel deep learning-based approach to detect whether an utterance is sarcastic or non-sarcastic by utilizing the given contexts in a hierarchical manner.,Theory Proposal,Theory Proposal
"We perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (Yang et al., 2019) (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.",Applications,Applications
"we aim to detect token-level metaphors from plain texts by focusing on content words (Verbs, Nouns, Adjectives and Adverbs) of two corpora: VUA1 and TOFEL2",Theory Proposal,Theory Proposal
we design an ALBERTBiLSTM structure to recognize metaphorical words in TOEFL dataset,Dataset Creation,Dataset Creation
"we use concatenation of GloVe (Pennington et al., 2014) and ELMo (Peters et al., 2018) vectors augmented with character level features using CNN and highway network (Kim et al., 2016; Srivastava et al., 2015)",Theory Proposal,Theory Proposal
"We propose two models for metaphor detection1 with the input prepared as above - a vanilla BiLSTM model and a vanilla Transformer Encoder (Vaswani et al., 2017) model similar to BERT (Devlin et al., 2019) (but without pre-training).",Model Proposal,Model Optimization
This work explores the differences and similarities between neural image classifiers’ mis-categorisations and visually grounded metaphors - that we could conceive as intentional mis-categorisations,Theory Proposal,Theory Proposal
we introduce a gold standard data set of human x-phemism judgments and evaluate our models for this task.,Performance Evaluation,Performance Evaluation
we build our metaphor detection model upon RoBERTa to leverage its strength in capturing contextual information.,Model Proposal,Model Proposal
we are interested in relation-level metaphor identification focusing on the data availability for this level of processing.,Dataset Creation,Dataset Creation
we report preliminary results from applying this approach to two distinct scenarios: debates on gun rights and marriage equality,Applications,Resources
we describe computational ethnography studies to demonstrate how machine learning techniques can be utilized to exploit bias resident in language data produced by communities with online presence.,Theory Proposal,Model Proposal
"we set out a preliminary investigation of oxymorons based on naturally occurring data from Italian, with a view to contributing to the NLP-oriented research on figurative language by supplying an initial list of oxymorons and oxymoronic structures that can be used for further analyses and for evaluation tasks.",Dataset Creation,Dataset Creation
"Proposing the first model for humor style transfer, building a transformer model that “translates” from regular to humorous English1",Model Proposal,Model Proposal
we investigate whether Gao et al. (2018)’s findings can be replicated when detecting metaphors in TOEFL essays rather than the BNC,Performance Evaluation,Performance Evaluation
we present a novel resourceinexpensive architecture for metaphor detection based on a residual bidirectional long short-term memory and conditional random fields.,Theory Proposal,New Algorithm/ Method
we investigate the supervised disambiguation of potential occurrences of German VIDs,Performance Evaluation,Performance Evaluation
"we participate in the 2020 Metaphor Detection Shared Task (Leong et al., 2020).",Theory Proposal,Theory Proposal
we present the first neural metaphor processing architecture that models a broader discourse through the use of attention mechanisms,Theory Proposal,New Algorithm/ Method
"we present our results from the Second Shared Task on Metaphor Detection, hosted by the Second Workshop on Figurative Language Processing",Theory Proposal,New Algorithm/ Method
We propose using both BERT and XLNet language models to create contextualized embeddings and a bidirectional LSTM to identify whether a given word is a metaphor.,Model Proposal,Model Proposal
We present an ensemble approach for the detection of sarcasm in Reddit and Twitter responses in the context of The Second Workshop on Figurative Language Processing held in conjunction with ACL 20201 .,Theory Proposal,New Algorithm/ Method
we present a transformer-based sarcasm detection model that takes both the target utterance and its context and predicts if the target utterance involves sarcasm.,Theory Proposal,New Algorithm/ Method
"we explore teacher-student distillation as a means of increasing the efficiency of neural network systems used to undertake a core task in NLP, dependency parsing.",Performance Evaluation,Performance Evaluation
develops a novel approach to the problem based on general graph parsing techniques;,Algorithm/Method Optimization,Model Optimization
proposes and evaluates different ways of integrating ‘external’ grammatical information;,Performance Evaluation,Performance Evaluation
We propose an end-to-end variational autoencoding parsing (VAP) model for semisupervised graph-based projective dependency parsing,Model Proposal,Model Proposal
we define a neural-network left-corner parser with bounded stack memory for parsing and psycholinguistic prediction.,Theory Proposal,Theory Proposal
we consider a softer version of homomorphic encryption in the form of obfuscation for natural language,Model Optimization,Model Optimization
"we present a generalization of this concept: latent-variable semiring parsing. With our framework, any semiring weighted logic program can be latentified by transforming weights from scalar values of a semiring to rank-n arrays, or tensors, of semiring values, allowing the modeling of latent variables within the semiring parsing framework",Theory Proposal,New Algorithm/ Method
we are proposing a new nonterminal naming scheme for hybrid grammars. We hypothesize that these steps are complementary in improving the accuracy of the parsing model.,Model Proposal,Model Proposal
"we lay the theoretical foundations for a supertagging-based LCFRS parser. As LCFRS obtained from corpora such as the PTB are usually not lexical, we employ a lexicalization procedure",Theory Proposal,Theory Proposal
"we propose SS-PRPN, a semi-supervised extension of the UP architecture PRPN (Shen et al., 2018a), which can be trained jointly on language modeling and supervised parsing.",Model Proposal,Model Proposal
we try to improve both speed and accuracy of chart-based parsers,Theory Proposal,Theory Proposal
Development of a robust dependency parsing model using the latest transformer encoder.,Algorithm/Method Optimization,Model Proposal
development of a deep parser for Spanish that uses a HPSG grammar and returns trees that contain both syntactic and semantic information.,Algorithm/Method Optimization,Model Proposal
"we introduce the task of parsing into enhanced universal dependencies, describes the datasets used for training and evaluation, and evaluation metrics",Dataset Creation,Dataset Creation
We present the approach of the TurkuNLP group to the IWPT 2020 shared task on Multilingual Parsing into Enhanced Universal Dependencies.,Theory Proposal,New Algorithm/ Method
"we describe our system to predict enhanced dependencies for Universal Dependencies (UD) treebanks, which ranked 2nd in the Shared Task on Enhanced Dependency Parsing with an average ELAS of 82.60%. Our system uses a hybrid two-step approach.",Theory Proposal,Theory Proposal
we presents our parsing approach to the Shared Task on Enhanced Universal Dependencies at IWPT 202,Theory Proposal,New Algorithm/ Method
We present the system submission from the FASTPARSE team for the EUD Shared Task at IWPT 2020.,Theory Proposal,New Algorithm/ Method
"we exploit a hybrid approach, coupling an algorithmic graph transformation of the dependency tree with predictions made by a multitask machine learning model.",New Algorithm/ Method,New Algorithm/ Method
This paper presents the system used in our submission to the IWPT 2020 Shared Task. Our system is a graph-based parser with secondorder inference,Theory Proposal,New Algorithm/ Method
"In this paper, we present the submission of team CLASP to the IWPT 2020 Shared Task on parsing enhanced universal dependencies",Theory Proposal,Model Optimization
"We present Køpsala, the Copenhagen-Uppsala system for the Enhanced Universal Dependencies Shared Task at IWPT 2020.",Theory Proposal,New Algorithm/ Method
This paper presents our system at the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies,Theory Proposal,New Algorithm/ Method
"This paper describes the ON-TRAC Consortium translation systems developed for two challenge tracks featured in the Evaluation Campaign of IWSLT 2020, offline speech translation and simultaneous speech translation.",New Algorithm/ Method,New Algorithm/ Method
This paper describes KIT’s submissions to the IWSLT2020 Speech Translation evaluation campaign.,Performance Evaluation,Performance Evaluation
we build a simultaneous translation system for text-to-text(t2t) and speech-to-text(s2t) problems based on Transformer wait-k model,Model Proposal,Model Proposal
we describe the system submitted to the IWSLT 2020 Offline Speech Translation Task. We adopt the Transformer architecture coupled with the meta-learning approach to build our end-to-end Speechto-Text Translation (ST) system,Theory Proposal,Theory Proposal
Our system is an endto-end model based on an adaptation of the Transformer for speech data.,Applications,Applications
"This paper describes the submission to IWSLT 2020 End-to-End Speech Translation task by Samsung R&D Institute, Poland",Theory Proposal,Theory Proposal
We propose a few improvements to our previous system,Algorithm/Method Optimization,Algorithm/Method Optimization
"This paper describes the University of Helsinki Language Technology group’s participation in the IWSLT 2020 offline speech translation task, addressing the translation of English audio into German text",Theory Proposal,Theory Proposal
"This paper describes the LIT Team’s submission to the IWSLT2020 open domain translation task, focusing primarily on Japanese-toChinese translation direction.",Theory Proposal,Theory Proposal
"we demonstrate our system applied for the IWSLT 2020 open domain text translation task, which aims to translate Chinese from/to Japanese 1",Performance Evaluation,Performance Evaluation
This paper describes the University of Edinburgh’s neural machine translation systems submitted to the IWSLT 2020 open domain Japanese↔Chinese translation task.,Theory Proposal,Theory Proposal
"sambiguation (Tang et al., 2018a,b). In this paper, we describe our Transformer based neural machine translation system submitted to the IWSLT 2020 Chinese→Japanese and Japanese→Chinese open domain translation task",Theory Proposal,Model Optimization
establishing an efficient data pre-processing pipeline for large web-crawled corpora to train a transformer model for NMT and exploiting large amount of monolingual data with back-translation and language modeling.,Performance Evaluation,Performance Evaluation
we introduce University of Tsukuba’s submission to the IWSLT20 Open Domain Translation Task.,New Algorithm/ Method,Theory Proposal
"we describe the Xiaomi’s neural machine translation (NMT) systems evaluated at IWSLT 2020 (Ansari et al., 2020) shared open domain translation task in two directions, Chinese→Japanese (Zh→Ja) and Japanese→Chinese (Ja→Zh)",Performance Evaluation,Performance Evaluation
"This paper describes the neural machine translation (NMT) system of the Institute of Scientific and Technical Information of China (ISTIC) for the 17th International Conference on Spoken Language Translation (IWSLT 2020) (Ebrahim et al., 2020)",Theory Proposal,Theory Proposal
"we describe the data and training pipeline for building our NMT system. We start with the two datasets provided by the shared task organizers—the existing parallel (EP) 167 dataset that includes public, parallel sentences, as well as the Web crawled (WC) dataset created by crawling, aligning, and filtering JA-ZH parallel sentences from the Web",Dataset Creation,Dataset Creation
we propose a novel domain adaptation method through style transfer of out-of-domain data using unsupervised machine translation.,New Algorithm/ Method,New Algorithm/ Method
we propose a framework for disfluency removal that utilizes a simple noise induction technique for data augmentation using fluent monolingual text in the target language.,Theory Proposal,Theory Proposal
we present details of our system in the IWSLT Video Speech Translation evaluation.,Theory Proposal,Theory Proposal
"This paper describes our submission to Non-Native Speech Translation Task in IWSLT 2020 (Ansari et al., 2020).",Theory Proposal,Theory Proposal
"This paper describes the submission of the EU project ELITR (European Live Translator)1 to the non-native speech translation task at IWSLT 2020 (Ansari et al., 2020).",Theory Proposal,Theory Proposal
"we propose Speech Translation as an alternative to the template creation process. We experiment with cascade systems, i.e. pipelined ASR+MT architectures, and direct, end-to-end ST systems",Theory Proposal,Theory Proposal
We evaluate a combination of retranslation techniques that have not previously been studied together,Performance Evaluation,Performance Evaluation
"We provide the first empirical comparison of re-translation and streaming models, demonstrating that re-translation operating in a very low-revision regime can match or beat the quality-latency trade-offs of streaming models",Model Optimization,Model Optimization
"We test a 0-revision configuration of re-translation, and show that it is surprisingly competitive, due to the effectiveness of data augmentation with prefix pairs.",Performance Evaluation,Performance Evaluation
"We therefore propose the use of Adaptive Computation Time (Graves, 2016) for simultaneous machine translation",Theory Proposal,Theory Proposal
we integrate a source chunk boundary detection component into a bidirectional recurrent NMT model.,Model Proposal,Model Proposal
this work investigates ASR with output compression. We test our approaches on German TV subtitles,Performance Evaluation,Performance Evaluation
we present research work to enhance a STST pipeline in order to comply with the timing and rendering requirements posed by cross-lingual automatic dubbing of TED Talk videos,New Algorithm/ Method,New Algorithm/ Method
we highlight several of such language mixing phenomena related to the task of localization for translation and focus on two distance (miles to kilometers) and temperature (Fahrenheit to Celsius) conversion tasks.,Model Optimization,Model Optimization
we propose a solution for automatic punctuation that is both cost efficient and easy to train,Performance Evaluation,Performance Evaluation
we detail two non-invasive ways of detecting translationese,Theory Proposal,Theory Proposal
we compare translationese across human and machine translations from text and speech.,Theory Proposal,Theory Proposal
"we introduced a new shared task, organised by Duolingo, which encouraged models to produce as many correct translations as possible for a given input.",Model Proposal,Model Optimization
we propose a one-to-many text style transfer framework that can be trained using non-parallel text,Theory Proposal,Theory Proposal
"we have proposed a novel procedure for training encoder-decoder models, where the softmax function is applied to the output of each of the M decoder layers derived using the output of each of the N encoder layers",Model Proposal,Model Proposal
we propose an improved method of scaling the quantization centres,New Algorithm/ Method,New Algorithm/ Method
we propose a new approach that enables NMT systems to effectively adapt to a new domain using few-shots learning,Theory Proposal,Theory Proposal
"we collect, rank and evaluate a new publicly available headline paraphrase corpus (ParaPhraser Plus), and then perform text generation experiments with manual evaluation on automatically ranked corpora using the Universal Transformer architecture.",Performance Evaluation,Performance Evaluation
we propose to train an end-to-end XLS model to directly generate target language summaries given the source articles by matching the semantics of the predictions with the semantics of the source language summaries,Model Proposal,Model Proposal
"We propose a question type driven framework for AG-QG, which enables the model to generate diverse questions with high quality",Model Proposal,Model Proposal
We develop methods for producing text headings and section-level embeddings through a new task: generation of section titles for Wikipedia articles,New Algorithm/ Method,New Algorithm/ Method
"we explore unexpected and erroneous changes in the output of NMT models. Consider the simple example in Table 1 where the Transformer model (Vaswani et al., 2017) is used to translate very similar sentences.",Model Proposal,Model Proposal
Our approach can be used to mitigate problems commonly associated with language models,Model Proposal,Model Proposal
we perform a large-scale empirical analysis to attempt to discover best practices when using knowledge distillation in combination with domain adaptation,Applications,Applications
we introduce a system built for the Duolingo Simultaneous Translation And Paraphrase for Language Education (STAPLE) shared task at the 4th Workshop on Neural Generation and Translation,New Algorithm/ Method,New Algorithm/ Method
"we focus on two approaches, both based on VAE: one that attempts to achieve the diversity by generalizing the sentence representation produced by the encoder; and another which randomly perturbs the encoder’s output during the sentence generation.",New Algorithm/ Method,New Algorithm/ Method
"we demonstrate that even though we use a simple approach, it is possible to generate varied paraphrased transcriptions which do not simply replace one word with another, contrarily, it utilizes different styles, opposition, word order etc.",Performance Evaluation,Performance Evaluation
we propose a transferlearning-based simultaneous translation model by extending BART,Model Proposal,Model Proposal
"we experiment with various methods to improve the diversity of translations, while preserving their quality",New Algorithm/ Method,New Algorithm/ Method
we propose to address the STAPLE task primarily as a MT task to better understand the strengths and weaknesses of neural MT architectures for generating multiple learner-relevant translations,Model Optimization,Model Optimization
We find that stronger BLEU performance of the beam-search generated translation is not indicative of improvements on the task metric—weighted macro F1 of a set of hypotheses—and suggest this should encourage further research on how to train NMT models when n-best lists are needed (§7.1).,Applications,Applications
This paper describes the third place submission to the shared task Mayhew et al. (2020) on simultaneous translation and paraphrasing for language education at the 4th workshop on Neural Generation and Translation (WNGT) for ACL 2020.,Theory Proposal,Theory Proposal
"We also optimized the Transformer model decoding in engineering, such as caching the decoder’s attention results and using low precision data type.",Dataset Creation,Dataset Creation
"This paper describes the OpenNMT (Klein et al., 2017) submissions to the Workshop on Neural Generation and Translation 2020 efficiency shared task.",Performance Evaluation,Performance Evaluation
This paper describes the University of Edinburgh’s submissions to the Workshop on Neural Generation and Translation (WNGT) 2020 Efficiency Shared Task1 using the Marian machine translation toolki,Performance Evaluation,Performance Evaluation
we aim to demonstrate performance optimization in a particular domain by training document-level models on large out-of domain parallel corpus combined with small in-domain corpus using domain adaptation techniques.,Performance Evaluation,Performance Evaluation
we introduce a new task called Simultaneous Translation and Paraphrasing for Language Education (STAPLE).,New Algorithm/ Method,Theory Proposal
"We propose a novel KB-QA system, MULTIQUE, that combines information from curated and extracted knowledge bases to answer complex questions.",Theory Proposal,Theory Proposal
"Dataset for a task of classifying type of logical statement, gathered on MTurk platform and consisting of 851 sentences, belonging to six classes.",Dataset Creation,Dataset Creation
We provide novel analysis and selection of interpolation coefficients for combining global models with user-personalized models.,Performance Evaluation,Performance Evaluation
we address the problem of having insufficient data collection methodologies by proposing a novel approach that accelerates the data collection process for use in NL-to-QL models,Model Proposal,Model Proposal
we formulate text normalization and sanitization as a multi-task text generation approach and propose a neural pointer-generator network based on multihead attention,Theory Proposal,Theory Proposal
we explore the possibility of mitigating the problems related to ASR inconsistency and code-switching in our input data by using two alternate representations of text in our NLU model: ISO-15919 and IndicSOUNDEX. ISO-159191 was developed as a standardized Latin-based representation for Indic languages and scripts,Model Proposal,Model Proposal
we propose some simple alternatives and show that they lead to 13 better performance.,Model Optimization,Model Optimization
We introduce copy mechanism for BERTbased models with a unified encoder-decoder framework for question generation. We further extend this copy mechanism using selfattentions.,Model Proposal,Model Optimization
"we address the problems of training on a domain with effectively limitless possible vocabulary, and aim to create a DST system capable of scaling to unseen vocabulary at inference. We do this by first utilizing a language model (LM) based Transformer that is capable of handling any possible input and output in a textual manner, letting the same exact architecture scale to new intents, slots, and slot values, with no modifications needed",Model Proposal,Model Proposal
"we propose to use efficient dual sentence encoders such as Universal Sentence Encoder (USE) (Cer et al., 2018) and ConveRT (Henderson et al., 2019b) to support intent detection",Performance Evaluation,Performance Evaluation
"we present a vastly simplified, single-layer convolutional model (Kim, 2014; Bai et al., 2018) that is highly compressible but nonetheless achieves competitive results on task-oriented natural language understanding benchmarks",New Algorithm/ Method,New Algorithm/ Method
"we propose DLGNet, a transformer-based model for multi-turn dialogue modeling that addresses some of the highlighted problems above",Model Proposal,Model Proposal
"we propose a simple data augmentation method leveraging a confusionmatrix-based ASR error simulator (Fazel-Zarandi et al., 2019; Schatzmann et al., 2007).",New Algorithm/ Method,New Algorithm/ Method
we explore automating the creation of a template pool for a customer service chat application through clustering historical agent utterances and choosing representative utterances from each cluster,New Algorithm/ Method,New Algorithm/ Method
"We propose a two-stage training strategy. We first coarse-train the state tracking models on reading comprehension datasets, then finetune them on the target state tracking dataset",Model Proposal,Model Proposal
"we propose a multi-task setting to train the model. More specifically, our model is encouraged to explicitly ensure the two aforementioned effects of the contextual information for the task of SF.",Model Proposal,Model Proposal
"we propose the task of few-shot IC/SF, catering to domain adaptation in low resource scenarios, where there are only a handful of annotated examples available per intent and slot in the target domain",Theory Proposal,Theory Proposal
"We identify the annotation errors, inconsistencies, and ontology issues in MultiWOZ 2.1, and publish its improved version.",Model Optimization,Model Optimization
"We propose Sketch-Fill-A-R, a dialogue agent framework that can learn to generate fluent, consistent and engaging chit-chat responses. Our key motivation is the hypothesis that human-like chit-chat responses often 1) follow common conversational patterns with insertions of agent-specific traits, and 2) condition explicitly on those persona traits.",Theory Proposal,Theory Proposal
we propose a set of eight probing tasks to measure the conversational understanding of neural dialog models,Model Proposal,Model Proposal
"This paper introduces CODA-19, the COVID19 Research Aspect Dataset and presents the first outcome of our exploration in using non-expert crowds for large-scale scholarly article annotation",Dataset Creation,Dataset Creation
"In this paper, we present an information retrieval system on a corpus of scientific articles related to COVID-19.",Theory Proposal,theory Proposal
"We present COVID-Q, a dataset of 1,690 questions about COVID from 13 online sources.",Dataset Creation,Dataset Creation
we developed a Natural Language Processing (NLP) system to extract potential positive COVID-19 cases from clinical text within the Department of Veterans Affairs (VA).,New Algorithm/ Method,New Algorithm/ Method
"we present and make publicly available a high quality, ground truth text dataset of emotional responses to COVID-19.",Dataset Creation,Dataset Creation
We formulate the task of cross-lingual transfer learning for epidemiological outbreak alignment across countries.,Theory Proposal,Theory Proposal
We create a multi-label classifier based on transfer learning that can detect conspiracyladen comments. We find that misinformation videos contain a significantly higher proportion of conspiratorial comments.,Theory Proposal,Theory Proposal
"We developed NEMSI (Suendermann-Oeft et al., 2019), or the NEurological and Mental health Screening Instrument, to bridge this gap.",Algorithm/Method Optimization,Model Proposal
"We tested that for long document classification, a simple feature-based approach can work better than state-of-the-art models.",Performance Evaluation,Performance Evaluation
"We propose two novel training signals for FSL. These signals can remarkably improve the performance of existing FSL models. As these signals do not require any additional information (e.g. dependency tree or part-of-speech), they can be applied in any metric-based FSL models",Model Proposal,Model Proposal
"we investigate how an author’s and reader’s identity, as well as overall writing setup, influence how stories are written and rated. We introduce and release STORIESINTHEWILD, 1 containing 1,630 short stories written on a volunteerbased crowdsourcing platform, paired with author demographics and personality information",Theory Proposal,Theory Proposal
"we extend an existing scheme of annotation of events (Goud et al., 2019); we provide guidelines for annotation of mood of events (realis vs irrealis) and guidelines for annotation of event arguments,",Theory Proposal,Theory Proposal
" we explore how learning to extract
meaning from speech differs when learning from
CDS and ADS.",Theory Proposal,Theory Proposal
We discuss task performance on the training register as well as generalization across registers,Applications,applications
"emphasize that in order to capture the whole slot entity, it is pivotal for the model to share its parameters for all slot types in the source domains and learn the general pattern of slot entities",Model Proposal,Model Proposal
model can maintain good performances in crossdomain and low-resource settings.,Applications,Applications
DST-SC is designed with a slot connecting mechanism to establish the connection between the target slot and its source slot explicitly,Model Proposal,Model Proposal
We demonstrate that DST-SC is more effective for handling the related-slot problem and outperforms state-of-the-art baselines.,Performance Evaluation,Performance Evaluation
"We propose a recurrent knowledge interaction, which chooses knowledge dynamically among decoding steps, integrating multiple knowledge into the response coherently",Theory Proposal,Theory Proposal
"We use a knowledge-aware pointer network to do knowledge copy, which solves oov problem and keeps knowledge integrity, especially for long-text knowledge",Theory Proposal,Theory Proposal
"exploring the explicit guidance to help the variational response generator exploit persona information hidden in the nonstructured contents produced by the users, by utilizing intuitive characteristics of personalized conversations for model trainin",Model Proposal,Model Optimization
We introduce a new conversational task and demonstrate added value over traditional conversation modeling through both better control and response generatio,Model Proposal,Model Optimization
"We document the creation of a large, multiturn, multi-actor conversational dataset",Dataset Creation,Dataset Creation
" We demonstrate that by increasing model size from 117M to 8.3B parameters, human evaluations measuring preference of model gener- 68 ated samples over held out target distribution increase with respect to realism, style matching, grammar, and conversation coherency",Performance Evaluation,Performance Evaluation
"we propose a new method to tackle the above challenges, aiming to obtain a highquality pre-training model for dialogue generation.",New Algorithm/ Method,New Algorithm/ Method
we propose Iterative Rectification Network (IRN) to improve slot consistency for general NLG systems.,Theory Proposal,Theory Proposal
we will  focus on dialogues for transactions; other kinds of dialogues such as opinion sharing will have different model,Performance Evaluation,Performance Evaluation
" We explore the task of Chinese discourse parsing with a variety of strategies, and our parser achieves the state-of-the-art performance. Our robust dynamic-oracle procedure can be applied to other shift-reduce parsers",Applications,Applications
"We release the pre-trained, standalone, readyto-use parser as a resource for the research community.1",Theory Proposal,Theory Proposal
we propose a novel TransS-driven joint learning neural network framework that leverages the latent geometric structure information of argument-relation instance,Theory Proposal,Theory Proposal
"we adopt a multi-level encoder to further enrich the argument representations, which could obtain the deeper semantics of discourse",Model Optimization,Model Optimization
"We design a novel model, conditional masked prediction model with mix-attention (CoMMA), to measure the token dependency for sequence generation. •",Model Proposal,Model Proposal
"knowledge distillation and imposing source-target alignment constraint reduce the target-token dependency, and thus reduce the difficulty of training NAR models",Model Optimization,Model Optimization
"we conduct a study aimed at answering the following question: given a large annotated web-scale dataset such as Conceptual Captions (Sharma et al., 2018) in one language, and a baseline machine translation system",Dataset Creation,Dataset Creation
"We focus our study on the task of automatic image captioning, as a representative for cross-modal language generation where back-and-forth consistency cannot be leveraged in a straightforward manner",New Algorithm/ Method,New Algorithm/ Method
"we consider a new and specific setting of it, referred to as fact-based text editing, in which a draft text and several fact",Theory Proposal,Theory Proposal
"We propose the new research problem of fewshot NLG, which has great potential to benefit a wide range of real-world applications.",Theory Proposal,Theory Proposal
"To study different algorithms for our proposed problem, we create a multi-domain table-totext dataset",New Algorithm/ Method,New Algorithm/ Method
Our proposed algorithm can make use of the external resources as prior knowledge to significantly decrease human annotation effort,New Algorithm/ Method,New Algorithm/ Method
we develop SEQ2SEQ models that generate fluent and informative answer responses to conversational questions,Algorithm/Method Optimization,Model Proposal
we transform the answers from an existing QA dataset into fluent responses via data augmentation,Dataset Creation,Dataset Creation
"We propose a novel hierarchical variational framework for generating diverse QA pairs from a single context, which is, to our knowledge, the first probabilistic generative model for questionanswer pair generation",Model Proposal,Model Proposal
"We propose an InfoMax regularizer which effectively enforces the consistency between the generated QA pairs, by maximizing their mutual information. This is a novel approach in resolving consistency between QA pairs for QAG",Theory Proposal,Theory Proposal
We evaluate our framework on several benchmark datasets,Performance Evaluation,Performance Evaluation
We build a new dataset containing 7.2K passages and 81.9K questions from CoQA. It is the first dataset specially built for SQG,Dataset Creation,Dataset Creation
We perform semi-autoregressive SQG under dual-graph interaction,Applications,New Algorithm/ Method
We use extensive experiments to show that our model outperforms previous work by a substantial margin,Algorithm/Method Optimization,Algorithm/Method Optimization
We train and evaluate our approach on the largescale English paraphrase dataset,Performance Evaluation,Performance Evaluation
"we show that position embeddings provide a simple yet effective way to encode reordering information, and that the generated paraphrases exhibit high compliance with the desired reordering input.",Model Optimization,Model Optimization
"We propose a novel framework, PPVAE, for conditional text generation, which allows a separate training for a new condition without retraining the whole network",Theory Proposal,Theory Proposal
We conduct extensive experiments and analysis to verify the effectiveness of our proposed PPVAE. Our framework achieves state-of-the-art performance on conditionality in both automatic and human evaluations,Theory Proposal,Theory Proposal
We employ a simple uniform distribution of the masking ratio and name the model as u-PMLM. We prove that u-PMLM actually learns an autoregressive language model on random permutations of training sequences,Model Proposal,Model Optimization
We present a largescale analysis of generated text with a special focus on studying artifacts produced by large generative models.,Model Optimization,New Algorithm/ Method
We propose the new task of distinguishing between different fine-grained configurations 276 based on the generated text alone,Theory Proposal,Theory Proposal
"A new practical task, namely question generation from reviews without annotated instance, is proposed and it has good potential for multiple applications",Theory Proposal,Theory Proposal
A novel adaptive instance transfer and augmentation framework is proposed for handling the data lacking challenge in the task,Theory Proposal,Theory Proposal
we propose a Type Auxiliary Guiding (TAG) encoder-decoder framework,Theory Proposal,Theory Proposal
An adaptive Type-associated encoder which can summarize the information according to the node type,Applications,Applications
A Type-restricted decoder with a two-stage process to reduce the search space for the code comment generation,Theory Proposal,Theory Proposal
We propose the novel UPSA framework that addresses Unsupervised Paraphrasing by Simulated Annealing,Theory Proposal,Theory Proposal
We design a searching objective function for paraphrasing that not only considers language fluency,Model Proposal,Model Proposal
We propose a copy mechanism as one of our search actions of simulated annealing to address rare words,Theory Proposal,Theory Proposal
We achieve the state-of-the-art performance on four benchmark datasets,Dataset Creation,Dataset Creation
a model that performs segmentation and labeling jointly rather than separately,New Algorithm/ Method,New Algorithm/ Method
we introduce contextualized weak supervision to train a text classifier based on userprovided seed words.,New Algorithm/ Method,New Algorithm/ Method
We propose a novel framework enabling contextualized weak supervision for text classification,Theory Proposal,Theory Proposal
We develop an unsupervised method to automatically group word occurrences of the same word into an adaptive number of interpretations based on contextualized representations and userprovided seed information,New Algorithm/ Method,New Algorithm/ Method
We design a principled ranking mechanism to identify words that are discriminative and highly label-indicative,Model Proposal,Model Proposal
"We propose a new graph neural network for text classification, where each document is an individual graph and text level word interactions can be learned in i",Theory Proposal,Theory Proposal
"Our approach can generalise to new words that absent in training, and it is therefore applicable for inductive circumstances.",Theory Proposal,Theory Proposal
We demonstrate that our approach outperforms state-of-the-art text classification methods experimentally,New Algorithm/ Method,New Algorithm/ Method
"We propose a novel Bidirectional Adversarial Topic (BAT) model, which is, to our best knowledge, the first attempt of using bidirectional adversarial training in neural topic modeling",Model Proposal,Model Proposal
We extend BAT to incorporate the word relatedness information into the modeling process and propose the Bidirectional Adversarial Topic model with Gaussian,Model Proposal,Model Proposal
"Our multi-tasking learning model consistently outperforms the state-of-the-art model in terms of both single and multi-label classifications, sentence and document classifications, and classifications in three languages",Applications,Applications
") We encode the content words of the source sentence as a new source representation, and learn an additional content word context vector based on it to improve translation performance;",Model Optimization,Model Optimization
"we thereby make an initial attempt to measure explanation methods for NMT according to the second dimension of interpretability, which covers all target words",New Algorithm/ Method,New Algorithm/ Method
It presents an attempt at evaluating the explanation methods for neural machine translation from a new viewpoint of fidelity.,New Algorithm/ Method,New Algorithm/ Method
"It proposes a principled metric for evaluation, and to put it into practice it derives a simple yet efficient approach to approximately calculate the metric",Performance Evaluation,Performance Evaluation
It quantitatively compares several different explanation methods and evaluates their effects in terms of the proposed metric.,Performance Evaluation,Performance Evaluation
"While previous works only concentrate on manipulating the decoder, we illustrate and emphasize the importance of the encoder in NAT models and propose the encoder masking strategy to improve its training",Model Proposal,Model Proposal
We propose the consecutive masking strategy of the decoder input and the n-gram loss function to alleviate the problem of repetitive translations of NAT models.,Model Proposal,Model Proposal
We integrate the two parts above in the jointly masked sequence-to-sequence model which shows strong performance on benchmark machine translation datasets,Model Optimization,Model Optimization
" To address the large phrase table issue, we propose an attentive feature extraction model and generate phrase representation based on token representations.",Model Proposal,Model Proposal
"To the best of our knowledge, our work is the first to model phrase representations and incorporating them into the Transformer",Model Optimization,Model Proposal
"We empirically demonstrate that a simple modification made in the Transformer’s official implementation (Vaswani et al., 2018) which changes the computation order of residual connection and layer normalization can effectively ease its optimization",Performance Evaluation,Performance Evaluation
we show that recurrent models equipped with this new attention mechanism can extrapolate to longer sequences,Model Proposal,Model Optimization
"The deep MSC nets (with 72-layer encoders) bring great improvements on translation quality from increased depth, producing results that substantially better than existing systems",Theory Proposal,Theory Proposal
"we propose a novel norm-based criterion for the difficulty of a sentence, which takes advantage of both model-based and linguistically motivated difficulty features",Model Proposal,Model Proposal
"We observe that the norms of the word vectors trained on simple neural networks are expressive enough to model the two features, which are easy to obtain while possessing learning-dependent features",Model Optimization,Model Optimization
"We demonstrate the effectiveness of our proposed technique using fixed (Ma et al., 2019a) and adaptive (Zheng et al., 2019a) policies in both Chineseto-English and English-to-Chinese translation",Theory Proposal,Theory Proposal
"We compare the expressive power of rational and non-rational RNNs, distinguishing between state expressiveness (what kind and amount of information the RNN states can capture) and language expressiveness (what languages can be recognized when the state is passed to a classifier)",Theory Proposal,Theory Proposal
"A two-parameter generalization of the Zipf’s/power law is the Zipf-Mandelbrot law, where f ∝ (r + β) −α (Mandelbrot, 1965). Li et al. (2010) considered the reversed rank of rmax+1−r, where rmax is the maximum of ranking index, and proposed a two-parameter formulation of f ∝ r −α(rmax + 1 − r) β .",Theory Proposal,Theory Proposal
we propose to use dice loss in replacement of the standard cross-entropy objective for data-imbalanced NLP tasks,Theory Proposal,Theory Proposal
"we propose to replace CE or MLE with losses based on the Sørensen–Dice coefficient (Sorensen, 1948) or Tversky index (Tversky, 1977).",Performance Evaluation,Performance Evaluation
we argue that syntax can be inferred from a sample of natural language with very minimal supervision,Theory Proposal,Theory Proposal
We introduce an information theoretical definition of what constitutes syntactic information,Theory Proposal,Theory Proposal
we specifically focus on the Japanese language due to its complex and flexible word order,Theory Proposal,Theory Proposal
Discuss and validate the use of LMs as a tool for word order analysis as well as investigate the sensitivity of LMs against different word orders in non-European language,Performance Evaluation,Performance Evaluation
Find encouraging parallels between the results obtained with the LM-based method and those with the previously established method on various hypotheses of canonical word order of Japanese,New Algorithm/ Method,New Algorithm/ Method
Showcase the advantages of an LM-based method through analyzing linguistic phenomena that is difficult to explore with the previous data-driven methods,New Algorithm/ Method,New Algorithm/ Method
We study a novel and more realistic scenario of fake news detection on social media,Model Proposal,Model Proposal
"For accurate detection, we develop a new model, GCAN, to better learn the representations of user interactions, retweet propagation, and their correlation with source short text",Model Proposal,Model Proposal
"deals with fake news detection under a more realistic scenario on social media. We predict whether a source tweet story is fake, given only its short text content and its retweet sequence of users, along with user profiles",Theory Proposal,Theory Proposal
"We propose two novel GCN-based models, TPC-GCN and DTPC-GCN, for post-level controversy detection",Model Proposal,Model Proposal
"We build a Chinese dataset for controversy detection, consisting of 5,676 posts collected from Chinese Weibo, each of which are manually labeled as controversial or noncontroversial. To the best of our knowledge, this is the first released Chinese dataset for controversy detection",Dataset Creation,Dataset Creation
we propose to apply unsupervised stance detection to automatically tag a large number of Twitter users with their positions on specific topics,Theory Proposal,Theory Proposal
We use unsupervised stance detection to automatically determine the stance of Twitter users with respect to several polarizing topics,Theory Proposal,Theory Proposal
We then use distant supervision based on these discovered user stances to accurately characterize the political leaning of media outlets,Theory Proposal,Theory Proposal
We evaluate our approach by comparing its bias predictions for a number of news outlets against gold labels from Media Bias/Fact Check,Performance Evaluation,Performance Evaluation
"We propose a new and simple method for detecting usage change, that does not involve vector space alignment",New Algorithm/ Method,New Algorithm/ Method
"we use it to identify word usage changes in a variety of corpus pairs, reflecting different data division criteria",Dataset Creation,Dataset Creation
we propose a new framework for emotion-controllable response generation named Curriculum Dual Learning (CDL),Theory Proposal,Theory Proposal
"Enabling efficient DST, generating the values of a minimal subset of the slots by utilizing the previous dialogue state at each turn",Performance Evaluation,Performance Evaluation
Achieving state-of-the-art performance on MultiWOZ 2.0 and MultiWOZ 2.1 in an open vocabulary-based DST setting,Applications,Applications
Highlighting the potential of improving the state operating prediction accuracy in our proposed framework,Theory Proposal,Theory Proposal
We propose an effective model framework of five major layers on off-topic response detection task,Model Proposal,Model Proposal
"To explore the essence of our proposed model, we conduct visualization analysis from two perspectives: bi-attention visualization and semantic matching representation visualization to reveal important information on how our model works.",Model Proposal,Model Proposal
"To improve our result on unseen prompts further, we propose a novel negative sampling data augmentation method to enrich training data by shuffling words from the negative sample in off-topic response detection task",New Algorithm/ Method,New Algorithm/ Method
" To the best of our knowledge, this is the first study on applying meta-learning to retrieval-based end-to-end goal-oriented dialog systems;",Applications,Applications
we leverage the MAML algorithm to optimize a human-machine collaborative dialog system and show very promising results on the lowresource dialog tasks,New Algorithm/ Method,New Algorithm/ Method
we propose a new dataset and hope that can help bring forward the research in this area,Theory Proposal,Theory Proposal
We investigate and demonstrate the feasibility of applying lexical ontology to facilitate recognizing OOV words in the few-shot scenario,Performance Evaluation,Performance Evaluation
We propose a knowledge integration mechanism and use multi-level graph attention to model explicit lexical relations,Model Proposal,Model Proposal
"we propose Multi-Agent Dialog Policy Learning (MADPL), where the user is regarded as another dialog agent rather than a user simulator",Theory Proposal,Theory Proposal
We apply actor-critic based multi-agent reinforcement learning to learn the task-oriented dialog policy to facilitate pretraining and avoid explicitly building a user simulator,Applications,Applications
We propose Hybrid Value Network for reward decomposition to deal with the asymmetric role issue between the system agent and the user agent in the task-oriented dialog.,Theory Proposal,Theory Proposal
"We conduct in-depth experiments on the multidomain, multi-intent task-oriented dialog corpus to show the effectiveness, reasonableness and scalability of our algorithm",New Algorithm/ Method,New Algorithm/ Method
we propose to construct dialog paraphrases that consider dialog context in order to improve dialog generation quality,Theory Proposal,Theory Proposal
we propose a method to construct a response-anticipated memory to contain document information that is potentially more important in generating responses,New Algorithm/ Method,New Algorithm/ Method
"To the best of our knowledge, we are the first to approach semi-supervised dialogue policy learning",Theory Proposal,Theory Proposal
We propose a novel reward estimation approach to dialogue policy learning which relives the requirements of extensive annotations and promotes a stable learning of dialogue policy,Theory Proposal,Theory Proposal
We propose an action embedding learning technique to effectively train the reward estimator from either partially labeled or unlabeled dialogues,Theory Proposal,Theory Proposal
We conduct extensive experiments on the benchmark multi-domain dataset. Results show that our approach consistently outperforms strong baselines coupled with semi-supervised learning technique,Dataset Creation,Dataset Creation
"This paper proposes a general learning framework using the duality between NLU and NLG, where supervised and unsupervised learning can be flexibly incorporated for joint training.",Theory Proposal,Theory Proposal
This work is the first attempt to exploits the dual relationship between NLU and NLG towards unsupervised learning,Theory Proposal,Theory Proposal
The benchmark experiments demonstrate the effectiveness of the proposed framework,Theory Proposal,Theory Proposal
"a strongly-correlated, unsupervised and reference free metric is proposed for evaluating open-domain dialog systems",Theory Proposal,Theory Proposal
a thorough human quality annotation is carried out and is released1 to facilitate future benchmarking of dialog evaluation metrics,Performance Evaluation,Performance Evaluation
We introduce a group of discrete latent variables to model the underlying semantic components,Model Optimization,Model Optimization
"We also show that our model indeed learns meaningful and informative latent codes, and generates more precise and specific definitions",Model Optimization,Model Optimization
", we argue that this phenomenon is not model specific, but is due to the widely-used log loss: we demonstrate that log loss is not robust to noisy and invalid references",Theory Proposal,Theory Proposal
we show that optimizing for distinguishability is robust in the face of noisy and even invalid data,Dataset Creation,Dataset Creation
"We propose a novel graph-to-sequence model, which firstly uses the line graph to model the relationships between AMR edges",Model Proposal,Model Proposal
We integrate higher-order neighborhood information into graph encoders to model the relationships between indirectly connected nodes,Model Proposal,Model Proposal
We demonstrate that both higher-order neighborhood information and edge relations are important to graph-to-sequence modeling.,Performance Evaluation,Performance Evaluation
We propose to tackle a new challenging task: rigid formats controlled text generation. A pre-training and fine-tuning framework named SongNet is designed to address the problem,Theory Proposal,Theory Proposal
Sets of symbols are tailor-designed to improve the modeling performance. We improve the attention mechanism to impel the model to capture the future information to further enhance the sentence integrity,New Algorithm/ Method,New Algorithm/ Method
"To verify the performance of our framework SongNet, we collect two corpora, SongCi and Sonnet, in Chinese and English respectively. We design several automatic evaluation metrics and human evaluation metrics to conduct the performance evaluation",Resources,Resources
" Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results given arbitrary formats, including the cold-start formats or even the formats newly defined by ourselves",Model Optimization,Model Optimization
"We evaluate our QG framework, Syn-QG against three QG systems on a mixture of Wikipedia and commercial text sentences outperforming existing approaches in grammaticality",Performance Evaluation,Performance Evaluation
"It allows processing each arriving short text in an online way. The online model is not only free of determining the optimal batch size, but also lends itself to handling large-scale data streams efficiently",Performance Evaluation,Performance Evaluation
"To the best of our knowledge, it is the first work to integrate semantic information for model-based online clustering, which is able to handle “term ambiguity"" problem effectively and finally support high-quality clustering",Model Proposal,Model Optimization
" Equipped with Poly Urn Scheme, the number of clusters (topics) are determined automatically in our cluster model",Model Proposal,Model Optimization
" to introduce correlations among the bits of hash codes, we propose to employ the distribution of Boltzmann machine as the variational posterior",Theory Proposal,Theory Proposal
"To obtain similarity-preserving hash codes, extensive efforts have been made to learn hash functions that can preserve the similarity information of original documents in the binary embedding space",Theory Proposal,Theory Proposal
" We formulate the interactive process of a term collection, which brings clarity to the problem to be solved",Theory Proposal,Theory Proposal
We develop a method that captures an analyst’s intention from a small number of samples with our formulation as the basis,New Algorithm/ Method,New Algorithm/ Method
we propose an automatic evaluation framework that provides a systematic assessment for interactive methods,New Algorithm/ Method,New Algorithm/ Method
"we propose a treestructured neural topic model (TSNTM), which is parameterized by neural networks and is trained using AEVB",Model Proposal,Model Proposal
"we overcome the aforementioned unsupervised gap, by using distant supervision to train neural models",Model Optimization,Model Optimization
"To overcome the lack of training data in the latter’s case, we further implement a novel weaksupervision approach using automatically generated question paraphrases, coupled with smart filtering to ensure high-quality paraphrases",Model Proposal,Model Proposal
"To the best of our knowledge, PCPR is the first work to jointly model contextualized word embeddings and pronunciation embeddings to recognize puns. Both contexts and phonological properties are beneficial to pun recognition",Model Proposal,Model Proposal
Extensive experiments are conducted on two benchmark datasets. PCPR significantly outperforms existing methods in both pun detection and pun location. In-depth analyses also verify the effectiveness and robustness of PCPR.,New Algorithm/ Method,New Algorithm/ Method
We release our implementations and pre-trained phoneme embeddings at https://github.com/ joey1993/pun-recognition to facilitate future research.,Theory Proposal,Theory Proposal
"in response to the above question, we propose a novel bidirectional language model named the Transformer-based Text Autoencoder (T-TA), which has a reduced computational complexity of O(n 2 ) when applying the model to unsupervised applications",Model Proposal,Model Proposal
"we propose a Fine-grained Interest Matching network (FIM), which is a new architecture for news recommendation that can tackle the above challenges",Theory Proposal,Theory Proposal
to the burgeoning body of research on using NLP techniques in key financial applications.,Theory Proposal,Theory Proposal
"We demonstrate that the user geolocation (especially) for the network-based methods, is largely dominated by the geographical locations of the 1- hop neighboring nodes",New Algorithm/ Method,New Algorithm/ Method
"We propose an attention-based, autoregressive model, bilingual attention language model (BALM), that not only learns the latent alignment from a parallel corpus for cross-lingual word embedding but also captures the word sequential dependency",Model Proposal,Model Proposal
"Adhering to the Matrix Language Frame theory (Myers-Scotton, 1997) and Equivalence Constraint theory (Poplack, 2000; Sankoff, 1998), we implement an objective function by jointly optimizing the cross-entropy loss as the monolingual constraint and the quasitranslation loss as the cross-lingual constraint",Theory Proposal,Theory Proposal
We show that BALM can learn from bilingual parallel data without the need for CS data,Dataset Creation,Dataset Creation
We propose a novel end-to-end trainable SpellGCN to integrate the pronunciation and shape similarities into the semantic space. Its essential components such as the specialized graph convolution and attentive combination operations are carefully investigated,Theory Proposal,Theory Proposal
We investigate the performance of SpellGCN both quantitatively and qualitatively. Experimental results indicate that our method achieves the best results on three benchmark datasets,New Algorithm/ Method,New Algorithm/ Method
proposal of the novel neural architecture Soft-Masked BERT for the CSC problem,Theory Proposal,Theory Proposal
empirical verification of the effectiveness of Soft-Masked BERT.,Theory Proposal,Theory Proposal
"We propose novel attention-based frame representation models, which take full advantage of LUs and F-to-F relations to model frames with attention schema",Model Proposal,Model Proposal
We propose a new Frame-based Sentence Representation (FSR) method that integrates multi-frame semantic information to obtain richer semantic aggregation for better sentence representation,New Algorithm/ Method,New Algorithm/ Method
Our experimental results demonstrate our proposed frame-based sentence representation (FSR) method is very effective on Machine Reading Comprehension (MRC) task,New Algorithm/ Method,New Algorithm/ Method
we propose a new procedure to increase the speed of the annotation process,Theory Proposal,Theory Proposal
"we propose a new procedure to increase the speed of the annotation process. For this, we first introduce an intermediate representation of the structured queries, which we call Operation Trees",Theory Proposal,Theory Proposal
It reduces the time needed for an annotation,Theory Proposal,Theory Proposal
we introduce a method to learn a Contextualized Sparse Representation (SPARC) for each phrase and show its effectiveness in opendomain QA under phrase retrieval setup,New Algorithm/ Method,New Algorithm/ Method
We introduce a dynamic sampling strategy that selects instances from a dataset with probability proportional to the gap between its current performance on some metric (like EM or F1 score) and measured single-task performance of the same model on that dataset,Dataset Creation,Dataset Creation
We design two novel auxiliary tasks in multitask fine-tuning to help improve the accuracy of answer span boundary detection for multilingual MRC model.,Model Proposal,Model Proposal
We propose a language-agnostic method to mine language-specific knowledge phrase from search engines. This method is lightweight and easy to scale to any language,New Algorithm/ Method,New Algorithm/ Method
"We conduct extensive experiments to prove the effectiveness of our proposed approach. In addition to an open benchmark dataset, we also create a new multilingual MRC dataset from real-scenario together with fine-grained answer type labels the in-depth impact analysis",Theory Proposal,Theory Proposal
"we propose a new framework of conversational machine reading with a novel Explicit Memory Tracker (EMT), which explicitly tracks each rule sentence to make decisions and generate follow-up questions",Theory Proposal,Theory Proposal
" A method for injecting skills into pre-trained LMs, given that automatic data generation is possible",New Algorithm/ Method,New Algorithm/ Method
"GENBERT, an architecture for pre-trained LM with generative and extractive abilities",Theory Proposal,Theory Proposal
A framework for generating numerical and textual synthetic data for numerical reasoning,Dataset Creation,Dataset Creation
We propose a new task for follow-up question identification in a conversational reading comprehension setting which supports automatic evaluation,Theory Proposal,Theory Proposal
"We present a new dataset, namely LIF, which is derived from the recently released conversational QA dataset QuAC",Dataset Creation,Dataset Creation
We propose a three-way attentive pooling network which aims to capture topic shift and topic continuity for follow-up question identification. The proposed model significantly outperforms all the baseline systems,Model Proposal,Model Proposal
we handle both constraints and multi-hop relations together for complex KBQA,Theory Proposal,Theory Proposal
We propose to modify the staged query graph generation method by allowing longer relation path,New Algorithm/ Method,New Algorithm/ Method
"We construct a diverse (in terms of lexicon usage), wide-coverage (in problem type), and publicly available1 MWP corpus, with annotations that can be used to assess the capability of different systems.",Theory Proposal,Theory Proposal
We propose a lexicon usage diversity metric to measure the diversity of an MWP corpus and use it to evaluate existing corpora,Performance Evaluation,Performance Evaluation
We show that the real performance of state-of-the-art (SOTA) systems is still far behind human performance if evaluated on a corpus that mimics a real human test,Performance Evaluation,Performance Evaluation
we add the concept of mismatch into cosine similarity by a threshold for mismatch detection and proper penalization,Theory Proposal,Theory Proposal
we attempt to deepen the understanding of cross-lingual word embeddings from the perspective of the choice of the context window through carefully designed experiments,Model Proposal,Model Proposal
We present a jointly optimized bi-encoder model (BEM) for WSD that improves performance on all-words English WSD,Model Optimization,Model Proposal
"We show that our model’s improvements come from better performance on LFS and zero-shot examples, without sacrificing accuracy on the most common senses",Algorithm/Method Optimization,New Algorithm/ Method
"We examine why our model performs well on LFS with a number of experiments, including an evaluation of the BEM in a few-shot learning setting demonstrating that the bi-encoder generalizes well from limited data",Model Optimization,Model Optimization
") humour detection (Khandelwal et al., 2018), (ii) sarcasm detection (Swami et al., 2018) and (iii) hate speech detection (Bohra et al., 2018) for HindiEnglish code-switched data",Dataset Creation,Dataset Creation
"We propose a transparent and interpretable scheme that incorporates decision tree model into co-attention networks, which not only discovers evidence for explainable claim verification but also provides interpretation for the discovery process of evidence through the decision conditions",Model Proposal,Model Proposal
"Designed co-attention networks promote the deep semantic interaction between evidence and claims, which can train DTE to obtain more powerful evidence and effectively focus on the false parts of claims",Model Proposal,Model Proposal
"Experiments on two public, widely used fake news datasets demonstrate that our DTCA achieves more excellent performance than previous state-of-the-art methods",New Algorithm/ Method,New Algorithm/ Method
We identify the task of conversational recommendation over multi-type dialogs.,Theory Proposal,Theory Proposal
"To facilitate the study of this task, we create a novel dialog dataset DuRecDial, with rich variability of dialog types and domains",Dataset Creation,Dataset Creation
We propose a conversation generation framework with a novel mixed-goal driven dialog policy mechanism.,Theory Proposal,Theory Proposal
We propose a semantic-enhanced Gaussian mixture model (SEG) for unknown intent detection by incorporating class semantic information into a Gaussian mixture distribution,Model Proposal,Model Proposal
"We explore to improve existing generalized zero-shot intent classification systems with an unknown intent identifier. To the best of our knowledge, this is the first attempt to apply unknown intent detection in this task",Model Optimization,Model Optimization
We conduct extensive experiments on three real-world datasets to validate the effectiveness of the proposed SEG model for unknown intent detection and its application in generalized zero-shot intent classification,Model Proposal,Model Proposal
"We propose the new task of expertise style transfer, which aims to facilitate communication between experts and laymen",Theory Proposal,Theory Proposal
We contribute a challenging dataset that requires knowledge-aware and structural modification techniques,Dataset Creation,Dataset Creation
"We establish benchmark performance and discuss key challenges of datasets, models and evaluation metrics",Model Optimization,Model Optimization
"we aim to overcome the above problems to automatically generate faithful texts from tables. In other words, we aim to produce the writing that a human without any external knowledge would do given the same table data as input",Performance Evaluation,Performance Evaluation
we propose Dynamic Memory Induction Networks (DMIN) to further tackle the above challenges.,Theory Proposal,Theory Proposal
"to our best knowledge, we are the first to design a hierarchical decoding process for the keyphrase generation problem",Model Proposal,Model Proposal
) we propose two novel exclusion mechanisms to avoid generating duplicated keyphrases as well as improve the generation accuracy,Theory Proposal,Theory Proposal
our method consistently outperforms all the SOTA sequential decoding methods on multiple benchmarks under the new setting,New Algorithm/ Method,New Algorithm/ Method
"With the prior hierarchy knowledge, we adopt typical structure encoders for modeling label dependencies in both top-down and bottomup manners, which has not been investigated for hierarchical text classification",Performance Evaluation,Performance Evaluation
We empirically demonstrate that both variants of HiAGM achieve consistent improvements on various datasets when using different structure encoders.,Dataset Creation,Dataset Creation
We release our code and experimental splits of Web-of-Science and NYTimes for reproducibility,Theory Proposal,Theory Proposal
"We report significant improvements for strong retrieval models on a standard benchmark collection, showing that keyphrases produced by state-of-the-art models are consistently helpful for document retrieval, even, to our surprise, when author keywords are provided",Resources,Resources
We introduce a new extrinsic evaluation framework for keyphrase generation that allows for a deeper understanding of the limitations of current models,Model Proposal,Model Optimization
"We present a derivational graph auto-encoder (DGA) that combines semantic and syntactic information with associative information from the mental lexicon, achieving very good results on MWF prediction and performing on par with a character-based LSTM at a fraction of the number of trainable parameters",Model Optimization,Model Proposal
", we present a new data set of about 1500 sentences randomly sampled from the romanized Algerian dialectal Arabic corpus of Cotterell et al.",Dataset Creation,Dataset Creation
") the Webis Gmane Email Crawl 2019, a crawl of more than 153 million emails from a wide range of mailing lists",Theory Proposal,Theory Proposal
"the Chipmunk email segmenter, a newly developed end-to-end neural model, a",Algorithm/Method Optimization,Model Optimization
"the complete preprocessing of the crawled emails using our model to construct the largest corpus of “ready-to-use” emails to date. Our corpus encompasses more than 20 years worth of discussions on a diverse set of topics, including important political and societal issues.",Model Proposal,Model Optimization
"We propose a language-neutral, fine-grained definition of cross-linguistic morphosyntactic divergences (CLMD) that allows for their extraction using a syntactically annotated, content-wordaligned parallel corpus.",Theory Proposal,Theory Proposal
data quality. Finding the right trade-off between the two is in fact a key element for an effective automatic CN generation.,Dataset Creation,Dataset Creation
To our understanding none of the collection strategies presented so far is able to fulfill this requirement.,Model Optimization,Model Proposal
KLEJ: A set of nine tasks constructed from both existing and newly introduced datasets used for the Polish language understanding evaluation,Dataset Creation,Dataset Creation
An online platform1 to evaluate and present the model results in the form of a leaderboard,Performance Evaluation,Performance Evaluation
"HerBERT: Transformer-based model for the Polish language understanding,",Model Proposal,Model Optimization
"Evaluation of several LSTM-based baselines, multilingual Transformer-based models and HerBERT.",Performance Evaluation,Performance Evaluation
We here propose an approach based on crosslingual distant supervision to generate almost arbitrarily large emotion lexicons for any target language and emotional variable,Theory Proposal,Theory Proposal
We study different ways to generate additional MT hypotheses by exploring uncertainty in NMT models,Model Optimization,Model Optimization
We devise methods to effectively explore multiple MT hypotheses to better evaluate MT output quality with existing evaluation metrics,Performance Evaluation,Performance Evaluation
"we introduce the task of Multimodal QE (MQE) for MT as an attempt to improve QE by using external sources of information, namely images",New Algorithm/ Method,New Algorithm/ Method
we propose several ways of incorporating visual information in neural-based and featurebased QE architectures,Theory Proposal,Theory Proposal
we achieve the state-of-the-art performance for such architectures in document and sentence-level QE,Applications,Applications
" this paper introduces a unique challenge, PuzzLing Machines, made up of ∼100 Rosetta Stone, a.k.a translation puzzles covering 81 languages from 39 different language families based on the Linguistic Olympiads",New Algorithm/ Method,New Algorithm/ Method
We develop an annotation scheme for marking information on materials-science experiments on scientific publications,Algorithm/Method Optimization,Algorithm/Method Optimization
" We provide a new corpus of 45 materialsscience publications in the research area of SOFCs, manually annotated by domain experts for information on experimental settings and results",Model Optimization,Model Optimization
We identify three sub-tasks of extracting experiment information and provide competitive baselines with state-of-the-art neural network approaches for them,Model Optimization,Model Optimization
We show the applicability of our findings to modeling the annotations of another materialsscience corpus,Performance Evaluation,Performance Evaluation
we present the iSarcasm dataset of tweets labelled for sarcasm by their authors,Dataset Creation,Dataset Creation
"We introduce a new approach tackling AMR parsing, following the incremental sequence-tograph transduction paradigm",New Algorithm/ Method,New Algorithm/ Method
" We present a new large-scale dataset for MDS, that is better aligned with several real-world industrial use cases",Dataset Creation,Dataset Creation
We provide an extensive analysis of the properties of this dataset,Dataset Creation,Dataset Creation
We provide empirical results for several baselines and state-of-the-art MDS methods aiming to facilitate future work on this datase,New Algorithm/ Method,New Algorithm/ Method
"We introduce a novel and efficient method which integrates the operation of attending, translating, and summarizing",Performance Evaluation,Performance Evaluation
We present three effective strategies to acquire the translation probability. It has shown that all these strategies can significantly improve the performance over the baseline,Model Proposal,Model Proposal
Experimental results demonstrate that our method can achieve remarkable improvements over baselines and achieve comparable performance with the state-of-the-art on both English-to-Chinese and Chinese-to-English cross-lingual summarization tasks,New Algorithm/ Method,New Algorithm/ Method
we examine existing strategies for the full TLS task and how well they actually work,Theory Proposal,Theory Proposal
We compare different TLS strategies side-byside using suitable evaluation metrics to provide a better picture for how well the full TLS task for news is solved so far,Performance Evaluation,Performance Evaluation
" We propose a simple addition to existing methods to significantly improve date-wise TLS, achieving new state-of-the-art results",New Algorithm/ Method,New Algorithm/ Method
We present a new TLS dataset that is larger than previous datasets and spans longer time ranges,Algorithm/Method Optimization,Algorithm/Method Optimization
", we explore improving the truthfulness in abstractive summarization on two datasets, English Gigaword and JApanese MUlti-Length Headline Corpus (JAMUL)",Dataset Creation,Dataset Creation
we analyze headlines generated by the state-of-the-art encoder-decoder model and show that the model sometimes generates unexpected words,Resources,Resources
"we conjecture that one of the reasons why the model sometimes exhibits such an untruthful behavior lies in untruthful article-headline pairs, which are used for training the model",Model Optimization,Model Optimization
"First, to better measure the semantic overlap between source documents and machine-generated summaries, we propose to use state-of-the-art contextualized text encoders and its variant SentenceBERT (SBERT) ",Model Optimization,Model Optimization
We present a guided copy mechanism based on source word centrality that is obtained by the indegree or outdegree centrality measures,Model Optimization,Model Proposal
We propose a centrality-aware attention and a guidance loss to encourage the model to pay attention to important source word,Model Proposal,Model Proposal
We achieve state-of-the-art on the public text summarization dataset,Dataset Creation,Dataset Creation
we take on the challenge of calibrating a large number of noisy self-reported user ratings to build better dialog evaluation models,Resources,Resources
"we focus on the static embedding, for it is flexible and efficient. The previous works learn the embedding from intra-sentence within a single space, which is not enough for dialog systems",Performance Evaluation,Performance Evaluation
we propose a new method to learn the conversational word embedding from human dialogue in two different vector spaces,New Algorithm/ Method,New Algorithm/ Method
We propose a few-shot CRF framework for slot tagging that computes emission score as wordlabel similarity and estimate transition score by transferring previously learned label dependencie,Algorithm/Method Optimization,Algorithm/Method Optimization
we address two key-questions that arise when training RL dialog agents with expert demonstrations:,Performance Evaluation,Performance Evaluation
"we can evaluate reasoning ability in chatbots, which can potentially allow us to bridge the gap between high performance on leader-board and unsatisfactory practical performance",Performance Evaluation,Performance Evaluation
we develop an open domain Multi-Turn dialogue reasoning dataset (MuTual) to facilitate conversation model reasoning capabilities,Model Optimization,Model Optimization
"we propose Persona Perception Bot (P 2 BOT), explicitly modeling the understanding between interlocutors with a transmitter-receiver framework",Model Proposal,Model Proposal
we formalize bridging anaphora resolution as a question answering problem and propose a QA model to solve the task,Model Proposal,Model Proposal
we explore a new method to generate a large amount of “quasi-bridging” training dataset and demonstrate its value for bridging anaphora resolution,New Algorithm/ Method,New Algorithm/ Method
we carefully carry out a series of experiments on two referential bridging corpora and provide some error analysis to verify the effectiveness of our QA model to resolve the context-dependent bridging anaphors in ISNotes,Model Optimization,Model Optimization
"proposing an MTL-based approach for dialogue coherence assessment using DAP as an auxiliary task, yielding more informative utterance representations for coherence assessment",Theory Proposal,Theory Proposal
alleviating the need for DA labels for dialogue coherence assessment during evaluations,Performance Evaluation,Performance Evaluation
"an empirical evaluation on two benchmark dialogue corpora, showing that our model substantially outperforms the state-of-theart coherence model on DailyDialog, and performs on par with it on SwitchBoard",Performance Evaluation,Performance Evaluation
" we tackle linearization decoding in a different way, by casting it as a Traveling Salesman Problem (TSP)",Theory Proposal,Theory Proposal
"we solve the dependency tree linearization task as a TSP. With the help of TreeLSTM to encode the tree and biaffine attention as a bigram language model, we can use a greedy TSP solver to linearize the tree effectively",Model Optimization,Model Optimization
" we propose the problem of Deep Question Generation (DQG), which aims to generate questions that require reasoning over multiple pieces of information in the passage",Theory Proposal,Theory Proposal
"the very first work, to the best of our knowledge, to investigate deep question generation",Performance Evaluation,Performance Evaluation
"a novel framework which combines a semantic graph with the input passage to generate deep questions, and",Model Proposal,Model Proposal
a novel graph encoder that incorporates attention into a GGNN approach,Model Proposal,Model Proposal
"We introduce a fresh perspective to revisit the relational triple extraction task with a principled problem formulation, which implies a general algorithmic framework that addresses the overlapping triple problem by design.",New Algorithm/ Method,New Algorithm/ Method
We instantiate the above framework as a novel cascade binary tagging model on top of a Transformer encoder,Model Proposal,Model Proposal
"Extensive experiments on two public datasets show that the proposed framework overwhelmingly outperforms state-of-the-art methods, achieving 17.5 and 30.2 absolute gain in F1-score on the two datasets respectively",New Algorithm/ Method,New Algorithm/ Method
"we propose the problem of Deep Question Generation (DQG), which aims to generate questions that require reasoning over multiple pieces of information in the passage.",Theory Proposal,Theory Proposal
a novel framework which combines a semantic graph with the input passage to generate deep questions,Model Proposal,Model Proposal
a novel graph encoder that incorporates attention into a GGNN approach.,Model Proposal,Model Proposal
" We introduce a fresh perspective to revisit the relational triple extraction task with a principled problem formulation, which implies a general algorithmic framework that addresses the overlapping triple problem by design",New Algorithm/ Method,New Algorithm/ Method
We instantiate the above framework as a novel cascade binary tagging model on top of a Transformer encode,Model Proposal,Model Proposal
". Extensive experiments on two public datasets show that the proposed framework overwhelmingly outperforms state-of-the-art methods, achieving 17.5 and 30.2 absolute gain in F1-score on the two datasets respectively",New Algorithm/ Method,New Algorithm/ Method
This work aims to enable rapid comprehension of a large scientific document by identifying a) the central concepts in a text,Theory Proposal,Theory Proposal
"We formulate a noisy sequence labeling problem, where the input undergoes an unknown noising process (§2.2), and we introduce a model to estimate the real error distribution",Model Proposal,Model Optimization
• We propose a data augmentation algorithm (§3.3) that directly induces noise in the input data to perform training of the neural model using a mixture of noisy and clean samples,Model Proposal,Model Proposal
"We implement a stability training method (Zheng et al., 2016), adapted to the sequence labeling scenario, which explicitly addresses the noisy input data problem by encouraging the model to produce a noise-invariant latent representation",New Algorithm/ Method,New Algorithm/ Method
We evaluate our methods on real OCR errors and misspellings against state-of-the-art baseline models,Performance Evaluation,Performance Evaluation
"To support future research in this area and to make our experiments reproducible, we make our code and data publicly available",Theory Proposal,Model Optimization
"A broad collection of labelling functions for NER, including neural models trained on various textual domains, gazetteers, heuristic functions, and document-level constraint",Model Optimization,Model Optimization
. A novel weak supervision model suited for sequence labelling tasks and able to include probabilistic labelling predictions,Model Proposal,Model Proposal
. An open-source implementation of these labelling functions and aggregation model that can scale to large datasets,Model Optimization,Dataset Creation
"Our goal in this paper is to understand which features of the input a model conditioned on relation extraction has learned as useful for the task, in order to be able to better interpret and explain model predictions",Theory Proposal,Model Optimization
"We construct a document-level graph for inference in an end-to-end fashion without relying on co-references or rules, which may not always yield optimal structures",Theory Proposal,Theory Proposal
"• We perform quantitative and qualitative analyses to compare with the state-of-the-art mod1Our model is implemented in PyTorch (Paszke et al., 2017) els in various settings",Algorithm/Method Optimization,New Algorithm/ Method
"We validate the 5k most challenging examples in the TACRED development and test sets, and provide a revised dataset2 that will improve the accuracy and reliability of future RE method evaluations",New Algorithm/ Method,New Algorithm/ Method
"We evaluate the most challenging, incorrectly predicted examples of the revised test set, and develop a set of 9 categories for common RE errors, that will also aid evaluation on other datasets",Performance Evaluation,Performance Evaluation
We verify our error hypotheses on three stateof-the-art RE models and show that two groups of ambiguous relations are responsible for most of the remaining errors and that models exploit cues in the dataset when entities are unmasked,Model Optimization,Model Optimization
"A novel MT task is proposed which can only use the ground-truth bilingual dictionary and monolingual corpora, while is independent on parallel sentences",Theory Proposal,Theory Proposal
AT is proposed as a solution to the task. AT uses the bilingual dictionary to place anchors that can encourage monolingual spaces of both languages to become closer so that translation becomes easier,Theory Proposal,Theory Proposal
" The detailed evaluation on various language pairs shows that AT, especially Bi-view AT, performs significantly better than various methods, including word-by-word translation, unsupervised MT, and cross-lingual embedding transformation",New Algorithm/ Method,New Algorithm/ Method
we perform an in-depth investigation of the suitability of self-attention models for character-level translation,Performance Evaluation,Performance Evaluation
• introducing PASCAL: an effective parameterfree local self-attention mechanism to incorporate source-side syntax into Transformer,New Algorithm/ Method,New Algorithm/ Method
"• adapting LISA (Strubell et al., 2018) to subword representations and applying it to NMT",Model Optimization,Model Optimization
"• similar to concurrent work (Pham et al., 2019), we find that modeling linguistic knowledge into the self-attention mechanism leads to better translations than other approaches",Performance Evaluation,Performance Evaluation
Increasing the capacity of multilingual NMT yields large improvements and narrows the performance gap with bilingual models. Lowresource translation benefits more from the increased capacity,Algorithm/Method Optimization,New Algorithm/ Method
Language-specific modeling and deep NMT architectures can slightly improve zero-sho,Model Optimization,Model Optimization
"Finetuning multilingual NMT with ROBT substantially reduces the proportion of offtarget translations (by ∼50%) and delivers an improvement of ∼10 BLEU in zero-shot settings, approaching the conventional pivotbased method",New Algorithm/ Method,New Algorithm/ Method
" we propose cross-mutual information (XMI), a new metric towards cross-linguistic comparability in NMT. In contrast to BLEU, this information-theoretic quantity no longer explicitly depends on language, model, and tokenization choices",Model Proposal,Model Proposal
we incorporate a language-aware Interlingua module into the Encoder-Decoder architecture,Theory Proposal,Theory Proposal
"we comparatively evaluate a number of reference-free MT evaluation metrics that build on the most recent developments in multilingual representation learning, namely cross-lingual contextualized embeddings (Devlin et al., 2019) and cross-lingual sentence encoders",Performance Evaluation,Performance Evaluation
"we use demographicallyrepresentative author samples from five languages (Dutch, English, French, German, Italian), and translate them with three commercially available machine translation systems",Model Optimization,Model Proposal
"This paper presents MMPE, the first translation environment combining standard mouse & keyboard input with touch, pen, and speech interactions for PE of MT",Model Optimization,Model Proposal
we study the trade-off between quantity and quality of data for training contextualized representations,Model Optimization,Model Proposal
" we offer initial answers to these questions, systematically assessing the syntactic generalization abilities of neural language models on 34 targeted test suites (33 adapted from previously published work, and 1 novel) covering a wide range of syntactic phenomena",Algorithm/Method Optimization,Algorithm/Method Optimization
"In this paper, we examine German number inflection, which has been identified as a crucial test case 1746 for connectionist modeling",Model Optimization,Model Optimization
"This paper aims to model suspense in computational terms, with the ultimate goal of making it deployable in NLP systems that analyze or generate narrative fiction",Resources,Resources
", we seek to address this area by building models to predict, understand, and interpret factors that could affect an article’s reading tim",Model Optimization,Model Optimization
"r, we propose a generative model for Joint natural language Understanding and Generation (JUG), which couples NLU and NLG with a latent variable representing the shared intent between natural language and formal representations",Model Proposal,Model Proposal
"we study three popular random decoding strategies—top-k, nucleus, and temperature sampling—applied to GPT-2",Theory Proposal,Theory Proposal
"• A comprehensive study of generated text detection systems’ sensitivity to model structure, decoding strategy, and excerpt length",Model Optimization,Model Optimization
"An analysis of human raters’ ability to identify machine-generated content, and how human raters differ from automatic detectors",Resources,Resources
"• This work is the first attempt that represents dialog transitions as a graph, and conducts graph grounded policy learning with RL",Resources,Resources
"we explore the possibility of directly fine-tuning a pre-trained transformer language model on a sequential representation of AMR graphs,",Model Proposal,Model Proposal
) the task of automatically updating an existing comment based on source code changes,Theory Proposal,Theory Proposal
novel approach for learning to relate edits between source code and natural language that outperforms multiple baselines on several automatic metrics and human evaluation,Model Proposal,Model Proposal
We introduce BPE-dropout – a simple and effective subword regularization method,New Algorithm/ Method,New Algorithm/ Method
We show that our method outperforms both BPE and previous subword regularization on a wide range of translation task,New Algorithm/ Method,New Algorithm/ Method
We analyze how training with BPE-dropout affects a model and show that it leads to a better quality of learned token embeddings and to a model being more robust to noisy inpu,Resources,Resources
We propose a novel seq2seq-based model to incorporate the salient clinical terms into the summarizer,Model Proposal,Model Proposal
Our model statistically significantly improves over the competitive baselines on MIMIC-CXR publicly available clinical dataset,Dataset Creation,Dataset Creation
" First, intrinsic and extrinsic hallucinations happen frequently – in more than 70% of single-sentence summaries",Theory Proposal,Theory Proposal
" the majority of hallucinations are extrinsic, which potentially could be valid abstractions that use background knowledge",Theory Proposal,Theory Proposal
"we are interested in summarizing longer narratives, i.e., screenplays, whose form and structure is far removed from newspaper articles",Theory Proposal,Theory Proposal
we develop methods for instilling knowledge about narrative structure into generic su- 1922 pervised and unsupervised summarization algorithms,New Algorithm/ Method,New Algorithm/ Method
we enable the use of supervised techniques for unsupervised summarization,Theory Proposal,Theory Proposal
The objective of the current study is to quantify the extent to which the differences between neural LMs trained on language produced by DAT patients and controls reflect known deficits in language use in this disease - in particular the loss of access to relatively infrequent terms that occurs with disease progression,Theory Proposal,Model Optimization
This paper introduces several novel probes for testing systematic generalization,New Algorithm/ Method,Theory Proposal
we investigate whether neural networks can in fact prioritize simultaneous interpretations in a human-like way,Performance Evaluation,Performance Evaluation
", we present a measure of relative word confusability based on both a language model and psychoacoustic data",Model Proposal,Model Proposal
"The paper concludes with a discussion of what our results tell us about adjective order and related issues, and a look towards future work",Theory Proposal,Theory Proposal
"The goal of this paper is to set a new direction for future task-oriented dialog system research: while retrieving the best candidate is crucial, it should be equally important to identify when the correct response (i.e. ground truth) is not present in the candidate set.",Model Proposal,Model Proposal
demonstrating that it is crucial to learn the relationship amongst the candidates as a set instead of looking at point-wise matching to solve the NOTA detection task,Performance Evaluation,Performance Evaluation
extensive experiments show that the raw output score (logits) is more informative in terms of representing model confidence than normalized probabilities after the Softmax laye,Model Proposal,Model Proposal
"we compare several ways to combine tasks designed to evaluate and improve a single conversational skill, ranging from multi-task training over several datasets to training a top-level classifier to play the role of a dialogue manage",Performance Evaluation,Performance Evaluation
we propose and explore the negative training framework to correct unwanted behaviors of a dialogue response generator,Theory Proposal,Theory Proposal
negative training is used to address the malicious response problem and the frequent response problem  in open-domain dialogue response generation,Theory Proposal,Theory Proposal
"We propose a recursive, hierarchical framebased representation that captures complex relationships between slots labels,",Theory Proposal,Theory Proposal
We formulate frame generation as a templatebased tree-decoding task,Theory Proposal,Theory Proposal
We extend (local) tree-based loss functions with global supervision optimize jointly for all loss functions end-to-end and show that this improves performance,Algorithm/Method Optimization,Applications
we study the task of SQL parse correction with natural language feedback to enable text-to-SQL systems to seek and leverage human feedback to further improve the overall performance and user experience,Algorithm/Method Optimization,Applications
we define the task of SQL parse correction with natural language feedback,Resources,Resources
We create a framework for explaining SQL parse in natural language to allow text-to-SQL users (who may have a good idea of what kind of information resides on their databases but are not proficient in SQL Hendrix et al. (1978)) to provide feedback to correct inaccurate SQL parses,Model Optimization,Model Optimization
"we demonstrate that neural network models show high calibration errors for NLP tasks such as POS, NER and QA",Performance Evaluation,Performance Evaluation
we explore using natural language explanations (Figure 1) to generate features that can augment modern neural representations,Theory Proposal,Theory Proposal
we extend the BERT training with unlabeled data in a generative adversarial setting,Dataset Creation,Dataset Creation
"we propose a novel framework, named Consensus Network (CONNET), for sequence labeling with multi-source supervisions",Theory Proposal,Theory Proposal
"we introduce a new data augmentation method, called TMix",New Algorithm/ Method,New Algorithm/ Method
"we propose MobileBERT to fill this gap. In practice, task-agnostic compression of BERT is desirable",Theory Proposal,Theory Proposal
"we seek to fill in this missing knowledge, and put this practice on more rigorous footing",Theory Proposal,Model Optimization
", we review the theory of importance sampling, providing proof that importance sampled perplexity estimates are stochastic upper bounds of the true perplexity—a previously unnoted justification for this evaluation technique",Algorithm/Method Optimization,Algorithm/Method Optimization
Our proposed neural model directly encodes the structural information from a noisy graph into the embedding space,Model Proposal,Model Proposal
"Our study suggests that collecting data and training on the target tasks is a solution worth considering, especially in production environments where accuracy is not the only considered factor, rather inference latency is often just as crucial",Dataset Creation,Dataset Creation
"First, we explain why BLI does not reflect downstream task accuracy",Theory Proposal,Theory Proposal
we introduce two post-processing methods to improve downstream models by fitting the training dictionary better,New Algorithm/ Method,New Algorithm/ Method
Method: We propose a distillation method leveraging internal representations and parameter projection that is agnostic of teacher architecture,New Algorithm/ Method,New Algorithm/ Method
"Inference: To learn model parameters, we propose stage wise optimization schedule with gradual unfreezing outperforming prior schemes",Model Proposal,Model Proposal
Experiments: We perform distillation for multilingual NER on 41 languages with massive compression and comparable performance to huge models,Algorithm/Method Optimization,Algorithm/Method Optimization
"Study: We study the influence of several factors on distillation like the availability of annotation resources for different languages, model architecture, quality of multilingual word embeddings, memory footprint and inference latency",Model Optimization,Model Proposal
we investigate the stealthiness of state-of-the-art authorship obfuscation methods,New Algorithm/ Method,New Algorithm/ Method
We study the problem of obfuscation detection for state-of-the-art authorship obfuscation method,New Algorithm/ Method,New Algorithm/ Method
We explore 160 distinct BERT and GPT-2 based neural language model architectures designed to leverage text smoothness for obfuscation detection,Model Proposal,Model Proposal
"We conduct a comprehensive evaluation of these architectures on 2 different datasets. Our best architecture achieves F1 of 0.87, on average, demonstrating the serious lack of stealthiness of existing authorship obfuscation methods",New Algorithm/ Method,New Algorithm/ Method
"we conduct experiments on BERT and RoBERTa with six GLUE datasets, showing that DeeBERT is capable of accelerating model inference by up to ∼40% with minimal model quality degradation on downstream tasks",Dataset Creation,Dataset Creation
"A robust model for HTC, with few parameters and short training time, that follows the paradigm of sequence-to-sequence learning",Model Optimization,Model Proposal
The practical application of an auxiliary (and not expensive) task that strengthens the model capacity for prediction in a bottom-up scheme,Model Optimization,Model Proposal
An exploration of strategies that take advantage of external information about textual definition of the classes,Theory Proposal,Theory Proposal
"We develop a multi-task framework that leverages inductive transfer between our main task (grading spoken language proficiency) and auxiliary objectives – predicting morphosyntactic labels, the learner’s first (‘native’) language (L1) and language modeling (LM)",New Algorithm/ Method,New Algorithm/ Method
"We investigate the performance of two encoder types for the speech scoring task: bidirectional recurrent neural networks, and bidirectional representations from transformers",Performance Evaluation,Performance Evaluation
"We analyze model performance under different conditions: namely, with and without filled pauses included in the transcriptions, with varying rates of word error in the ASR transcriptions, and according to the proficiency of the student response",Algorithm/Method Optimization,Algorithm/Method Optimization
We make our code publicly available for others to use for benchmarking and replication experiments,Performance Evaluation,Performance Evaluation
we introduce a new method for learning general-purpose vector representations of scientific documents,New Algorithm/ Method,New Algorithm/ Method
"we focus on the Search-based Pseudocode to Code (SPoC) dataset (Kulal et al., 2019) due to its challenging multiline programs and availability of input-output test suites to evaluate denotation accuracy",Performance Evaluation,Performance Evaluation
We propose the use of semantic scaffolds to add semantic constraints to models for longform language-to-code generation tasks,Model Proposal,Model Proposal
"We introduce a hierarchical beam search algorithm that incorporates these constraints, resulting in heightened efficiency, better coverage of the search space, and stronger performance when compared with the standard approach",Performance Evaluation,Performance Evaluation
We achieve a new state-of-the-art accuracy of 55.1% on the SPoC pseudocode-to-code dataset.,Dataset Creation,Dataset Creation
" We propose the OLP task, an OLP evaluation protocol, and a method to create an OLP benchmark dataset",New Algorithm/ Method,New Algorithm/ Method
"We propose a new English natural language inference dataset, INFOTABS, to study the problem of reasoning about semi-structured data",Theory Proposal,Theory Proposal
" To differentiate models’ ability to reason about the premises from their memorization of spurious patterns, we created three challenge test sets with controlled differences that employ similar reasoning as the training set",Performance Evaluation,Performance Evaluation
"We show that several existing approaches for NLI underperform on our dataset, suggesting the need for new modeling strategies",Dataset Creation,Dataset Creation
We describe a method to make MRC datasets interactive and formulate the new task as an RL problem,New Algorithm/ Method,New Algorithm/ Method
We develop a baseline agent that combines a top performing MRC model and two state-ofthe-art RL optimization algorithms and test it on iMRC task,New Algorithm/ Method,New Algorithm/ Method
We conduct experiments on several variants of iMRC and discuss the significant challenges posed by our setting,Resources,Resources
We constructed augmentation sets by applying syntactic transformations to a small number of examples from MNL,Applications,Applications
we aim to improve the generalization of the future frame prediction task by adding an auxiliary objective that serves as a regularization,Theory Proposal,Theory Proposal
we present a successful framework for fine-tuning BERT and XLNet for multimodal inpu,Theory Proposal,Model Proposal
We propose an efficient framework for finetuning BERT and XLNet for multimodal language data,Performance Evaluation,Performance Evaluation
MAG-BERT and MAG-XLNet set new state of the art in both CMU-MOSI and CMUMOSEI datasets,Dataset Creation,Dataset Creation
Our model utilizes the online temporal alignment between the input audio signal and its raw ASR transcription,Model Optimization,Model Proposal
We achieve consistent and significant improvements from learning jointly from the two modalities compared to ASR transcriptions and audio only,Applications,Applications
Our evaluation framework features a challenging real-world task with noisy inputs and realtime processing requirements,Performance Evaluation,Performance Evaluation
a fusion mechanism for audio and visual modalities based on the crossmodal scaled-dot product attention,Theory Proposal,Theory Proposal
an end to end training procedure for multimodal grounding in ASR,Theory Proposal,Theory Proposal
the use of a multiresolution training scheme for character and subword level recognition in a seq2seq setting without relying on explicit phonetic information,Theory Proposal,Theory Proposal
"We carefully curate Selected Pairs Of Learnable ImprovisatioN (SPOLIN), the first largescale corpus of yes-and dialogue acts, sourced from improv and movie dialogues",Theory Proposal,Theory Proposal
"We iteratively build a high-precision yes-and classifier, which we use to mine additional yesands from dialogue corpora with high volume but low yes-and densit",Theory Proposal,Theory Proposal
We fine-tune existing open-domain conversational models with our corpus and confirm via human evaluations that this approach improves creative grounding,Performance Evaluation,Performance Evaluation
"We release our models and data for public use, including a 64,000 turn pair extension of the core SPOLIN",Dataset Creation,Dataset Creation
" we take a step towards these goals by considering grounded dialogue involving openended discussion of a given image, a setting that is naturally fun for humans (Hu et al., 2014), and study neural conversational models for task",Model Proposal,Model Proposal
" a completely unsupervised unreferenced metric MAUDE (Metric for automatic Unreferenced dialogue evaluation), which leverages state-of-the-art pretrained language model combined with a novel discoursestructure aware text encoder and contrastive training approach",Model Proposal,Model Proposal
w We propose a neural model for generating these response timings in SDSs,Model Proposal,Model Proposal
"First, we present how our dataset is structured and our training objective",Dataset Creation,Dataset Creation
we present an overview of related work on automatic poetry generation,Theory Proposal,Theory Proposal
We propose a dual encoding method to narrow the structural gap between data encoder and text decoder for data-to-text generation,New Algorithm/ Method,New Algorithm/ Method
"We propose a neural planner, which is more efficient and effective than previous method",Performance Evaluation,Performance Evaluation
Experiments show that our method outperforms all baselines on a variety of measure,New Algorithm/ Method,New Algorithm/ Method
"In this work, we present infilling by language modeling (ILM), a simple framework which en- 2493 ables LMs to infill variable-length spans while preserving their aforementioned benefits: generation quality, efficient sampling, and conceptual simplicity",Performance Evaluation,Performance Evaluation
"We study the task of sentence infilling, which requires the model to handle inter-sentential correlation and to predict missing semantic information",Model Optimization,Model Optimization
"Our approach decouples understanding, planning, generation, and leverages existing largescale pre-trained understanding and generation models (BERT, GPT-2",Model Optimization,Model Optimization
Our model predicts a feature vector in the latent semantic space for the missing sentence and maps the vector to text,Model Optimization,Model Optimization
Our model allows the generation to be of arbitrary length,Model Proposal,Model Proposal
"Compared with directly processing text, our approach significantly reduces computation time and memory usage during training, as (after pre-computing sentence features) the sequence length is the number of sentences rather than that of tokens",Theory Proposal,Theory Proposal
we propose a model-based imitation-learning method to overcome the aforementioned issues in text-generation tasks,Model Proposal,Model Proposal
"we show that generation performance can be improved with a retrieve-edit-rerank approach that instead retrieves a set of outputs from  the training set, edits each independently",Applications,Applications
we investigate another crucial aspect of following the instructions: can a VLN agent generalize to following longer instructions by learning from shorter ones?,Performance Evaluation,Performance Evaluation
"We propose a new task, MultiMedia Event Extraction, and construct the first annotated news dataset as a benchmark to support deep analysis of cross-media events",Theory Proposal,Theory Proposal
"We develop a weakly supervised training framework, which utilizes existing singlemodal annotated corpora, and enables joint inference without cross-modal annotation",New Algorithm/ Method,Model Optimization
" Our proposed method, WASE, is the first to leverage structured representations and graph-based neural networks for multimedia common space embedding",New Algorithm/ Method,New Algorithm/ Method
" Generative models tend to do better than discriminative models of the same or similar model class at learning the full range of step types, which benefits action segmentation;",Model Optimization,Model Proposal
"Task structure affords strong, feature-agnostic baselines that are difficult for existing systems to surpass",Theory Proposal,Theory Proposal
Reporting multiple metrics is necessary to understand each model’s effectiveness for action segmentation,Resources,Resources
we explore models for building an automated Builder agent,Model Optimization,Model Proposal
we propose the MemoryAugmented Recurrent Transformer (MART) model  a transformer-based model that uses a shared encoder-decoder architecture augmented with an external memory module to enable the modeling of the previous history of video segments and sentences,Model Proposal,Model Proposal
we analyze the Visually Grounded Neural Syntax Learner (VG-NSL) model of Shi et al. (2019),Resources,Resources
In this paper we take a low-overhead approach to add limited interaction to intent classification,Theory Proposal,Model Optimization
study the effect of interaction on the system performance,Algorithm/Method Optimization,Applications
avoid the cost and complexities of interactive data collection,Dataset Creation,Dataset Creation
This work analyzes the contribution of various techniques proposed for transfer learning between languages for the task of sequence tagging,Theory Proposal,Theory Proposal
"Our work studies the corresponding pseudo-loglikelihood scores (PLLs) from MLMs (Wang and Cho, 2019), given by summing the conditional log probabilities log PMLM(wt | W\t ) of each sentence token (Shin et al., 2019",Theory Proposal,Theory Proposal
" a novel distance-based knowledge graph embedding called orthogonal transform embedding (OTE) with graph context is proposed to alleviate the 1-to-N, N-to-1 and N-to-N issues, while keeps the desired relation patterns as RotatE",Theory Proposal,Theory Proposal
"A new orthogonal transform embedding OTE, is proposed to extend RotatE from 2D space to high dimensional space, which also models symmetry/antisymmery, inversion and compositional relation patterns",Model Proposal,Model Optimization
A directed graph context modeling method is proposed to integrate knowledge graph context (including both neighboring entity nodes and relation edges) into the distance scoring function,Model Proposal,New Algorithm/ Method
"Experimental results of OTE on standard benchmark FB15k-237 and WN18RR datasets show consistent improvements over RotatE, the state of art distance-based embedding model, especially on FB15k-237 with many high in-degree nodes. On WN18RR our results achieve the new state-of-the-art performance",Dataset Creation,Dataset Creation
the classifier’s performance. We propose a simple but effective training technique called Posterior Calibrated (PosCal) training that optimizes the task objective while calibrating the posterior distribution in training,Theory Proposal,Theory Proposal
This work proposes a method for augmenting any neural decoder architecture to incorporate finegrained control states,New Algorithm/ Method,New Algorithm/ Method
"In this work, we systematically study the OOD robustness of various NLP models, such as word embeddings averages, LSTMs, pretrained Transformers, and more",Theory Proposal,Model Optimization
"Our primary contribution is robust encodings (RobEn), a framework to construct encodings that can make systems using any model robus",Theory Proposal,Theory Proposal
"Our main contributions are as follows: First, we prove that their estimator is biased under weak conditions and provide an unbiased solution",Model Optimization,Model Optimization
Our main contribution is a new framing for the sentence ordering task as a constraint solving problem,Theory Proposal,Theory Proposal
We also propose a new and simple approach for this task in this new framework,Theory Proposal,Theory Proposal
we raise a question about this trend from a different angle: “could widespread adoption of the practice of downloading publicly distributed weights pose a security threat?”,Theory Proposal,Theory Proposal
The ratio of the architecture design dimensions within a BERT encoder layer can be modified to obtain a layer with better performance. Transformer design dimensions suggested in Vaswani et al. (2017) are suboptimal,Algorithm/Method Optimization,Applications
"When we aim to obtain a computationally lighter model, using a ‘tall and narrow’ architecture provides better performance than a ‘wide and shallow’ architecture",Model Optimization,Model Optimization
The fully-connected component applied to each token separately plays a much more significant role in the top layers as compared to the bottom layer,Theory Proposal,Theory Proposal
", we propose to combine the beneficial effects of multilingual NMT with the selfsupervision from monolingual data",Theory Proposal,Theory Proposal
Our contribution is an extensive empirical evaluation of top-performing NMT systems to validate or disproof some of the above conjectures,Performance Evaluation,Performance Evaluation
"In this paper, we propose to achieve an adaptive policy via a much simpler heuristic composition of a set of wait-k policies (e.g., k = 1 ∼ 10)",Theory Proposal,Theory Proposal
". We introduce the novel structured logits mechanism, which enables the exploitation of concept relatedness as determined by LKB edges",New Algorithm/ Method,Theory Proposal
"We generalise the sense vector dot product technique from EWISE, showing that off-theshelf pretrained embeddings can be used",Theory Proposal,Theory Proposal
We show that the structured logits mechanism and the use of sense embeddings are orthogonal and can be exploited jointl,Theory Proposal,Theory Proposal
In this work we propose to learn a joint functionspecific word vector space that accounts for the study eat need food help assistance support subject art researcher science chicken scientist implementation cat chicken different roles and functions a word can take in text,Theory Proposal,Theory Proposal
"we first semi-automatically collect German specialized domain corpora to create a gold standard of term technicality across four domains: automotive, cooking, hunting and DIY",Theory Proposal,Theory Proposal
we focus on how identification of verbal metaphors can be helped by verbal MWEs,Theory Proposal,Theory Proposal
we aim to understand the bias in multilingual word embeddings,Theory Proposal,Theory Proposal
We build datasets for studying the gender bias in multilingual NLP systems,Dataset Creation,Dataset Creation
We analyze gender bias in multilingual word embeddings from both intrinsic and extrinsic perspectives,Resources,Resources
We show that simple mitigation methods can help to reduce the bias in multilingual word embeddings and discuss directions for future work to further study the problem,New Algorithm/ Method,New Algorithm/ Method
"This paper aims to investigate this issue, focused around the examination of a paper recently published at EMNLP 2019 on automatic prison term prediction by Chen et al. (2019)",Performance Evaluation,Performance Evaluation
"Propose MORPHEUS, a method for generating plausible and semantically similar adversaries by perturbing the inflections in the clean examples",New Algorithm/ Method,New Algorithm/ Method
"Demonstrate its effectiveness on multiple machine comprehension and translation models, including BERT and Transforme",Performance Evaluation,Performance Evaluation
"Show that adversarially fine-tuning the model on an adversarial training set generated via weighted random sampling is sufficient for it to acquire significant robustness, while preserving performance on clean examples",Applications,Applications
we conduct a systematic study to quantify the bias in the predicted distribution over labels,Resources,Resources
we present an evaluation framework to analyze social bias in NRE models,Theory Proposal,Model Proposal
"We create WikiGenderBias, a new dataset for evaluating gender bias in NRE systems",Dataset Creation,Dataset Creation
We present an evaluation framework to demonstrate that gender bias is exhibited in NRE model outputs,Theory Proposal,Model Proposal
We test several existing bias mitigation approaches to reducing gender bias in NRE system,Performance Evaluation,Performance Evaluation
we propose here a novel probabilistic generative model for analyzing extracted images of individual printed characters in historical document,Model Proposal,Model Optimization
. We draw from work on both deep generative modeling and interpretable models of the printing press to develop an approach that is both flexible and controllable – the later being a critical requirement for such analysis tool,New Algorithm/ Method,Model Optimization
we propose an Attentive Pooling with Learnable Norms (APLN) approach to enhance the learning of text representations,Theory Proposal,Theory Proposal
"Our contributions are a family of novel methods to compute the similarity of sequence tagging datasets, where the similarity values correlate with the change in multi-task learning performance when using one dataset as auxiliary data for training the other",New Algorithm/ Method,New Algorithm/ Method
SSANs can identify the improper word orders in both local (§4.1) and global (§4.2) ranges by learning to attend to the expected words,Theory Proposal,Theory Proposal
SSANs produce more syntactic representations (§5.1) with a better modeling of structure by selective attention,Theory Proposal,Model Proposal
The selective mechanism improves SANs by paying more attention to content words that posses semantic content and contribute to the meaning of the sentence,Theory Proposal,Theory Proposal
we design a new family of transformer models that follow a distinct sublayer ordering pattern: sandwich transformer,Model Proposal,Model Proposal
we propose a novel method that replicates the effects of the ensemble technique with a single model,Model Proposal,New Algorithm/ Method
We propose a self-training based method to leverage unlabeled data in zero-shot text classification,New Algorithm/ Method,New Algorithm/ Method
We propose a reinforcement learning framework to learn data selection policy automatically instead of using manually designed heuristic,Theory Proposal,Theory Proposal
Experimental results on both benchmarks and a real-world e-commerce dataset show that our method outperforms previous methods with a large margin of 15.4% and 5.4% on average in generalized and non-generalized ZSL respectively,New Algorithm/ Method,New Algorithm/ Method
we propose a novel graph-based multi-modal fusion encoder for NMT,Theory Proposal,Theory Proposal
" We propose a unified graph to represent the input sentence and image, where various semantic relationships between multi-modal semantic units can be captured for NMT",Theory Proposal,Theory Proposal
" We propose a graph-based multi-modal fusion encoder to conduct graph encoding based on the above graph. To the best of our knowledge, our work is the first attempt to explore multimodal graph neural network (GNN) for NMT",Theory Proposal,Theory Proposal
We conduct extensive experiments on Multi30k datasets of two language pairs,Dataset Creation,Dataset Creation
We release the code at https://github.com/ DeepLearnXMU/GMNMT,Theory Proposal,Theory Proposal
" Greedy algorithms: Wu et al. (2016) segment words by recursively selecting the longest subword prefix. Sennrich et al. (2016) recursively combine adjacent word fragments that co-occur most frequently, starting from characters",New Algorithm/ Method,New Algorithm/ Method
We view the subword segmentation of output sentences in machine translation as a latent variable that should be marginalized out to obtain the probability of the output sentence given the inpu,Theory Proposal,Theory Proposal
we take this point of view and learn cross-lingual word alignment by finding alignment between the second order statistics of the source and the target language embedding space,Theory Proposal,Theory Proposal
"We demonstrate the necessity of studying inference calibration for NMT, which can serve as useful indicators of translation error",Performance Evaluation,Performance Evaluation
"We reveal certain linguistic properties of miscalibrated predictions in NMT, which provides potentially useful information for the design of training procedures",Model Optimization,Model Optimization
"We revisit recent advances in architectures and regularization techniques, and provide variants that can boost translation performance by improving inference calibration",Model Optimization,Model Optimization
" We propose a SIGNAL model in the contex of Chinese text spam detection, to address the imbalance, efficiency, and text camouflage problems",Model Proposal,Model Optimization
") We develop an end-to-end framework, i.e., LADAN, to solve the LJP task. It addresses the confusing charges issue by mining similarities between fact descriptions and law articles as well as the distinctions between confusing law articles",New Algorithm/ Method,Model Proposal
We propose a novel graph distillation operator (GDO) to extract discriminative features for effectively distinguishing confusing law articles,Theory Proposal,Theory Proposal
We conduct extensive experiments on realworld datasets. The results show that our model outperforms all state-of-the-art methods,New Algorithm/ Method,New Algorithm/ Method
We propose a novel task of job posting generation that is defined as the conditional generation given a job description and basic company information to generate a job requiremen,Theory Proposal,Theory Proposal
A data-driven generation approach SAMA is proposed to model the complex mapping relationships and generate informative and accurate job requirements,Model Proposal,Model Optimization
We build a real-world job posting dataset and conducte extensive experiments to validate the effectiveness and superiority of our proposed approach,Theory Proposal,Theory Proposal
we propose a novel method termed as Hyperbolic and Co-graph Representation method (HyperCore,New Algorithm/ Method,New Algorithm/ Method
"We propose to connect CNN and RNN in parallel to simultaneously extract local and global contextual information, which would be complementary to each othe",Theory Proposal,Theory Proposal
"HYPERCAPS with HDR are formulated to aggregate features in a label-aware manner, and hyperbolic capsules benefits from the representation capacity of the hyperbolic space",Theory Proposal,Model Proposal
• Adaptive routing is furthermore presented to improve the scalability of HYPERCAPS and fit the large label set of MLC,Theory Proposal,Model Proposal
"Extensive experiments on four benchmark MLC datasets demonstrate the effectiveness of HYPERCAPS, especially on tail labels",Dataset Creation,Dataset Creation
"We introduce a novel task towards understanding technical support problems, which has implications on a variety of downstream application",New Algorithm/ Method,Theory Proposal
". We benchmark the performance of state of the art sequence labelling models on the task, studying their performance and limitations",Applications,Applications
"we present MOOCCube, a data repository that integrates courses, concepts, student behaviors, relationships, and external resources",Theory Proposal,Model Proposal
We propose a novel framework that stacks the Bayesian network ensembles on top of the entity-aware convolutional neural networks to bring interpretability into automatic diagnosis without compromising the accuracy of deep learning,Theory Proposal,Theory Proposal
We bring forward three variants of Bayesian Networks for disease inference that provides interpretability,Model Optimization,Model Optimization
We publish the Chinese medical knowledge graph of Gynaecology and Respiration used in our Bayesian Network for disease inference with this paper for reproducibility,Theory Proposal,Theory Proposal
This paper analyzes the persuasive effect of style in news editorial argumentation on readers with different political ideologies (conservative vs. liberal),Theory Proposal,Theory Proposal
"we propose a new end-to-end ECPE solution, called ECPE-Two-Dimensional (ECPE-2D), to represent the emotion-cause pairs by a 2D representation scheme, and integrate the emotion-cause pair representation, interaction and prediction into a joint framework",Theory Proposal,Theory Proposal
", we propose the first end-toend approach for emotion-cause pair extraction, which is a unified model to tackle this task from a ranking perspective",Model Proposal,Model Optimization
Our approach emphasizes inter-clause modeling by integrating inter-clause relationship modeling and kernel-based relative position enhanced clause pair ranking,Model Optimization,Model Proposal
"Experimental results demonstrate that our onestep approach significantly outperforms the current best-performing systems, especially in the condition of extracting multiple pairs in one document",Performance Evaluation,Performance Evaluation
"We construct a semantic-emotion heterogeneous graph from external semantic and emotion lexicons, and employ GCN to learn the semantic graph representation",Theory Proposal,Model Proposal
"We extend the standard LSTM cell with an additional memory unit, effectively integrating external knowledge into the classifier for stance detection",Theory Proposal,Theory Proposal
We conduct extensive experiments on a large dataset expanded from SemEval-2016 Task 6 to verify the effectiveness of our model for cross-domain stance detection,Dataset Creation,Dataset Creation
"We propose KinGDOM, a domain-adversarial framework that uses an external KB (ConceptNet) for unsupervised domain adaptation",Theory Proposal,Theory Proposal
"We demonstrate, through experiments, that KinGDOM surpasses state-of-the-art methods on the Amazon-reviews dataset (Blitzer et al., 2007b), thus validating our claim that external knowledge can aid the task of cross-domain SA",New Algorithm/ Method,New Algorithm/ Method
We propose the multi-channel CSAE model which distils grammatical aspects into contextualized features for improving sequential taggings,Model Proposal,Model Optimization
We contribute the LCFS-ASC which can analyze syntactical connections between words to better understand local contexts that are relevant to target aspect terms,Theory Proposal,Theory Proposal
We study the importance of the SRD by exploring the attention score in the LCF layer,Theory Proposal,Theory Proposal
", we propose to augment parallel data with three specific data augmentation methods to help improve the model’s generalization ability and reduce the overfitting risk",Model Proposal,New Algorithm/ Method
We propose an aspect-oriented tree structure by reshaping and pruning ordinary dependency trees to focus on the target aspects,Theory Proposal,Theory Proposal
We propose a new GAT model to encode the dependency relations and to establish the connections between aspects and opinion words,Model Proposal,Model Optimization
The source code of this work is released for future research,Theory Proposal,Theory Proposal
"We propose an end-to-end model for a new task PAOTE. To the best of our knowledge, it is the first end-to-end model that can jointly extract the AT/OT and the pair-wise relations between them",Model Proposal,Model Optimization
We design a novel span-based multi-task neural network for PAOTE. It can overcome the drawbacks of sequence tagging methods by taking advantage of the span-level information,New Algorithm/ Method,New Algorithm/ Method
We conduct extensive experiments and the results show that our proposed model outperforms the state-of-the-art methods,Model Proposal,New Algorithm/ Method
"r, we present a novel model for nontree argument mining",Theory Proposal,Model Proposal
", we propose a novel linearization of constituent trees tied on their span representations",Theory Proposal,Theory Proposal
"we propose three standardized experimental settings with respect to data preprocessing, post-processing, evaluation metrics, and tuning.",Theory Proposal,Theory Proposal
we propose a novel parsing approach that casts constituency parsing into a series of pointing problems,Theory Proposal,Theory Proposal
We for the first time propose second-order TreeCRF for neural dependency parsing,Theory Proposal,Theory Proposal
"We propose to batchify the inside algorithm via direct large tensor computation on GPUs, leading to very efficient TreeCRF loss computation",Performance Evaluation,Performance Evaluation
We conduct experiments on 27 datasets from 13 languages,Dataset Creation,Dataset Creation
"we explore dynamic conversation recommendation, which can model the change of user interests over time",Model Optimization,Model Proposal
"We design the model to capture user interests from both what they said in the past, and how they interacted with each other in the conversation structure",Performance Evaluation,Performance Evaluation
"• We propose a Multimodal Transformer model for the task of MNER, which empowers Transformer with a multimodal interaction module to capture the inter-modality dynamics between words and images",Model Proposal,Model Optimization
"we further design a unified architecture to incorporate a text-based entity span detection module, aiming to alleviate the bias of the visual context in MNER with the guidance of entity span predictions from this auxiliary module",Model Proposal,Model Proposal
"We model the leading political ideology (left, center or right bias) and the factuality of reporting (high, mixed, or low) of news media by modeling the textual content of what they publish vs. who reads it in social media (Twitter, Facebook, and YouTube)",Resources,Resources
" We combine a variety of information sources about the target medium, many of which have not been explored for our tasks, e.g., YouTube video channels, political bias estimates of their Facebook audience, and information from the profiles of the media followers on Twitter",Theory Proposal,Theory Proposal
"We use features from different data modalities: text, metadata, and speech. The latter two are novel for these tasks",Model Proposal,Model Proposal
We achieve sizeable improvements over the current state-of-the-art for both tasks,Applications,Applications
"We propose various ensembles to combine the different types of features, achieving further improvements, especially for bias detection",Theory Proposal,Theory Proposal
"We release the data, the features, and the code necessary to replicate our result",Dataset Creation,Dataset Creation
"we discuss some related work, followed by a description of our system’s architecture and the information sources we use",Theory Proposal,Theory Proposal
"In this paper, to obtain a new insight into the syntactic abilities of neural LMs, in particular RNNLMs, we perform a series of experiments under a different condition from the prior work",Theory Proposal,Model Optimization
We propose a novel approach to simulating various grammatical errors,Theory Proposal,Theory Proposal
We conduct a systematic analysis of the robustness of language encoders and enhance previous work by studying the performance of models on downstream tasks with various grammatical error type,Algorithm/Method Optimization,Algorithm/Method Optimization
We demonstrate the robustness of existing language encoders against grammatical errors varies,Performance Evaluation,Performance Evaluation
we suggest an analysis method which helps understand where linguistic properties are learned and represented along attention heads in transformer architectures,New Algorithm/ Method,New Algorithm/ Method
"we show that using analysis results, attention heads can be maximally utilized for performance gains during the fine-tuning process on the downstream tasks and for capturing linguistic properties",Applications,Applications
"We argue that the attention scores (rather than attention weights) are able to capture the global, absolute importance of word tokens within a corpus",Theory Proposal,Theory Proposal
We present R-MeN – a novel KG embedding model to memorize and encode the potential dependencies among relations and entities for two real applications of triple classification and search personalization,Theory Proposal,Model Proposal
"R-MeN obtains better performance than up-to-date embedding models, in which R-MeN produces new state-of-the-art results on SEARCH17 3430 for the search personalization task, and a new highest accuracy on WN11 and the secondhighest accuracy on FB13 for the triple classification task",Applications,Applications
"we propose MC-Tailor, which can tailor the resulting density of model distribution by cutting the probability mass of over-estimated zones to under-estimated zones, leading to more realistic model distribution after fine-tuning",Model Proposal,Model Optimization
"we propose a new architecture, named Multi-source Word Aligned Attention (MWA)",Theory Proposal,Theory Proposal
"we propose the Coupled-VAE approach, which couples the VAE model with a deterministic network with the same structure",Model Proposal,Model Optimization
We observe the encoder-decoder incompatibility in VAE and connect it to the posterior collapse problem,Theory Proposal,Theory Proposal
"We propose the Coupled-VAE, which helps the encoder and the decoder to learn better parameterizations of the data manifold with a coupled deterministic network, via encoder weight sharing and decoder signal matching",Model Optimization,Model Optimization
we propose a general co-teaching framework with three specific teaching strategies that cover both teaching with loss functions and teaching with data curriculum.,Theory Proposal,Theory Proposal
We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph,Model Proposal,Model Proposal
we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple,Theory Proposal,Theory Proposal
"demonstrating that applying standard topic discovery algorithms such as NMF and LDA on aggregated
documents results in discovery of topics related
to the aggregation method.",Applications,Applications
"we propose using tree-structured semantic representations, like those used in traditional rule-based NLG systems, for better discourse-level structuring and sentence-level planning;",New Algorithm/ Method,New Algorithm/ Method
"Our work explores the possibility that limited
training data could be better exploited by including attentive collocation information.",Theory Proposal,Theory Proposal
"we compare the improvements
obtained on these two tasks in three South
Slavic languages (Slovenian, Croatian and Serbian) by moving from traditional approaches to
the neural ones.",Performance Evaluation,Performance Evaluation
"contextualized word embeddings have enhanced previous word embedding techniques by computing
word vector representations dependent on the
sentence they appear in.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose
aspects of NLI and of the annotation task itself
that should be taken into account when designing future NLI corpora and annotation guidelines.",New Algorithm/ Method,New Algorithm/ Method
"We use distributed event representation based on the Role Factored Tensor Model
(RFTM) (Weber et al., 2018) to realize a robust
matching of event causality relations, even if these
causalities are not included in the extracted event
causality pairs",Model Proposal,Model Proposal
"we also
show that the neural encoder-decoder architecture trained to predict the minimum edit operations can produce considerably better results than the architecture trained to predict the
characters in lemmata directly as in previous
studies.",Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a novel approach to estimate WER per sentence and to aggregate them to provide WER estimation per recording or for a whole test set,New Algorithm/ Method,New Algorithm/ Method
We investigate two pragmatic inferencetypes that are known to differ from classical en-tailment: scalar implicatures and presuppositions,Theory Proposal,Theory Proposal
we propose a novel approach to filter out noisysentence pairs from web-crawled corpora viapre-trained language models.,New Algorithm/ Method,New Algorithm/ Method
"we introduce a new loss func-tion for CVAEs that counteracts posterior collapse,motivated by our analysis of CVAE’s evidencelower bound objective (ELBO).",New Algorithm/ Method,New Algorithm/ Method
we make the first steps towards the adoption of MI as a measure of semantic similarity between dense word embeddings,Performance Evaluation,Performance Evaluation
"we propose two improvements to active learning for coreference resolution. First, we introduce the notion of discrete annotation. Second, we introduce mention clustering (Section 4).",Performance Evaluation,Performance Evaluation
The degree of correction of the neural GEC model can be controlled using the WER,Model Optimization,Model Optimization
"the basic ideas around how modern
NLP and NLG techniques could be applied to describe and summarize textual data in format that is
non-linguistic in nature or has some structure",Theory Proposal,Theory Proposal
"it focuses on the
copula construction and its negation and
the case-stacking phenomenon thereof.",Theory Proposal,Theory Proposal
"we show that facial expressions, voice, eyes
and body movements are the top three channels
among which the emotion is expressed,",Theory Proposal,Theory Proposal
"we present an analysis of user responses to a September 27, 2018 announcement about the quarantine policy on Reddit as
a case study of to what extent the discourse
on content moderation is polarized by users’
ideological viewpoint.",Applications,Applications
"we present an open
source desktop application for the annotation process.",Applications,Applications
we provide the introduction of a new NLP task: identifying actionable feedback in collaborative work conversations,Theory Proposal,Theory Proposal
We explore theusefulness ofinterpolatedtreebank vectors whichare computed via a weighted combination of thepredefined fixed ones,Performance Evaluation,Performance Evaluation
"we focus on investigating and re-ducing biases in the task of Natural Language In-ference (NLI), where the target of the model isto classify the relations between a pair of sen-tences into three categories: entailment, neutraland contradiction",New Algorithm/ Method,New Algorithm/ Method
"We show thatby preventing models from being overconfident onbiased examples, they are less likely to exploit thesimple cues from these examples",Model Optimization,Model Optimization
Our new system achievesstate-of-the-art resultsfor FEVERand we present anevaluation of ourmodelsincluding ablation studies (Section 6). Dataand code will be released to the community.,Model Proposal,Model Proposal
"we first present a comprehensiveanalysis of the trade-offs and limitations of multi-lingual language models at scale, inspired by re-cent monolingual scaling efforts (Liu et al., 2019).",Theory Proposal,Theory Proposal
"We present the first joint UDS parser, whichlearns to extract both graph structures and attributesfrom natural language input.",Model Proposal,Model Proposal
"we present TABERT, a pretrained LM that jointlylearns representations for NL sentences and(semi-)structured tables.",Model Proposal,Model Proposal
we present a structured tuning framework to improve models using softened constraints only at training time,Model Optimization,Model Optimization
we show that the benefits from taskadaptive pretraining increase when we have additional unlabeled data from the task distribution that has been manually curated by task designers or annotators,Performance Evaluation,Performance Evaluation
we complement previous work targeting possession existence with two attributes: duration (for how long does the possession hold true?) and co-possession (are there other possessors possessing the possessee concurrently?),Theory Proposal,Theory Proposal
"We conduct experiments across several sample selection algorithms using existing gold data for user labels and show that both of our contributions significantly improve performance on the CoNLL2012 dataset (Pradhan et al., 2012).",Algorithm/Method Optimization,Algorithm/Method Optimization
"we do so by building on Time Biased Gain (TBG, Smucker and Clarke, 2012),an IR evaluation measure that models the expected number of relevant items a user can find in a ranked list given a time budget",Performance Evaluation,Performance Evaluation
"I propose that our focus shifts towards interpreting the language together with its userdependent, contextual personal and social aspects, in order to truly process the “natural” language of a user",Theory Proposal,Theory Proposal
we conduct a corpus analysis of papers published in recent ACL venues to determine whether the community is collectively forgetting about older papers as it experiences a period of rapid growth,Dataset Creation,Dataset Creation
"We then investigate what happens when the input is an original sentence in the source language and the model’s output is also biased to be original, a scenario never observed in training.",Theory Proposal,Theory Proposal
"we introduce a procedure for generating synthetic training examples by recombining real ones, such that (2a) is assigned non-negligible probability because it already appears in the training dataset",New Algorithm/ Method,New Algorithm/ Method
"We collect a high-quality annotated dataset
for coreference resolution and information
completion in multi-turn dialogues, which
might benefit future related research.",Dataset Creation,Dataset Creation
we explore acoustic-prosodic and linguistic indicators of information concealment by collecting a unique corpus of professionals practicing for oral exams while concealing information.,Dataset Creation,Dataset Creation
"we introduce a new dataset constructed
from Wikipedia and Wikidata - DocRED annotates both named entities and relations, and is the largest humanannotated dataset for document-level RE from
plain text",Dataset Creation,Dataset Creation
introduce a challenging dataset using this representation for the weather domain,Dataset Creation,Dataset Creation
"we compare the parsing performances between Abstract Meaning Representation (AMR) and Minimal Recursion Semantics (MRS), and provide an in-depth analysis of what factors contributed to the discrepancy in their parsing accuracy.",Theory Proposal,Theory Proposal
"we propose a new type of semantic representation of Construction Grammar
that combines constructions with the vector
representations used in Distributional Semantics.",New Algorithm/ Method,New Algorithm/ Method
"we describe the creation of a data set
that contains news articles and corresponding
comments from Croatian news outlet 24 sata.",Dataset Creation,Dataset Creation
"We propose a way to effectively
construct a huge amount of silver data for the con-text reconstruction task.",New Algorithm/ Method,New Algorithm/ Method
we propose a straightforward active learning strategies for both traditional and overnight data collection that significantly reduce data annotation requirements,New Algorithm/ Method,New Algorithm/ Method
We propose a reinforcement learning based framework for medical DS. Experiment results on our dataset show that our dialogue system is able to collect symptoms from patients via conversation and improve the accuracy for automatic diagnosis,New Algorithm/ Method,New Algorithm/ Method
We use a neural generative model for slot filling on the data without word-level annotations which has received less attention,Model Proposal,Model Proposal
"We conclude that scalar annotation protocols should beadopted in future NLI-style dataset creation, whichshould enable new work in modeling a richer spaceof interesting inferences",Model Proposal,Model Proposal
we introduce the task of automati-cally generating To-Do items from email contextand meta-data to assist users with following up ontheir promised actions (also referred to as commit-ments in this work).,New Algorithm/ Method,New Algorithm/ Method
we investigate different end-to-end models tolearn label distributions on crowd-sourced dataand capture inter-subjectivity across all annota-tions,Model Proposal,Model Proposal
we focus on the task of mapping from natural language utterances to SQL queries executable in a database. Most prior work in mapping from natural language to SQL queries train and test the system on a single database,New Algorithm/ Method,New Algorithm/ Method
"We collect TVQA+, a large-scale spatiotemporal video question answering dataset, which augments the original TVQA dataset with frame-level bounding box annotations",Dataset Creation,Dataset Creation
"An innovative semantic parsing framework
based on dual learning is introduced, which
can fully exploit data (labeled or unlabeled)
and incorporate various prior-knowledge as
feedback signals. We are the first to introduce dual learning in semantic parsing to the
best of our knowledge",New Algorithm/ Method,New Algorithm/ Method
"We aim to further leverage this promising
methodology into more sophisticated and critical neural models, i.e., neural machine translation (NMT) models, since NMT models recently
play one of the central roles in the NLP research
community",Algorithm/Method Optimization,Algorithm/Method Optimization
"develop an adaptive inference scheme
for NMT ensembles by extending Bayesian Interpolation (BI) (Allauzen and Riley, 2011) to
sequence-to-sequence models.",New Algorithm/ Method,New Algorithm/ Method
"we propose an alternative to the
self-attention layer to reduce the computational
burden of a Transformer. Our layer learns its optimal context size, resulting in a network where
each attention layer gathers information on their
own context.",Algorithm/Method Optimization,Algorithm/Method Optimization
"We build on a state-of-theart convolutional neural encoder-decoder model
and incorporate cross-sentence context from previous sentences using an auxiliary encoder.",Model Proposal,Model Proposal
"our new loss function effectively reduces
gender bias in the language models during training by equalizing the probabilities of male and
female words in the output;",Theory Proposal,Theory Proposal
"A semantically-based framework for mention identification and coreference resolution
as a layer of UCCA (§3). Reusing UCCA
units as mentions facilitates efficient and consistent multilayer annotation.",New Algorithm/ Method,New Algorithm/ Method
"we propose models which generate
more diverse and interesting outputs by 
training models to focus attention on important keyphrases of the story",Model Proposal,Model Proposal
"The approach adopted consists
of two key components: fine-tuning the BERT
language representation model (Devlin et al.,
2018) and the usage of external datasets during the training process",New Algorithm/ Method,New Algorithm/ Method
"By developing a generic approach for restricting the predictions of a seq2seq model to grammatically permissible continuations, we arrive at a widely applicable technique for speeding up semantic parsing",New Algorithm/ Method,New Algorithm/ Method
"Twenty teams participated, developing a range of neural network
models, including some that successfully incorporated external data to boost performance.",Model Proposal,Model Proposal
we aim to improve topic quality with LDA by increasing the importance of named entities in the mode,Model Optimization,Model Optimization
"we proposed Se-qVAT, a variant of VAT that can be used alongwith CRF.",New Algorithm/ Method,New Algorithm/ Method
We propose two end-to-end debiasing techniquesthat can be used when the existing bias patterns areidentified.,New Algorithm/ Method,New Algorithm/ Method
we explore multilingual transfer learning to de-tect multiple frames from just the news head-line in a genuinely low-resource context wherethere are few/no frame annotations in the tar-get language,Resources,Resources
"we propose amethod for using the interpretable output of theattention layers of a neural AES for source-basedessay writing, with the goal of extracting TCs.",New Algorithm/ Method,New Algorithm/ Method
we propose two additional mea-sures for robustness which quantify the changesin translation when perturbations are added to theinput.,Algorithm/Method Optimization,Algorithm/Method Optimization
"we introduce “entity triggers,” aneffective proxy of human explanations for fa-cilitating label-efficient learning of NER mod-els.",Model Optimization,Model Optimization
"We propose a neural architecture for NER tai-lored to these three experimental setups, based onthe popular BiLSTM-CRF architecture (Lampleet al., 2016).",New Algorithm/ Method,New Algorithm/ Method
"we present a model for handling lexicalized and non-lexicalized features jointly. We use a sequence-to-sequence architecture, with different parameter sharing strategies at the encoder and decoder sides for the different features.",Model Proposal,Model Proposal
We propose to tackle this problem by leveraging richer training signals that can guide our model for preserving input information.,Model Proposal,Model Proposal
"we propose to use the recent, highly successful self-supervised pre-trained language models, e.g. Devlin et al. (2019); Liu et al. (2019) for domain data selection.",Model Proposal,Model Proposal
"we examine how pre-trained language models generalize on the Winograd Schema Challenge (WSC). Named after Terry Winograd, the WSC, in its current form, was proposed by Levesque et al. (2012) as an alternative to the Turing Test.",Performance Evaluation,Performance Evaluation
"We introduce a
novel weakly supervised learning approach, learning with partial labels, that exploits the modular
structure to reduce the supervision effort.",New Algorithm/ Method,New Algorithm/ Method
"we propose a goal-directed endto-end deep reinforcement learning framework to
resolve coreference.Specifically, we leverage the neural architecture",New Algorithm/ Method,New Algorithm/ Method
"We design a model controlling specificity of generated questions, unlike prior work on QA generation",Model Proposal,Model Proposal
We describe a neural PCFG inducer which employs context embeddings in a normalizing flow model to extend PCFG induction to use semantic and morphological information,Theory Proposal,Theory Proposal
"We propose to model reviewer biases from their review texts and rating distributions, and learn a bias-aware opinion representation.",Model Proposal,Model Proposal
"we present MoNoise, an easy-touse normalization system, consisting of an online
demo as well a more elaborate command line interface.",New Algorithm/ Method,New Algorithm/ Method
"We present a prototype coaching system, Level-Up, that applies the method to English learners’ essays in order to assist them in
writing and reading",New Algorithm/ Method,New Algorithm/ Method
"We demonstrate how fine-tuning large pretrained language models, the latest breakthrough in NLP, enhance state of the art on few
of the abusive language datasets, and show
that the domain shift isn’t considerable when
applied to abusive language datasets.",Model Optimization,Model Optimization
"introduces a theoretical
model for explaining aggressive online
comments from a sociological perspective",Theory Proposal,Theory Proposal
"Demonstrating that standard debiasing approaches like those introduced in (Bolukbasi et al., 2016) actually worsen the bias
of downstream tasks by providing a denoised
channel for communicating demographic information.",Theory Proposal,Theory Proposal
"We devise a fully data-driven neural conversational model that leverages conversation history and topic information in the response generation process through a hierarchical joint attention mechanism; making the
dialogue more diverse and engaging.",Model Proposal,Model Proposal
we propose a new model calledScriptWriterto address theproblem of script generation/selection with the helpof a narrative,Model Proposal,Model Proposal
We propose learning contextualized representa-tions that leverage both free text and informationfrom knowledge bases.,Theory Proposal,Theory Proposal
we pro-pose a framework forcategory-specificattributevalue extraction that is both efficient and effective.,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose an architecture consisting of a candi-date generator and a list-wise ranker based onBERT.,New Algorithm/ Method,New Algorithm/ Method
We propose a concept normalization frame-work consisting of a candidate generator anda list-wise classifier.,New Algorithm/ Method,New Algorithm/ Method
"we therefore propose a neural framework, WMSEG, which uses memory networks to incorporate wordhood information with several popular encoder-decoder combinations for CWS.",New Algorithm/ Method,New Algorithm/ Method
"We propose Frugal Paradigm Completion, an approach that predicts all related forms in a morphological paradigm from as few manually provided forms as possible",New Algorithm/ Method,New Algorithm/ Method
"we show that competitive results on VisDial can indeed be achieved by replicating the top performing model for VQA (Yu et al., 2019b) – and effectively treating visual dialog as multiple rounds of question-answering, without taking history into account",Model Optimization,Model Optimization
"we propose a novel deep learning model for RE that uses the dependency trees to extract the syntax-based importance scores for the words, serving as a tree representation to introduce syntactic information into the models with greater generalization",Model Proposal,Model Proposal
We first propose a recurrent generative model that generates multiple keyphrases as delimiter-separated sequences. Generation diversity is further enhanced with two novel techniques by manipulating decoder hidden states,Model Proposal,Model Proposal
we suggest a new NLG task where a model is tasked with generating natural language statements that can be logically entailed by the facts in an open-domain semi-structured table.,New Algorithm/ Method,New Algorithm/ Method
"Our approach investigates a new direction for semantic parsing that models explaining a demonstration in a context, rather than mapping explanations to demonstrations.",New Algorithm/ Method,New Algorithm/ Method
"We introduce a new framework for incorporating first-order logic rules into neural network design in order to guide both training
and prediction.",New Algorithm/ Method,New Algorithm/ Method
"we use text simplification
methods to improve the understandability of clinical letters.",Performance Evaluation,Performance Evaluation
"we propose a novel attention-based graph decoder that walks an optimal path within a large commonsense KG (100K entities, 1.1M facts) to effectively prune unlikely candidate entities,",Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose Two novel methods to train NLI models that
are more robust to dataset-specific artifacts.",Model Proposal,Model Proposal
"We propose a novel multi-hop retrieval approach, which we believe is imperative for
truly solving the open-domain multi-hop QA
task.",New Algorithm/ Method,New Algorithm/ Method
"describes the methods developed by team TMRLeiden for the
2019 Social Media Mining for Health Applications (SMM4H) Shared Task.",New Algorithm/ Method,New Algorithm/ Method
presents an effort to build a general purpose AMR-annotated corpus for Brazilian Portuguese by translating and adapting AMR English guidelines.,Dataset Creation,Dataset Creation
"We therefore propose Natural-language Infer-ence over Label-specific Explanations (NILE)1,which we train and evaluate on English languageexamples",Model Proposal,Model Proposal
we address this shortcoming by in-troducing a novel debiasing method that improvesmodels’ performance on the out-of-distribution ex-amples while preserves the in-distribution accu-racy,Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose a novel multi-perspective cross-lingual neural framework forcode–text matching, inspired in part by a previ-ous model for monolingual text-to-text match-ing, to capture both global and local similari-ties",New Algorithm/ Method,New Algorithm/ Method
we propose a method that instead automatically learns howto weight training data through a data scorerthat is optimized to maximize performance onall test languages.,New Algorithm/ Method,New Algorithm/ Method
"We propose a novel methodthat takes the explicit ontology structure into ac-count, by amulti-level learning to rankapproachthat ranks the candidate types conditioned on thegiven entity mention.",New Algorithm/ Method,New Algorithm/ Method
we propose a novel iterative set expansion framework that leverages automatically generated class names to address the semantic drift issue,New Algorithm/ Method,New Algorithm/ Method
"we propose a method of “soft gazetteers” that incorporates ubiquitously available information from English knowledge bases, such as Wikipedia, into neural named entity recognition models through cross-lingual entity linking.",New Algorithm/ Method,New Algorithm/ Method
"we propose a joint neural framework, ONEIE, that aims to extract the globally optimal IE result as a graph from an input sentence",New Algorithm/ Method,New Algorithm/ Method
"We propose ESPRIT, a framework for commonsense reasoning about qualitative physics in natural language that generates interpretable descriptions of physical events",New Algorithm/ Method,New Algorithm/ Method
we propose to apply the VNMT framework to the state-of-the-art Transformer and introduce a more flexible approximate posterior based on normalizing flows.,Applications,Applications
"we reproduce a comparison of NMT and PBSMT in different data conditions, showing
that when following our best practices, NMT
outperforms PBSMT with as little as 100 000
words of parallel training data",Performance Evaluation,Performance Evaluation
"we propose and evaluate two strategies for automatically changing the gaps of a C-test
in order to reach a given target difficulty",Performance Evaluation,Performance Evaluation
"an approach determining the entire argument structure
based on just the relations between the four functional components of proposition across three heterogeneous corpora of which two are monological
and the other is dialogical",New Algorithm/ Method,New Algorithm/ Method
"We firstly propose to leverage both semantic and phonetic features of Chinese characters
in NLP tasks by introducing Pinyin Romanization and Wubi Input embeddings, which are easily accessible and effective in representing semantic and phonetic feature.",New Algorithm/ Method,New Algorithm/ Method
"We evaluate the proposed multiembedding scheme on Bakeoff2005 and CTB6
corpora.",Performance Evaluation,Performance Evaluation
"Conducting preliminaries experiments on
multi-label abusive language and hate speech
detection (including hate speech target, category, and level detection) in Indonesian Twitter using machine learning approaches.",Applications,Applications
"Comparing the efficacy of embedding based
debiasing techniques to manual word scrubbing techniques on both overall model performance and fairness.",Model Optimization,Model Optimization
the first study to introduce the shuffle languages to analyze the computational power of neural networks,Theory Proposal,Theory Proposal
"a metric definition, its validation with six real projects over the course of one year (2018.Q2 through 2019.Q1), as well as an extensible implementation1 and testing plan, which is described in “Metric Definition” below.",Theory Proposal,Theory Proposal
"We investigate the problem of choosing tree-bank embedding vectors for new, possibly out-of-domain, sentence",Theory Proposal,Theory Proposal
"Our evaluation demonstrates that Seq-VAT brings significant improvements in supervisedsettings, rather than marginal improvements re-ported from previous VAT-based approaches Clarket al..",Performance Evaluation,Performance Evaluation
we test rigorously the hypothesisof the utility of second-order features,Performance Evaluation,Performance Evaluation
We perform evaluation of the different strate-gies on the MWE-Aware English Dependency Cor-pus and treebanks for five additional languagesfrom the Universal Dependencies 2.2 corpus thathave frequent multi-word headless constructions,Performance Evaluation,Performance Evaluation
"We also show that neural representation sharingthrough MTL is an effective strategy, as it ac-counts for a large portion of our observed im-provements",Algorithm/Method Optimization,Algorithm/Method Optimization
"Finally, in our analysis we iden-tify general guidelines for strong cross-lingualembedding baselines, that extend to languagepairs that do not include English",Theory Proposal,Theory Proposal
"We evaluate the proposed method on the WMT2018 Parallel Corpus Filtering shared task, andon our own web-crawled Japanese-Chinese parallel corpus.",Performance Evaluation,Performance Evaluation
"we propose a more holistic analysis and evaluation setup for XSP. We propose to evaluate a semantic parsing system not only on evaluation data designed for XSP, but also on datasets that have only been studied in the SSP setting",Performance Evaluation,Performance Evaluation
We investigate the benefits of automatically learning related tasks to boost the performance of diacritic restoration,Performance Evaluation,Performance Evaluation
"We find that their improved accuracy does not actually emerge from proper visual grounding, but from regularization effects, where the model forgets the linguistic priors in the train set, thereby performing better on the test set.",Model Optimization,Model Optimization
"we advance the stateof-the-art on HTM by means of the design and evaluation of CluHTM, a novel nonprobabilistic hierarchical matrix factorization aimed at solving the specific issues of HTM",Model Proposal,Model Proposal
We propose two separate metrics to evaluate both the clustering of attested forms into paradigms and cells and the prediction of unseen inflected forms,New Algorithm/ Method,New Algorithm/ Method
a creation of a simple technique for integration of structured information into an ED system with graph embeddings,New Algorithm/ Method,New Algorithm/ Method
"The program is
used to generate a segmentation of a sentence
corpus, whose consistency is calculated and
compared with the current morpheme-based
segmentation of the same corpus",New Algorithm/ Method,New Algorithm/ Method
"As a benchmark model for scenario detection,
we present a two-stage model that combines
established methods from topic segmentation
and text classification",Model Proposal,Model Proposal
"we extract the task-specific features from the optimal layer of BERT for coreference resolution where we observe pronouns
strongly attend to the corresponding candidate entities.",New Algorithm/ Method,New Algorithm/ Method
"We demonstrate the effectiveness of NILEcompared to existing systems, in terms of la-bel and explanation accuracy",Model Optimization,Model Optimization
"we consider attribute value extrac-tion for real-world hierarchical taxonomies withthousands of product categories, where directly applying previous approaches presents limitations.",Theory Proposal,Theory Proposal
we experiment with neural networks to predict the focus of negation. Our main novelty is leveraging a scope detector to introduce the scope of negation as an additional input to the network,Algorithm/Method Optimization,Algorithm/Method Optimization
"We first investigate how end-toend neural sequence models (with pre-trained language model representations) perform on document-level role filler extraction, as well as how the length of context captured affects the models’ performance",Performance Evaluation,Performance Evaluation
"Our paper presents a concrete formalization of the PDP. Then, as a baseline for future work, we introduce a heuristic benchmark system.",New Algorithm/ Method,New Algorithm/ Method
"we propose to search for Hardware-Aware Transformers (HAT) by directly involving the latency feedback into the design loop. In this way, we do not need FLOPs as the latency proxy and can search specialized models for various hardware",Algorithm/Method Optimization,Algorithm/Method Optimization
"we deviate from learning a linear projection matrix (i.e., a parametric model) and propose a non-parametric model which translates vectors by estimating instance-specific geometric translations.",Model Proposal,Model Proposal
"The trained utterance rewriter, when integrated into two real-life online chatbots, is
shown to bring significant improvement over
the original system.",Algorithm/Method Optimization,Algorithm/Method Optimization
"to the best of our knowledge, we conduct the first systematic exploration on learning general-purpose binarized (memory-efficient)
sentence representations, and four different strategies are proposed;",New Algorithm/ Method,New Algorithm/ Method
"we study one type of domain adaptation for NER, denoted here heterogeneous tagsets.",Theory Proposal,Theory Proposal
"We adapt sequentially across two SpanishEnglish and three English-German tasks, comparing unregularized fine-tuning, L2 and Elastic Weight Consolidation",Performance Evaluation,Performance Evaluation
"we
focus on zero-shot generalization: training parsers
on a single treebank and evaluating
on a range of broad-coverage, out-of-domain treebanks , Genia the English Web Treebank",New Algorithm/ Method,New Algorithm/ Method
We demonstrate that automatic domain adaptation performs better at predicting financial outcomes than previous work based on manual domain adaptation,Performance Evaluation,Performance Evaluation
describe our work towards an unsupervised approach to classify documents into a set of categories described by a short sentence,New Algorithm/ Method,New Algorithm/ Method
"to study the
impact of both verbal and vocal features on financial markets, specifically, stock volatility.",Theory Proposal,Theory Proposal
we analyze gender stereotypes directly from writings under different metrics.,Theory Proposal,Theory Proposal
"This research
work proposes an improved framework for
social media feed pre-processing that
leverages on the combination of integrated
local knowledge bases and adapted Lesk
algorithm to facilitate pre-processing of
social media feeds",Algorithm/Method Optimization,Algorithm/Method Optimization
We have proposed an annotation scheme for EUs and its relations for ChangeMyView;,Theory Proposal,Theory Proposal
"describes the MARDY tool, an interactive annotation environment for political claims analysis in computational political science (see Pado et al. ´ (2019) for a task analysis and initial modeling results)",New Algorithm/ Method,New Algorithm/ Method
"A discussion of multilayer design principles
informed by existing semantically annotated
corpora",Theory Proposal,Theory Proposal
"diversification of the research on
hate speech by provision of a new dataset of
hate speech in another language than English,
namely Portuguese",Theory Proposal,Theory Proposal
"we want to show how to deal with
this problem for one of these languages: Polish, without having a large dedicated data set
and using solutions prepared for other NLP tasks",Theory Proposal,Theory Proposal
"a novel two-step procedure for eliciting
discourse connective insertions from na¨ıve
workers;",New Algorithm/ Method,New Algorithm/ Method
"Our focus is on
building an annotation schema which can help
writers recognise appropriate intentions in writing their Related Work section, and indicate when
these are missing.",New Algorithm/ Method,New Algorithm/ Method
"focused on
building an implementation using AllenNLP
with out-of-the-box methods to facilitate easy
operation and reuse",New Algorithm/ Method,New Algorithm/ Method
the identification of the schemes for which available tools are readily available for use;,Theory Proposal,Theory Proposal
we propose a novel simple abstract feature representation which is surprisingly effective,Theory Proposal,Theory Proposal
"We proposeUncertain Natural Language Infer-ence(UNLI), a refinement of NLI that capturesmore subtle distinctions in meaning by shiftingaway from categorical labels to the direct predic-tion of human subjective probability assessments",Theory Proposal,Theory Proposal
"We propose NILE, an NLI system which gen-erates and processes label-specific explana-tions to infer the task label, naturally provid-ing explanations for its decisions",New Algorithm/ Method,New Algorithm/ Method
we investigate the utilization ofnarratives in a special case of text generation –movie script generation.,Theory Proposal,Theory Proposal
we aim to learn associations be-tween visual attributes of fonts and the verbalcontext of the texts they are typically appliedto.,New Algorithm/ Method,New Algorithm/ Method
"We design a novel video question answering framework, Spatio-Temporal Answerer with Grounded Evidence (STAGE), to jointly localize moments, ground objects, and answer questions",New Algorithm/ Method,New Algorithm/ Method
"we study a relatively new setting in which we predict relations between entities based on the global co-occurrence statistics aggregated from a text corpus, and focus on medical relations and clinical texts in Electronic Medical Records (EMRs).",Theory Proposal,Theory Proposal
we propose the task of learning interpretable relationships from open domain facts to enrich and refine concept graphs,Theory Proposal,Theory Proposal
"we present BART, which pre-trains a model combining Bidirectional and Auto-Regressive Transformers. BART is a denoising autoencoder built with a sequence-to-sequence model that is applicable to a very wide range of end tasks",Theory Proposal,Theory Proposal
we investigate this capability of PLMs in the context of (1) negation and what we call (2) mispriming.,Theory Proposal,Theory Proposal
"we reflect on the progress of Automated Writing Evaluation (AWE), using Ellis Page’s seminal 1966 paper to frame the presentation",Theory Proposal,Theory Proposal
"We then investigate diagonal alignments with auto-encoders over real languages and randomly generated sequences, finding even randomly generated sequences as parents yield noticeable but smaller gains.",Theory Proposal,Theory Proposal
"we study the temporal aspects of text data, focusing on the information extraction task of named entity recognition in the Twitter domain.",Theory Proposal,Theory Proposal
"We further propose a novel validity reward focusing on the surface and semantics of logical forms, which is a feedback signal indicating whether the generated logical form is well-formed. It involves the prior- knowledge about structures of logical forms predefined in a domain.15:15",New Algorithm/ Method,New Algorithm/ Method
"We propose a GNN
architecture based on extending the self-attention
mechanism of the Transformer (Vaswani et al.,
2017) to make use of relations between input elements.",New Algorithm/ Method,New Algorithm/ Method
"we propose to approximate the
content information by bag-of-words (BoW) features, where we focus on style-neutral, nonstopwords. Along with traditional style-oriented
auxiliary losses, our BoW multi-task loss and
BoW adversarial loss enable better disentanglement of the style and content spaces",Algorithm/Method Optimization,Algorithm/Method Optimization
"We evaluate (i) by testing for
noise reduction in a control condition, (ii) on
large and controlled artificial data and (iii) on
a manually annotated LSC testset.",Performance Evaluation,Performance Evaluation
"In this paper, we fill a gap in the literature by proposing a thorough evaluation of Pereira et al. (2018), using previously untried evaluation metrics.",Theory Proposal,Theory Proposal
"The goal of this work is to study the use of deep neural models i.e., contextualized word represen-tation model BERT (Devlin et al., 2018) and Gated
Recurrent Units (GRU) (Cho et al., 2014) with
an attention mechanism, paired with word2vec
word embeddings and contextualized ELMo embeddings (Peters et al., 2018).",Applications,Applications
"we introduce an open-source
toolkit, NeuralClassifier4
, a neural hierarchical
multi-label text classification toolkit based on
PyTorch. It is designed for solving the hierarchical multi-label text classification problem
with effective and efficient neural models",Model Optimization,Model Optimization
"we introduce Parallax1
, a tool explicitly
designed for this task. Parallax allows the user
to use both state-of-the-art embedding analysis methods (PCA and t-SNE) and a simple yet
effective task-oriented approach where users
can explicitly define the axes of the projection
through algebraic formulae",New Algorithm/ Method,New Algorithm/ Method
"Conduct an empirical study to deepen our understanding of current datasets that focus on
different types of abusive language, which
are sometimes overlapping (racism, sexism,
hate speech, offensive language and personal
attacks). Show that our stacked Bidirectional
Long Short Term Memory architecture with
contextual attention is comparable to or out-performs state of the art approaches on all the
existing datasets.",Theory Proposal,Theory Proposal
"we investigate the
performance of a multi-dimension Capsule network as opposed to using a fixed dimension Capsule network for capturing a sentence representation and we shall discuss how well it captures
features necessary for classification of such sentences",Performance Evaluation,Performance Evaluation
"we manually reannotated the Turkish PUD treebank for consistency in the annotation. As we do not fully agree
with the annotation scheme of previous Turkish
treebanks, we had incorporated a more strict view
of the SD scheme and tried to balance the six directives of Manning’s Law",Model Optimization,Model Optimization
"Instead of only training models for each treebank separately, we use a two-stage training
process to incorporate cross-linguistic information present in other treebanks, training
multilingually over all treebanks in the first
stage and then monolingually using saved
multilingual weights in the second stage",Model Optimization,Model Optimization
we propose a hierarchical multi-scale language model in which short time-scale dependencies are encoded in the hidden state of a lower-level recurrent neural network while longer time-scale dependencies are encoded in the dynamic of the lower-level network by having a meta-learner update the weights of the lower-level neural network in an online meta-learning fashion,Model Proposal,Model Proposal
"we focus on the Multi-Genre Natural Language Inference (MNLI)dataset (Williams et al., 2018) in English, and ontwo specific kinds of dataset bias: Contradiction Word Bias (CWB) and Word Overlapping Bias (WOB)",Dataset Creation,Dataset Creation
"We propose a new neural structurefor this and name the resulting implementation s-QUASE, where “s” stands for “single;” in con-trast, we name the straightforward implementationmentioned above p-QUASEfor “paired.” Resultsshow that s-QUASEoutperforms p-QUASEsignif-icantly on3single-sentence tasks—SRL, NER, andsemantic dependency parsing (SDP)—indicatingthe importance of this distinction",New Algorithm/ Method,New Algorithm/ Method
"We evaluate our models on challenging bench-marks in textual entailment and fact verification, in-cluding HANS (Heuristic Analysis for NLI Systems)(McCoy et al., 2019b), hard NLI sets (Gururanganet al., 2018) of Stanford Natural Language Inference(SNLI) (Bowman et al., 2015) and MultiNLI (MNLI)(Williams et al., 2018), and FEVER Symmetric testset (Schuster et al., 2019).",Performance Evaluation,Performance Evaluation
"we attempt to explore the possibility of gaining plausi-ble judgments of how well an NLP model canperform under an experimental setting,with-out actually training or testing the model",Performance Evaluation,Performance Evaluation
we propose a probabilistic model whose loss function is derived from external su-pervision as regularization for the context gates.,Model Proposal,Model Proposal
"we study the problem in a real-world scenario where we crawl a large Japanese-Chinese parallel corpus from various websites and build open-domain machine translation systems between Japanese and Chinese, by filtering theweb crawled parallel corpus",New Algorithm/ Method,New Algorithm/ Method
"we focus on one class of meth-ods, subword regularization, which addresses NMT robustness without introducing any changes tothe architectures or to the training regime, solelythrough dynamic segmentation of input into sub-words (Kudo, 2018; Provilkov et al., 2019).",Theory Proposal,Theory Proposal
"we ask the question: “is it possi-ble tolearnan optimal strategy to automaticallybalance the usage of data in multilingual modeltraining?” To this effect, we propose a method that learns a language scorer that can be used through-out training to improve the model performanceonalllanguages.",New Algorithm/ Method,New Algorithm/ Method
"we focus on decoding informally romanized texts back into their original scripts. We view the task as a decipherment problem and propose an unsupervised approach, which allows us to save annotation effort since parallel data for informal transliteration does not occur naturally.",Model Proposal,Model Proposal
"we propose a neural model named TWASP for joint CWS and POS tagging following the character-based sequence labeling paradigm, where a two-way attention mechanism is used to incorporate both context feature and their corresponding syntactic knowledge for each input character.",Model Proposal,Model Proposal
"we improve the performance of diacritic restoration by building a multitask learning model (i.e. joint modeling). Multitask learning refers to models that learn more than one task at the same time, and has recently been shown to provide good solutions for a number of NLP tasks",Model Optimization,Model Optimization
we investigate how to utilize visual content for disambiguation and promoting latent space alignment in unsupervised MMT. Our model employs multimodal back-translation and features pseudo visual pivoting in which we learn a shared multilingual visual-semantic embedding space and incorporate visuallypivoted captioning as additional weak supervision,Applications,Applications
"we create PIXELHELP, a corpus that pairs English instructions with actions performed by people on a mobile UI emulator. To scale training, we decouple the language and action data by (a) annotating action phrase spans in HowTo instructions and (b) synthesizing grounded descriptions of actions for mobile user interfaces",Dataset Creation,Dataset Creation
"we propose a novel angle to further improve this representation learning, i.e., feature projection. This method projects existing features into the orthogonal space of the common features. The resulting projection is thus perpendicular to the common features and more discriminative for classification",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose a solution for “zero-shot” open-domain relation extraction from webpages with a previously unseen template, including from websites with little overlap with existing sources of knowledge for distant supervision and websites in entirely new subject verticals",Theory Proposal,Theory Proposal
we explore the sources of multilingual transfer in polyglot NER models and examine the weight structure of polyglot models compared to their monolingual counterparts. We find that polyglot models efficiently share many parameters across languages and that fine-tuning may utilize a large number of those parameters,Performance Evaluation,Performance Evaluation
"we approach event understanding as a form of linking, more akin to coreference resolution than sentence-level SRL. An event trigger evokes a set of roles regarded as latent arguments, with these implicit arguments then potentially linked to explicit mentions in the text",Applications,Applications
"we aim at adapting monolingual models to code-switched text in various tasks. Specifically, we transfer English knowledge from a pre-trained ELMo model to different code-switched language pairs (i.e., NepaliEnglish, Spanish-English, and Hindi-English) using the task of language identification",Model Optimization,Model Optimization
"We propose an unsupervised approach for sarcasm generation based on a non-sarcastic input sentence. Our method employs a retrieve-andedit framework to instantiate two major characteristics of sarcasm: reversal of valence and semantic incongruity with the context, which could include shared commonsense or world knowledge between the speaker and the listener",Algorithm/Method Optimization,Algorithm/Method Optimization
"We also introduce a new dataset (ST A C KEX) that expands beyond the only existing genre (i.e., academic writing) in keyphrase generation tasks.",Dataset Creation,Dataset Creation
We further propose two evaluation metrics tailored towards the variable-number generation.,New Algorithm/ Method,New Algorithm/ Method
We propose a novel neural CRF alignment model which not only leverages the sequential nature of sentences in parallel documents but also utilizes a neural sentence pair model to capture semantic similarity. Experiments demonstrate that our proposed approach outperforms all the previous work on monolingual sentence alignment task by more than 5 points in F1.,Model Proposal,Model Proposal
"we propose an iterative, editbased unsupervised sentence simplification approach, motivated by the shortcomings of existing work. We first design a scoring function that measures the quality of a candidate sentence based on the key characteristics of the simplification task, namely, fluency, simplicity, and meaning preservation.",New Algorithm/ Method,New Algorithm/ Method
"we present a novel approach, Conditional Masked Language Modeling (C-MLM), to enable the finetuning of BERT on target generation tasks. The finetuned BERT (teacher) is exploited as extra supervision to improve conventional Seq2Seq models (student) for better text generation performance.",Model Optimization,Model Optimization
"We propose BLEURT, a learned evaluation metric based on BERT that can model human judgments with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize",Model Proposal,Model Proposal
we examine female first author percentages and the citations to their papers in Natural Language Processing (1965 to 2019). We determine aggregatelevel statistics using an existing manually curated author–gender list as well as first names strongly associated with a gender,Theory Proposal,Theory Proposal
"we make two key contributions. First, we argue that existing approaches do not adequately define comprehension; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehension—a TEMPLATE OF UNDERSTANDING—for a widely useful class of texts, namely short narratives",Theory Proposal,Theory Proposal
"We analyze the age of outgoing citations in papers published at selected ACL venues between 2010 and 2019, finding that there is indeed a tendency for recent papers to cite more recent work, but the rate at which papers older than 15 years are cited has remained relatively stable.",Theory Proposal,Theory Proposal
"We present the first statistical schwa deletion classifier for Hindi, which relies solely on the orthography as the input and outperforms previous approaches. We trained our model on a newly-compiled pronunciation lexicon extracted from various online dictionaries",Model Proposal,Model Proposal
We present Neural Machine Translation (NMT) training using document-level metrics with batch-level documents.,Model Proposal,Model Proposal
"We propose two methods to train translationese classifiers using only monolingual text, coupled with synthetic text produced by machine translation.Using only original→translationese and translationese→original training pairs, we apply techniques from zero-shot multilingual MT to enable original→original translation",New Algorithm/ Method,New Algorithm/ Method
"we propose treating gender debiasing as a domain adaptation problem, since NMT models can very quickly adapt to a new domain (Freitag and Al-Onaizan, 2016). To the best of our knowledge this work is the first to attempt NMT bias reduction by fine-tuning, rather than retraining",Model Proposal,Model Proposal
This paper presents a dynamic data selection method to multi-domain NMT. Things we do differently from previous work in mixing data are the choice of instance-level features and the employment of a multi-domain curriculum that is additionally able to denoise.,Algorithm/Method Optimization,Algorithm/Method Optimization
"we take this direction to an extreme by developing a variant of MHA without any learned parameters (Section 3). Concretely,we replace each attention head with a “hard-coded” version, which is simply a standard normal distribution centered around a particular position in the sequence (Figure 1).1",Resources,Resources
"we aim at making agents communicate with humans in natural language. Our starting point is a language model that has been trained on generic, not task-specific language data.",Model Proposal,Model Proposal
"we learn representations directly based on the relevance score inspired by the ideas from IR models. In contrast to the attention mechanism and Transformer models, we claim that the relevance patterns are as important. With proper alignment of the representation spaces of different input modalities, matching can be applied to those spaces.",Theory Proposal,Theory Proposal
"we propose GROLLA – a multitask evaluation framework for Grounded Language Learning with Attributes that expands a goal-oriented evaluation – based on the standard final task measure, with two auxiliary tasks: 1) Object attribute prediction (AP), and 2) Zero-shot evaluation (ZS).",New Algorithm/ Method,New Algorithm/ Method
"we try to leverage annotated training data from other domains. Motivated by the hypothesis that events, despite being domain/ task-specific, often occur in similar contextual patterns, we try to inject lexical domain-invariance into supervised models, improving generalization, while not overpredicting events",Theory Proposal,Theory Proposal
This work proposes an augmented pre-training for language models to improve their understanding of several important temporal phenomena. We address two kinds of reporting biases by effectively acquiring weak supervision from free-form text and utilizing it to learn multiple temporal dimensions jointly,Algorithm/Method Optimization,Algorithm/Method Optimization
"we present a unified framework, called RAT-SQL,1 for encoding relational structure in the database schema and a given question. It uses relation-aware self-attention to combine global reasoning over the schema entities and question words with structured reasoning over predefined schema relations.",New Algorithm/ Method,New Algorithm/ Method
"One of the challenges we face is to provide information on visual cues to the BERT model. We overcome this challenge by extracting densecap captions(densecaps) (Johnson et al., 2016) to provide textual information about the image objects, their properties, and interactions. This is motivated by the approaches of Visual Question Answering (VQA)",Model Optimization,Model Optimization
"we introduce a novel Information-theoretic Disentangled Embedding Learning method (IDEL) for text, based on guidance from information theory. Inspired by Variation of Information (VI), we introduce a novel information theoretic objective to measure how well the learned representations are disentangled.",New Algorithm/ Method,New Algorithm/ Method
"we investigate a simple question: can we use short-range attention for the majority of layers in the Transformer and recover the same performance? The hypothesis is that this should be possible, because many steps of reasoning will only involve short-range correlations, i.e. to piece characters together to form words or phrases. We find indeed it is possible.",Theory Proposal,Theory Proposal
"we propose to use minimal existing supervision for learning a commonsense-aware representation. Specifically, we provide the model with a supervision level identical to the test time of the Winograd challenge. For that, we introduce a self-supervised pre-training task, which only requires pair of sentences that differ in as few as one word (namely, “trigger” words).",Model Optimization,Model Optimization
"In this paper, we introduce SCIREX, a new comprehensive dataset for information extraction from scientific articles. Our dataset focuses on the task of identifying the main results of a scientific article as a tuple (Dataset, Metric, Task, Method) from raw text. It consists of three major subtasks, identifying individual entities, their document level relationships, and predicting their saliency in the document (i.e., entities that take part in the results of the article and are not merely, for example, mentioned in Related Work).",Dataset Creation,DataSet Creation
we present a simple URE approach relying only on entity types that can obtain improved performance compared to current methods,Algorithm/Method Optimization,Algorithm/Method Optimization
We address this issue by extending the recurrent units with multiple blocks along with a trainable routing network. T,Performance Evaluation,Performance Evaluation
