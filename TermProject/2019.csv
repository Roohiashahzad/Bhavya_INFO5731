Contribution,Annotation 1,Annotation 2
"We introduce in this paper a novel method, that
we call Multi-Task Supervised Pre-training and Adaptation (MuTSPad)",New Algorithm/ Method,New Algorithm/ Method
"we pro-pose to build multi-task datasets for the News and
Tweets domains, by unifying the aforementioned
task-independent datasets.",Dataset Creation,Dataset Creation
"Hence our model can grasp
useful word-level semantic information and al-leviate the interference of segmentation error
cascading.",Model Optimization,Model Optimization
"The above operations provide a
wealth of resources to allow the model to in-
fer word-level deep characteristics, rather than
bluntly impose segmentation information.",Resources,Resources
"For document
level, we reused last year’s English-French data
for training and validation, but introduced a new
test set from the same corpus",Performance Evaluation,Performance Evaluation
"For QE as a metric we ran the evaluation jointly with the WMT19 metrics task, which meant applying the QE systems to news translation submissions and evaluating them against the human judgments collected this year",Performance Evaluation,Performance Evaluation
fair assessment of the progress in APE technology and for tests in more challenging conditions,Performance Evaluation,Performance Evaluation
"reusing the same test English-German set used last year, the evaluation framework allows us for a direct comparison with the last year’s outcomes at least on one language",Performance Evaluation,Performance Evaluation
"construction of training data and the official test sets, including statistics and an evalua- 31 tion of the quality of the test sets",Dataset Creation,Dataset Creation
a description of the three baselines that we developed for comparison,Theory Proposal,Theory Proposal
"an overview of the task, presents the results for the participating systems and provides analysis on additional subset sizes and the average sentence length of sub-selected data.",Performance Evaluation,Performance Evaluation
We obtain new results using referential translation machines with increased number of learning models in the set of results that are stacked to obtain a better mixture of experts prediction,Theory Proposal,Theory Proposal
We extend OpenKiwi with a Transformer predictor-estimator model,Model Optimization,Model Optimization
"We propose new ensembling techniques for combining word-level and sentence-level predictions, which outperform previously used stacking approaches",Model Optimization,Model Optimization
"We apply transfer learning techniques, finetuning BERT (Devlin et al., 2018) and XLM (Lample and Conneau, 2019) models in a predictor-estimator architecture",Applications,Applications
We build upon our BERT-based predictorestimator model to obtain document-level annotation and MQM predictions via a simple wordto-annotation conversion scheme,Model Optimization,Model Optimization
we propose a “bilingual” BERT using multi-task learning for translation quality estimation (called the QE BERT).,New Algorithm/ Method,New Algorithm/ Method
"we introduce our base model, which is a modified version of phrase-level Shef-bRNN (Ive et al., 2018), and further develop it by using different methods of extracting features from the input alongside the bi-RNN features",Model Optimization,Model Optimization
"we present two different approaches for the sentence-level QE task, which employ bi-directional translation knowledge and large-scale monolingual knowledge to the QE task, respectively",Theory Proposal,Theory Proposal
a simple ensemble of them can help to achieve better quality estimation performance in the sentence-level QE task,Performance Evaluation,Performance Evaluation
"we introduce a light-weight neural method with pre-trained embeddings, that means it does not require any pre-training",New Algorithm/ Method,New Algorithm/ Method
"to predict the required post-editing cost, measured in HTER",Performance Evaluation,Performance Evaluation
to rank all sentence pairs in descending translation quality,Performance Evaluation,Performance Evaluation
we propose a multisource APE model by extending Transformer to contain a joint multi-source encoder and a decoder that involves a multi-source attention layer to combine the outputs of the encoder.,New Algorithm/ Method,New Algorithm/ Method
"We also introduce the conservativeness penalty, a simple yet effective mechanism that controls the freedom of our APE in modifying the given MT output",New Algorithm/ Method,New Algorithm/ Method
we present a multi-source neural APE architecture model called transference,New Algorithm/ Method,New Algorithm/ Method
we explore the effect of adding tokens that identify partitions in the training data which may be relevant to guide the behaviour of the NPE system,Applications,Applications
"In order to tackle the over-correction problem and to induce a post-editing strategy that resembles the work of a human post-editor, we add a special token to the beginning of both the source text and the MT output indicating the amount of required post-editing",Performance Evaluation,Performance Evaluation
we re-implement a multi-source transformer model for the task,Model Optimization,Model Optimization
we designed a data preparation strategy for domainspecific translation systems to enrich data with terminology information without affecting the model architecture,Model Optimization,Model Optimization
we present an approach which aims at increasing the training corpus by mining similar in domain (Bio Med) sentences from out of domain data,Theory Proposal,Theory Proposal
"We have developed NMT system for English-French language pair, for translation in both directions",Theory Proposal,Theory Proposal
we present Huawei’s practices on adapting our NMT systems from general-domain to in-domain,New Algorithm/ Method,Model Proposal
"We apply transfer learning iteratively on datasets from different domains, obtaining strong models that cover two domains for both directions of the English-German language pair, and three domains for both directions of EnglishSpanish.",Applications,Applications
We therefore investigate applying Bayesian Interpolation for language-model based multi-domain ensemble weighting,Applications,Applications
"For that matter, we developed a machine translation (MT) system based on neural machine translation (NMT), using OpenNMT-py",New Algorithm/ Method,New Algorithm/ Method
This paper introduces a novel approach to translation modeling that is currently being developed,Model Proposal,Model Proposal
in this article we aimed to determine whether the neural or the statistical approach is a better one to solve the given problem.,Theory Proposal,Theory Proposal
We first briefly introduce the phenomenon of intercomprehension between Slavic languages and our idea how to take advantage of it for machine translation purposes,New Algorithm/ Method,Theory Proposal
The next section spreads out our plans on Czech-Polish translation by exploring the similarities and differences between the two languages,Theory Proposal,Theory Proposal
"The task focuses on improving machine translation results for three language pairs Czech-Polish
(Slavic languages), Hindi-Nepali (Indo-Aryan languages) and Spanish-Portuguese (Romance languages).",Model Optimization,Model Optimization
"To examine the efficiency of our NMT systems, the predicted translations exposed to automatic evaluation using the BLEU score",Performance Evaluation,Performance Evaluation
"For both translation directions, we trained supervised neural MT (NMT) and statistical MT (SMT) systems, and combined them through n-best list reranking using different informative features as proposed by Marie and Fujita (2018a)",Model Optimization,Model Optimization
"Keeping in view the recent results obtained in MT developments, we experimented with both PBSMT as well as NMT models and evaluated how different models perform in comparison to each other",Performance Evaluation,Performance Evaluation
we describe the UDS-DFKI system to the WMT 2019 Similar Language Translation task.,Theory Proposal,Theory Proposal
we assume that proper subword segmentation will be beneficial for neural machine translation (NMT) performance but we aim at consistent segmentation across both related languages,Performance Evaluation,Performance Evaluation
"We participated only in the Sinhala-English track, basing our system on that of JunczysDowmunt (2018) but extensively modified for the 2019 low-resource scenario",Resources,Resources
"we describe the 4 systems we submitted, which have three main components: pre-filtering rules, sentence pair scoring, and reranking to improve vocabulary coverage",Theory Proposal,Theory Proposal
"In our submission for this shared task, we use of multilingual sentence embeddings obtained from LASER2 which uses an encoder-decoder architecture to train a multilingual sentence representation model using a relatively small parallel corpus.",Resources,Resources
"we include a text quality metric in the subcorpus-building process, rather than combining it afterward.",Resources,Resources
describes the participation of Webinterpret in the shared task on parallel corpus filtering at the Fourth Conference on Machine Translation,Theory Proposal,Theory Proposal
"We present a method based on projecting word embeddings learned from a monolingual corpus in a highresource language, to the target low-resource language through whatever parallel text is available",New Algorithm/ Method,New Algorithm/ Method
we introduce a filtering method for noisy parallel corpora based mainly on generating hypotheses for each sentence pair from noisy data and scoring based on hypothesis and target sentence similarity,New Algorithm/ Method,New Algorithm/ Method
The aim of this shared task is to extract two smaller sets of high-quality parallel sentences from a very noisy parallel corpus,Dataset Creation,Dataset Creation
This methodology allowed us to build a simple and reliable system that is easily adaptable to other language pairs.,Model Proposal,Model Proposal
"In order to gain further insight into the performance of individual MT systems, we organized a call for dedicated “test suites”, each focussing on some particular aspect of translation quality",Performance Evaluation,Performance Evaluation
"QE developers were invited to perform the same scoring as standard metrics participants, with the exception that they refrain from using a reference translation in production of their scores. We then evaluate the QE submissions in exactly the same way as regular metrics are evaluated",Performance Evaluation,Performance Evaluation
"The goal of this shared task is to provide a testbed for improving MT models’ robustness to orthographic variations, grammatical errors, and other linguistic phenomena common in usergenerated content, via better modelling, training, adaptation techniques, or leveraging monolingual training data",Model Optimization,Model Optimization
we investigated character-based tokenisation vs. sub-word segmentation of Chinese text,Algorithm/Method Optimization,Algorithm/Method Optimization
"introduce the method of data filtering, mainly in the application of language model and describe the techniques on transformer architecture and show the conducted experiments in detail of all directions, including data preprocessing,
model architecture, back-translation and knowledge distillation",New Algorithm/ Method,New Algorithm/ Method
upperbounds on the translation performance using lowercased coverage to identify which models used data in addition to the parallel corpus,Model Optimization,Model Optimization
"we introduced two new translation directions involving two European languages, namely French and German",New Algorithm/ Method,New Algorithm/ Method
examine transfer learning for the Kazakh–English language pair using additional parallel data from Turkish–English.,Performance Evaluation,Performance Evaluation
We choose news translation task and focus on KazakhEnglish (and vice versa) language pair,Resources,Resources
Lingua Custodia’s submission to the WMT’19 news shared task for German-to-French on the topic of the EU elections,Resources,Resources
a self-attention model based on the decoder part of the Transformer architecture was trained on the two pseudoparallel corpora,Model Proposal,Model Proposal
"We focused on the new Germanto-French language direction, and mostly used current standard approaches to develop a Neural Machine Translation system",Theory Proposal,Theory Proposal
"we describe all the systems for Kazakh↔English, Gujarati↔English, Chinese↔English, and English→Finnish, that we developed and submitted for WMT 2019 under the team name “NICT.",Theory Proposal,Theory Proposal
we propose a novel augmentation method Cycle Translation and a data mixture strategy Big/Small parallel construction to entirely exploit the synthetic corpus,New Algorithm/ Method,New Algorithm/ Method
"Our system is based on the self-attentional Transformer networks, into which we integrated the most recent effective strategies from academic research (e.g., BPE, back translation, multi-features data selection, data augmentation, greedy model ensemble, reranking, ConMBR system combination, and postprocessing)",Model Optimization,Model Optimization
"describes the systems and experiments conducted to participate in the news translation tasks of WMT 2019 for Gujarati– English (gu–en, low-resourced language pair) and German–English (de–en, document-level evaluation).",Theory Proposal,Theory Proposal
"Our experiments show that Multilingual Neural Machine Translation leveraging parallel data from related language pairs helps in significant BLEU improvements upto 11.5, for low resource language pairs like Gujarati-English",Performance Evaluation,Performance Evaluation
We also proposed our own model architectures and applied them in the tasks.,Applications,Applications
"we refine our approach to training popular neural machine translation toolkits, experiment with a new domain adaptation technique and again measure improvements in performance on the Russian–English language pair",Model Optimization,Model Optimization
"We conduct an in-depth evaluation of the translation performance of different models, highlighting the trade-offs between methods of sharing decoder parameters",Performance Evaluation,Performance Evaluation
"In this edition, we have submitted systems for the German ↔ English and German ↔ French language pairs, participating in both directions of each pair",Theory Proposal,Theory Proposal
Our main focus is document-level neural machine translation with deep transformer models.,Model Proposal,Model Proposal
we describe our approach to low-resource NMT,Theory Proposal,Theory Proposal
This paper describes our submitted systems with embeddings pre-trained on monolingual corpora,Theory Proposal,New Algorithm/ Method
"We proposed four novel Deep-Transformer architectures based on (Wang et al., 2019) as our baseline, which outperformed the standard Transformer-Big significantly in terms of both translation quality and convergence speed.",Model Proposal,Model Proposal
Our submission is a multi-source NMT system taking both the original Kazakh sentence and its Russian translation as input for translating into English,Model Proposal,Model Proposal
"the systems we implement for the German-Czech language pair are built based on the previously proposed unsupervised MT systems, with some adaptations made to accommodate the morphologically rich characteristics of German and Czech",Algorithm/Method Optimization,Algorithm/Method Optimization
We created a News transalated Shared task system to to translate news text from Lithuanian to English.,Theory Proposal,Theory Proposal
We submitted systems for both directions of the EnglishGerman language pair,Theory Proposal,Theory Proposal
This paper describes the unsupervised neural (NMT) and statistical machine translation (SMT) systems built for the participation of the National Institute of Information and Communications Technology (NICT) to the WMT19 shared News Translation Task,Model Proposal,Model Proposal
"we participate with neural MT systems for two language pairs and in three directions: English-Russian, EnglishGerman and German-English",Model Proposal,Model Proposal
we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for English–Gujarati language pair within the translation task subtrack,Theory Proposal,Theory Proposal
"We participate with the methods for shared news translation task in four language
directions, English ↔ German and English
↔ Russian in both directions",Resources,Model Proposal
"The systems have been developed with the aim of identifying and following rather than establishing best practices, under the constraints imposed by a low resource training and decoding environment normally used for our production system",Model Proposal,Model Proposal
"The systems have been developed with the aim of identifying and following rather than establishing best practices, under the constraints imposed by a low resource training and decoding environment normally used for our production system",Algorithm/Method Optimization,Algorithm/Method Optimization
"I describe a rule-based, bidirectional machine translation system for the Finnish—English language pair.",Theory Proposal,Theory Proposal
We describe our NMT systems submitted to the WMT19 shared task in English→Czech news translation.,Theory Proposal,Theory Proposal
"describes the neural machine translation systems developed at the RWTH Aachen University for the De→En, Zh→En and Kk→En news translation tasks",Theory Proposal,Theory Proposal
"Our two new news translation tasks address the low-resource
English-to-Kazakh language pair, for which only
a few thousand in-domain parallel sentences are
available",Theory Proposal,Theory Proposal
"Elastic weight consolidation (Kirkpatrick et al., 2017, EWC) is a domain adaptation technique that aims to avoid degradation in performance on the original domain",Model Proposal,Model Proposal
"To incorporate document-level context in a light-weight fashion, we propose a modification to the Transformer (Vaswani et al., 2017) that has separate attention layers for inter- and intra-sentential context.",New Algorithm/ Method,Model Proposal
"Even though the performance gap between NMT and traditional statistical machine translation (SMT) is growing rapidly on the task at hand, SMT can still improve very strong NMT ensembles",Performance Evaluation,Performance Evaluation
"we focus on the improvement of single system, and propose three novel Transformer variants",New Algorithm/ Method,New Algorithm/ Method
we trained a single multilingual translation system using the constrained parallel and monolingual data for several language pairs.,Model Optimization,Model Optimization
"neural machine translation (NMT) systems for English↔Kazakh
(henceforth referred to as EN↔KK) constrained
tasks.",Theory Proposal,Theory Proposal
we describe the system we developed at the LMU Munich Center for Information and Language Processing,New Algorithm/ Method,Theory Proposal
"We submit constrained systems, i.e, we rely on the data provided for this language pair and do not use any external data.",Resources,Resources
"we present the University of Helsinki submissions to the WMT 2019 shared task on news translation in three language pairs: English–German, English–Finnish and Finnish–English",Resources,Resources
"Neural architecture optimization (NAO), our newly proposed method (Luo et al., 2018), leverages the power of a gradient-based method to conduct optimization and guide the creation of better neural architecture in a continuous and more compact space given the historically observed architectures and their performances",New Algorithm/ Method,New Algorithm/ Method
"This paper is based on Transformer, a neural machine translation network structure, to develop a two-way evaluation task between Russian and English.",Performance Evaluation,Theory Proposal
This paper describes the DFKI-NMT submission to the WMT19 News translation task for both English-to-German and German-toEnglish directions,Model Proposal,Model Proposal
"we use the DFKI test suite for German→English MT (Burchardt et al., 2017) in order to analyze the performance of the 16 MT Systems that took part at the translation task",Model Proposal,Model Proposal
We provide a test suite for WMT19 aimed at assessing discourse phenomena of MT systems participating in the News Translation Task.,Performance Evaluation,Performance Evaluation
We present a test set for evaluating an MT system’s capability to translate ambiguous conjunctions depending on the sentence structure,New Algorithm/ Method,New Algorithm/ Method
we present a languageindependent method for automatically building ContraWSD-style test suites,New Algorithm/ Method,New Algorithm/ Method
"a machine translation test set of documents from the auditing domain and its use as one of the “test suites” in the WMT19 News Translation Task for translation directions involving Czech, English and German.",Performance Evaluation,Performance Evaluation
we propose WMDO (metric) – an extension to WMD that incorporates word order,Performance Evaluation,Performance Evaluation
we seek to directly address the problem mentioned before by adopting a syntactic-level language resource into Meteor.,Theory Proposal,Theory Proposal
"We present YiSi, a unified automatic semantic machine translation quality evaluation and estimation metric for languages with different levels of available resources",New Algorithm/ Method,New Algorithm/ Method
" introduces a new MT metric: Extended Edit Distance (EED), based on an extension of the Levenshtein distance",Dataset Creation,Dataset Creation
We propose a method to filter pseudo-references by paraphrasing for automatic evaluation of machine translation (MT),New Algorithm/ Method,New Algorithm/ Method
We proposed one single and one ensemble system for each translation direction,New Algorithm/ Method,New Algorithm/ Method
we describe our neural machine translation (NMT) systems for Japanese↔English translation which we submitted to the translation robustness task,Theory Proposal,Theory Proposal
"describes the systems of Fraunhofer FOKUS for the WMT 2019 machine translation robustness task on EN-FR, FR-EN, and JA-EN language pairs",Theory Proposal,Theory Proposal
We further improved the performance of our model by fine-tuning on the in-domain noisy data without influencing the translation quality on the news domain,Model Optimization,Model Optimization
"Our submission combined techniques including utilization of a synthetic corpus, domain adaptation, and a placeholder mechanism, which significantly improved over the previous baseline",Algorithm/Method Optimization,Algorithm/Method Optimization
we built straightforward 6-layer Transformer models and experimented with a handful of variables including subword processing (FR–EN) and a handful of hyperparameters settings (JA↔EN),Model Proposal,Model Proposal
We illustrated that adding a domain symbol in source sentence improves the robustness of the model,Model Optimization,Model Optimization
We found that “social-media-style” sentences can be generated by training a translation model with different “start-of-sentence” symbols for sentences in different domains in the decoder side,Model Proposal,Model Proposal
we propose a multitask learning algorithm for transformer-based MT systems that is more resilient to this noise.,New Algorithm/ Method,New Algorithm/ Method
"We propose a series of such methods that are model-agnostic, are able to be applied either offline or online, and do not require parameter update or architectural change",New Algorithm/ Method,New Algorithm/ Method
Our work here focuses on the zero-shot translation aspect of universal multilingual NMT,Theory Proposal,Theory Proposal
This is one of the first attempts at using syntax to improve Transformer-based NMT,Model Optimization,Model Optimization
We introduce two methods for adding syntax to NMT that are straightforward to incorporate in practice,New Algorithm/ Method,New Algorithm/ Method
"We empirically evaluate both methods on translation from English into 21 diverse target languages, finding that the multi-task method improves consistently over a nonsyntactic baseline",Performance Evaluation,Performance Evaluation
We introduce an APE model trained only on synthetic data generated with RTT for fixing typical translation errors from NMT output and investigate its scalability,Model Proposal,Model Proposal
We improve the BLEU of top submissions of the recent WMT evaluation campaigns,Algorithm/Method Optimization,Model Optimization
"We propose separately reporting scores on test sets whose source sentences are translated and whose target sentences are translated, and call for higher-quality test sets",Performance Evaluation,Performance Evaluation
we focus on investigating why sampling creates better training data by re-writing the loss criterion of an NMT model to include a model-based data generator,Dataset Creation,Dataset Creation
"We propose a simpler alternative to noising techniques, consisting of tagging back-translated source sentences with an extra token.",Algorithm/Method Optimization,Algorithm/Method Optimization
We introduce and explore different approaches for using document embeddings in parallel document mining,New Algorithm/ Method,New Algorithm/ Method
We adapt the previous work on hierarchical networks to introduce a simple hierarchical document encoder trained on document pairs for this task.,Dataset Creation,Dataset Creation
Empirical results show our best document embedding model leads to state-of-the-art results on the document-level bitext retrieval task on two different datasets,Performance Evaluation,Performance Evaluation
"We study in depth the effect of translationese on test data, using the test sets from the last three editions of WMT’s news shared task, containing 17 translation directions.",Performance Evaluation,Performance Evaluation
"we present a customized NMT system for subtitling, with focus on the entertainment domain",New Algorithm/ Method,New Algorithm/ Method
"We introduce our work, which to the best of our knowledge is the first of its kind, on integrating synchrony constraints into the machine translation paradigm",Model Proposal,Model Proposal
We propose the use of lexical shortcuts as a simple strategy for alleviating the representation bottleneck in NMT models,New Algorithm/ Method,New Algorithm/ Method
We demonstrate significant improvements in translation quality across multiple language pairs as a result of equipping the transformer with lexical shortcut connections,Performance Evaluation,Performance Evaluation
We report a positive impact of our modification on the model’s ability to perform word sense disambiguation,Model Optimization,Model Optimization
This paper presents a high-quality multilingual dataset for the documentation domain to advance research on localization of structured text,Dataset Creation,Dataset Creation
"In this talk I will give an overview of advances on the identification and treatment of multiword expressions, in particular concentrating on techniques for identifying their degree of idiomaticity.",Theory Proposal,Theory Proposal
" we present the types of VMWEs existing in each language, as they are reflected in the respective corpora created within PARSEME",Model Proposal,Model Proposal
This paper reports on the Romanian journalistic corpus annotated with verbal multiword expressions following the PARSEME guidelines.,Theory Proposal,Theory Proposal
"We show how the Multiword Expressions (MWEs) contained in OdeNet can be morphologically specified by the use of the lexical representation and linking features of OntoLex-Lemon, which also support the formulation of restrictions in the usage of such expressions.",Resources,Resources
introduction of a new task in NLP that sheds light on the basic mechanisms underlying conceptual creativity; an automatic way of evaluating newly generated language; a temporally-aware neural model that learns what are plausible new conceptual combinations by generalising over attested combinations and corrupted instances thereof.,New Algorithm/ Method,New Algorithm/ Method
this unsupervised method to a bilingual vector space so as to model translation as a process of compositional contextualization.,Algorithm/Method Optimization,Algorithm/Method Optimization
this paper also contributes with a new freely available dataset of 273 EnglishSpanish compound equivalents,Dataset Creation,Dataset Creation
This paper presents a systematic evaluation of twelve AMs —both symmetric and directional— which have been proposed for collocation extraction.,Theory Proposal,Theory Proposal
we aimed to replicate the MWS frequency effects found for adult native language speakers based on evidence from self-paced reading and sentence recall tasks in an ecologically more valid eye-tracking study,Model Optimization,Model Optimization
we present the distribution and treatment of MultiWord Expressions (MWEs) within BTB-WN — a data-driven Bulgarian WordNet.,Model Proposal,Model Proposal
We focus on modeling compositionality of MWEs as reflected in their morphosyntactic and semantic properties.,Performance Evaluation,Performance Evaluation
We propose a scenario for coupling MWEI with MWE discovery via syntactic MWE lexicons,Theory Proposal,Theory Proposal
This paper is a position statement based on an analysis of the state of the art in MWEI,Theory Proposal,Theory Proposal
"we test the quality of noun compound representations produced by different methods, including distributional representations, composition functions, and paraphrase-based phrase embeddings",Performance Evaluation,Performance Evaluation
"our own proposal of how to deal with semantics of collocations; we argue that the notion of a semantic frame in the sense of FrameNet (Ruppenhofer et al., 2016) provides a suitably general semantic framework that is applicable to a wide range of semantic fields",Applications,Applications
We propose to tackle the problem of verbal multiword expression (VMWE) identification using a neural graph parsing-based approach.,New Algorithm/ Method,New Algorithm/ Method
this paper aims to determine whether the sentiment of the component words of an idiom is related to the sentiment of that idiom.,Theory Proposal,Theory Proposal
"We report on the ongoing development of IDION, a web resource of richly documented multiword expressions (MWEs) of Modern Greek addressed to the human user and to NLP",New Algorithm/ Method,New Algorithm/ Method
describe how we created a dataset for noun-adjective neologisms and in particular how we constructed a weak negative set for evaluation,Dataset Creation,Dataset Creation
describe our baseline methodologies and how we used pretrained language models in order to identify adjective-noun neologism with increased accuracy,Applications,Applications
"we propose a deep encoderdecoder architecture generating for every MWE word its corresponding part in the lemma, based on the internal context of the MWE",Model Proposal,Model Proposal
we aim to close this gap and present an evaluation study that considers both corpus- and documentlevel ATE.,Performance Evaluation,Performance Evaluation
we propose a neural model that improves MWE identification by jointly learning MWE and dependency parse labels,Model Proposal,Model Proposal
"we propose, to the best of our knowledge for the first time, a cross-lingual transfer learning method for processing MWEs",New Algorithm/ Method,New Algorithm/ Method
"We show that MWE identification models, when multitasked with dependency parsing, outperform the models which naively add dependency parse information as additional features",Resources,Resources
"Our work aims to compile a comprehensive lexicon of Irish MWEs (Ilfhocail) for the purposes of NLP, by leveraging both existing monolingual and bilingual lexical resources and generating new MWE entries through methods of semiautomatic discovery",New Algorithm/ Method,New Algorithm/ Method
"Our goal is to study the impact of word representations on verbal MWE (VMWE) identification, comparing lemmas, surface forms, traditional word embeddings and subword representations.",Performance Evaluation,Performance Evaluation
We explore a variety of methods for the novel task of classifying four types of assertions about activity performance,Model Optimization,Model Optimization
"We propose a neural network model, which is a combination of a convolutional neural network (CNN) (LeCun et al., 1989), a recurrent neural network (RNN) (Elman, 1990), and a residual network (He et al., 2016) inspired by their recent successes in multiple tasks",New Algorithm/ Method,Model Proposal
Application of VAE in context to clinical paraphrasing task,Applications,Applications
"In this work, we build a unifying framework for RE, applying this on three highly used datasets (from the general, biomedical and clinical domains) with the ability to be extendable to new datasets",New Algorithm/ Method,Theory Proposal
we develop a simple measure of sentence importance and demonstrate its effectiveness in interpreting a complex LSTM model’s decision making process,New Algorithm/ Method,New Algorithm/ Method
we discover clusters in the high-dimensional space of the sentence embedding model and test their correlation with feature importance scores for a given diagnosis class,Performance Evaluation,Performance Evaluation
We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results,Performance Evaluation,Performance Evaluation
"We present a deep learning approach to combining in real time available diagnosis codes (ICD codes) and free-text notes: Patient Context Vectors. Patient Context Vectors are created by averaging ICD code embeddings, and by predicting the same from free-text notes via a Convolutional Neural Network",New Algorithm/ Method,New Algorithm/ Method
to present the construction of a biomedical gold standard corpus annotated both with part-of-speech tags and named entities,New Algorithm/ Method,New Algorithm/ Method
"Two different approaches for domain adaptation of SRL for biological processes, with our code and models publicly available",Model Optimization,Model Optimization
Analysis of the model performance when the target corpus is annotated with event-event relationships to the SRL corpus,Performance Evaluation,Performance Evaluation
We present DEep Contextualized Biomedical Abbreviation Expansion (DECBAE) model,Model Proposal,Model Proposal
we will tackle the word categorization task and compare the performance of classification model on different feature sets: standard linguistic and non-linguistic features,Performance Evaluation,Performance Evaluation
we propose to apply deep learning techniques to improve identification of readability and understandability of medical words by nonexpert users,Algorithm/Method Optimization,Algorithm/Method Optimization
"Construct a dataset for training machine learning models to identify and extract data from full-text articles on diagnostic test accuracy. We focus on the target condition, index test, and reference standard.",Dataset Creation,Dataset Creation
"a discriminative model for automatically constructing high-coverage and domain-specific corpora for information extraction,",Model Proposal,Model Proposal
"an approach for automatically selecting queries using index terms as candidates,",New Algorithm/ Method,New Algorithm/ Method
an automated method to evaluate queries based on a sample corpus,Model Optimization,Model Optimization
We present a simple and computationally efficient approach using a widely-available “off-theshelf” retrofitting algorithm to align pretrained embeddings according to semantic verb clusters,Model Optimization,Model Optimization
"we show that by using semantic clusters for verbs, a large lexicon of verb classes derived from biomedical literature, we are able to improve the performance of common pretrained embeddings in downstream tasks by retrofitting them to verb classes",Model Optimization,Model Optimization
We compare wordbased and context-based representations for the three classification problems.,Performance Evaluation,Performance Evaluation
We propose a number of methods for extracting patterns from a sentence in which two eligible entities co-occur; different types of patterns have different trade-offs between expressive power and coverage,New Algorithm/ Method,New Algorithm/ Method
we propose a method which utilises these seed pairs to rank newly discovered patterns in terms of their compatibility with the existing data.,New Algorithm/ Method,New Algorithm/ Method
"We provide a resource to be distributed for research purposes in the BioNLP community. MedLexSp includes inflected forms (singular/plural, masculine/feminine) and conjugated verb forms of term lemmas, which are mapped to UMLS Concept Unique Identifiers",Resources,Resources
We present a novel multichannel TextCNN model for MeSH term indexing.,Model Proposal,Model Proposal
Experimental results show that incorporating figure and table information improves the performance of automatic MeSH indexing,Performance Evaluation,Performance Evaluation
We make available a labeled full text biomedical document dataset,Dataset Creation,Dataset Creation
We publish a dataset of 2010 sentences with complete annotations of biological entities and binding interactions between the entities,Dataset Creation,Dataset Creation
"We propose a benchmark task with a welldefined evaluation system, which follows the best practices of machine learning research",Theory Proposal,Theory Proposal
We perform extensive evaluation of several competing methods on the dataset and report the results.,Performance Evaluation,Performance Evaluation
The first NLP method to focus specifically on drug information for nursing mothers.,Model Proposal,Model Proposal
"Application of a deep learning-based system on two separate lactation information sources, drug labels and LactMed.",Applications,Applications
Evaluation of cross-corpus similarity in terms of important lactation information,Performance Evaluation,Performance Evaluation
"we investigated how temporal information is documented in clinical text by annotating a corpus of medical reports with time expressions (TIMEXes), based on TimeML",Model Proposal,Model Proposal
we propose a novel annotation schema that could be useful for timeline reconstruction: CALendar EXpression (CALEX).,New Algorithm/ Method,New Algorithm/ Method
We present a method for the semantic categorization of clinical terms based on their surface form.,New Algorithm/ Method,Algorithm/Method Optimization
"we build a dataset of PIO elements by improving the methodology found in (Jin and Szolovits, 2018)",Dataset Creation,Dataset Creation
"we built a multi-label PIO classifier, along with a boosting framework, based on the state of the art text embedding, BERT",Model Proposal,Model Proposal
A collection of Portuguese clinical texts with manuallylabelled named entities,Dataset Creation,Dataset Creation
"A model of word embeddings learned from a larger collection of Portuguese clinical text (i.e., Neurology clinical case descriptions)",Model Optimization,Model Optimization
"An analysis of the performance of state-of-the-art models in Portuguese clinical NER, namely BiLSTM-CRF neural networks (Lample et al., 2016), tested on the labelled collection, either using the previous word embeddings or general-language word embeddings",Performance Evaluation,Performance evaluation
We present two models for combining word and character embeddings for cause-of-death classification of verbal autopsy reports using the text of the narrative,Model Proposal,Model Proposal
a single methodology to generate medical text for a series of downstream NLP tasks,New Algorithm/ Method,New Algorithm/ Method
an assessment of the utility of the generated data as complementary training data in two important biomedical NLP tasks: text classification (phenotype classification) and temporal relation evaluation,Performance Evaluation,Performance Evaluation
"we introduce our work on building a Chinese medical QA corpus named ChiMed
by crawling data from a big Chinese medical forum",Applications,Applications
Our goal in this paper is to maximize the predictive power of clinical notes by bridging the gap between information extraction and deep learning models,Theory Proposal,Theory Proposal
we present the semantic annotations we made on a corpus of clinical cases written in French by domain experts,Theory Proposal,Theory Proposal
"We develop a two-stage federated natural language processing method that enables utilization of clinical notes from different hospitals or clinics without moving the data, and demonstrate its performance using obesity and comorbities phenotyping as medical task",Model Optimization,Model Optimization
"focus on causal sentence detection as a binary classification task and  to consider causal sentence detection in
both generic and biomedical texts",Model Proposal,Model Proposal
We propose a new NE method that leverages the strengths of both structure and content-oriented approaches.,New Algorithm/ Method,New Algorithm/ Method
Our objective is to propose methods and material for the creation of transformation rules from a small set of parallel sentences differentiated by their technicity,New Algorithm/ Method,New Algorithm/ Method
We also propose a typology of transformations and quantify them,Theory Proposal,Theory Proposal
We detail the performance of two packages of models released in scispaCy and demonstrate their robustness on several tasks and datasets,Performance Evaluation,Performance Evaluation
this paper will focus on presenting the best NER performance achieved to date on full chemical patent corpus,Resources,Resources
"Our main research contribution is a new neural model that detects ADRs by firstly learning to classify sentiment, using a publicly available corpus of Tweets that is annotated with sentiment information and then using transfer learning to adapt this classifier to the detection of ADRs in social media postings",Theory Proposal,Theory Proposal
This work instead examines the evolution in biomedical knowledge over time using scientific literature in terms of diachronic change.,Performance Evaluation,Performance Evaluation
"we present our approach towards extracting outcomes, significance levels and relations between them, that can be incorporated into a spin detection pipeline",Algorithm/Method Optimization,Algorithm/Method Optimization
"In this paper, we describe the tasks, the datasets, and the participants’ approaches and results of shared task.",Theory Proposal,Theory Proposal
"we demonstrate that we can achieve significant performance gains over traditional deep learning models like ESIM by adapting pre-trained language
models into the medical domain",Model Proposal,Model Proposal
"we introduce an end-to-end system, trained in a multi-task setting, to filter
and re-rank answers in medical domain",Theory Proposal,Theory Proposal
we investigate different methods to combine and transfer the knowledge from the two different sources and illustrate our results on the MEDIQA shared task,Performance Evaluation,Performance Evaluation
We apply the transfer learning method with two general domain NLI datasets and show that a source task in a domain can benefit learning a target task in a different domain,Model Optimization,Model Optimization
We show the independent strengths of the proposed approaches in quantitative and qualitative manners,Performance Evaluation,Performance Evaluation
"we propose a hybrid approach to biomedical NLI, which includes three main components",Model Proposal,New Algorithm/ Method
"To enhance our model, we also use model ensemble and conflict resolution strategies",Model Optimization,Model Optimization
we specialize our model on the MedNLI dataset.,Model Optimization,Model Optimization
"In this paper, we propose a novel model called Adversarial Multi-Task Network (AMTN) for jointly modeling Recognizing Question Entailment (RQE) and medical Question Answering (QA) tasks.",Model Proposal,Model Proposal
"Our approach for both task 1 and task 2 is based on the state-of-the-art natural language understanding model MT-DNN (Liu et al., 2019), which combines the strength of multi-task learning (MTL) and language model pre-training. MTL in deep networks has shown performance gains when related tasks are trained together resulting in better generalization to new domains",Theory Proposal,Theory Proposal
This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain,Theory Proposal,Theory Proposal
we present our novel approach to detect question entailment by determining the type of question asked rather than focusing on the type of the ailment given,Model Proposal,Model Proposal
"we detail our approach in MEDIQA which addresses some of the problems with biomedical text such as utilising deep contextual relationships between words within a sentence for semantic understanding and ambiguity associated with esoteric terminology, abbreviations, and patient colloquialism",Model Proposal,Model Proposal
we present Biomedical MultiTask Deep Neural Network (Bio-MTDNN) on the NLI task of MediQA 2019 challenge,Applications,Applications
we describe our proposed model and the implementation details for both tasks,Model Proposal,Model Proposal
"This paper describes our approach to the Natural Language Inference (NLI) subtask of the MEDIQA 2019 shared task (Ben Abacha et al., 2019)",Theory Proposal,Theory Proposal
This paper explores the use of Bidirectional Encoder Representation from Transformer (BERT) for solving MedNLI,New Algorithm/ Method,Theory Proposal
" Our proposed systems produce
encouraging results",Performance Evaluation,Performance Evaluation
Our approach explored a common Transformer-based architecture that could be applied to each task.,Performance Evaluation,Performance Evaluation
"Our solution explores a BERT-based model, in which the BiLSTM network with attention mechanism is integrated for textual inference",Performance Evaluation,Performance Evaluation
"We discuss the Proposed Architecture for NLI, RQE and QA and  the results,
performance of the various models for each task,
followed by error analysis, conclusion and references",Performance Evaluation,Performance Evaluation
"we propose a new component
that aims to address this particular weakness of
seq2seq models",New Algorithm/ Method,New Algorithm/ Method
"we propose a new testing paradigm based on overgeneralization, that can be used to gain more insights in the biases of a model which cannot be inferred from task success alone",New Algorithm/ Method,New Algorithm/ Method
the creation of a challenging sentiment dataset from previously available data,Dataset Creation,Dataset Creation
finally presenting a practical use-case demonstrating how the dataset can be used to probe the particular types of errors made by a new model.,Applications,Applications
We create an artificial data set with target words displaying context overlap in different orders of co-occurrence and show that SGNS behaves similarly to SVD in capturing second-order co-occurrence information,Dataset Creation,Dataset Creation
we present a new evaluation dataset1 that covers a wide range of monotonicity reasoning that was created by crowdsourcing and collected from linguistics publications,Dataset Creation,Dataset Creation
we study what the meaningful units to highlight are  so that all highlighted symptoms can be directly used for explaining the model.,New Algorithm/ Method,New Algorithm/ Method
Our aim is to identify what strategy deep learning models for visual question answering learn when trained on such questions,New Algorithm/ Method,Model Proposal
we compare the explanations from the two models through human evaluation on Mechanical Turk and find that the model trained with human rationales is judged to generate explanations that better support its decisions,Performance Evaluation,Performance Evaluation
visualizing attention in the Transformer at three levels of granularity,Model Optimization,Model Optimization
"The proposal of a neural network architecture, the Headline Attention Network that is designed to capture the important parts of news article causing political bias by paying headline attention",New Algorithm/ Method,New Algorithm/ Method
"we show that, contrary to our expectations, most models fail to generalize across the different datasets.",Performance Evaluation,Performance Evaluation
we examine the behavior of POS taggers across languages from the perspective of individual hidden units within the character LSTM,Performance Evaluation,Performance Evaluation
"One approach to explainable VQA is to generate visual explanations, which highlight image regions that most contributed to the system’s answer, as determined by attention mechanisms or gradient analysis",Theory Proposal,Theory Proposal
"we evaluate and compare the aforementioned methods, using two different experimental setups, thereby we assess basic properties and differences between the explanation methods",Algorithm/Method Optimization,Algorithm/Method Optimization
"we explore how word relevances can be used to build sentence-level representations, and demonstrate how the relevance visualization can help to understand the (mis-)classification of selected samples w.r.t. semantic composition.",Algorithm/Method Optimization,Algorithm/Method Optimization
We present a detailed comparison of two types of sequence to sequence models trained to conduct a compositional task,Performance Evaluation,Performance Evaluation
"we show that a seq2seq model with attention mechanism not only solves the tagging task, but also generalizes well over unseen depths",Performance Evaluation,Performance Evaluation
"we propose a new KBC model, the Context Path Model (CPM), which provides a path-based explanation for newly proposed facts.",Model Proposal,Model Proposal
we extend previous work on longdistance dependencies to tease apart the potential grounds for the different outcomes by making previous work more comparable,Resources,Resources
"we examine whether the word embeddings (trained on the whole words, not using any subword units or individual characters) capture derivational relations",Performance Evaluation,Performance Evaluation
we present a suite of experiments probing whether neural language models trained on linguistic data induce these stack-like data structures and deploy them while incrementally predicting words,Performance Evaluation,Performance Evaluation
"we define and apply representational stability analysis (ReStA), an intuitive way of analyzing neural language models.",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel approach to the study of how artificial neural network perceive the distinction between grammatical and ungrammatical sentences, a crucial task in the growing field of synthetic linguistics",New Algorithm/ Method,New Algorithm/ Method
"We propose a method for robustness evaluation without goldstandard translation references, and perform experiments and extensive analysis on all available English Grammar Error Correction (GEC) corpora",New Algorithm/ Method,New Algorithm/ Method
we introduce a visualization technique for performing further analysis,New Algorithm/ Method,New Algorithm/ Method
we attempt to detect the presence of latent representations of hierarchical structure through an exploration of the unsupervised learning of constituency structure,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a white-box attack algorithm called “Global Search” method and compare it with a simple misspelling noise and a more sophisticated and common white-box attack approach called “Greedy Search,New Algorithm/ Method,New Algorithm/ Method
We propose a simple attention-based metric called the confusion score that captures BERT’s response to syntactic distortions in an input sentence,New Algorithm/ Method,New Algorithm/ Method
"This paper presents a simple but general and effective method to debug the output of machine learning (ML) supervised models, including neural networks",Theory Proposal,Theory Proposal
"We propose a transparent deterministic method of quantifying the amount of syntactic information present in the self-attentions, based on automatically building and evaluating phrasestructure trees from the phrase-like sequences.",New Algorithm/ Method,New Algorithm/ Method
we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention,Model Proposal,Model Proposal
"We introduce novel computational models for modeling semantic bleaching, a widespread category of change in which words become more abstract or lose elements of meaning, like the development of arrive from its earlier meaning ‘become at shore.’",Model Proposal,Model Proposal
"This paper is an attempt to understand what has changed in poetry over the last 150 years within the age of mechanical reproduction of art, named so by Benjamin and Underwood",Theory Proposal,Theory Proposal
"The present study employs Word2Vec models (Mikolov et al., 2013) to investigate two questions about the FOOD>MEAT>FLESH chain.",Performance Evaluation,Performance Evaluation
The paper focuses on diachronic evaluation of semantic changes of harm-related concepts in psychology.,Performance Evaluation,Performance Evaluation
"We propose a novel, attentional, diachronic word embedding model that derives inductive biases from several contextualized, sociodemographic, features to fit the data accurately",Model Proposal,Model Proposal
"our work is also the first to estimate the usefulness of the diachronic word embeddings
for downstream task like tweet classification.",Theory Proposal,Theory Proposal
I discuss how evolutionary approaches to language change allow the modeling of cognate evolution,Theory Proposal,Theory Proposal
This paper introduces a novel method to track collocational variations in diachronic corpora that can identify several changes undergone by these phraseological combinations and to propose alternative solutions found in later periods.,New Algorithm/ Method,New Algorithm/ Method
We propose an accurate and interpretable model for identifying the era of authorship of old Thai prose,Model Proposal,Model Proposal
"We are the first to provide statistical evidence that Traiphumikatha and Pumratchatham might be both written in the Sukhothai era, contrary to previous hypotheses",Applications,Applications
we conclude that grammaticalized words and polyfunctionalized words are the strongest distinguishing indicators of prose from the Sukhothai era,Theory Proposal,Theory Proposal
we propose a data-driven methodology for identifying temporal trends in a corpus of medieval charters,New Algorithm/ Method,New Algorithm/ Method
This paper examines gender bias in historical newspapers,Resources,Resources
The paper at hand presents a computational method based on deep neural networks to predict phonetic features of historical sounds where the exact quality is unknown and to test the overall coherence of reconstructed historical phonetic features,Model Proposal,Model Proposal
"we introduce ParHistVis: a novel, free, easy-to-use, interactive visualization tool for parallel, multilingual, diachronic and synchronic linguistic data.",Theory Proposal,Theory Proposal
"We collected a large corpus for this purpose, composed of thousands of books and newspapers published in France between 1789 and 1914",Dataset Creation,Dataset Creation
"we present DiaHClust, a new approach which can be used to identify stages in diachronic change based on quantitative corpusderived data",New Algorithm/ Method,New Algorithm/ Method
"we propose an approach that fits additional, theoretically informative parameters to configure a mixture of embeddings",New Algorithm/ Method,New Algorithm/ Method
We propose a novel method to investigate the pace of language change based on the entire embedding matrix,New Algorithm/ Method,New Algorithm/ Method
"I propose that as words immigrate to new syntactic environments over time, they tend to push out words that populated these environments prior to immigration",New Algorithm/ Method,New Algorithm/ Method
we investigate semantic change across languages by measuring the semantic distance of cognate words in multiple languages,Performance Evaluation,Performance Evaluation
Verify that the represented temporal change reflects syntax rather than simply word frequency.,Theory Proposal,Theory Proposal
"The paper showcases the application of word embeddings to change in language use in the domain of science, focusing on the Late Modern English period",Theory Proposal,Theory Proposal
we model the contact possibility based on two of the most important factors in sociolinguistics to be affecting language change: age and distance,Model Optimization,Model Optimization
We reformulate the well-known word analogy task such that multiple correct answers or no correct answer at all become possible,Theory Proposal,Theory Proposal
We process historical armed conflicts data and present it as a ready-to-use evaluation set,Dataset Creation,Dataset Creation
we show that our learned cosine threshold approach can significantly improve the temporal one-to-X analogies performance by filtering out false positives.,Algorithm/Method Optimization,Model Optimization
"we investigate on is there a general trend in human languages which makes evaluative adjectives change
more intensely over time",Performance Evaluation,Performance Evaluation
we investigate to what extent diachronic semantic change occurs in the Hansard record by examining the contexts in which words appear during two different periods in the corpus,Performance Evaluation,Performance Evaluation
"we illustrate this importance and propose methods that take these risks into account
when investigating conceptual change using word
embeddings.",New Algorithm/ Method,New Algorithm/ Method
we present the first study on the compositionality of compounds over time.,Theory Proposal,Theory Proposal
we introduce a linguistic classification that allows to better characterize the variants than edit operations,Model Proposal,Model Proposal
we propose to focus on a specific concept—that of Circular Economy (CE).,Theory Proposal,Theory Proposal
This paper proposes a Gaussian Process model of sound change targeted toward questions in Indo-Aryan dialectology,Model Proposal,Model Proposal
"we apply computational methods, to the extent that it is possible, to gain insight into the nature of language change that occurred in historical West-Frisian, a lesser-used language spoken in the Dutch province of Fryslan",New Algorithm/ Method,New Algorithm/ Method
"This paper presents a significant extension of HistoBankVis, a multilayer visualization system which allows a fast and interactive exploration of complex linguistic data",Model Proposal,Model Proposal
we implement a new query strategy for selecting “unlabeled” instances from a target domain and investigate its effect on fine-tuning a generic NMT model,Dataset Creation,Dataset Creation
This paper compares morphologyaware DA word segmentation to other word segmentation approaches like Byte Pair Encoding (BPE) and Sub-word Regularization (SR).,Theory Proposal,Theory Proposal
we investigate the possibility of using POS tagging to improve word-level language identification for diglossic Arabic in a deep-learning system,Performance Evaluation,Performance Evaluation
we present syntax-ignorant n-gram embeddings to be used in sentiment analysis of several Arabic dialects,New Algorithm/ Method,New Algorithm/ Method
we propose six Arabic-English cross-lingual word embedding models,Model Proposal,Model Proposal
We introduce automatic selective diacritization as a viable step in lexical disambiguation and provide an encouraging baseline for future developments towards optimal diacritization,New Algorithm/ Method,New Algorithm/ Method
We propose several unsupervised data-driven methods for the automatic identification of ambiguous words,New Algorithm/ Method,New Algorithm/ Method
We evaluate and analyze the impact of partial sense disambiguation (i.e. selective diacritic restoration of identified homographs) in downstream applications for MSA.,New Algorithm/ Method,New Algorithm/ Method
" The proposed model
integrates various tailored techniques together,
including representation learning, feature engineering, sequence labeling, and ensemble
learning.",Model Proposal,Model Proposal
we aim at advancing performance and generalization capabilities of Arabic NLP tasks by developing new ULMs for Arabic,Resources,Resources
"We develop the first Arabic specific ULM model, called hULMonA",Resources,Resources
We introduce a newly built (small) ALG dataset for STS.,Model Proposal,Model Proposal
"We compare the performance of different DNN configurations on this dataset, namely: various combinations of Recurrent Neural NetworksConvolutional Neural Networks (CNNs),
pre-training of embeddings, including a replication of two new state-of-the art attention models.",Performance Evaluation,Performance Evaluation
we propose to leverage this sequential substructure to improve the root extraction process and morphological decomposition,Model Optimization,Model Optimization
"we investigate the effect of different Arabic segmentation schemes, sentence length and embedding sizes on learning Arabic-English (Ar-En) Bilingual word embeddings",Model Optimization,Model Optimization
"Crowdsourced Arabic Reading Comprehension Dataset (ARCD) of 1,395 questions, and translated Arabic-SQuAD: 48k translated questions",Dataset Creation,Dataset Creation
"End-toend system for open domain Arabic questions using a hierarchical TF-IDF retriever, BERT and linear answer ranking",Resources,Resources
"we show how NLP applications
can scale up their performance on dialectal data by
integrating a basic and simple preprocessing step,
i.e. segmentation",Performance Evaluation,Performance Evaluation
"we propose a semi-supervised deep learning approach, which we refer to as deep co-learning.",New Algorithm/ Method,New Algorithm/ Method
"We present a collection of morphologically annotated corpora for seven Arabic
dialects",Theory Proposal,Theory Proposal
This paper reports on the construction and annotation of a comprehensive 100-million-word corpus of contemporary Arabic,New Algorithm/ Method,New Algorithm/ Method
our goal is building an ArabicTurkish machine translation on the news domain,Theory Proposal,Theory Proposal
we propose the use of domain adaptation to address this challenge while considering the task of sentiment analysis (SA) also referred to as Opinion Mining (OM).,New Algorithm/ Method,New Algorithm/ Method
This paper presents the first version of the Open Source International Arabic News (OSIAN) corpus.,Theory Proposal,Theory Proposal
we proposed speech act classification for asynchronous conversations on Twitter using multiple machine learning methods including SVM and deep neural networks,New Algorithm/ Method,New Algorithm/ Method
"we present Mazajak , an Online Arabic sentiment analysis system that utilises deep learning and massive Arabic word embeddings",Resources,Resources
we present the results and findings of the MADAR Shared Task on Arabic Fine Grained Dialect Identification,Applications,Applications
We propose a simple classification approach that only utilizes word and character n-grams using Na¨ıve Bayes learning model.,Model Proposal,Model Proposal
the relationships between entities in an image by utilizing only image captions and object locations as the source of supervision,New Algorithm/ Method,New Algorithm/ Method
"we study multimodal summarization with various methods to summarize the intent of open-domain instructional videos stating the exclusive and unique features of the video, irrespective of modality",Model Optimization,Model Optimization
"we (i) collect human edits for machine-generated stories from two different state-of-the-art models, (ii) analyze what people edited, and (iii) advance the task of visual story post-editing",Performance Evaluation,Performance Evaluation
This technique can greatly reduce the workload of radiologists for interpreting CXR images and writing corresponding reports.,Algorithm/Method Optimization,Algorithm/Method Optimization
"an end-to-end model that extends the standard Transformer network (Vaswani et al., 2017) to learn representations directly from unaligned multimodal streams",Model Proposal,Model Proposal
"we introduce a high-level object-based visual representation to ground language into visual context in a more generalizable way, using the symbolic output of a pretrained object detection system",New Algorithm/ Method,New Algorithm/ Method
"This is done by building on the Word Mover’s Distance (WMD) metric, which measures the distance between two texts in a word embeddings space. Another contribution is the extension of WMD to allow for multiple references to be used to model object importance",Performance Evaluation,Performance Evaluation
: (i) a novel approach to MMT based on deliberation networks and structured visual information which gives state of the art results (Sections 3.2 and 5.1); (ii) a frequency bias-free investigation on the need for visual context in MMT (Sections 4.2 and 5.2); and (iii) a thorough investigation on different visual sual representations for transformer-based architectures,New Algorithm/ Method,New Algorithm/ Method
we propose to construct an imagegrounded vocabulary as a way to leverage the image semantics for image captioning,New Algorithm/ Method,New Algorithm/ Method
"the Collaborative Drawing (CoDraw) task, which combines grounded language understanding and learning effective goal-driven communication into a single, unified testbed",New Algorithm/ Method,New Algorithm/ Method
"leveraging upstream models that are capable of producing fine-grained entity names, and integrating them in a controlled manner to produce captions that are both fluent and highly informative",Model Optimization,Model Optimization
"a novel attention mechanism that consumes a word lattice and the probability scores from the ASR system. ii) The proposed approach is naturally applied to both the encoder self-attention and encoder-decoder attention. iii) Another appealing feature is that the lattice transformer can be reduced to standard latticeto-sequence model without probability scores, fitting the text translation task. iv) Extensive experiments on speech translation datasets demonstrate that our method outperforms the previous transformer and Lattice-LSTMs",Algorithm/Method Optimization,Algorithm/Method Optimization
(i) We propose a ReDAN framework that supports multi-step reasoning for visual dialog. (ii) We introduce a simple rank aggregation method to combine the ranking results of discriminative and generative models to further boost the performance. (iii) Comprehensive evaluation and visualization analysis demonstrate the effectiveness of our model in inferring answers progressively through iterative reasoning steps,New Algorithm/ Method,New Algorithm/ Method
"to encourage the model to learn speech representations which are correlated with the encoding of spoken language as a sequence of characters. Additionally, and for completeness, we also consider a second auxiliary task matching text to images.",Model Proposal,Model Proposal
• An end-to-end architecture for goal-oriented visual dialogue combining Information Gain with Reinforcement Learning. • A novel reward function for goal-oriented visual question generation to model long-term dependencies in dialogue. • Both versions of our model outperform the current baselines on the GuessWhat?! dataset for the task of identifying an undisclosed object in an image by asking a series of questions.,New Algorithm/ Method,Model Proposal
"generating text as a sequence of segments, where each segment is generated either character-by-character from a sequence model or as a single draw from a lexical memory of multi-character units. The segmentation decisions and decisions about how to generate words are not observed in the training data and marginalized during learning using a dynamic programming algorithm",Model Optimization,Model Optimization
"(1) a procedure for collecting visually rich images paired with semantically-diverse language descriptions; (2) NLVR2, which contains 107,292 examples of captions and image pairs, including 29,680 unique sentences and 127,502 images ",New Algorithm/ Method,New Algorithm/ Method
we use an implicit data gathering approach to label human activities in videos.,New Algorithm/ Method,New Algorithm/ Method
"our latent variable MMT formulation improves considerably over strong baselines, and compares favourably to the state-of-the-art. • we exploit correlations between both modalities at training time through a joint generative approach and do not require images at prediction time.",Theory Proposal,Theory Proposal
"1. We propose a model fusing transcript of narrated instructional video during procedure extraction and captioning. 2. We employ the pre-trained BERT(Devlin et al., 2018) and self-attention(Vaswani et al., 2017) layer to embed transcript, and then integrate them to visual encoding during procedure extraction. 3. We adopt the sequence-to-sequence model to generate captions by merging tokens of the transcript with the aligned video frames.",Model Proposal,Model Proposal
"We introduce a uniqueness measure to evaluate topic quality more wholistically. • W-LDA produces significantly better quality topics than existing topic models in terms of topic coherence and uniqueness. • We experiment with both the WAE-GAN and WAE-MMD variants (Tolstikhin et al., 2017) for distribution matching and demonstrate key performance advantage of the latter with a carefully chosen kernel, especially in high dimensional settings. • We discover a novel technique of adding noise to W-LDA to significantly boost topic coherence. This technique can potentially be applied to WAE in general and is of independent interest.",Performance Evaluation,Performance Evaluation
". Using a qualitative analysis, we further show that RAT works as a regularizer and prohibits NMT to overfit to TC vocabulary",Performance Evaluation,Performance Evaluation
We explore possible explanations for the finding that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks and provide a set of adaptation guidelines for the NLP practitioner.,Theory Proposal,Theory Proposal
"We propose a novel approach to handle the discrete nature of text, during training, using word embeddings.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we explore a multilingual translation model with a cross-lingually shared layer that can be used as fixed-size sentence representation in different downstream tasks.",Model Proposal,Model Proposal
we present a multilingual translation system that efficiently tackles the task of learning language-agnostic sentence representations,New Algorithm/ Method,New Algorithm/ Method
In this article we propose an adaptation of Doubly Stochastic Variational Inference for Automatic Relevance Determination (DSVIARD) for neural networks compression.,Performance Evaluation,Performance Evaluation
"We introduce a simple yet effective, self-supervised post-processing method that constructs task-specialized word representations by picking from a menu of reconstructing transformations to yield improved end-task performance (MORTY)",New Algorithm/ Method,New Algorithm/ Method
"we compile several key pitfalls of evaluation of sentence embeddings, a currently very popular NLP paradigm",Performance Evaluation,Performance Evaluation
We propose a novel model architecture and training algorithm to learn bilingual sentence embeddings from a combination of parallel and monolingual data,New Algorithm/ Method,New Algorithm/ Method
"In this work, we present POSTLE, an all-words post-specialization model for the asymmetric LE relation",New Algorithm/ Method,Model Proposal
we propose two novel constraints for composing linguistically informed and intuitively explainable noun phrase representations and show how these approaches could benefit future composition methods.,New Algorithm/ Method,Model Proposal
We apply pre-trained language models to low-resource named entity recognition for Historic German.,New Algorithm/ Method,New Algorithm/ Method
"We propose a simple entity-pair ranking (PR) protocol (PR), which is more suitable to assess model performance for KBC.",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel supertagger based on the Transformer architecture (Vaswani et al., 2017) that is capable of constructing categories inductively, bypassing the aforementioned limitations.",Algorithm/Method Optimization,Algorithm/Method Optimization
"In this work, we introduce a deep generative model that generates source and target sentences jointly from a shared latent representation",New Algorithm/ Method,Model Proposal
"In this paper, we propose BilLex (Bilingual Word Embeddings Based on Lexical Definitions) to learn bilingual word embeddings.",New Algorithm/ Method,New Algorithm/ Method
We empirically study how pre-trained embeddings and language models perform when used to analyze text from social media.,New Algorithm/ Method,Theory Proposal
This paper extends the task of probing sentence representations for linguistic insight in a multilingual domain.,Resources,Resources
We develop a fine-grained entity typing model that embeds both entity types and entity mentions in hyperbolic space.,New Algorithm/ Method,Theory Proposal
We propose to generate multilingual metarepresentations from pre-trained monolingual word embeddings. The model can learn how to construct the best word representation by mixing multiple sources without explicit language identification.,New Algorithm/ Method,Model Proposal
"we explore and evaluate several sub-word unit based embedding strategies – character n-grams, lemmatization provided by an NLP-pipeline, and segments obtained in unsupervised learning (morfessor) – to boost semantic consistency in Hungarian word vectors.",Algorithm/Method Optimization,Performance Evaluation
"The method we propose, learns discriminative features from both an autoencoder and a sentence embedding, then uses assignments from a clustering algorithm as supervision to update weights of the encoder network",Model Proposal,Algorithm/Method Optimization
"In this paper, we introduce a new approach to warm-start embedding models with morphological information, in order to reduce training time and enhance their performance.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we aim to gain a better insight into the inner workings of recurrent models with respect to incrementality while taking inspiration from and drawing parallels to this psycholinguistic perspective.",New Algorithm/ Method,Model Proposal
In this paper we investigate how representing adversarial training models as committees can be used to effectively improve the performance of QuestionAnswer (QA) Ranking.,Performance Evaluation,Model Proposal
"We propose to consider lifelong relation extraction as a metalearning challenge, to which the machinery of current optimization-based meta-learning algorithms can be applied",New Algorithm/ Method,Theory Proposal
"In this paper, we investigate the best practices for constructing the seed dictionary for a specific domain.",Algorithm/Method Optimization,Performance Evaluation
"we present a novel technique that efficiently combines PCA based dimensionality reduction with a recently proposed post-processing algorithm (Mu and Viswanath, 2018), to construct effective word embeddings of lower dimensions",Algorithm/Method Optimization,Theory Proposal
We present a modified skip-gram negative sampling algorithm that produces related word and context vectors.,New Algorithm/ Method,New Algorithm/ Method
"We present a novel approach for cross-lingual representation learning that combines methods for multi-task learning of monolingual sentence representations (Cer et al., 2018; Subramanian et al., 2018) with recent work on dual encoder methods for obtaining multilingual sentence representations for bi-text retrieval (Guo et al., 2018; Yang et al., 2019).",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel method, Modality-based Redundancy Reduction Fusion (MRRF), for understanding and modulating the relative contribution of each modality in multimodal inference tasks",New Algorithm/ Method,New Algorithm/ Method
we present the results of our experiments on learning a simple multi-task neural network model for partof-speech and semantic tagging for Welsh using a pre-trained embedding model from FastText.,Performance Evaluation,Model Proposal
In this paper we discuss different definitions of fairness and possible ways to apply them to educational applications.,Applications,Applications
"we propose a method for estimating the difficulty of MCQs from a high-stakes medical exam, where all questions were deliberately written to a common reading level.",New Algorithm/ Method,New Algorithm/ Method
we propose a novel testing strategy by combining automatic item generation (AIG) and computerized adaptive testing (CAT) in vocabulary assessment for Chinese L2 learners.,Performance Evaluation,Performance Evaluation
"we  explore the use of computational linguistic methods to investigate how taskappropriate complexity and accuracy relate to the grading of overall performance, content performance, and language performance as assigned by teachers.",Algorithm/Method Optimization,Performance Evaluation
In this paper we present a model for automatic scoring of summaries based on analysing a rhetorical structure of a student’s summary compared to that of reference summaries.,New Algorithm/ Method,Model Proposal
This paper reports on the BEA-2019 Shared Task on Grammatical Error Correction (GEC).,Resources,Resources
This paper addresses automatic correction of spelling errors where the misspelled string is not a valid word in the language.,Resources,Performance Evaluation
The present study explores how fluency filtering can affect the quality of artificial errors.,Resources,Performance Evaluation
In this paper we present first results for automated essay scoring of Norwegian learner language.,Theory Proposal,Performance Evaluation
"In this paper, we perform a systematic comparison of ELMo, BERT and Flair embeddings on a range of public GED datasets, and propose an approach to effectively integrate such representations in current methods, achieving a new state of the art on GED.",Performance Evaluation,Performance Evaluation
We formulate precise hypotheses about the possible effects of adding character representations to word-based models and test these hypotheses on large-scale real-world content scoring datasets.,Model Optimization,Performance Evaluation
"In this paper, we up the ante by exploring the potential of more sophisticated language models in GEC and offer some key insights on their strengths and weaknesses.",Model Optimization,Model Optimization
We introduce unsupervised techniques based on phrase-based statistical machine translation for grammatical error correction (GEC) trained on a pseudo learner corpus created by Google Translation.,New Algorithm/ Method,Model Proposal
"We propose a new method for combining systems (§4) that can combine many systems and relies solely on their output, i.e., it uses systems as a black-box.",New Algorithm/ Method,New Algorithm/ Method
"In this work, we investigate a similar approach by systematically generating parallel data for pretraining.",Dataset Creation,Dataset Creation
This paper describes our two systems for the three tracks in the BEA-2019 GEC Shared Task,Algorithm/Method Optimization,Algorithm/Method Optimization
This paper presents the contributions from the Cambridge University Engineering Department to the latest GEC competition at the BEA 2019 workshop.,Resources,Resources
We introduce the AIP-Tohoku grammatical error correction (GEC) system for the BEA2019 shared task in Track 1 (Restricted Track) and Track 2 (Unrestricted Track) using the same system architecture,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present our models and their results in the restricted, unrestricted, and lowresource tracks.",New Algorithm/ Method,Model Proposal
"In the following, we present our low-resource approach to GEC, which ranked as the 6th best performing system in the low-resource 192 track of the BEA 2019 shared task.",New Algorithm/ Method,Model Proposal
"In this paper, we describe the submissions from the group of Beijing Language and Culture University (BLCU) in the first two tracks.",Applications,Applications
we propose to finetune BERT on learner corpora with grammatical errors for re-ranking.,Theory Proposal,New Algorithm/ Method
"In this paper, we introduce a neural GEC system that combines the power of pre-training and transfer learning.",New Algorithm/ Method,Model Proposal
We present a system pipeline that utilises both error detection and correction models.,New Algorithm/ Method,New Algorithm/ Method
we explore two approaches of generating error-focused phrases and examine whether these phrases can lead to better performance in grammatical error correction for the restricted track of BEA 2019 Shared Task on GEC.,Algorithm/Method Optimization,Algorithm/Method Optimization
we suggest an alternative approach for GEC with “Multi-headed” architecture that uses BERT as Encoder and specialized “Heads” networks enabling additional text processing based on particular error types.,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a simple and surprisingly effective unsupervised synthetic error generation method based on confusion sets extracted from a spellchecker to increase the amount of training data,New Algorithm/ Method,New Algorithm/ Method
"This paper compares three end-to-end resources for collocation learning, all of which used the same corpus but different methods",Resources,Resources
The experiments presented in this paper aim to analyze how much each of these phenomena reveal about the L2 speaker’s native language,New Algorithm/ Method,Theory Proposal
we present a novel method based on deep learning applied to the task of automatic prerequisite relations identification between concepts to automatically create pedagogically motivated sequences of LOs.,New Algorithm/ Method,New Algorithm/ Method
our study develops an example sentence retrieval system with grammatical error detection using the large-scale Lang-8 dataset for JSL by focusing on the usability of automatic incorrect example retrieval.,New Algorithm/ Method,Model Proposal
we propose an automated algorithm which provides feedback about the specific content of non-native English speakers’ spoken responses.,New Algorithm/ Method,Resources
This paper provides an analytical assessment of student short answer responses with a view to potential benefits in pedagogical contexts.,New Algorithm/ Method,Theory Proposal
we discuss leveraging this observation in our efforts to build audio-visual content for young learners’ vocabulary learning.,Algorithm/Method Optimization,Algorithm/Method Optimization
"we discuss our system, Curio SmartChat for self-paced K-12 learning through Question Answering as a mode",New Algorithm/ Method,Model Proposal
This paper proposes a support tool for evaluating student summaries in terms of their contents by suggesting the links between the ideas of a source text and its summary.,New Algorithm/ Method,Theory Proposal
"we take first steps towards understanding the relation between expert annotations, reader proficiency and comprehension for automatic readability assessment research by conducting a web-based reading study with over 100 participants in a natural reading environment.",Performance Evaluation,Performance Evaluation
we assess the effectiveness of an automatic classification tool for the evaluation of text complexity in Italian,Performance Evaluation,Performance Evaluation
"Our goal is to create a machine teacher that can detect and exploit situations where incidental learning can occur in narrative text (stories, articles etc.).",New Algorithm/ Method,Theory Proposal
We track the development of writing complexity and accuracy in German students’ early academic language development from first to eighth grade.,Applications,Applications
We developed an automated oral proficiency scoring system for non-native English speakers’ spontaneous speech,New Algorithm/ Method,New Algorithm/ Method
"we build a system that learns relationships between LOs, and we achieve up to human-level performance in the LO relationship extraction task.",New Algorithm/ Method,New Algorithm/ Method
"we study several simplistic machine understanding systems, described in § 2.4 and empirically examine the correlation between their performance and the actual complexity of texts, measured by humans (see § 3).",Algorithm/Method Optimization,Algorithm/Method Optimization
In this paper we investigate metaphors in the context of news texts simplification.,Model Optimization,Model Optimization
"This paper presents a roadmap for now incorporating equity into the design, evaluation, and implementation of those systems",Performance Evaluation,Performance Evaluation
" In this paper, we go one step further, assisting students to learn to use confusing words appropriately in a productive task: sentence translation.",New Algorithm/ Method,Theory Proposal
"we propose a tool, Dexter, that extracts a subjectspecific corpus from a heterogeneous corpus, such as Wikipedia, by relying on a small seed corpus and distributed document representations.",Resources,Resources
"we investigate how effective are different model architectures in generating artificial, parallel data to improve a GEC model.",Model Optimization,Model Optimization
"This paper explores network structures, contextualized embeddings and pre-training strategies aimed at capturing discourse characteristics of essays",Resources,Resources
"we present a simple and effective method for assessing the proficiency of language learners, as well as the difficulty of linguistic concepts, by utilizing the Elo formula, (Elo, 1978)— in an unsupervised fashion.",New Algorithm/ Method,New Algorithm/ Method
"We present a unique dataset of student sourcebased argument essays to facilitate research on the relations between content, argumentation skills, and assessment",Dataset Creation,Dataset Creation
"we designed a principled framework of boosting response generation,
based on the recently developed theory of boosting generative models",New Algorithm/ Method,New Algorithm/ Method
"we propose an adversarial training algorithm to learn two sets
of better word weights which contribute to
two emotion dimensions in two attention layers.",New Algorithm/ Method,New Algorithm/ Method
"Two auxiliary tasks are designed to enhance
the labeling of ATE and ASC, and an extra
RNN cell ReGU is proposed to improve the
capability of feature extraction.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose an approach that provides an
entity-level representation in a simple and intuitive
manner, and also facilitates end-to-end optimization.",New Algorithm/ Method,New Algorithm/ Method
"We analyze the discriminative features that
help the best performing method, string kernels, in (i) distinguishing the Moldavian and
the Romanian dialects and in (ii) categorizing the text samples by topic.",Algorithm/Method Optimization,Algorithm/Method Optimization
we focus on the transferability of our methods from biased datasets to ones having different or no biases.,New Algorithm/ Method,New Algorithm/ Method
We propose a Siamese neural network architecture shown to outperform several baselines on both a prior convincingness data set and our own.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose a new task: emotion-cause pair extraction (ECPE). It solves the shortcomings of the traditional ECE task that depends on the annotation of emotion before extracting cause, and allows emotion cause analysis to be applied to real-world scenarios.",New Algorithm/ Method,New Algorithm/ Method
"we introduce a new word replacement order determined by both the word saliency and the classification probability, and propose a greedy algorithm called probability weighted word saliency (PWWS) for text adversarial attack.",New Algorithm/ Method,New Algorithm/ Method
we propose a strong unsupervised system for parallel sentence mining and show that the mined data improves the performance of unsupervised MT systems.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose a simple algorithm on top of these parses that allows us to control the average chunk size, which in turn limits the number of autoregressive decoding steps we have to perform.",New Algorithm/ Method,New Algorithm/ Method
"We introduce a “Co-curricular learning”, for transfer learning across data quality. It extends the single curriculum learning work in NMT and makes
the existing domain-data selection method
work better with noisy data.",Theory Proposal,Theory Proposal
"we propose an imitation learning framework for nonautoregressive machine translation, which still enjoys the fast translation speed but gives comparable translation performance compared to its auto-regressive counterpart.",New Algorithm/ Method,New Algorithm/ Method
"We extend the recently-proposed Average Lagging latency metric, making it differentiable and calculable in expectation, which allows it to be used as a training objective.",New Algorithm/ Method,New Algorithm/ Method
"Our ARNOR framework achieves significant improvement over state-of-the-art noise reduction methods, in terms of both RC performance and noise reduction effect.",Algorithm/Method Optimization,Algorithm/Method Optimization
"We evaluate our method even with contextual embeddings. The relative performance of
the adaptation alternatives remain fairly stable whether the adapted embeddings are used
on their own, or concatenated with contextsensitive embeddings",Performance Evaluation,Performance Evaluation
Our aim in this paper is to integrate the advantages of TMs into NMT systems in order to improve MT quality by utilizing existing translations for highly similar source sentences in a given TM,Applications,Applications
"we attempt to obtain diverse translations by using sentence codes to condition the sentence generation. We describe two methods to extract the codes, either with or without the help of syntax information.",Theory Proposal,Algorithm/Method Optimization
"we propose a method to distill the important domain signal as part of a multi-domain learning system, using a latent variable model in which parts of a neural model are stochastically gated based on the inferred domain.",New Algorithm/ Method,New Algorithm/ Method
"we propose a new head-modifier templatebased method to improve the readability and data fidelity of generating type descriptions, which is also the first attempt of integrating head-modifier rule into neural generative models",New Algorithm/ Method,New Algorithm/ Method
"We propose a syntax-infused VAE that integrates syntactic trees with sentences, to grammatically improve the generated sentences. i",New Algorithm/ Method,New Algorithm/ Method
"We propose a simple domain embedding approach to merge the sourceand target-domain training data, which is shown to be more effective than both direct corpus concatenation and multi-task learning.",Theory Proposal,Theory Proposal
We propose a domain adaptive dialog generation method based on meta-learning (DAML). DAML is an end-to-end trainable dialog system model that learns from multiple rich-resource tasks and then adapts to new domains with minimal training samples.,New Algorithm/ Method,New Algorithm/ Method
Our goal is to design a counter-argument generation system to address the above challenges and produce paragraph-level arguments with rich-yetcoherent content.,Theory Proposal,Theory Proposal
we propose a sequence-level training method based on a novel reinforcement algorithm for NAT to reduce the variance and stabilize the training procedure,New Algorithm/ Method,New Algorithm/ Method
"We propose SynGCN, a Graph Convolution based method for learning word embeddings. Unlike previous methods, SynGCN utilizes syntactic context for learning word representations without increasing vocabulary size.",New Algorithm/ Method,New Algorithm/ Method
"we demonstrate that our proposed methods obtain substantial improvement over state-of-the-art approaches, and also yield an advantage when used in conjunction with
methods",Algorithm/Method Optimization,Algorithm/Method Optimization
"Based on BERT, we introduce target word embedding dropout for helping substitute candidate proposal, and a substitute candidate validation method based on the substitution’s influence on the global contexts.",New Algorithm/ Method,New Algorithm/ Method
a method for assessing the credibility of claims derived from medical usergenerated content.,New Algorithm/ Method,New Algorithm/ Method
we propose a noise-added strategy to add noise samples into the training set in the form of pseudo data,Theory Proposal,Theory Proposal
"we investigate the potential of using MT methods to normalize non-canonical texts in Turkish, a morphologically-rich, agglutinative language, allowing for a very large number of common word forms.",Performance Evaluation,Performance Evaluation
", we present an improved and effective methodology to classify domain-specific freeform speech commands while utilizing this direct classification and transfer learning approaches.",Algorithm/Method Optimization,Algorithm/Method Optimization
We introduce a hybrid Convolutional Neural Network (CNN) and Long Short Term Memory Network (LSTM) approach to dementia detection that takes advantage of both targeted and implicitly learned features to perform classification.,New Algorithm/ Method,New Algorithm/ Method
propose a method that uses graph embeddings for integrating structured information from the knowledge base with unstructured information from text-based representations,New Algorithm/ Method,New Algorithm/ Method
"we introduce a demo system of
our in-house OL framework, in which we integrated our translation servers with the translators
user-friendly interface SDL Trados Studio",New Algorithm/ Method,New Algorithm/ Method
"we address these limitations
by introducing a tool that provides a flexible
and efficient way to query the Semantic Scholar
knowledge base, a semi-automatically constructed
knowledge base of scientific literature",New Algorithm/ Method,New Algorithm/ Method
"We present TARGER, an open source neural argument mining framework for tagging arguments in free input texts and for keyword-based retrieval of arguments from an argument-tagged web-scale corpus",New Algorithm/ Method,New Algorithm/ Method
we have described a method to merge multiple medical terminologies into a single network preserving both terminology-specific and cross-terminology relations.,New Algorithm/ Method,New Algorithm/ Method
"developed two systems based on bidirectional encoder representations from transformers (BERT) (Devlin, Chang, Lee, & Toutanova, 2018) for the two subtasks respectively",New Algorithm/ Method,New Algorithm/ Method
We propose an iterative algorithm to form a single representation for up-to l-length walks between the entities of a pair,New Algorithm/ Method,New Algorithm/ Method
we propose to improve the end-toend coreference resolution system by using a biaffine attention model to get antecedent scores for each possible mention,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose the HSCRF architecture which employs both word-level and segment-level labels for segment score calculation,New Algorithm/ Method,New Algorithm/ Method
we propose a joint CRF-HSCRF training framework and a naive joint decoding algorithm for neural sequence labeling,New Algorithm/ Method,New Algorithm/ Method
"We have devised a simple but effective strategy to deal with questions having options like none of the above, two of the above, all of the above, both (a) and (b) etc",Theory Proposal,Theory Proposal
we propose a method of dynamic sentence sampling (DSS) to improve the NMT training efficiency,Algorithm/Method Optimization,Algorithm/Method Optimization
we design a memory network method to capture discourse cohesion implicitly in order to improve discourse parsing,New Algorithm/ Method,New Algorithm/ Method
we apply a simple policy gradient method to train four different state-of-theart transition-based constituency parsers to maximize expected F1,Applications,Applications
"We investigated the impact of a specific
set of grammatical roles on coherence, we instead investigate a large set
of GR types, and train the model to predict the
type of role dependents participate in.",Performance Evaluation,Performance Evaluation
"We perform an extensive analysis of ways to represent the conversational-context in terms of the number of utterance history, and sampling strategy considering to use the generated sentences or the true preceding utterance.",Theory Proposal,Theory Proposal
"We present a universal representor to replace encoder and decoder, leading to a compact translation model, which fully explores the commonality between languages.",Model Optimization,Model Optimization
"we propose a new solution that can complete the multiple entityrelations extraction task with only one-pass encoding on the input corpus, and achieve a new state-of-the-art accuracy performance, as demonstrated in the ACE 2005 benchmark.",New Algorithm/ Method,New Algorithm/ Method
"We propose an entmax sparse output layer, together with a natural loss function. In largevocabulary settings, sparse outputs avoid wasting probability mass on unlikely outputs, substantially improving accuracy.",New Algorithm/ Method,New Algorithm/ Method
"we use adversarial training across tasks, to “softcode” shared and private spaces, to avoid the shared space gets too sparse.",Theory Proposal,Theory Proposal
"We note that our approach differs from other applications in the NLP literature in using the mean reward as our baseline, and in comparing different reward functions",Theory Proposal,Theory Proposal
"we aim not to merely study this phenomenon qualitatively, but instead to quantify the degree to which the language used to describe men and women is different and, moreover, different in a positive or negative way.",Theory Proposal,Theory Proposal
"It application of a well-studied graphical model to a
novel domain, outperforming previous approaches
on word and sentence-level translation retrieval tasks.",Applications,Applications
The proposed reordering mechanism can be easily integrated into the Transformer to learn reordering-aware sentence representation for machine translation.,Applications,Applications
we extend the architecture search approach to an important paradigm of transfer learning across multiple data sources: continual learning. The major problem in continual learning is catastrophic forgetting,New Algorithm/ Method,New Algorithm/ Method
"In order to adapt to non-parallel data, we design a cycle reinforcement learning algorithm CycleRL to guide the model training in an unsupervised way.",New Algorithm/ Method,New Algorithm/ Method
"We propose a new and effective framework for CQG, which is equipped with a dynamic reasoning component to generate a conversational question and is further fine-tuned via a reinforcement learning mechanism.",New Algorithm/ Method,New Algorithm/ Method
"We show the effectiveness of our method using the recent CoQA dataset. Moreover, we
show its wide applicability by using it to create multi-turn QA conversations for passages
in SQuAD",Performance Evaluation,Performance Evaluation
we propose to train the decoder in a sequence of steps that encourages the source and target embedding spaces to remain aligned during adaptation,Theory Proposal,Theory Proposal
"We introduce and experiment with various self-supervised approaches for extractive summarization, one of which achieves the new state-ofthe-art results with a basic hierarchical model.",Theory Proposal,Theory Proposal
Token-level cross-passage information interaction is implemented through the application of the proposed DynSA at relatively less computational costs.,New Algorithm/ Method,New Algorithm/ Method
QFE adaptively determines the number of evidence sentences by considering the dependency among the evidence sentences and the coverage of the question.,New Algorithm/ Method,New Algorithm/ Method
"we show that policy gradient fine-tuning learns an easy-first strategy, which reduces error propagation",Performance Evaluation,Performance Evaluation
We present the first ever application of this formalism to the task of realistic wide-coverage parsing.,Theory Proposal,Theory Proposal
"we survey the state of the art in constructing author profiling corpora for the first time, compiling a taxonomy of construction strategies applied.",Theory Proposal,Theory Proposal
"we show that in the multihop HotpotQA dataset, the examples often contain reasoning shortcuts through which models can directly locate the answer by word-matching the question with a sentence in the context.",Performance Evaluation,Performance Evaluation
"we perform a replication and a series of reproductions. These techniques were until recently quite rare in this field, despite the inherently repeatable nature of most natural language processing experiments.",Theory Proposal,Theory Proposal
We propose alternative evaluation metrics based on example difficulty and provide a reference implementation.,New Algorithm/ Method,New Algorithm/ Method
we apply a different analysis based on intermediate representation erasure to assess whether attention weights can instead be relied upon to explain the relative importance of the inputs to the attention layer itself.,New Algorithm/ Method,New Algorithm/ Method
"we propose to apply RSA to neural representations of strings from a language on one side, and to structured symbolic representations of these strings on the other side.",Theory Proposal,Theory Proposal
"we empirically show that our approach is competitive with previous work and that HardKuma has further applications,",New Algorithm/ Method,New Algorithm/ Method
We show how pre-trained BERT models can also be used and fine-tuned as the decoder in a language generation task.,Theory Proposal,Theory Proposal
we focus on the multilingual transfer setting where training data in multiple source languages is leveraged to further boost target language performance.,New Algorithm/ Method,New Algorithm/ Method
we investigate the problem of biomedical name embedding and its applications. We pay attention to the similarity between semantically related names as well as the names of the same concept.,Theory Proposal,Theory Proposal
we have manually annotated 100 sentences from the Turkish translation of the novel “The Little Prince” with AMRs to describe the differences between these annotations and their English counterparts,Theory Proposal,Theory Proposal
Our goal is to develop robust ASR systems for pathological speech and incorporate the ASR technology to detect their speech intelligibility problems.,New Algorithm/ Method,New Algorithm/ Method
The first is to provide a formal definition of the notion of informativeness applied to both sentential context (as a whole) and context words (taken individually).,Theory Proposal,Theory Proposal
"we show that ELMo models can be successfully fine-tuned on a small in-domain corpus, bringing significant improvements to strategies involving contextual embeddings.",Model Optimization,Model Optimization
"we apply and compare simple shallow capsule networks for hierarchical multi-label text classification and show that they can perform superior to other neural networks, such as CNNs and LSTMs, and non-neural network architectures such as SVMs.",Theory Proposal,Theory Proposal
"we characterize the available datasets as capturing various phenomena related to abusive language, and investigate this characterization in cross-domain classification.",New Algorithm/ Method,New Algorithm/ Method
This paper presents a new annotation tool that is designed to fill the niche of a lightweight interface for users with a terminal-based workflow.,New Algorithm/ Method,New Algorithm/ Method
"The entire operable SARAL system itself, an end-to-end CLIR and summarization system that combines SEARCHER and traditional IR techniques and applies them to text and speech documents in low-resource languages",New Algorithm/ Method,New Algorithm/ Method
We demonstrate the practical utility of our approach by applying it on a set of 67 novel event types.,Performance Evaluation,Performance Evaluation
", the system is designed to
make it easy to port to other application domains (e.g., the dialogue component factors
out domain-specific execution from domaingeneral actions such as requesting and updating slot values).",New Algorithm/ Method,New Algorithm/ Method
"we show that crossturn dependencies can be learned automatically, this eliminates the rule-based NBT component and effectively yields a fully statistical dialogue state tracker",Algorithm/Method Optimization,Algorithm/Method Optimization
we demonstrate the feasibility of using NLP for this task in the form of a highaccuracy classifier of actionable feedback,Model Optimization,Model Optimization
we apply our model to label 10.8M Twitter posts and 6.2M Reddit comments in order to evaluate the speed and type of user reactions to various news sources,Model Proposal,Model Proposal
we aim to give transparency and user-comprehensible explainability,Theory Proposal,Theory Proposal
we investigate the empirical hypothesis that NMT is able to learn from the good chunks of a noisy sentence and describe a simple way of utilizing such chunk-level feedback in NMT training,Theory Proposal,Theory Proposal
"We provide a detailed empirical comparison of various attention transformations, including softmax, sparsemax",Performance Evaluation,Performance Evaluation
We demonstrate the benefits of multilingual Neural NER on low-resource languages,Theory Proposal,Theory Proposal
"we provide a large number of highquality training examples which can be bootstrapped from state-of-the-art Open IE systems, which is released for future research",Dataset Creation,Dataset Creation
we conduct comprehensive experiments on a large benchmark dataset to compare different Open IE systems to show the neural approach’s promising potential,Performance Evaluation,Performance Evaluation
"We devise a new formulation of graphstructured stack (Tomita, 1991) which requires no extra bookkeeping, proving a new theorem that gives deep insight into GSS",New Algorithm/ Method,New Algorithm/ Method
"our parser is substantially faster for long sentences on the Penn Treebank, and orders of magnitude faster for end-to-end discourse parsing",Algorithm/Method Optimization,Algorithm/Method Optimization
"We evaluate the proposed model over two
real-world datasets. We adapt distant supervision with co-reference resolution and paraphrase detection to obtain high-quality training
data.",Model Optimization,Model Optimization
"We introduce the task of email subject line generation
(SLG) and build a benchmark dataset AESLC",New Algorithm/ Method,New Algorithm/ Method
"We propose the Multimodal EmotionLines Dataset (MELD), which includes not only
textual dialogues, but also their corresponding visual and audio counterparts.",Dataset Creation,Dataset Creation
"we extend, improve, and further develop the EmotionLines dataset for the multimodal
scenario.",Dataset Creation,Dataset Creation
"introduce a
new color-grid reference task and data set consisting of higher dimensional objects and more complex speaker language",Dataset Creation,Dataset Creation
"We propose a set of cross-domain coherence
datasets with increasingly difficult evaluation
protocols.",Dataset Creation,Dataset Creation
"We introduce a novel large corpus containing
33564 text samples written in the Moldavian
and the Romanian dialects",Dataset Creation,Dataset Creation
"We propose OneSeC (One Sense per Category), a novel fully-automatic method
that produces multilingual sense-annotated
datasets on a large scale by mapping
Wikipedia categories to word senses.",New Algorithm/ Method,New Algorithm/ Method
"we present SP-10K, which is unprecedented in both size and the number of SP
relations. It contains 10,000 selectional triplets
consisting of 2,500 frequent verbs, nouns, and
adjectives in American English.",Dataset Creation,Dataset Creation
"We propose a new dataset, ChID, for clozestyle reading comprehension in Chinese language. ChID contains 581K passages and
729K blanks from three domains",Dataset Creation,Dataset Creation
we explore the use of noisy counseling data obtained from public sources for the analysis of counseling quality,Performance Evaluation,Performance Evaluation
we obtain substantial improvement over prior models for both entities and negations on the 2010 i2b2/VA challenge task as well as a proprietary de-identified clinical note dataset for medical conditions,Model Optimization,Model Optimization
"we present a new data set, IBMEviConv, of pairs of evidence labeled for convincingness, designed to be more challenging than existing alternatives.",Dataset Creation,Dataset Creation
"Based on a benchmark ECE corpus, we construct a corpus suitable for the ECPE task. The experimental results prove the feasibility of the ECPE task as well as the effectiveness of our approach.",Dataset Creation,Dataset Creation
We introduce the first large-scale multi-document summarization datasets in the news domain.,Dataset Creation,Dataset Creation
"To learn such an embedding, we create the largest distant supervision dataset by linking the entire English ClueWeb09 corpus to Freebase. The dataset is publicly available",Dataset Creation,Dataset Creation
"We extend the GPT to handle bag-level, multi-instance training and prediction for distantly supervised datasets, by aggregating sentence-level information with selective attention to produce bag-level predictions",New Algorithm/ Method,New Algorithm/ Method
"We perform extensive experiments on five publicly available datasets for entity alignment tasks, and achieve significant improvements of 5% Hits@1 on average. Further ablation study demonstrates the effectiveness of our key components.",Dataset Creation,Dataset Creation
"We propose new formulations for training topicspecific embeddings on a limited target corpus DT by adapting generic pre-trained word embeddings E, and/or selecting from any available broad-coverage corpus DS",New Algorithm/ Method,New Algorithm/ Method
We also show that the existing paths in the dataset are not ideal for evaluating instruction following because they are direct-to-goal shortest paths. We join existing short paths to form more challenging extended paths to create a new data set,Performance Evaluation,Performance Evaluation
We create a novel human language guided image editing dataset to boost the study in describing visual relationships,New Algorithm/ Method,New Algorithm/ Method
"We contribute a new dataset, named as VID-sentence, to serve as a benchmark for the novel WSSTG task",Dataset Creation,Dataset Creation
we propose a data-collection task formulated as a collaborative game prompting two online participants to refer to images utilising both their visual context as well as previously established referring expressions.,Dataset Creation,Dataset Creation
"we propose a new dataset with two new automatic metrics for this task, and experiments show that our method achieves stateof-the-art performance on both datasets.",Dataset Creation,Dataset Creation
"We propose a method to construct a pseudo parallel dataset for the surface realization model, without the need of labeled data.",New Algorithm/ Method,New Algorithm/ Method
"we create a new dataset, that contains 1716 summaries for papers from several computer science conferences, that can be used as training data",Dataset Creation,Dataset Creation
the new state-of-the-art performance on five real-world datasets in a setting where a model is able to determine the number of keyphrases to generate.,New Algorithm/ Method,New Algorithm/ Method
"we present a novel dataset, BIGPATENT, consisting of 1.3 million records of U.S. patent documents along with human written abstractive summaries.",Dataset Creation,Dataset Creation
a large-scale multi-sentence compression corpus is introduced along with a manually created test set for future research. We release source code and data here,Dataset Creation,Dataset Creation
"we introduce a cross-lingual OpenQA dataset called XQA. It consists of a training set in English, and development and test sets in English, French, German, Portuguese, Polish,Chinese, Russian, Ukrainian, and Tamil.",Dataset Creation,Dataset Creation
We create a new dataset for multi-modal Twitter sarcasm detection and release it,Dataset Creation,Dataset Creation
we explore the task of predicting human activities from user-generated content. We collect a dataset containing instances of social media users writing about a range of everyday activities.,Dataset Creation,Dataset Creation
"We propose a silver dataset containing user-generated reviews labelled with a approximation of the socio-economic status of their author, based on the price range of restaurants",Dataset Creation,Dataset Creation
"To address real-world, large-scale application scenarios and to facilitate the possibility of adopting modern ‘data-hungry’ language models in this domain, we collect a new largescale book review dataset from goodreads.com.",Dataset Creation,Dataset Creation
"we report on the construction of the first large-scale corpus of celebrity profiles, describing our acquisition approach based on a reliable matching of Twitter accounts to Wikidata items.",Theory Proposal,Theory Proposal
"We create a dataset for ranking constructive comments including 100K+ Japanese comments with constructiveness scores, in collaboration with Yahoo! News. Our dataset will be publicly available.",Dataset Creation,Dataset Creation
We propose the task of cross-modal automatic commenting (CMAC) and construct a large-scale dataset.,Dataset Creation,Dataset Creation
We introduce a novel data set of tweets posted by U.S. politicians who self-reported their tweets using a signature.,Dataset Creation,Dataset Creation
We use a back-translation procedure that generates pseudo source sentences paired with the true summaries to build a training corpus for the cross-lingual ASSUM.,New Algorithm/ Method,New Algorithm/ Method
A massive collection of parallel texts for over 300 diverse languages is our main contribution to facilitate multilingual NLP,Dataset Creation,Dataset Creation
We propose the creation of a dataset to learn the QAR strategy with weak supervision.,Dataset Creation,Dataset Creation
we build a corpus of New Zealand English tweets containing Maori loan- ¯ words,Theory Proposal,Theory Proposal
We present a Telugu-English code-mixed corpus with the corresponding named entity tags.,Theory Proposal,Theory Proposal
", we introduce the French
CASS dataset, composed of judgments from
the French Court of cassation and their corresponding summaries.",Dataset Creation,Dataset Creation
"we introduce manually verified corpus of compelling fake and questionable news articles on the USA politics, containing around 700 articles from Aug-Nov, 2016",Theory Proposal,Theory Proposal
we visualize probably the first job posting data set with labels from domain experts showing the intensity of PhD-level research skills,Dataset Creation,Dataset Creation
"we present a ranking-based model that has been successfully applied to predicting PhD skills intensity from job postings, with empirical performance evaluation.",Model Proposal,Model Proposal
we use a generic and simple frame-slots data-structure with pre-defined dialogue policies that allows for fast design and implementation at the price of some flexibility reduction.,New Algorithm/ Method,New Algorithm/ Method
"We benchmark OpenKiwi on two datasets from WMT 2018 (English-German SMT and NMT), yielding state-of-the-art performance on the word-level tasks and near state-of-the-art in the sentencelevel tasks",Performance Evaluation,Performance Evaluation
"we provide an annotated dataset of 5,727 partwhole relations , which contains 8 subtypes for the bootstrapping RE system",Dataset Creation,Dataset Creation
we study how to automatically extract such relationship through a sentence-level relation classifier and aggregating the scores of entity pairs from a large corpus,Theory Proposal,Theory Proposal
we propose a large structured dataset of automatically linguistically annotated software developer conversations for feature exploration,Dataset Creation,Dataset Creation
we propose a smaller manually-labeled subset of that dataset for hypothesis testing,Dataset Creation,Dataset Creation
We demonstrate the usefulness of this general-domain dataset by applying an existing visual-linguistic annotation framework that successfully annotates image regions by combining gaze and language data,Theory Proposal,Theory Proposal
"we study the performance of plagdet, the main measure for Plagiarism Detection Systems evaluation, on manually paraphrased plagiarism datasets (such as PAN Summary)",Performance Evaluation,Performance Evaluation
we design a large scale news dataset with 1.02 million sentence compression pairs are compiled for this task in addition to 200 manually created sentences.,Dataset Creation,Dataset Creation
"We annotate the first medical dataset for dialogue system that consists of two parts, one is self-reports from patients and the other is conversational data between patients and doctors",Dataset Creation,Dataset Creation
we incorporate knowledge of the lexico-syntactic fixedness of VNCs — automatically acquired from corpora using the method of Fazly et al. (2009) — into our various embedding-based approaches,Theory Proposal,Theory Proposal
we verified the effectiveness of the method on public data sets,Performance Evaluation,Performance Evaluation
"we construct the discourse dependency corpus SciDTB1 . based on scientific abstracts, with the reference to the discourse dependency representation in Li et al. (2014)",Dataset Creation,Dataset Creation
"we show that metadata is crucial for modeling voting outcomes in new contexts, as changes between sessions lead to changes in the underlying data generation process",Model Optimization,Model Optimization
"We introduce pivot translation into unsupervised NMT to improve the accuracy of distant
languages.",Model Optimization,Model Optimization
"We propose an n-gram based attention model
to effectively map the multi-word mentions of
entities and their relationships into uniquely
identified entities and predicates.",Model Proposal,Model Proposal
"we empirically show that multimodal learning with audio and text can indeed reduce prediction error, compared to previous work that relies
on text only.",Performance Evaluation,Performance Evaluation
"we try to model the multidimensional learning task as a multi-task learning
task through adversarial learning.",Model Proposal,Model Proposal
"We propose global fusion to obtain an overall view of multimodal embeddings via a specifically designed ABS-LSTM, in which we integrate two levels of attention mechanism: Regional Interdependence Attention and Global Interaction Attention.",New Algorithm/ Method,New Algorithm/ Method
"We propose the factored tensor network FTN
to model the complex semantic interactions,
and it has the advantage of significantly reducing the complexity of the original model",Model Optimization,Model Optimization
"This paper codifies model and task agnostic principles for
informative error analysis, and presents Errudite, an interactive tool for better supporting this process.",Model Proposal,Model Proposal
"we propose a new fully-trainable, language-independent mention detectors that outperform the Stanford CORE mention detector in a variety of genres.",Algorithm/Method Optimization,Algorithm/Method Optimization
introduce a constrained decoding approach for Seq2Seq models that leverages this representation to improve semantic correctness,New Algorithm/ Method,New Algorithm/ Method
"We show that the proposed approaches outperform baselines in both indomain and cross-domain evaluation, demonstrating that the model learns domain-agnostic walking
patterns that are generalizable for unseen domains.",Model Optimization,Model Optimization
we propose a graph-based evidence aggregating and reasoning (GEAR) framework which enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multievidence information.,New Algorithm/ Method,New Algorithm/ Method
our goal is to induce semantic information from the proposed multimodal model into an acoustic model. We study a more challenging scenario where we establish that lexical information is available during,Model Proposal,Model Proposal
"We introduce a multi-task learning framework based on the neural network model, transformer",New Algorithm/ Method,New Algorithm/ Method
"we present a novel approach to CWI based on sequence modelling. Our system is capable of performing CWI in context, does not require extensive feature engineering and outperforms state-of-the-art systems on this task",New Algorithm/ Method,New Algorithm/ Method
we incorporate the global lattice structure into the model through reachability masks that mimic the pairwise conditioning structure of previous recurrent approaches.,Model Optimization,Model Optimization
"we introduce a model suitable for this scenario, and demonstrate that it is effective on our new benchmarks without sacrificing performance as measured with BLEU.",Model Proposal,Model Proposal
"We extend a novel graph neural network model with generated parameters, to enable relational message-passing with rich text information, which could be applied to process relational reasoning on unstructured inputs such as natural language.",Model Proposal,Model Proposal
"We incorporate the embeddings of characterwise/word-wise BIO tag from NER task to enrich the input representation, which proves to be very effective not only for our model but for other models as well.",Model Optimization,Model Optimization
"We propose a novel neural framework named MGNER for Multi-Grained Named Entity Recognition, aiming to detect both nested and non-overlapping named entities effectively in a single model",New Algorithm/ Method,New Algorithm/ Method
"MGNER is highly modularized. Each module
in MGNER can adopt a wide range of neural network designs. Moreover, MGNER can
be easily extended to many other related information extraction tasks.",Applications,Applications
we show experimental results show that our model significantly outperforms previous methods of using gazetteers and the state-of-the-art Chinese NER models,Model Optimization,Model Optimization
"we propose an alternative approach to address this limitation, and in particular, to train models by marginalizing over the set of segmentations",Model Optimization,Model Optimization
We propose a phrase prediction model that improves the performance of state-of-the-art word-level language models,Model Optimization,Model Optimization
We introduce an adaptive optimizer to selfadjust the number of iterations for each example in order to improve instance-level convergence and enhance the reliability of routing processes.,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a neural P2C conversion model augmented by an online updated vocabulary with a sampling mechanism to support open vocabulary learning during IME working.,Model Proposal,Model Proposal
we propose a method to simultaneously learn tokenization and text classification to address these problems. Our model incorporates a language model for unsupervised tokenization into a text classifier and then trains both models simultaneously,New Algorithm/ Method,New Algorithm/ Method
"we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others.",Performance Evaluation,Performance Evaluation
"We introduce LSTMEmbed, an RNN model based on a bidirectional LSTM for learning word and sense embeddings in the same semantic space, which – in contrast to the most popular approaches to the task – takes word ordering into account.",Model Proposal,Model Proposal
The proposed translation models outperform the state-of-the-art NMT baselines systems with a similar number of parameters and achieve comparable results compared to NMT systems with much more parameters.,Applications,Applications
"we analyze the performance of different models on different types of constituents, and find that our model shows substantial improvement on noun phrases and prepositional phrases which are common in captions",Performance Evaluation,Performance Evaluation
"We design novel relationalspeaker models, including a dynamic relational
attention module, to handle the problem of twoimage captioning by focusing on all their visual
relationships",Model Proposal,Model Proposal
We conduct extensive experiments showing that our model outperforms the state-of-theart both in automated and human evaluations.,Performance Evaluation,Performance Evaluation
"We propose a sentiment intensity controlled generative model Seq2SentiSeq, in which a sentiment intensity value is introduced via a Gaussian kernel layer to achieve fine-grained sentiment control of the generated sentence.",Model Proposal,Model Proposal
"We propose to break up the table-to-text generation into two stages with two separate models, so that the model can be trained with fewer annotated data.",Model Proposal,Model Proposal
"We redesign the ELBO of the joint log likelihood, to accommodate two separate latent spaces in one VAE framework, for two SIVAE model variants based on different intuitions, which can be further used for other applications.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we utilize a multi-level decoder structure to capture the coherent long-term structure inherent in long-form texts, by generating intermediate sentence representations as highlevel plan vectors.",New Algorithm/ Method,New Algorithm/ Method
"we extend supervised DIM to semi-supervision setup (SEMIDIM), where unsupervised learning objectives based on unlabeled data are also optimized",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose that the rich multi-modal data from recording the meeting environment, especially cameras facing each participant, can provide speaker interaction and participant feedback to discover salient utterances.",Theory Proposal,Theory Proposal
We introduce multi-style learning that enables our model to control answer styles and improves RC for all styles involved.,New Algorithm/ Method,New Algorithm/ Method
We use a co-attention mechanism to model sentence coherence and integrate the coherenceand entailment-based attentions into our proposed hierarchical attention framework for better evidence embedding,New Algorithm/ Method,New Algorithm/ Method
we analyze the usefulness of a user’s network information over the user’s tweets for predicting its occupational group. We extend the existing dataset for occupation classification by introducing the network information about a user,Theory Proposal,Theory Proposal
we propose the WMM2Seq for dialog generation which separates the storage of dialog history and KB information by using the episodic and semantic memories and then leverages the working memory to interact with them,Theory Proposal,Theory Proposal
"we consider an extension to the FC scenario, where a practitioner has the computational capacity to fit multiple models in parallel.",New Algorithm/ Method,New Algorithm/ Method
It seamlessly integrates implicit anticipation and translation in a single model that directly predicts target words without explictly hallucinating source ones.,Model Proposal,Model Proposal
Our prefix-to-prefix framework is tailored to simultaneous translation and trained from scratch without using full-sentence models.,New Algorithm/ Method,New Algorithm/ Method
"We combine the ability of BERT to handle sentence pair inputs together with its pre-trained multilingual model, to use both the src and mt in a cross-lingual encoder, that takes a multilingual sentence pair as input",New Algorithm/ Method,New Algorithm/ Method
"we propose a framework, which
we call LANGRANK, to empirically answer the
question posed above: given a particular task lowresource language and NLP task, how can we determine which languages we should be performing
transfer",New Algorithm/ Method,New Algorithm/ Method
"We propose a morphology-aware alignment model for unsupervised bilingual lexicon induction, which aims to alleviate the adverse effect of morphological variation by introducing grammatical information learned from pre-trained language model.",Model Proposal,Model Proposal
"We demonstrate a speed-up of several orders of magnitude when predicting word similarity by vector operations on our embeddings as opposed to directly computing the respective path-based measures, while outperforming various other graph embeddings",New Algorithm/ Method,New Algorithm/ Method
"we design an NPI-based model that simulates the editing process by a programmer and an interpreter, which outperforms the state-of-the-art neural MT-based TS models by large margins in terms of SARI and is judged by humans as simpler and overall better",Model Proposal,Model Proposal
"It proposes the use of a unique combination of lexical, sentiment, durational and further derivative features of adjacency pairs to train traditional classification models",Dataset Creation,Dataset Creation
"r aims to improve existing document
embedding models (Le and Mikolov, 2014; Li
et al., 2016a) by training document embeddings
using cosine similarity instead of dot product",Model Optimization,Model Optimization
r presents an alternative to the current morpheme-based scheme for Japanese word segmentation,Theory Proposal,Theory Proposal
"we propose a joint neural model to simultaneously extract names and kinships from obituaries, which combines a two-layer bidirectional Long Short-Term Memory (bi-LSTM) (Hochreiter and Schmidhuber, 1997) and a unique tagging scheme",Model Proposal,Model Proposal
"we exploited ensembles based on a pretrained language representation with a neural transformer architecture (BERT) (Tasks 1
and 4) and a CNN-BiLSTM(-CRF) network
within a multi-task learning scenario",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel architecture that encodes
locally stored domain information into sentence representation.",New Algorithm/ Method,New Algorithm/ Method
"we propose a new approach for learning thematic relatedness between sentences, formulating the related TDC task and creating a thematic clustering benchmark",New Algorithm/ Method,New Algorithm/ Method
"we propose a new approach to triclustering, achieving state-of-the-art performance on the frame induction task",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose an approach based on linguistic knowledge for identification of aliases mentioned using proper nouns, pronouns or noun phrases with common noun headword",New Algorithm/ Method,New Algorithm/ Method
we propose a new parallel recurrent neural network model for entity recognition,Model Proposal,Model Proposal
we use named entities as domain-specific terms for newscentric content and present a new weighting model for Latent Dirichlet Allocation,Model Proposal,Model Proposal
we study the problem of word ambiguities in definition modeling and propose a possible solution by employing latent variable modeling and soft attention mechanisms,Theory Proposal,Theory Proposal
The proposed CNN model performs comparatively or better than LSTM-based baselines on two different datasets,Model Proposal,Model Proposal
we extend the beam search to introduce more flexibility,Algorithm/Method Optimization,Algorithm/Method Optimization
"we analized the the encoder-decoder framework learns the sequence-to-sequence task directly, bypassing other hand-crafted patterns and alleviating error propagation",Performance Evaluation,Performance Evaluation
"we model the response
selection problem as a multi-class classification
problem with sequences as input, where the label of the true response is set to one and the
other candidates are set to zero.",Model Proposal,Model Proposal
"we introduce a different way to
handle reentrancy, and propose an attention-based model that treats AMR parsing as sequence-tograph transduction.",Model Proposal,Model Proposal
"we propose a novel
reliability-aware name tagging model to tackle
this issue. We design a set of word frequencybased reliability signals to indicate the quality
of each word embedding.",Model Proposal,Model Proposal
"We propose an end-to-end model for extract-
ing and canonicalizing triples to enrich a KB.
The model reduces error propagation between
relation extraction and NED, which existing
approaches are prone to.",Model Proposal,Model Proposal
"We propose the novel AGGCNs that learn a
“soft pruning” strategy in an end-to-end fashion, which learns how to select and discard
information. Combining with dense connections, our AGGCN model is able to learn a
better graph representation",Model Proposal,Model Proposal
"we proposed DihEdral to model
the relation in KG with the representation of dihedral group. The elements in a dihedral group are
constructed by rotation and reflection operations
over a 2D symmetric polygon.",Model Proposal,Model Proposal
we propose a novel recursive neural network architecture consisting of a decomposable attention framework in every branch,New Algorithm/ Method,New Algorithm/ Method
"It proposes a probabilistic model,
JELTA, which jointly estimates the credibility of
claims and the trustworthiness of sources, when
claims are made by sources directly, indirectly, or
both",Model Proposal,Model Proposal
"Our framework incorporates a TE model
as part of the global inference framework as a way
to link evidence (and thus, sources) to claims.",Model Proposal,Model Proposal
"We propose
a novel model to generate email subjects. Our automatic and human evaluations demonstrate that
our model outperforms competitive baselines and
approaches human-level quality.",Model Proposal,Model Proposal
"We propose a generic hierarchical fusion strategy, termed ‘divide, conquer and combine’, to explore both local and global interactions in multiple stages each focusing on
different dynamics.",New Algorithm/ Method,New Algorithm/ Method
"we propose an interactive multitask learning network (IMN), which solves both
tasks simultaneously, enabling the interactions between both tasks to be better exploited.",Model Proposal,Model Proposal
"we propose a novel Transfer
Capsule Network (TransCap) model to transfer
sentence-level semantic knowledge from DSC to
ASC.",Model Proposal,Model Proposal
"we
propose a progressive self-supervised attention learning approach for neural ASC models, which automatically mines useful attention supervision information from a training
corpus to refine attention mechanisms.",Model Optimization,Model Optimization
"A novel framework DOER is proposed to address the aspect term-polarity co-extraction
problem in an end-to-end fashion. A crossshared unit (CSU) is designed to leverage the
interaction of the two tasks",Model Proposal,Model Proposal
"We propose a MTL approach to coherence assessment
and compare it against a number of baselines",New Algorithm/ Method,New Algorithm/ Method
"we
designed a novel discourse relation identification pipeline specifically tuned for opendomain dialogue systems.",New Algorithm/ Method,New Algorithm/ Method
"we introduce Word Injection to LSC, a modeling idea drawn from term extraction, that overcomes the problem of vector space alignment.",Model Proposal,Model Proposal
"We introduce unified models for multi-task learning that learn three sets of features: task, task group, and task universe features;",Model Proposal,Model Proposal
"We propose a knowledge attention module,
which helps to select the most related and helpful knowledge from different KGs",Theory Proposal,Theory Proposal
we propose An end-to-end hierarchical neural model consisting of a shared encoder and different decoding schemes to jointly extract entities and negations.,Model Proposal,Model Proposal
"we present a novel method inspired by the determinantal point process for multi-document summarization. The method includes a diversity measure assessing the redundancy between sentences, and a quality measure that indicates the importance of sentences",New Algorithm/ Method,New Algorithm/ Method
we propose to learn topic-aware news representations by jointly training the news encoder with an auxiliary topic classification task,New Algorithm/ Method,New Algorithm/ Method
Proposing a novel end-toend sequence labeling architecture utilizing LDL to model the emphasis words in a given text.,New Algorithm/ Method,New Algorithm/ Method
"We propose a classifier by integrating multiple text feature sets, including the publicly available pre-trained textual language model Bi-directional Encoder Representation from transformers (BERT)",New Algorithm/ Method,New Algorithm/ Method
we propose the use of lattice positional embeddings to model positioning and ordering of lattice nodes.,Model Proposal,Model Proposal
"We propose the novel task of learning general-purpose embedding of textual relations, which has the potential to facilitate a wide range of relational understanding tasks",New Algorithm/ Method,New Algorithm/ Method
We present a novel and concise joint model to handle the joint type inference problem based on graph convolutional network,Model Proposal,Model Proposal
"We introduce a binary relation classification
task to explore the structure of entity-relation bipartite graph in a more efficient and interpretable way",New Algorithm/ Method,New Algorithm/ Method
"we propose GraphRel, a neural end-to-end joint model for entity recognition and relation extraction that is the first to handle all three key aspects in relation extraction",Model Proposal,Model Proposal
"we propose a neural pattern diagnosis framework, DIAG-NRE, that can automatically summarize and refine highquality relational patterns from noise data with human experts in the loop.",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel Multi-channel GNN model MuGNN that learns alignmentoriented embeddings by encoding graphs from different perspectives: completion and pruning, so as to be robust to structural differences.",Model Proposal,Model Proposal
"we propose a lightweight recurrent network (LRN), which combines the strengths of ATR and SRU. The structure of LRN is simple: an input gate and a forget gate are applied to weight the current input and previous hidden state, respectively",Model Proposal,Model Proposal
we focus on perfectly decodable encoding of sentences which will be very useful in designing good generative models that can generate longer sentences.,Theory Proposal,Theory Proposal
"we present a new approach to counterfactual data augmentation 
for mitigating gender stereotypes associated with
animate nouns for morphologically rich languages.",New Algorithm/ Method,New Algorithm/ Method
"we introduce a generative latent-variable model that jointly represents adjective choice, with its sentiment, given the natural gender of a head noun.",Model Proposal,Model Proposal
we first propose a relation-aware semantic projection model to estimate probabilistic distributions of lexical relations over unlabeled data.,Model Proposal,Model Proposal
"we introduce a novel ‘continual architecture search’ (CAS) approach, where the model parameters evolves and adapts when trained sequentially on a new task while maintaining the performance on the previously learned tasks.",New Algorithm/ Method,New Algorithm/ Method
we propose a novel aspect-aware coarse-tofine decoder for generating product reviews. We first utilize unsupervised topic models to extract aspects and tag review sentences with aspect labels.,New Algorithm/ Method,New Algorithm/ Method
We propose a novel metaphor and personification generation model with a rhetorically controlled encoder-decoder.,New Algorithm/ Method,New Algorithm/ Method
We propose a memory-augmented neural model with adversarial training to integrate external commonsense knowledge into topicto-essay generation.,Model Proposal,Model Proposal
"we propose various multi-level network structures for the VAE model (ml-VAE), to address coherency and repetitiveness challenges associated with long-form text generation.",Theory Proposal,Theory Proposal
"we propose a novel data-totext generation model with two modules, one for saliency tracking and another for text generation.",Model Proposal,Model Proposal
"we propose the Extended Transformer model for Abstractive Document Summarization (ETADS) to tackle the above issues. Specifically, we design a novel focusattention mechanism and saliency-selection network equipped in the encoder and decoder",Model Proposal,Model Proposal
We propose a novel unsupervised end-to-end model to generate an abstractive summary of a single product review while inducing a latent discourse tree,Model Proposal,Model Proposal
We propose an RL approach with a novel adaptive reward function that explicitly encourages the model to generate both sufficient and accurate keyphrases,New Algorithm/ Method,New Algorithm/ Method
a new evaluation method that considers name variations of the keyphrase labels,Performance Evaluation,Performance Evaluation
"we propose a multi-modal hierarchical attention mechanism across topic segments, utterances, and words. We learn topic segmentation as an auxiliary task and limit the attention within each segment.",New Algorithm/ Method,New Algorithm/ Method
"we propose an end-to-end MRC model named as Knowledge Aided Reader (KAR), which explicitly uses the above extracted general knowledge to assist its attention mechanisms.",Model Proposal,Model Proposal
"we propose RE3QA, a neural question answering model that conducts the full retrieve-read-rerank process for multi-document RC tasks.",Model Proposal,Model Proposal
We propose QFE for explainable multi-hop QA. We use the multi-task learning of the QA model for answer selection and QFE for evidence extraction.,New Algorithm/ Method,New Algorithm/ Method
"We devise a new approach KTNET to MRC. It outperforms competitive baselines, ranks the 1st place on the ReCoRD leaderboard, and is also the best single model on the SQuAD",Model Optimization,Model Optimization
We propose two novel methods to handle the simplified HPSG parsing.,New Algorithm/ Method,New Algorithm/ Method
"We are the first to introduce the deep transition architecture for sequence labeling, and further enhance it with the global contextual representation at the sentence level, named GCDT",Theory Proposal,Theory Proposal
"We conduct elaborate investigations of global contextual representation, model complexity and effects of various components in GCDT.",Performance Evaluation,Performance Evaluation
We propose a novel claim verification framework based on hierarchical attention neural networks to learn sentence-level evidence embeddings to obtain claim-specific representation,New Algorithm/ Method,New Algorithm/ Method
"we propose a simple, automatic recipe towards reducing hallucination for neural surface realisers by enhancing the semantic equivalence between pairs of MRs and utterances.",Theory Proposal,Theory Proposal
"We present a novel co-attention model, which aims at capturing intrinsic interactions between multiple modal contents.",Model Proposal,Model Proposal
We Propose a novel path-based reasoning approach for multi-hop QA over text that produces explanations in the form of explicit paths,New Algorithm/ Method,New Algorithm/ Method
"We design A model, PathNet, which aims to extract implicit relations from text and compose them",Model Proposal,Model Proposal
We define author context as the embedded representation of their historical posts on Twitter and suggest neural models that extract these representations.,Theory Proposal,Theory Proposal
we develop a novel framework for temporal relation representation that puts event duration front and center.,New Algorithm/ Method,New Algorithm/ Method
We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence.,New Algorithm/ Method,New Algorithm/ Method
we propose a novel model namely Reference Network that incorporates the referring process into translation decoding of NMT.,Model Proposal,Model Proposal
we propose a hard-attention based NMT model which selects a subset of source tokens for each target token to effectively handle long sequence translation.,Model Proposal,Model Proposal
we propose a sentencelevel agreement module to directly minimize the difference between the representation of source and target sentence.,New Algorithm/ Method,New Algorithm/ Method
"we introduce the topic entity graph, a local sub-graph of an entity, to represent entities with their contextual information in KG.",Theory Proposal,Theory Proposal
we focus on methods for cross-lingual transfer to distant languages and propose to learn a generative model with a structured prior that utilizes labeled source data and unlabeled target data jointly,Theory Proposal,Theory Proposal
"we propose to encode relational knowledge in a separate word embedding, which is aimed to be complementary to a given standard word embedding.",New Algorithm/ Method,New Algorithm/ Method
we propose a word embedding model which explicitly aims to learn context vectors that are organised in clusters.,Model Proposal,Model Proposal
"We propose a BERT-based end-to-end lexical substitution approach without relying on
any annotated data and external linguistic resources.",New Algorithm/ Method,New Algorithm/ Method
We propose a novel Seq2Seq model that decomposes the paraphrase generation into learning paraphrase patterns at different granularity levels separately,Model Proposal,Model Proposal
a methodology for testing existing models and proposed extensions.,New Algorithm/ Method,New Algorithm/ Method
proposing the use of Inverted Softmax and Cross-modal Local Scaling to replace naive nearest neighbor search (for inference).,Theory Proposal,Theory Proposal
"we present a recurrent neural model to detect ad hominem attack in a paragraph, and we experiment with various other models to compare them",Model Proposal,Model Proposal
We put forward a shared Bi-LSTM-CRF model for efficiently integrating multiple embeddings and sharing useful linguistic features;,Model Proposal,Model Proposal
"we propose a
new training schedule that allows the system
to scale to more languages without modification of the previous components based on
joint training and language-independent encoder/decoder modules allowing for zero-shot
translation.",New Algorithm/ Method,New Algorithm/ Method
we develop a neural model based on a CNN-LSTM architecture that learns to detect AD and related dementias using targeted and implicitly-learned features from conversational transcripts,Model Proposal,Model Proposal
we build the NMT systems for both EN-ID and ID-EN directions using the Transformer model,New Algorithm/ Method,New Algorithm/ Method
"We propose a new strategy for using scheduled sampling in Transformer models by
making two passes through the decoder in
training time.",New Algorithm/ Method,New Algorithm/ Method
"we propose an approach
of using semantic similarity between the output
sequence and the ground-truth sequence to train
the generation model.",Theory Proposal,Theory Proposal
"We present a modular framework for the rapidprototyping of linguistic, web-based, visual
analytics applications.",New Algorithm/ Method,New Algorithm/ Method
We present a demonstration of a neural interactive-predictive system for tackling multimodal sequence to sequence tasks,Theory Proposal,Theory Proposal
provides pretrained conversational models that can be either used directly or loaded for fine-tuning or bootstrapping other models; these models power an online demo of our framework.,Model Proposal,Model Proposal
"we present PERSPECTROSCOPE, a web-based system which lets users query a discussion-worthy natural language claim, and extract and visualize various perspectives in support or against the claim, along with evidence supporting each perspective",New Algorithm/ Method,New Algorithm/ Method
"We demonstrate HEIDL, a prototype HITLML system that exposes the machine-learned model through high-level, explainable linguistic expressions formed of predicates representing semantic structure of text",New Algorithm/ Method,New Algorithm/ Method
"We describe My Turn
To Read, an app that uses interleaved reading
to help developing and struggling readers improve reading skills while reading for meaning
and pleasure.",New Algorithm/ Method,New Algorithm/ Method
"we present ClaimPortal, a webbased platform for monitoring, searching, checking, and analytics of factual claims on Twitter. ClaimPortal is available at https://idir.
uta.edu/claimportal",New Algorithm/ Method,New Algorithm/ Method
We propose a graph walk based neural model that considers multiple entity pairs in relation extraction from a sentence,Model Proposal,Model Proposal
we develop a linguistically-infused neural network model to classify reactions in social media posts,Model Proposal,Model Proposal
we model this task using CNN regression with an auxiliary ordinal regression objective,Model Proposal,Model Proposal
we propose an unified approach to filter noisy bitexts and to mine bitexts in huge monolingual texts,New Algorithm/ Method,New Algorithm/ Method
Our model takes question-option tuple to generate a score for the concerned option,Model Proposal,Model Proposal
"we gauge human ability to perform cross-lingual gender detection, an angle of analysis which has not been studied thus far",Theory Proposal,Theory Proposal
we propose an entity-centric neural crosslingual coreference model,Model Proposal,Model Proposal
"we propose a novel Document Embedding Enhanced Bi-RNN model, called DEEB-RNN, for ED at sentence level",Model Proposal,Model Proposal
we propose a model that jointly identifies the domain and tracks the belief states corresponding to that domain,Model Proposal,Model Proposal
We propose the task of automatically rating academic papers and build a new dataset for this task,New Algorithm/ Method,New Algorithm/ Method
"proposal of a novel interaction-over-interaction
network which enables deep-level matching with
carefully designed interaction block chains",New Algorithm/ Method,New Algorithm/ Method
"we propose a novel method for
zero-shot multilingual transfer, inspired by research in truth inference in crowd-sourcing, a related problem, in which the ‘ground truth’ must be
inferred from the outputs of several unreliable annotators",New Algorithm/ Method,New Algorithm/ Method
"We propose the learning to route
(LTR) method to automatically select the good
translation path",New Algorithm/ Method,New Algorithm/ Method
"We propose a machine learning algorithm that
uses self-regulation in order to balance the cost
and effect of learning from different types of feedback.",New Algorithm/ Method,New Algorithm/ Method
"We propose a systematic
and principled method of injecting semantic
change in a controlled fashion.",New Algorithm/ Method,New Algorithm/ Method
"We introduce a novel corpus on aspect-based
argument similarity and demonstrate how contextualized word embeddings help to improve clustering similar arguments in a supervised fashion with
little training data.",Dataset Creation,Dataset Creation
"We introduce the simplified topic model STM
to infer the latent topic-level representations
and employ such topic-level relevance to recognize Chinese implicit discourse relations.",Model Proposal,Model Proposal
we design a computational methodology to quantitatively track systematic changes along the two dimensions of within- and between-counselor linguistic diversification.,New Algorithm/ Method,New Algorithm/ Method
We present algorithms for finding both consistent and contrastive expansions and demonstrate their effectiveness empirically.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose a multimodal method that is inspired by the way humans process emotions in a conversation. That is, lexical and acoustic information is simultaneously perceived at every word step.",New Algorithm/ Method,New Algorithm/ Method
"We propose a two-step framework to address the ECPE task, which first performs individual emotion extraction and cause extraction and then conduct emotion-cause pairing and filtering.",New Algorithm/ Method,New Algorithm/ Method
We propose an end-to-end method to incorporate MMR into pointer-generator networks.,New Algorithm/ Method,New Algorithm/ Method
We propose a method for text categorization that complements implicit representation by leveraging a predominant sense of a word.,New Algorithm/ Method,New Algorithm/ Method
we propose a new multi-task learning approach for rumor detection and stance classification tasks.,New Algorithm/ Method,New Algorithm/ Method
It systematically studies word alignment from NMT and proposes two approaches to induce word alignment which are agnostic to specific NMT models,Model Proposal,Model Proposal
"We present MILk attention, which allows us to build the first simultaneous MT system to learn an adaptive schedule jointly with an NMT model that attends over all source tokens read thus far",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel attention regularization method for reducing the noise in DS. Our method forces the model to clearly explain the relation patterns in terms of attention, and selects trustable instances if they can be explained by the model.",New Algorithm/ Method,New Algorithm/ Method
We propose novel algorithms to generate more natural adversarial examples that both preserve the semantics and mislead the classifiers.,New Algorithm/ Method,New Algorithm/ Method
"we present our method for learning representations from imperfect human language across the language, visual, and acoustic modalities.",New Algorithm/ Method,New Algorithm/ Method
we propose a near lossless method for encoding long sequences of texts as well as all of their sub-sequences into feature rich representations.,New Algorithm/ Method,New Algorithm/ Method
"We propose a debiasing method that preserves the genderrelated information in feminine and masculine
words",New Algorithm/ Method,New Algorithm/ Method
We propose a simple method for TM-NMT integration that is based on augmenting the source data with retrieved fuzzy TM targets by means of concatenation.,New Algorithm/ Method,New Algorithm/ Method
we propose an approach based on dynamic linear combination of layers (DLCL) to memorizing the features extracted from all preceding layers.,Theory Proposal,Theory Proposal
"we propose a new and simpler method without a priori parallel corpora. Our premise is that NMT systems —either sequence to sequence models with RNNs, transformers, or any architecture based on encoder–decoder models",New Algorithm/ Method,New Algorithm/ Method
we introduce a novel constraint-driven approach to learning a document-level (‘global’) co-reference model without using any document-level annotation;,Model Proposal,Model Proposal
we propose a reinforcement learning (RL) framework that synchronously searches for training instances relevant to the target domain and learns better representations for them.,New Algorithm/ Method,New Algorithm/ Method
"We introduce a new task of Conversational Question Generation (CQG), which is crucial for developing intelligent agents to drive question-answering style conversations and can potentially provide valuable datasets for future relevant research.",New Algorithm/ Method,New Algorithm/ Method
We propose a novel bi-directional selective mechanism with two gates to mutually select important information from both article and template to assist with summary generation,New Algorithm/ Method,New Algorithm/ Method
We develop a Fast Rerank method to automatically select high-quality templates from training corpus.,Dataset Creation,Dataset Creation
"we propose a method to learn to select sentence singletons and pairs, which then serve as the basis for an abstractive summarizer to compose a summary sentence-by-sentence, where singletons are shortened and pairs are merged",New Algorithm/ Method,New Algorithm/ Method
We design a new network that can answer inferential question by recursively deducing the evidence chain from the text,New Algorithm/ Method,New Algorithm/ Method
We propose an effective termination mechanism which can dynamically determine the uncertain reasoning depth,New Algorithm/ Method,New Algorithm/ Method
"we propose a data enrichment method, which uses WordNet to extract inter-word semantic connections as general knowledge from each given passage-question pair",New Algorithm/ Method,New Algorithm/ Method
"We propose A novel text generation task (SQUASH), which converts documents into specificity-based hierarchies of QA pairs.",Theory Proposal,Theory Proposal
We proposed a novel PU learning algorithm to perform the NER task using only unlabeled data and named entity dictionaries.,New Algorithm/ Method,New Algorithm/ Method
"To make the above assumption hold as far as possible, we propose an adapted method, motivated by the AdaSampling algorithm, to enrich the dictionary.",New Algorithm/ Method,New Algorithm/ Method
we propose a new parsing algorithm for semantic dependency parsing (SDP) that combines transition-based and graph-based approaches,New Algorithm/ Method,New Algorithm/ Method
"we consider using cross-domain LM as a bridge cross-domains for NER domain adaptation, performing crossdomain and cross-task knowledge transfer by designing a novel parameter generation network.",Theory Proposal,Theory Proposal
"we propose a sequence-to-sequence (seq2seq) based neural keyphrase generation framework, enabling absent keyphrases to be created",New Algorithm/ Method,New Algorithm/ Method
A multi-task learning method that uses different sets of features to handle different types of hashtags,New Algorithm/ Method,New Algorithm/ Method
We propose a novel method for analyzing entities in a narrative that is both interpretable and generalizable,New Algorithm/ Method,New Algorithm/ Method
We propose the novel CogQA framework for multi-hop reading comprehension QA at scale according to human cognition,New Algorithm/ Method,New Algorithm/ Method
we propose a new method to solve the multi-hop RC problem across multiple documents.,New Algorithm/ Method,New Algorithm/ Method
We introduce methods based on sentence mover’s similarity; our automatic metrics evaluate text in a continuous space using word and sentence embeddings.,New Algorithm/ Method,New Algorithm/ Method
To propose a multi-level matching and aggregation network is proposed to encode query instances and class prototypes in an interactive fashion,New Algorithm/ Method,New Algorithm/ Method
"we introduce an adaptive and general framework for measuring similarity of the pairs of relations these distributions are
parameterized by a very simple neural network",New Algorithm/ Method,New Algorithm/ Method
we propose an unsupervised adaptation method which finetunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus.,New Algorithm/ Method,New Algorithm/ Method
we propose a two step pipeline for building a rapid neural MT system for many languages. The pipeline does not require parallel data or parameter fine-tuning when adapting to new source languages.,New Algorithm/ Method,New Algorithm/ Method
"We propose a general method to detect cognates from multilingual lexical resources, with precision and recall parametrable according to usage needs",New Algorithm/ Method,New Algorithm/ Method
we introduce a neural decipherment algorithm that delivers strong performances across several languages with distinct linguistic characteristics.,New Algorithm/ Method,New Algorithm/ Method
we propose a new method for this task based on multilingual sentence embeddings,New Algorithm/ Method,New Algorithm/ Method
"we propose to generate, without supervision, synthetic parallel sentences that can be directly exploited to jointly train BWE with existing algorithms",Applications,Applications
we define and distinguish three aspects constituting to quality of biomedical name representations. We propose a novel encoding framework that considers all these aspects in the representation learning.,New Algorithm/ Method,New Algorithm/ Method
"We also present SemGCN, a framework for incorporating diverse semantic knowledge in learned word embeddings, without requiring relation-specific special handling as in previous methods.",New Algorithm/ Method,New Algorithm/ Method
"we propose delta embedding learning, a novel method that aims to address the above problems together: using regularization to find the optimal fine-tuning of word embeddings.",New Algorithm/ Method,New Algorithm/ Method
"We investigate how an LSTM language model deals with lexical ambiguity in English, designing a method to probe its hidden representations for lexical and contextual information about words.",New Algorithm/ Method,New Algorithm/ Method
We propose a Method for mapping entities from a graphical representation to the space in which a pretrained embedding lies,New Algorithm/ Method,New Algorithm/ Method
"Based on the proposed model, we develop a simple yet effective method for unsupervised domain adaptation.",Applications,Applications
Our goal is to present a patient biomedical QA system that can address the gaps in biomedical research and allows a patient to query their symptoms,Theory Proposal,Theory Proposal
methods for extracting of aggregated knowledge from patient experiences on online fora,New Algorithm/ Method,New Algorithm/ Method
"a method for cross-linking curated knowledge and complementary patient knowledge, and",New Algorithm/ Method,New Algorithm/ Method
"we propose a general approach for permuting the words in an input sentence based on the notion of simplification,",New Algorithm/ Method,New Algorithm/ Method
we present an unsupervised pretraining method for NMT models using Elastic Weight Consolidation,New Algorithm/ Method,New Algorithm/ Method
we propose a method for neural grammar error correction (GEC) that can control the degree of correction,New Algorithm/ Method,New Algorithm/ Method
we propose a method to predict a DA of the next response based on the history of previous utterances and their DAs.,New Algorithm/ Method,New Algorithm/ Method
", we propose a novel task, automatically generating personalized comment based on
user profile.",New Algorithm/ Method,New Algorithm/ Method
", we propose an inexpensive, scalable, CPUtrainable and efficient method of extractive text
summarization based on the use of sentence embeddings.",New Algorithm/ Method,New Algorithm/ Method
"we propose a method for add weights to a training loss according to levels of words on top of (Scarton and Specia, 2018), and thus output only words under the desired level.",New Algorithm/ Method,New Algorithm/ Method
we present a hybrid architecture for the task of Sentiment Analysis of EnglishHindi code-mixed data,New Algorithm/ Method,New Algorithm/ Method
"we propose an unsupervised
method to capture discourse structure in terms
of cohesion and coherence for document embedding.",New Algorithm/ Method,New Algorithm/ Method
". SEARCHER, a novel CLIR approach designed
for low-resource conditions that relies on the
construction of a shared semantic space learned
from bitext and monolingual corpora",New Algorithm/ Method,New Algorithm/ Method
"We present an approach to rapidly gather event trigger examples for new event types, with minimal human effort.",New Algorithm/ Method,New Algorithm/ Method
We develop a User Interface (UI) to further expedite and improve the time efficiency of our approach,New Algorithm/ Method,New Algorithm/ Method
", we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism",New Algorithm/ Method,New Algorithm/ Method
"We introduce an open-source web-based data
annotation framework (AlpacaTag) for sequence tagging tasks such as named-entity
recognition (NER)",New Algorithm/ Method,New Algorithm/ Method
"we introduce a Knowledge-Constraint Typing Annotation Tool (KCAT1 ), which is efficient for fine-grained entity typing annotation",New Algorithm/ Method,New Algorithm/ Method
"We develop GLTR, a tool to support humans in detecting whether a text was generated by a model",New Algorithm/ Method,New Algorithm/ Method
"we develop and evaluate a multilabel, multidimensional deep neural network designed to predict PHQ-4 scores based on individuals written text",New Algorithm/ Method,New Algorithm/ Method
we propose a new method for the evaluation of frame induction enabling straightforward comparison of approaches,New Algorithm/ Method,New Algorithm/ Method
we propose methods for automatic seed selection for bootstrapping RE and noise reduction for distant supervised RE,New Algorithm/ Method,New Algorithm/ Method
"we propose the new task of automatic article commenting, and introduces a large-scale Chinese dataset1 with millions of real comments and a humanannotated subset characterizing the comments’ varying quality",New Algorithm/ Method,New Algorithm/ Method
"we design an effective syntaxbased evaluator is built as a post-hoc checker, yielding compression with better quality based upon the evaluation metrics",Algorithm/Method Optimization,Algorithm/Method Optimization
we learn word and sentence embeddings jointly by training a multilingual skip-gram model together with a cross-lingual sentence similarity model,Model Optimization,Model Optimization
"we propose an approach that aims at injecting syntactic information in NNs, still keeping them simple",New Algorithm/ Method,New Algorithm/ Method
we present a simple and effective approach by introducing a coverage-based feature into NMT,New Algorithm/ Method,New Algorithm/ Method
"we propose an approach that uses both the sentences and the bag-of-words as targets in the training stage, in order to encourage the model to generate the potentially correct sentences that are not appeared in the training se",New Algorithm/ Method,New Algorithm/ Method
"we propose Pseudofit, a method that improves word embeddings without external knowledge and focuses on semantic similarity and synonym extraction",Algorithm/Method Optimization,Algorithm/Method Optimization
"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them",New Algorithm/ Method,New Algorithm/ Method
We formulate constrained sparsemax and derive efficient linear and sublinear-time algorithms for running forward and backward propagation,Algorithm/Method Optimization,Algorithm/Method Optimization
We present a simple approach to select assisting language sentences based on symmetric KLDivergence of overlapping entities,New Algorithm/ Method,New Algorithm/ Method
"We devise a novel loss function which penalizes wrong spans that cross gold-tree spans, and employ max-violation update (Huang et al., 2012) to train this parser with structured SVM and beam search",New Algorithm/ Method,New Algorithm/ Method
we propose a new method that can leverage unlabeled data to learn matching models for retrieval-based chatbots,New Algorithm/ Method,New Algorithm/ Method
"we show that there are relations
between sentences and semantic representations
which can be described by compositional mechanisms which are bounded and non-projective, but
not by ones which are bounded and projective.",Theory Proposal,Theory Proposal
"more importantly, we demonstrate, on several sentence-matching datasets, that simply evaluating the Hamming distance over binary representations performs on par or even better than calculating the cosine similarity between their continuous counterparts",Performance Evaluation,Performance Evaluation
"We propose a
technique to quantitatively estimate this assumption of the isometry between two embedding spaces and empirically show that this assumption weakens as the languages in question become increasingly etymologically distant.",Performance Evaluation,Performance Evaluation
We present a large-scale evaluation of multilingual subword representations on two sequence tagging tasks,Performance Evaluation,Performance Evaluation
"We evaluate our approach on three different
NLP tasks: machine comprehension, textual
entailment, and text chunking. We show that
augmented models lead to large performance
gains in the low training data regimes",Performance Evaluation,Performance Evaluation
"We frame the problem of open-domain argument search as a combination of topic-dependent
argument classification and clustering and discuss how contextualized word embeddings can
help to improve these tasks across four different
datasets.",Model Optimization,Model Optimization
"After
training a supervised deep learning algorithm to
predict attachments on the STAC corpus1
, we then
constructed a weakly supervised learning system
in which we used 10% of the corpus as a development set.",New Algorithm/ Method,New Algorithm/ Method
"we frame zero-shot learning as
a challenge for pragmatic modeling and explore
zero-shot reference games, where a speaker needs
to describe a novel-category object in an image to
an addressee who may or may not know the category",Theory Proposal,Theory Proposal
"Our new method outperforms previous methods by a significant margin on both the previous closed domain WSJ dataset as well as on
all open-domain ones, setting the new stateof-the-art for coherence modelling.",Algorithm/Method Optimization,Algorithm/Method Optimization
"Even with the simplest sentence encoder, averaged GloVe, our method frequently outperforms previous methods, while it can gain
further accuracy by using stronger encoders.",Algorithm/Method Optimization,Algorithm/Method Optimization
"We provide a comprehensive
comparative evaluation of a wide range of stateof-the-art—both supervised and unsupervised—
projection-based CLE models.",Performance Evaluation,Performance Evaluation
"We unify
evaluation protocols for all models and conduct experiments over 28 language pairs spanning diverse
language types.",Performance Evaluation,Performance Evaluation
"provides a benchmark to evaluate the ability of understanding idioms, a unique yet common language phenomenon in Chinese.",Theory Proposal,Theory Proposal
"We conduct extensive experiments on the design of candidate idioms and the idiom representation methods, and compare state-ofthe-art models.",Performance Evaluation,Performance Evaluation
evaluates token-level topic assignment quality to understand which topic models produce meaningful local topics for individual documents and proposes metrics that correlate with human judgment of the quality of these assignments.,Performance Evaluation,Performance Evaluation
"we evaluate the proposed models to perform
multi-domain joint learning of slot filling and
intent classification on both public datasets
and a real-world dataset from the Alexa virtual assistant;+99:116",Performance Evaluation,Performance Evaluation
"We explore how to resolve pronoun coreferences with KGs, which outperforms all existing models by a large margin on datasets from two different domains.",Model Optimization,Model Optimization
We evaluate the performance of different pronoun coreference models in a cross-domain setting and show that our model has better generalization ability than state-of-the-art baselines.,Model Optimization,Model Optimization
We evaluate a large number of baselines on SherLIiC. The best-performing baseline makes use of typing,Performance Evaluation,Performance Evaluation
analysis of the performance of the models that provides meaningful insights for further improvements,Performance Evaluation,Performance Evaluation
"We test models for open-domain and multi-choice QA, showing the complexity of the dataset and its utility to encourage progress in QA",Performance Evaluation,Performance Evaluation
"We compared GOLC with two optimization methods, a maximum log-likelihood and a minimum risk training, on CNN/Daily Mail and a Japanese single document summarization data set of The Mainichi Shimbun Newspapers.",Performance Evaluation,Performance Evaluation
"We perform two tasks, a classification and a regression one.
The evaluation shows that our proposed model
successfully outperforms the earlier reported results in PeerRead",Model Optimization,Model Optimization
Defining evaluation metrics and providing comparisons with several baselines to assess the model performance.,Performance Evaluation,Performance Evaluation
we consider a novel and realistic set-up where a much larger amount of sentencelevel data is available compared to that aligned at the document level,Theory Proposal,Theory Proposal
"We verify our GP-GNNs on the task of relation extraction from text, which demonstrates its ability on multi-hop relational reasoning as compared to those models which extract relationships separately.",Performance Evaluation,Performance Evaluation
"We evaluate our fine-tuned language model
on the NYT10 dataset and show that it achieves a state-of-the-art AUC compared
to RESIDE 2018 and
PCNN+ATT in held-out
evaluation",Performance Evaluation,Performance Evaluation
"We publish a better manually labeled sentence-level test set1 for evaluating the performance of RC models. This test set contains 1,024 sentences and 4,543 entity pairs, and is carefully annotated to ensure accuracy.",Dataset Creation,Dataset Creation
"We evaluate our Quaternion NLP models on
a wide range of diverse NLP tasks such as
pairwise text classification, neural
machine translation (NMT), sentiment analysis, mathematical language understanding
(MLU), and subject-verb agreement",Performance Evaluation,Performance Evaluation
"We formulate routing processes as a proxy problem minimizing a total negative agreement score in order to evaluate how routing processes perform at instance level, which will be discussed more in depth later",New Algorithm/ Method,New Algorithm/ Method
We show that training with delayed rewards achieves better performance than maximum likelihood training across six different historical text normalization benchmarks,Theory Proposal,Theory Proposal
we present a transparent framework and metric for evaluating discrimination across protected groups with respect to their word embedding bias,New Algorithm/ Method,New Algorithm/ Method
"we aim to combine the power of neural networks with the dataefficiency of logical forms by pre-learning abstractions in a semi-supervised way, satiating part of the network’s data hunger on cheaper unlabeled data from the environment.",Theory Proposal,Theory Proposal
We develop a series of automatic evaluation metrics to comprehensively assess the quality of the generated essay.,Performance Evaluation,Performance Evaluation
"We evaluate our models on data with humanconstituted trees or parsed trees, and yield promising results in generating sentences with better reconstruction loss and less grammatical errors, compared to other baseline methods.",Performance Evaluation,Performance Evaluation
We propose DIM to capture the duality and adopt variational approximation to maximize the dual information,New Algorithm/ Method,New Algorithm/ Method
"The experimental results demonstrate that our model is competitive with or outperforms other unsupervised models. In particular, for long reviews, it achieves a competitive or better performance than the supervised models.",Performance Evaluation,Performance Evaluation
We propose Empirical evaluations on the benchmark dataset show our model has achieved a new state of the art.,Performance Evaluation,Performance Evaluation
"we show that our model improves performance over ADA and an expanded vocabulary alone and further, that a limited amount of labeled target data can achieve performance close to training on all labeled target data.",Performance Evaluation,Performance Evaluation
we compare different NLI models regarding their ability to rank more correct summaries above incorrect alternatives.,Performance Evaluation,Performance Evaluation
"we present a neural rewriter for multi-sentence compression without any parallel data. This rewriter significantly improves the grammaticality and novel word rate, while maintaining the information coverage according to automatic evaluation",New Algorithm/ Method,New Algorithm/ Method
"Our Dynamic Self-attention Network (DynSAN) achieves new state-of-the-art performance compared with previously published results on SearchQA, Quasar-T and WikiHop benchmarks.",Performance Evaluation,Performance Evaluation
"We show the effectiveness of our approach, which achieves state-of-the-art results in both single- and multi-hop open-domain QA benchmarks.",Performance Evaluation,Performance Evaluation
We correlate several linguistically- and psycholinguisticallymotivated predictors to parsing accuracy on a large multilingual grammar induction evaluation data set.,Performance Evaluation,Performance Evaluation
"Framing the problem as pairwise ranking using novel neural approaches, in contrast to previous work which ignored the relative order of candidate segmentations",Theory Proposal,Theory Proposal
"We experimentally confirm that our method is much more effective than several state-of-theart claim verification models using three public benchmark datasets collected from snopes.com, politifact.com and Wikipedia.",Performance Evaluation,Performance Evaluation
We explore a neural model of stylistic variation that can predict socioeconomic status with good performance,Model Proposal,Model Proposal
We investigate how to label comments for ranking and clarify that the performance of pairwise ranking models tends to be more enhanced by the variation in comments than that in articles,Performance Evaluation,Performance Evaluation
"The experiments show that our approach can achieve better performance than competitive baselines. With multiple modal information and co-attention, the generated comments are more diverse and informative.",Algorithm/Method Optimization,Algorithm/Method Optimization
"To evaluate model performance, we collect and annotate a large-scale dataset from Google Business News1 with diverse event types and explainable event schemas.",Performance Evaluation,Performance Evaluation
"we argue that this is a dual effect of the highly lexicalized nature of NMT, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words.",Theory Proposal,Theory Proposal
"We propose to improve the robustness of NMT to homophone noises by jointly embedding both textual and phonetic information of source sentences,",New Algorithm/ Method,New Algorithm/ Method
"We make a thorough empirical evaluation of different ways of coupling BERT models in an APE system, comparing different options of parameter sharing, initialization, and fine-tuning.",Theory Proposal,Theory Proposal
we propose to boost lowresource cross-lingual document retrieval performance with deep bilingual query-document representations.,Algorithm/Method Optimization,Algorithm/Method Optimization
"Extensive experimental results show that our approach achieves better performance than several state-of-the-art unsupervised systems, and even achieves competitive performance compared to supervised methods",New Algorithm/ Method,New Algorithm/ Method
"we evaluate the proposed encoder in biomedical synonym retrieval, name normalization, and semantic similarity and relatedness benchmarks.",Performance Evaluation,Performance Evaluation
"We evaluate our corpus by using it to train supervised classifiers to automatically assign aspectual categories to verbs in context, permitting favourable comparisons to previous work.",New Algorithm/ Method,New Algorithm/ Method
"we propose a novel approach for manual evaluation, HIGHlight-based Referenceless Evaluation of document Summarization",New Algorithm/ Method,New Algorithm/ Method
We demonstrate that the model achieves more interpretable and controllable generation of paraphrases.,Performance Evaluation,Performance Evaluation
"adding paraphrases with additional multilingual data yields mixed performance; its performance is better than training on language families alone, but is worse than training on both the source and target paraphrases without language families.",Theory Proposal,Theory Proposal
"A system that jointly performs NER and EL, with competitive results in both tasks.",Theory Proposal,Theory Proposal
A empirical qualitative analysis of the advantage of doing joint learning vs using separate models and of the influence of the different components to the result obtained.,Theory Proposal,Theory Proposal
we do an in-depth analysis of how adding community features may enhance the performance of classification models that detect religious hate speech in Arabic.,Theory Proposal,Theory Proposal
we define two ways of combining contextual and static embeddings and conclude that the naive concatenation of vectors is consistently outperformed by the addition of the static representation directly into the internal linear combination of ELMo;,Theory Proposal,Theory Proposal
"we perform an analytic comparison of these methods, and introduce our own results. By fine-tuning Google’s
recently published transformer-based architecture, BERT, on the fake review detection task",Theory Proposal,Theory Proposal
". A configuration format that natively enables
searching over hyperparameters and running
remote multistage experiments at scale.",Theory Proposal,Theory Proposal
"critical examinations of different training conditions and requirements under which unsupervised
algorithms can and cannot work effectively",Performance Evaluation,Performance Evaluation
the first corpus for evaluating mistake detection and correction in a medical patient forum,New Algorithm/ Method,New Algorithm/ Method
"We investigate the use of a
language representation model BERT trained
to obtain semantic representations of social
media texts",Performance Evaluation,Performance Evaluation
"we evaluate the linguistic differences between temporal cohorts, e.g. 20-year-olds in 2011 vs. 20-year-olds in 2015",Performance Evaluation,Performance Evaluation
we achieve state-of-the-art performance in CoNLL 2003 NER shared task,Algorithm/Method Optimization,Algorithm/Method Optimization
"We adopt the pointer network to handle the OOV problem in slot value prediction, which achieves good performance without any manually-designed rules or features",Algorithm/Method Optimization,Algorithm/Method Optimization
"we investigate how to simplify and recover abugidas, with the aim of developing a more efficient method of encoding abugidas for input",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose a conceptually simpler
approach to the issue, which is agnostic on any
parser architecture, namely, automatic generation
of CCGbanks (i.e., CCG treebanks)1
for new domains, by exploiting cheaper resources of dependency trees.",New Algorithm/ Method,New Algorithm/ Method
we present the first study exploiting capsule networks for determining sentence similarity for summarization purpose. It is important to recognize that summarization places particular emphasis on measuring redundancy between sentences,Theory Proposal,Theory Proposal
we formulate properties required from a useful notion of Importance as the quantity unifying these concepts. We provide intuitions to interpret the proposed quantities.,Theory Proposal,Theory Proposal
"We introduce a contextual gating mechanism to incorporate multiple types of embeddings, word, speech, and conversationalcontext embeddings.",New Algorithm/ Method,New Algorithm/ Method
we address the degeneracy problem due to capturing spurious correlations by quantitatively analyzing the mutual information between language IDs of the source and decoded sentences,Theory Proposal,Theory Proposal
"We demonstrate favorable trade-offs to those of wait-k strategies at many latency values, and provide evidence that MILk’s advantage extends from its ability to adapt based on source content",Theory Proposal,Theory Proposal
"We write and enabling the quick generalization to new relation types by only requiring a small number
of human annotations",Theory Proposal,Theory Proposal
"We propose to perform KG inference and alignment jointly, so that the heterogeneity of KGs are explicitly reconciled through completion by rule inference and transfer, and pruning via cross-KG attention.",Resources,Resources
"We construct entmax sparse attention, improving interpretability at no cost in accuracy.
We show that the entmax gradient has a simple
form revealing an insightful
missing link between softmax and sparsemax.",New Algorithm/ Method,New Algorithm/ Method
"We conduct comprehensive experiments to examine the robustness of RNN, Transformer, and BERT. Our results show that both
self-attentive models, whether pre-trained or
not, are more robust than recurrent models.",Performance Evaluation,Performance Evaluation
"We critically discuss issues with current debiasing methods with the purpose of identifying optimizations, knowledge gaps, and directions for future research.",Theory Proposal,Theory Proposal
"we first empirically characterize the racial bias present in several widely used Twitter corpora annotated for toxic content, and quantify the propagation of this bias through models trained on them",Applications,Applications
We present an innovative idea for taking advantage of pretrained embeddings by using them as an objective during training.,Theory Proposal,Theory Proposal
we offer a holistic quantification of the systematicity of the sign using mutual information and recurrent neural networks.,Theory Proposal,Theory Proposal
we explore the use of multitask learning and adversarial training to address morphological richness and dialectal variations in the context of full morphological tagging.,Theory Proposal,Theory Proposal
we show how Wikipedia and unlabeled data can be used to construct an accurate linker which rivals linkers constructed using expensive human supervision,New Algorithm/ Method,New Algorithm/ Method
"We Propose a novel entity-aware model for data-to-text generation which is linguistically motivated, yet resource lean (no preprocessing is required",Model Proposal,Model Proposal
"we note some writer-specific patterns and characteristics: how data records are selected to be mentioned; and how data records are expressed as text, e.g., the order of data records and the word usages.",New Algorithm/ Method,New Algorithm/ Method
we propose a new approach to automatically generate summaries for scientific papers based on video talks,New Algorithm/ Method,New Algorithm/ Method
we investigate the factors involved in representing sentence singletons and pairs. We perform extensive experiments and report findings on sentence selection and abstraction.,Theory Proposal,Theory Proposal
we propose the use of artificial titles for unlabeled target documents to train a decoder to learn the grammatical style of titles in the new domain,Theory Proposal,Theory Proposal
we present a detailed error analysis and discuss potential areas of improvements for consumer health question summarization.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We also propose using sentence-level representations for retrieval, and show the possible benefits of this approach over paragraph-level representations.",Theory Proposal,Theory Proposal
"We investigate and demonstrate the feasibility of enhancing pre-trained LMs with rich knowledge for MRC. To our knowledge, this is the first study of its kind, indicating a potential direction for future research.",Theory Proposal,Theory Proposal
investigating new configurations of GNNs for handling direct edges and nodes with multiple representations.,Theory Proposal,Theory Proposal
"We quantitatively show the significance of each modality in Twitter sarcasm detection. We further show that to fully unleash the potential of images, we would need to consider image attributes",Theory Proposal,Theory Proposal
Our study aims to help this body of research grow by automating the process of collection of tweets containing recollections of sexual harassment.,Theory Proposal,Theory Proposal
"we highlight the importance of contextualizing social information, capturing how this information is disseminated in social networks",Theory Proposal,Theory Proposal
we investigate novel decompositions of the story generation process that break down the problem into a series of easier coarse-tofine generation problems.,Theory Proposal,Theory Proposal
We show that the cognitive graph structure in our framework offers ordered and entitylevel explainability and suits for relational reasoning.,Performance Evaluation,Performance Evaluation
We learn incremental suggestion models for little data scenarios through continuous adjustments of the suggestion model and discuss suitable setups.,Model Optimization,Model Optimization
We propose a criterion to distinguish between obvious and non-obvious examples in text pair similarity datasets,Theory Proposal,Theory Proposal
We define the types of relationships between the text and the image of a social media post,Theory Proposal,Theory Proposal
"we build on extensions of Harris’ distributional hypothesis to relations, as well as recent advances in learning text representations to build task agnostic relation representations solely from entity-linked text.",New Algorithm/ Method,New Algorithm/ Method
we present a differentiable approach to extractive rationales including an objective that allows for specifying how much text is to be extracted,New Algorithm/ Method,New Algorithm/ Method
The pipeline only requires a comprehensive source to target dictionary. We show that this dictionary can be easily obtained using offthe shelf tools within a few hours.,Performance Evaluation,Performance Evaluation
we empirically show that jointly training multiple languages improves separately trained bilingual models,Performance Evaluation,Performance Evaluation
We also show how simple techniques over our data yield competitive results in building crosslingual word embeddings and annotation projection for part-of-speech tagger induction.,Theory Proposal,Theory Proposal
we ask the fundamental question of whether Chinese word segmentation (CWS) is necessary for deep learning-based Chinese Natural Language Processing.,Theory Proposal,Theory Proposal
we study the benefits of hybrid strategies of hypernymy via a hybrid of extremely simple models of pattern-based and distributional hypernym discovery.,Theory Proposal,Theory Proposal
we describe the commonly used approaches in a subarea of interest and specify their features which could improve or deteriorate the performance of these models,Theory Proposal,Theory Proposal
We focus on the NLG approaches based on semantic representations and discuss their advantages and limitations.,Theory Proposal,Theory Proposal
"analyzing the shortcomings of sum and maxmargin loss, proposing a kNN-margin loss as a trade-off (for training);",Theory Proposal,Theory Proposal
we define a hop as a computational step which could be performed for an output symbol many times,Theory Proposal,Theory Proposal
"we propose a fullyautomated, context-aware machine translation approach with fewer stages of processing.",New Algorithm/ Method,New Algorithm/ Method
"We compare several approaches for conditioning on the model predictions when they
are used instead of the gold target.",Theory Proposal,Theory Proposal
"we report on our shared framework and infrastructure that drives a multitude
of linguistic visualization projects,",Performance Evaluation,Performance Evaluation
"ConvLab provides a rich set of tools and recipes to develop dialog systems of different types, enabling researchers to compare widely different approaches under the same condition.",New Algorithm/ Method,New Algorithm/ Method
"an unsupervised datadriven spelling correction method that works well
on specialized domains with many OOV terms
without the need for a specialized dictionary",New Algorithm/ Method,New Algorithm/ Method
"we analyze the role of linguistic context in both humans and the models, with implications for cognitive plausibility and future modeling work",Theory Proposal,Theory Proposal
"we use petitions from the official UK and US government websites, whereby citizens can directly appeal to the government for action on an issue",Dataset Creation,Dataset Creation
"we allow for an underlying mapping function that is non-linear, but assume that it can be approximated by linear maps at least in small enough neighborhoods",Applications,Applications
"we extend the research to investigate the impact of context on human acceptability judgements, where context is defined as the full document environment surrounding a sentence",New Algorithm/ Method,New Algorithm/ Method
"our research aims to develop a distributed knowledge-based clinical autocoding system that would leverage on NLP and ML techniques, where a human coders will give their queries to the coding system and in revert the system will suggest a set of clinical codes.",Model Proposal,Model Proposal
"we take a step in that direction and
confirm some of these speculations, showing that
models do not make use of a lot of the information available to it, by subjecting the dialog history to a variety of synthetic perturbations.",Model Optimization,Model Optimization
"We perform systematic analyses on nine languages using two different architectures (transition-based and graph-based) across
two dimensions: with and without BiLSTM representations, and with and without features drawn
from structural context.",Performance Evaluation,Performance Evaluation
"we investigate
words classified by L&M as negative, litigious and
uncertain that our embedding classifier classifies
otherwise",Theory Proposal,Theory Proposal
"we examine analysts’ decision making behavior as it pertains to the
language content of earnings calls.",Performance Evaluation,Performance Evaluation
"We provide a general
modular framework for sequence learning tasks.
While we focus on sentiment analysis task, the
framework is broadly applicable to many other
tagging tasks",New Algorithm/ Method,New Algorithm/ Method
"several principled model changes
to produce better structures but that still do not resemble the structure of discourse.",Model Optimization,Model Optimization
comprehensive performance results on existing and additional tasks and datasets showing document-level structured attention is largely unhelpful,Performance Evaluation,Performance Evaluation
"We eliminate the dependency on the structure of a semantic network by relying only on
the association between Wikipedia pages and
categories and on a sparse vector representation of concepts",Theory Proposal,Theory Proposal
"we provide the first large-scale
evaluation of an extensive number of approaches.",Performance Evaluation,Performance Evaluation
approach to mention detection for large-scale coreference annotation projects in which the output of mention detectors is corrected using a Gamewith-a-Purpose,Algorithm/Method Optimization,Algorithm/Method Optimization
"To overcome the multi-turn mapping problem,
TRADE leverages its context-enhanced slot
gate and copy mechanism to properly track slot values mentioned anywhere in dialogue history",New Algorithm/ Method,New Algorithm/ Method
we demonstrate experimentally the superiority of introducing group-level features and learning features in both parallel and serial ways.,Theory Proposal,Theory Proposal
"we define the task, including the annotation scheme for labeling the clinical conversations and the evaluation metrics to measure model performance",New Algorithm/ Method,New Algorithm/ Method
"we address this knowledge gap by examining how individuals change their conversational language in a domain with profound societal importance, where conversations play a primary role: mental health counseling.",Theory Proposal,Theory Proposal
"we describe the process of acquiring, anonymizing and filtering the dataset, deduplicating the answer set, and our first attempts towards automating the answering of questions.",Dataset Creation,Dataset Creation
"We present HEAD-QA, a multichoice testbed of graduate-level questions about medicine, nursing, biology, chemistry, psychology, and pharmacology",Dataset Creation,Dataset Creation
"we take a step towards closing this gap, by introducing the task of Debate Topic Expansion – finding related topics that can enrich our arguments and strengthen our case when debating a given topic.",Theory Proposal,Theory Proposal
"we aim to explicitly define a taxonomy of such principled recurring arguments, and, given a controversial topic, to automatically identify which of these arguments are relevant to the topic",Theory Proposal,Theory Proposal
"we seek to better understand how neural extractive summarization systems could benefit from different types of model architectures, transferable knowledge and learning schemas",Theory Proposal,Theory Proposal
we find an effective way to improve current frameworks and achieve the state-ofthe-art result on CNN/DailyMail by a large margin based on our observations and analyses.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We define several concepts intuitively connected to summarization: Redundancy, Relevance and Informativeness. These concepts have been used extensively in previous summarization works and we discuss along the way how our framework generalizes them",Theory Proposal,Theory Proposal
"we focus on the problem of generating valid adversarial examples for text classification, which could inspire more works for NLP attack and defense.",Theory Proposal,Theory Proposal
We introduce an approach that models writing style difference as the Jensen-Shannon distance between the character n-gram distributions of texts,New Algorithm/ Method,New Algorithm/ Method
we use neural sequence generation models for automatic conversion of poetry to prose. Lack of sufficient poetry-prose parallel data is an impediment in framing the problem as a seq2seq task,Model Proposal,Model Proposal
"We introduce language-sensitive embedding, attention, and discriminator which augment the ability of Multi-NMT model in distinguishing different languages.",Model Proposal,Model Proposal
"We understand NMT from the viewpoint of
word alignment and investigates the effect
of alignment errors on translation errors via
quantitative analysis over many testing examples.",Theory Proposal,Theory Proposal
"we utilize both large-scale textual corpora and KGs to train an enhanced language
representation model, which can
take full advantage of lexical, syntactic, and
knowledge information simultaneously.",Model Optimization,Model Optimization
we firstly recognize named entity mentions in text and then align these mentions to their corresponding entities in KGs,New Algorithm/ Method,New Algorithm/ Method
we hypothesize that the underperformance of monotonic models stems from the lack of joint training of the alignments with the transduction.,Performance Evaluation,Performance Evaluation
"We 
summarize recent studies of algorithmic bias in
NLP under a unified framework for the ease of future discussion.",Dataset Creation,Dataset Creation
We perform a systematic comparison of our and several recent methods on three tasks spanning ten topics and offer many insights.,Performance Evaluation,Performance Evaluation
We show that the proper use of layer normalization is the key to learning deep encoders. The deep network of the encoder can be optimized smoothly by relocating the layer normalization unit.,Applications,Applications
"we generate phoneme labels for speech frames and average consecutive frames with the same label to create shorter, higher-level source sequences for translation.",New Algorithm/ Method,New Algorithm/ Method
"We tackle a novel task, namely weakly-supervised spatio-temporally video grounding (WSSTG), which localizes a spatiotemporal tube in a given video that semantically corresponds to a given natural sentence, in a weakly-supervised manner",New Algorithm/ Method,New Algorithm/ Method
we provide evidence that fully-annotated documents may not be as beneficial as previously believed.,Performance Evaluation,Performance Evaluation
"We present the first work to generate modern Chinese poetry while controlling for the use of metaphor and personification, which play an essential role in enhancing the aesthetics of poetry",New Algorithm/ Method,New Algorithm/ Method
"we report correctness estimates for summaries generated by three recent abstractive summarization systems, showing that even recent state-of-the-art
models have errors in 25% of their summaries",Performance Evaluation,Performance Evaluation
"To the best of our knowledge, we are the first to consider using the whole document to learn contextualized sentence representations with selfsupervision and without any human annotations.",Theory Proposal,Theory Proposal
"we explore data augmentation techniques, including semantic selection from open-domain datasets, and study the behavior of state-of-the-art neural abstractive models on the original and augmented datasets",Performance Evaluation,Performance Evaluation
We propose Dynamic Self-attention (DynSA) for information interaction in a long sequence.,New Algorithm/ Method,New Algorithm/ Method
"We introduce the pointer-generator mechanism for generating an abstractive answer from the question and multiple passages, which covers various answer styles",New Algorithm/ Method,New Algorithm/ Method
"Our model achieves state-of-the-art results on
PTB and CTB for both constituent and dependency parsing",Model Proposal,Model Proposal
"We proved that the proposed algorithm can unbiasedly and consistently estimate the task loss as if there is fully labeled data, under the assumption that the entities found out by the dictionary can reveal the distribution of entities.",Performance Evaluation,Performance Evaluation
we show that multitask learning of state representations for this parsing algorithm is superior to single-task training,Performance Evaluation,Performance Evaluation
"introducing graph neural networks to dependency parsing, which aims to efficiently encode high order information in dependency tree node representations.",Theory Proposal,Theory Proposal
We show an assessment of how well contextualized word embeddings capture affect information,Performance Evaluation,Performance Evaluation
We show empirical evidence that constructiveness scores are not always related to positive user feedback such as “Like”-button clicks,Theory Proposal,Theory Proposal
we propose to exploit social media and natural language processing techniques to enhance air quality prediction.,Theory Proposal,Theory Proposal
We study the effects of automatically suggesting annotations to expert annotators across two domains for a hard discourse-level sequence labelling task.,Performance Evaluation,Performance Evaluation
"We propose a solution that meets our three criteria. Particularly, we adapt to our problem the recently presented concept of Almost Stochastic Order (ASO) between two distributions",Theory Proposal,Theory Proposal
"we would like to focus on the joint effects of conversation context and user history, ignoring other information.",Theory Proposal,Theory Proposal
To analyse into the author’s demographic traits that are related to usage preference of textimage relationship types,Theory Proposal,Theory Proposal
To analyze manually annotated corpus of claims from debates about migration found in German newspaper reports,Theory Proposal,Theory Proposal
"we introduce HardKuma, which gives support to binary outcomes and allows for reparameterized gradient estimates",New Algorithm/ Method,New Algorithm/ Method
we approach the problem by training a neural MT system to learn how to use custom terminology when provided with the input. C,New Algorithm/ Method,New Algorithm/ Method
we propose a strategy to train multilingual unsupervised NMT for one source to many targets and many targets to one source translations,Theory Proposal,Theory Proposal
"we also show that without training the network for many-to-many translations, the network can translate between all the languages participating in the training",Theory Proposal,Theory Proposal
We propose teaching both summary word generation distribution and attention weights in the cross-lingual ASSUM networks by using the monolingual ASSUM networks.,Theory Proposal,Theory Proposal
We demonstrate consistent and significant improvements on benchmark datasets in unsupervised and supervised settings.,Algorithm/Method Optimization,Algorithm/Method Optimization
We devise a straightforward and efficient approach for combining distributional and hypernymy information for the task of noun phrase compositionality prediction.,New Algorithm/ Method,New Algorithm/ Method
"we claim that vector space models, despite giving close representations for synonyms and antonyms, contain subtle differences that allow to discriminate antonymy.",Theory Proposal,Theory Proposal
We propose An approach to constructing graphical representations of entities in a knowledge base in an unsupervised manner.,New Algorithm/ Method,New Algorithm/ Method
"we
show that existing embedding models are inadequate at constructing representations that
capture salient aspects of mathematical meaning for numbers, which is important for language understanding.",Theory Proposal,Theory Proposal
How is personal recovery discussed online by individuals meeting criteria for BD?,Theory Proposal,Theory Proposal
What new insights do we get about personal recovery and factors that facilitate or hinder it?,Theory Proposal,Theory Proposal
"This research proposal consequently explores this question in the context of a neural morphological analyzer for a polysynthetic language, St",Theory Proposal,Model Proposal
"we find that over the past few decades, gender stereotypes in writings by males have decreased.",Theory Proposal,Theory Proposal
"Our paraphrase-exploiting NMT uses only two languages, the source and the target languages, and achieves higher BLEUs than the multi-source and multi-target NMT that incorporates more languages",New Algorithm/ Method,Algorithm/Method Optimization
a system for ranking explicit and implicit questions by their appropriateness in a dialogue is presented,New Algorithm/ Method,New Algorithm/ Method
we investigate the effect of the textual information of the tweets that target users liked/retweeted.,Theory Proposal,Theory Proposal
"we present a machine learning approach for information extraction, which has a recall of 80% for a social media data source.",New Algorithm/ Method,New Algorithm/ Method
", we investigate the efficacy
of bias reduction during training by introducing a
new loss function which encourages the language
model to equalize the probabilities of predicting
gendered word pairs like he and she.",New Algorithm/ Method,Algorithm/Method Optimization
"Our proposed approach, which uses community-based graph information to augment hand-crafted features based on topic modeling and emotion detection on debate transcripts currently surpasses the benchmark results on the same dataset.",New Algorithm/ Method,New Algorithm/ Method
we propose an artificial neural network (ANN) solution which does not use a lexicon or any other manually labeled source.,Theory Proposal,Theory Proposal
"we explored the use of a domain-independent, multilingual lexicon of abusive words called HurtLex (Bassignana et al., 2018) in both cross-domain and cross-lingual settings",Theory Proposal,Theory Proposal
"we use logic-based representations as
unified meaning representations for texts and
images and present an unsupervised multimodal logical inference system that can effectively prove entailment relations between
them",New Algorithm/ Method,New Algorithm/ Method
"we focus on
extraction information of adverse drug reactions from various sources of biomedical textbased information, including biomedical literature and social media",Theory Proposal,Theory Proposal
"Our system shows the incorrect sentences and
the corresponding sentence as corrected by
a native speaker. Thus, learners can rectify
their mistakes during composition.",Theory Proposal,Resources
". An intuitive snippet extraction and presentation design which has been shown in human studies to provide readers with sufficient evidence to filter out erroneous query matches and preserve good ones, even in low-resource conditions",Theory Proposal,Theory Proposal
to provide a highly flexible research framework not only for technique oriented developers but also for non-technical oriented developers such as linguists,New Algorithm/ Method,New Algorithm/ Method
"Modular machine learning components to develop replicable, state of the art research
results. This includes: neural network
components (pretrained or not), benchmark
datasets, and standardized training and evaluation modules.",Theory Proposal,Theory Proposal
"an overview of linguistic structures and corresponding discourse analysis tasks that discourse researchers are generally interested in,
as well as key applications on which these discourse structures have an impact",Theory Proposal,Theory Proposal
"We aim to provide a gentle, all-round
introduction to methods and tasks related to computational analysis of political texts",Theory Proposal,Theory Proposal
"addresses the fundamentals
of statistical models and neural networks, and focus on a series of advanced Bayesian models and
deep models",Theory Proposal,Theory Proposal
we present a new task and results for training models to learn semantically-rich function words,Model Proposal,Model Proposal
we introduce a new way to deal with the problem of offensive language on social media,Theory Proposal,Theory Proposal
"we propose a simple and parameter-efficient adaptation technique that only requires adapting the bias of the output softmax to each particular user of the MT system, either directly or through a factored approximation",New Algorithm/ Method,New Algorithm/ Method
"we aim to compare the performance of attention-based models to another baseline, namely, neural hidden Markov models",Performance Evaluation,Performance Evaluation
We design the first neural parser that is both linear time and capable of searching over exponentially large space,New Algorithm/ Method,New Algorithm/ Method
We propose a modularized hierarchical convolutional neural network model that considers the overall information of the source paper,Model Proposal,Model Proposal
we propose to combine string kernels (low-level character n-gram features) and word embeddings (high-level semantic features) to obtain state-of-the-art AES results,Model Optimization,Model Optimization
"we develop a more principled approach to unsupervised SMT, addressing several
deficiencies of previous systems by incorporating subword information, applying a theoretically
well founded unsupervised tuning method, and developing a joint refinement procedure.",New Algorithm/ Method,New Algorithm/ Method
"Our model achieves new state-of-the-art results without additional computational over
Implementation is based on Pytorch (Paszke et al., 2017).
head when compared with previous GCNs.
Unlike tree-structured models (e.g., TreeLSTM (Tai et al., 2015)), it can be efficiently
applied over dependency trees in parallel.",Model Optimization,Model Optimization
"We find that different methods have different strengths: Monolingual BPEmb works
best in medium- and high-resource settings,
multilingual non-contextual subword embeddings are best in low-resource languages,
while multilingual BERT gives good or best
results across languages.",Performance Evaluation,Performance Evaluation
"we propose a span-based
extract-then-classify framework, where multiple opinion targets are directly extracted from
the sentence under the supervision of target
span boundaries, and corresponding polarities
are then classified using their span representations.",New Algorithm/ Method,New Algorithm/ Method
"We create SherLIiC, a new resource for LIiC, consisting of 3985 manually annotated InfCands. Additionally, we provide ~960k unlabeled InfCands (SherLIiC-InfCands), and the typed event graph SherLIiC-TEG, containing ~190k typed textual binary relations between Freebase entities.",Resources,Resources
"we conduct extensive analyses on conversational aspects such as turn-by-turn interaction, the sentiment expressed during the interaction, linguistic alignment, and salient topics during the conversation to obtain insights into what are the patterns of high-quality counseling.",Performance Evaluation,Performance Evaluation
"we propose a new paradigm to handle the task of entity-relation extraction. We formalize the task as a multi-turn question answering task: each entity type and relation type is characterized by a question answering template, and entities and relations are extracted by answering template questions",New Algorithm/ Method,New Algorithm/ Method
"We propose a multi-task architecture which jointly trains a model to perform relation identification with cross-entropy loss and relation classification task with ranking loss, which can successfully mitigate the negative effect of having too many negative instances.",New Algorithm/ Method,New Algorithm/ Method
"We propose two RelDist losses: a skewness
loss, which encourages the classifier to predict a class with confidence for a single sentence, and a distribution distance loss, which
encourages the classifier to scatter a set of
sentences into different classes",Theory Proposal,Theory Proposal
"we propose a novel multi-digraph model to learn how to combine the gazetteer information and to resolve conflicting matches in learning with contexts. To the best of our knowledge, we are the first neural approach to NER that models the gazetteer information with a graph structure",Model Proposal,Model Proposal
"we propose a regularization technique that exploits a symmetry in language models. A unique aspect of language modeling using
LSTMs (or any RNN) is that at each time step t,
the model takes as input a particular token xt from
a vocabulary W and using the hidden state of the
LSTM predicts a probability distribution on the next
token over the same vocabulary as output",Model Proposal,Model Proposal
"We propose Quaternion neural models for NLP. More concretely, we propose a novel Quaternion attention model and Quaternion Transformer for a wide range of NLP tasks. To the best of our knowledge, this is the first formulation of hypercomplex Attention and Quaternion models for NLP.",Model Optimization,Model Optimization
"we add morphology supervision to character language modeling and show that, across two benchmark datasets, multitasking morphology with CLMs improves bits-per-character (BPC) performance on twentyfour languages, even when the annotated morphology features and language modeling data do not
overlap",Model Optimization,Model Optimization
"we conduct the first large-scale multilingual evaluation of gender-bias in machine translation (MT), following recent small-scale qualitative studies which observed that online MT services, such as Google Translate or Microsoft Translator, also exhibit biases",Performance Evaluation,Performance Evaluation
"we answer several of these open questions. We begin by proving that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc via subspace projection is, under certain conditions, equivalent to training on an unbiased corpus without reconstruction error.",Theory Proposal,Theory Proposal
"we address both issues simultaneously: leveraging the high accuracy of English taggers and parsers, we project morphological information onto translations of the Bible in 26 varied test languages. Using an iterative discovery, constraint, and training process, we build inflectional lexica in the target languages.",Theory Proposal,Theory Proposal
"We propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information, and thus these learned reordering embeddings are added to the sentence representation for archiving reordering of words. To the best of our knowledge, this is the first work to introduce the reordering information to the Transformer translation system.",New Algorithm/ Method,Resources
We propose a novel attentive interactor to exploit fine-grained relationships between instances and the sentence to characterize their matching behaviors. A diversity loss is proposed to strengthen the matching behaviors between reliable instance-sentence pairs and penalize the unreliable ones during training,New Algorithm/ Method,Performance Evaluation
"We propose a new dataset for data-to-text generation which we hope will encourage further work in this area a comprehensive evaluation and
comparison study which highlights the merits and
shortcomings of various recently proposed datato-text generation models on two datasets.",Dataset Creation,Dataset Creation
"we show both automatic and human evaluations for our approach. We make our dataset and related code publicly available . To our knowledge, this is the first approach to automatically create extractive summaries for scientific papers by utilizing the videos of conference talks",Theory Proposal,Theory Proposal
"we define Question Summarization as generating a condensed question expressing the minimum information required to find correct answers to the original question, and we create a new corpus1 of 1K consumer health questions and their summaries based on this definition",Theory Proposal,Theory Proposal
"We propose a novel hierarchical fusion model
to address the challenging multi-modal sarcasm detection task in Twitter. To the best
of our knowledge, we are the first to deeply
fuse the three modalities of image, attribute
and text, rather than na¨ıve concatenation, for
Twitter sarcasm detection",Model Proposal,Model Proposal
"We aim to improve over existing MT evaluation methods, through developing a series of new metrics based on contextual word embeddings a technique which captures rich and portable representations of words in context, which have been shown to provide important signal to many other NLP tasks.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we describe the creation of the first large-scale, multilingual, expert-based dataset of hate speech/counternarrative pairs. This dataset has been built with the effort of more than 100 operators from three different NGOs that applied their training and expertise to the task",Dataset Creation,Dataset Creation
"we propose a hybrid attention mechanism to dynamically leverage both of the local and global information. Specifically, our approach uses a gating scalar for integrating both sources of the information, which is also convenient for quantifying their contributions.",Algorithm/Method Optimization,Algorithm/Method Optimization
We propose a new unsupervised multilingual word embedding method that overcomes the limitations of the existing methods. Our approach can successfully obtain multilingual word embeddings under the challenging conditions when only small monolingual corpora are available,Algorithm/Method Optimization,Algorithm/Method Optimization
"Extensive experimental results on two benchmark datasets show that our proposed method is able to perform better than several baselines and related works, and significantly reduce the performance gap between the crosslingual ASSUM and the monolingual ASSUM.",New Algorithm/ Method,New Algorithm/ Method
"we propose to model the edit operations explicitly for sentence simplification in an end-to-end fashion, rather than relying on MT-based models to learn the simplification mappings implicitly, which often generates outputs by blindly repeating the source sentences",Model Optimization,Model Optimization
"our research aims to develop a distributed knowledge-based clinical autocoding system that would leverage on NLP and ML techniques, where a human coders will give their queries to the coding system and in revert the system will suggest a set of clinical codes",Theory Proposal,Theory Proposal
"we describe a simple yet effective approach to merge lexicon information with
an attention LSTM model for ABSA in order to
leverage both the power of deep neural networks
and existing linguistic resources, so that the framework becomes more flexible and robust without
requiring additional labeled data",Model Optimization,Model Optimization
a better way is to utilize the system to assist human creation. The human-machine collaboration mechanism in Jiuge system can not only improve the emotions and semantics of generated poems but also guide and teach beginners to understand the poetic creation process.,Performance Evaluation,Performance Evaluation
"we design and construct a real-world online platform that offers PhD graduates a dedicated job search functionality, as well as helps governments, universities, and employers in increasing the understanding of different industries’ absorption of PhD graduates.",New Algorithm/ Method,New Algorithm/ Method
"We introduce Texar, a general-purpose text generation toolkit aiming to support popular and
emerging applications in the field, by providing researchers and practitioners a unified and flexible framework for building their models.
Texar has two versions, building upon TensorFlow
(tensorflow.org) and PyTorch (pytorch.
org), respectively, with the same uniform design",New Algorithm/ Method,New Algorithm/ Method
"we present an open source modular tool dedicated to automatic summarization. Written in Java, it is designed to first answer the lack of such a tool and so provide the community with an easy-to-use summarization tool, to allow a straightforward maintenance of existing modules and development of new modules, and to allow methods comparison in a unified framework.",New Algorithm/ Method,New Algorithm/ Method
"We present a prototype vocabulary
learning system, Linggle Booster, that applies
the method to corpora and web pages. Evaluation on a set of target words shows that the
method has reasonably good performance in
terms of generating useful and correct information for vocabulary learning.",New Algorithm/ Method,New Algorithm/ Method
"We will introduce researchers to state-of-theart methods for constructing resource-light crosslingual word representations and discuss their applicability in a broad range of downstream NLP
applications, covering bilingual lexicon induction,
machine translation (both neural and phrase-based),
dialogue, and information retrieval tasks",Model Optimization,Model Optimization
"Classification models that can generalize to different health contexts would be greatly beneficial to researchers in these fields (e.g., (Payam and Eugene, 2018)), as this would allow researchers to more easily apply existing tools and resources to new problems",Algorithm/Method Optimization,Algorithm/Method Optimization
"we present a MedNorm corpus consisting of 27,979 textual descriptions (phrases) simultaneously mapped to both MedDRA and SNOMED-CT, that have been sourced from five publicly available datasets across biomedical and social media domains. To combine them, we designed a data harmonisation pipeline that can be re-used in the future to integrate new datasets into the corpus or applied in relevant annotation and data processing tasks.",Dataset Creation,Dataset Creation
"We provide the language and vision communities with a unique multimodal dataset comprised of co-captured gaze and audio data, and transcriptions. This dataset was collected via an image-inspection task with 100 general-domain images and American English speakers",Dataset Creation,Dataset Creation
"we propose to improve the quality of input (source language) representations of rare words in NMT by augmenting its embedding layer with a bi-directional recurrent neural network (biRNN), which can learn compositional input representations at different levels of granularity",Model Optimization,Model Optimization
"We choose bidirectional long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) with an attention mechanism to represent EDUs directly from embeddings, and use simple position features to capture shallow discourse structures, without relying on off-the-shelf tools or resources",Resources,Resources
"we propose an approach based on linguistic knowledge for identification of aliases mentioned using proper nouns, pronouns or noun phrases with common noun headword. We use Markov Logic Network (MLN) to encode the linguistic knowledge for identification of aliases. We evaluate on four diverse history narratives of varying complexity as well as newswire subset of ACE 2005 dataset. Our approach performs better than the state-of-the-art.",Theory Proposal,Theory Proposal
"we study how to automatically extract such relationship through a sentence-level relation classifier and aggregating the scores of entity pairs from a large corpus. Also, we release two benchmark datasets for evaluation and future research.",Dataset Creation,Dataset Creation
"we study the performance of plagdet, the main measure for Plagiarism Detection Systems evaluation, on manually paraphrased plagiarism datasets (such as PAN Summary). We reveal its fallibility under certain conditions and propose an evaluation framework with normalization of inner terms, which is resilient to the dataset imbalance. We conclude with the experimental justification of the proposed measure. The implementation of the new framework is made publicly available as a Github repository",Dataset Creation,Dataset Creation
"we use named entities as domain-specific terms for newscentric content and present a new weighting model for Latent Dirichlet Allocation. Our experimental results indicate that involving more named entities in topic descriptors positively influences the overall quality of topics, improving their interpretability, specificity and diversity.",Resources,Resources
"we propose a simple and parameter-efficient adaptation technique that only requires adapting the bias of the output softmax to each particular user of the MT system, either directly or through a factored approximation. Experiments on TED talks in three languages demonstrate improvements in translation accuracy, and better reflection of speaker traits in the target text.",Theory Proposal,Theory Proposal
"we propose an approach that uses both the sentences and the bag-of-words as targets in the training stage, in order to encourage the model to generate the potentially correct sentences that are not appeared in the training set. We evaluate our model on a Chinese-English translation dataset, and experiments show our model outperforms the strong baselines by the BLEU score of 4.55.1",Model Proposal,Model Proposal
"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them. The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision. Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.1",Dataset Creation,Dataset Creation
"we aim to compare the performance of attention-based models to another baseline, namely, neural hidden Markov models. The neural HMM has been successfully applied in the literature on top of conventional phrasebased systems (Wang et al., 2017). In this work, our purpose is to explore its application in standalone decoding, i.e. the model is used to generate and score candidates without assistance from a phrase-based system. Because translation is done standalone using only neural models, we still refer to this as NMT. In addition, while Wang et al. (2017) applied feedforward networks to model alignment and translation, the recurrent structures proposed in this work surpass the feedforward variants by up to 1.3% in BLEU.",Performance Evaluation,Performance Evaluation
"we propose a model that jointly identifies the domain and tracks the belief states corresponding to that domain. It uses semantic similarity between ontology terms and turn utterances to allow for parameter sharing between different slots across domains and within a single domain. In addition, the model parameters are independent of the ontology/belief states, thus the dimensionality of the parameters does not increase with the size of the ontology, making the model practically feasible to deploy in multidomain environments without any modifications. Finally, we introduce a new, large-scale corpora of natural, human-human conversations providing new possibilities to train complex, neural-based models",Model Proposal,Model Proposal
