Contribution,Annotation 1,Annotation 2
This paper describes a generic framework for generating comprehension questions from short edited texts using coherence relations.,Theory Proposal,Theory Proposal
"We present a simple, unsupervised but robust and accurate syntactic method for achieving the first objective and a modified hierarchical lexical method for the second objective.",New Algorithm/ Method,New Algorithm/ Method
we present a large-scale and indepth computational readability study for Arabic,Resources,Resources
we worked with an annotated corpus of human tutoring sessions from which we identified effective sessions based on human expert judgments,New Algorithm/ Method,New Algorithm/ Method
"we discuss one of the aspects of essay-writing, namely style, and how we can predict it automatically",Theory Proposal,Theory Proposal
"We describe the task definition, data preparation, performance metrics, and evaluation results.",Performance Evaluation,Performance Evaluation
This paper introduces our system at NLPTEA2018 Chinese Grammatical Error Diagnosis task. We will describe how to combine the knowledge that learned from large scale text data and handcraft heuristics with deep learning framework,New Algorithm/ Method,New Algorithm/ Method
"This paper introduces the DM NLP team’s system for NLPTEA 2018 shared task of Chinese Grammatical Error Diagnosis (CGED), which can be used to detect and correct grammatical errors in texts written by Chinese as a Foreign Language (CFL) learners",New Algorithm/ Method,New Algorithm/ Method
we employ the sequence to sequence learning to model the task of grammar error correction.,Model Proposal,Model Proposal
we propose a sequence labeling method based on the Policy Gradient LSTM model and apply it to this task to solve the above problems.,Model Optimization,Model Optimization
" In this paper, we report on a user study on language learners’ perceived usefulness of the application",Model Optimization,Model Optimization
"the domain of multi-perspective elaboration is used to illustrate that while Natural Language Processing (NLP) techniques are able to aid in the evaluation and implementation of key tool learning design objectives, that principled and critical analysis of learner impact is required in order to select appropriate techniques.",Algorithm/Method Optimization,Algorithm/Method Optimization
we present a qualitatively enhanced deep convolution recurrent neural network for computing the quality of a text in an automatic essay scoring task,Algorithm/Method Optimization,Algorithm/Method Optimization
This paper describes two models that employ word frequency embeddings to deal with the problem of readability assessment in multiple languages,Model Optimization,Model Optimization
provide a tool that enriches the traditional language learning setting in an enjoyable way and helps to avoid problems with learner motivation that can be encountered in language classes.,New Algorithm/ Method,New Algorithm/ Method
"This work presents an exploratory approach to the computational study of written language, oriented towards improving literacy acquisition in school-age children.",New Algorithm/ Method,New Algorithm/ Method
"This study assesses an index for measuring the pronunciation difficulty of sentences (henceforth, pronounceability) based on the normalized edit distance from a reference sentence to a transcription of learners’ pronunciation.",Theory Proposal,Theory Proposal
In this paper we report how we build a system and how to test it with a translated corpus from two publicly available English corpus,Theory Proposal,Theory Proposal
"This study explores the use of natural language processing techniques to enhance bilingual lexical access beyond simple equivalents, to enable translators to navigate along a wider cross-lingual lexical space and more examples showing different translation strategies, which is essential for them to learn to produce not only faithful but also fluent translations.",New Algorithm/ Method,New Algorithm/ Method
we propose methods to measure the bias and systematically remove its effects from a statistical model that learns the instructor’s intervention decision.,New Algorithm/ Method,New Algorithm/ Method
This paper studies how to integrate heterogeneous features such as a neural image feature generated from the image of the Web page by a variant of CNN (convolutional neural network) as well as text features extracted from the body text of the HTML file of the Web page.,Dataset Creation,Dataset Creation
"In this paper we formalize the problem automatic fill-in-the-blank question generation using two standard NLP machine learning schemes, proposing concrete deep learning models for each.",Algorithm/Method Optimization,Algorithm/Method Optimization
"this study aims to propose a proper short text clustering module for the IRS, and demonstrate our implemented techniques through real-world examples, so as to provide experiences and insights for further study.",Theory Proposal,Theory Proposal
"we use both a conventional linear CRF model (Lafferty et al., 2001) with specific feature engineering and a LSTM-CRF model to solve CGED task",Model Proposal,Model Proposal
"we regard CGED task as a sequence labeling problem(Zheng et al., 2016) and propose a CGED model with contextualized character representation.",Model Proposal,Model Proposal
we regarded the CGED 2018 shared task as a character-based sequence labeling task. We proposed a Bidirectional LSTM CRF(BiLSTM-CRF) neural network that combines LSTM and CRF for sequence labeling without any hand-craft features.,Resources,Resources
"This paper proposes a integrated approach of combining CRFs, statistical information from Google ngrams and rule-based expert knowledge to detect the four types of errors.",Model Optimization,Model Optimization
we build a Chinese Grammatical Error Diagnosis system in the NLPTEA2018 CGED shared task,Applications,Applications
The main goal of Chinese grammatical error diagnosis task is to detect word errors in the sentences written by Chinese-learning students.,Theory Proposal,Theory Proposal
"We present an approach for recursively splitting and rephrasing complex English sentences into a novel semantic hierarchy of simplified sentences, with each of them presenting a more regular structure that may facilitate a wide variety of artificial intelligence tasks, such as machine translation (MT) or information extraction (IE)",Theory Proposal,Algorithm/Method Optimization
" We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic.",Model Optimization,Model Proposal
"We present the zero-shot entity linking task, where mentions must be linked to unseen entities without in-domain labeled data.",Theory Proposal,Algorithm/Method Optimization
We propose a new neural transfer method termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER).,New Algorithm/ Method,New Algorithm/ Method
"we introduce an efficient knowledge distillation (KD) technique that transfers knowledge from a syntactic language model trained on a small corpus to an LSTM language model, hence enabling the LSTM to develop a more structurally sensitive representation of the larger training data it learns from",Performance Evaluation,Performance Evaluation
"we propose an imitation learning approach to unsupervised parsing, where we transfer the syntactic knowledge induced by the PRPN to a Tree-LSTM model with discrete parsing actions. Its policy is then refined by GumbelSoftmax training towards a semantically oriented objective.",Model Proposal,Model Optimization
" we annotate the Wall Street Journal part of the Penn Treebank with the gender information of the articles’ authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women.",Applications,Applications
"we study a broader range  of pre-training conditions and experiment over a variety of languages, both jointly and individually.
",Theory Proposal,Theory Proposal
We present a new method for sentiment lexicon induction that is designed to be applicable to the entire range of typological diversity of the world’s languages,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a tree communication model using graph convolutional neural network and graph recurrent neural network, which allows rich information exchange between phrases constituent tree.",Model Proposal,Model Optimization
"we design the gated unit networks to incorporate corresponding word representation into the decoder, and position-aware attention to pay more attention to the adjacent words of a target word.",Theory Proposal,Algorithm/Method Optimization
"In this paper, we propose a reinforced bidirectional attention network approach to tackle the above two challenges",Theory Proposal,Theory Proposal
"In this work, we present ELI5: a Long Form Question Answering dataset that emphasizes the dual challenges of isolating relevant information within long source documents and generating paragraph-length explanations in response to complex, diverse questions",Dataset Creation,Dataset Creation
"In this paper, we focus on the following two major characteristics of the TQA dataset. In this work, we introduce a novel algorithm
for solving the textbook question answering
(TQA) task which describes more realistic QA
problems compared to other recent tasks.",New Algorithm/ Method,New Algorithm/ Method
We present a novel approach to improve VQA performance that exploits this connection by jointly generating captions that are targeted to help answer a specific visual question.,Theory Proposal,Algorithm/Method Optimization
this paper proposes a multi-grained attention method. It learns explicit wordobject correspondence by two types of wordlevel attention complementary to the sentenceimage association.,New Algorithm/ Method,New Algorithm/ Method
"We investigate catastrophic forgetting in the context of multimodal models for Visual Question Answering (Antol et al., 2015) motivated by evidence from psycholinguistics.",Performance Evaluation,Performance Evaluation
"we propose a combined Visual and Textual Question Answering (VTQA) model which takes as input a paragraph caption as well as the corresponding image, and answers the given question based on both inputs.",Model Proposal,Model Optimization
"In this work, we aim to enhance the word representations and the interactions between the source and target words, while using even fewer parameters.",Theory Proposal,Model Optimization
In this work we present a new dataset of literary events—events that are depicted as taking place within the imagined space of a novel.,Dataset Creation,Dataset Creation
we propose a novel word reordering detection task to quantify how well the word order information learned by SAN and RNN.,Theory Proposal,Theory Proposal
In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP,Theory Proposal,Model Optimization
we provide novel support for this claim by performing a series of experiments to unpack the elements of English language structure learned by BERT.,Model Proposal,Model Proposal
"In this position paper, we argue that the community needs to make three substantive changes: (1) expanding our scope of problems to tackle both more subtle and more serious forms of abuse, (2) developing proactive technologies that counter or inhibit abuse before it harms, and (3) reframing our effort within a framework of justice to promote healthy communities.",Theory Proposal,Model Optimization
"we propose the self-feeding chatbot, a dialogue agent with the ability to extract new training examples from the conversations it participates in",Theory Proposal,Theory Proposal
"We propose an emotional dialogue system (EmoDS) that can generate the meaningful responses with a coherent structure for a post, and meanwhile express the desired emotion explicitly or implicitly within a unified framework",Theory Proposal,Theory Proposal
we propose a hierarchical graph representation by leveraging the structural property of dialog acts.,Theory Proposal,Theory Proposal
"we propose a novel incremental learning framework to design task-oriented dialogue systems, or for short Incremental Dialogue System (IDS),",Theory Proposal,Theory Proposal
"In this paper, we propose a new model, named ReCoSa, to tackle this problem. Firstly, a word level LSTM encoder is conducted to obtain the initial representation of each context.",Model Proposal,Model Optimization
"In this paper, we frame the consistency of dialogue agents as natural language inference (NLI) and create a new natural language inference dataset called Dialogue NLI. We propose a method which demonstrates that a model trained on Dialogue NLI can be used to improve the consistency of a dialogue model, and evaluate the method with human evaluation and with automatic metrics on a suite of evaluation sets designed to measure a dialogue model’s consistency.",Performance Evaluation,Performance Evaluation
"we measure budget in terms of the number of real user interactions. That is, we strive to optimize a dialogue agent via a fixed, small number of interactions with real users.",Theory Proposal,Theory Proposal
"In this work, we perform an extensive survey of decoding-time strategies for generating diverse outputs from conditional language models",Theory Proposal,New Algorithm/ Method
" In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation",New Algorithm/ Method,New Algorithm/ Method
we present a Vocabulary Pyramid Network (VPN) which is able to incorporate multi-pass encoding and decoding with multi-level vocabularies into response generation,Theory Proposal,Algorithm/Method Optimization
we propose an on-device neural network SGNN++ which dynamically learns compact projection vectors from raw text using structured and context-dependent partition projections,Theory Proposal,Theory Proposal
"In this paper, we take a radical step towards building a human-like conversational agent: endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic)",New Algorithm/ Method,Theory Proposal
"we propose a memory-augmented generative model, which learns to abstract from the training corpus and saves the useful information to the memory to assist the response generation. Our model clusters query-response samples, extracts characteristics of each cluster, and learns to utilize these characteristics for response generation",Model Proposal,Model Optimization
"In this paper, we propose to utilize the multiple references by considering the correlation of different valid responses and modeling the 1-to-n mapping with a novel two-step generation architecture",Model Proposal,Model Optimization
"This paper examines various unsupervised pretraining objectives for learning dialog context representations. Two novel methods of pretraining dialog context encoders are proposed, and a total of four methods are examined",New Algorithm/ Method,New Algorithm/ Method
" We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure.",Dataset Creation,Dataset Creation
"in this paper, we introduce a self-supervised learning task, inconsistent order detection, to explicitly capture the flow of conversation in dialogues.",New Algorithm/ Method,New Algorithm/ Method
"We explore the model’s behaviour on this task in detail, and conclude that its ability to model
humans is considerably weaker than K&C suggest.",Model Optimization,Model Proposal
"We propose an unsupervised approach for assessing conceptual complexity of texts, based on spreading activation.",Theory Proposal,Theory Proposal
"We propose two end-to-end metaphor identification models2 , detecting metaphors based on MIP and SPV, respectively",Model Proposal,Model Optimization
"this paper proposes a sense representation and tracking framework based on deep contextualized embeddings, aiming at answering not only what and when, but also how the word meaning changes",Theory Proposal,Theory Proposal
"We propose here a new task capturing crucial aspects of the human environment, such as natural object affordances, and of human conversation, such as full symmetry among the participants.",Theory Proposal,Theory Proposal
" We evaluate here an out-of-the-box CNN on the most challenging SCAN tasks, and we uncover the surprising fact that CNNs are dramatically better than RNNs at compositional generalization",Performance Evaluation,Performance Evaluation
" In this paper, we present a computational model which successfully identifies known universals, including Greenberg universals, but also uncovers new ones, worthy of further linguistic investigation",Theory Proposal,New Algorithm/ Method
"In this paper, we sought to fill this gap by employing a systematic approach that samples both over the space of algorithms and the space of human languages.",New Algorithm/ Method,New Algorithm/ Method
"we introduce a collection of large written corpora that we annotated using state-of-the-art parsers trained on Universal Dependencies (UD) treebanks (Nivre et al., 2018).",New Algorithm/ Method,New Algorithm/ Method
" In this paper, we present a novel approach
for incorporating external knowledge in Recurrent Neural Networks (RNNs).",Theory Proposal,New Algorithm/ Method
" We present a corpus of over 8,000 annotated text passages with ambiguous pronominal anaphora. These instances are both challenging and realistic",Theory Proposal,Algorithm/Method Optimization
. In this paper we propose Self Attentive Revision Encoder (StRE) which leverages orthographic similarity of lexical units toward predicting the quality of new edits.,Theory Proposal,Theory Proposal
"We propose an unsupervised method for collecting quantitative information from large amounts of web data, and use it to create a new, very large resource consisting of distributions over physical quantities associated with objects, adjectives, and verbs which we call Distribution over Quantities (DOQ)",New Algorithm/ Method,New Algorithm/ Method
"In our work, we target for the single-round non-task-oriented short-text conversation data collected from social media platforms",Dataset Creation,Dataset Creation
"we design a rubric for scoring an important, yet unexplored dimension of persuasive essay quality, thesis strength, and annotate a corpus of essays with thesis strength scores",Model Proposal,Model Proposal
"With this paper, we publish and analyze deISEAR, a German corpus of emotional event descriptions, and its English companion enISEAR, each containing 1001 instances",Theory Proposal,Theory Proposal
"This paper presents a multilingual corpus with semantic annotation of collocations in English, Portuguese, and Spanish.",Theory Proposal,Theory Proposal
"In this paper, we release a benchmark to directly test whether a system can differentiate natural language statements that make sense from those that do not make sense.",Theory Proposal,Theory Proposal
"We collected a dataset of jokes and funny dialogues in Russian from various online resources and complemented them carefully with unfunny texts with similar lexical properties. In this work we describe the creation of a large
dataset of funny short texts in Russian. ",Dataset Creation,Dataset Creation
"In this work, we present a method to decouple the language from the problem by learning language agnostic representations and therefore allowing training a model in one language and applying to a different one in a zero shot fashion.",New Algorithm/ Method,New Algorithm/ Method
we propose a generative model that aggregates short texts into clusters by leveraging the associated meta information.,Model Proposal,Model Proposal
we present two types of decoding functions whose inverse can be easily derived without expensive inverse calculation.,Model Proposal,Model Proposal
In this paper we introduce a new anomaly detection method—Context Vector Data Description (CVDD)—which builds upon word embedding models to learn multiple sentence representations that capture multiple semantic contexts via the self-attention mechanism,New Algorithm/ Method,New Algorithm/ Method
"This paper presents a new method for Bilingual Lexicon Induction (BLI), which we call Hubless Nearest Neighbor (HNN).",New Algorithm/ Method,New Algorithm/ Method
we introduce a noise detection component in our model: it lets the model detect and disregard examples which are likely to be noisy,Model Proposal,Model Proposal
"e, we introduce a new approach that learns an AL query strategy directly for the target problem of interest",New Algorithm/ Method,New Algorithm/ Method
"we propose a novel hierarchical attention-based architecture to serve as the neural regression function, with which the context information of a word is encoded and aggregated from K observations.",Theory Proposal,Theory Proposal
"this work, we propose a new method for constructing diachronic words embeddings, which we show to be competitive with prior approaches",New Algorithm/ Method,New Algorithm/ Method
We present a novel neural network architecture to simultaneously learn a two-part representation which is based on the principle of segregating source specific representation from the common representation,Algorithm/Method Optimization,Algorithm/Method Optimization
"In this study, we propose to use a block-regularized 3 × 2 CV (3 × 2 BCV) in model comparison because it could regularize the difference in certain frequency distributions over linguistic units between training and validation sets and yield stable estimators of P, R, and F1.",Model Optimization,Model Optimization
"In this paper, we propose an iterative inference algorithm based on gradient search, which is the first inference algorithm that can be broadly applied to any neural sequence generative models for text infilling tasks",Model Optimization,Model Optimization
We present here a general-purpose addition to the standard seq2seq framework that aims to simultaneously tackle all of the above issues,Algorithm/Method Optimization,Algorithm/Method Optimization
"In this paper, we propose the MINA algorithm for automatically extracting minimum spans to benefit from minimum span evaluation in all corpora",New Algorithm/ Method,New Algorithm/ Method
We propose a neural architecture for cross-document coreference resolution.,Theory Proposal,Theory Proposal
We propose an efficient neural framework for sentence-level discourse analysis in accordance with Rhetorical Structure Theory (RST).,Performance Evaluation,Performance Evaluation
"In this work, we explore this property in a multi-task learning framework for IDRR in which the relations and the connectives are simultaneously predicted, and the mapping is leveraged to transfer knowledge between the two prediction tasks via the embeddings of relations and connectives. We propose several techniques to enable such knowledge transfer that yield the state-of-the-art performance for IDRR on several settings of the benchmark dataset (i.e., the Penn Discourse Treebank dataset).",Theory Proposal,Theory Proposal
we explore the hypothesis that linguistic deficits drive the error patterns of speaker commitment models by analyzing the linguistic correlates of model errors on a challenging naturalistic dataset,Dataset Creation,Dataset Creation
"In this paper, we suggest to view learning event embedding as a multi-relational problem, which allows us to capture different aspects of event pairs",Theory Proposal,Theory Proposal
"In this paper, we propose a method for whyquestion answering (why-QA) that uses an adversarial learning framework.",New Algorithm/ Method,New Algorithm/ Method
"k, we propose a data augmentation technique by automatically generating relevant unanswerable questions according to an answerable question paired with its corresponding paragraph that contains the answer",Theory Proposal,Theory Proposal
we present a detailed analysis of why single-hop reasoning works so well,Model Proposal,Model Proposal
"We propose a new end-to-end question answering model, which learns to aggregate answer evidence from an incomplete knowledge base (KB) and a set of retrieved text snippets",Model Optimization,Model Optimization
we propose an adaptive decoding method to avoid such intermediate representations.,New Algorithm/ Method,New Algorithm/ Method
"This paper tackles this gap and performs an in-depth investigation of the characteristics of legal and illegal text in the Darknet, comparing it to a clear net website with similar content as a control condition.",Performance Evaluation,Performance Evaluation
" In this paper, we propose a weakly-supervised information extraction framework for automated CTA transcript parsing",Theory Proposal,Theory Proposal
"In this paper, we first build a novel boundary during searching for new concepts via external knowledge base and then utilize heterogeneous features to verify the highquality results.",New Algorithm/ Method,New Algorithm/ Method
"We show that the imperceptibility of several existing linguistic steganographic systems (Fang et al., 2017; Yang et al., 2018) relies on implicit assumptions on statistical behaviors of fluent text",Theory Proposal,Theory Proposal
"We evaluate a broad variety of neural models on the new dataset, establishing strong baselines that surpass previous feature-based models in three tasks: (1) binary violation classification; (2) multi-label classification; (3) case importance prediction",Performance Evaluation,Performance Evaluation
" We propose an approach to improving the robustness of NMT models, which consists of two parts: (1) attack the translation model with adversarial source examples; (2) defend the translation model with adversarial target inputs to improve its robustness against the adversarial source inputs.",Model Optimization,Model Optimization
"In this paper, we address these issues by sampling context words not only from the ground truth sequence but also from the predicted sequence by the model during training, where the predicted sequence is selected with a sentence-level optimum.",Model Proposal,Model Proposal
"In this paper, we introduce an alternative reward function for optimizing NMT systems that is based on recent work in semantic similarity",New Algorithm/ Method,New Algorithm/ Method
"This paper proposes a novel AutoML strategy based on probabilistic grammatical evolution, which is evaluated on the health domain by facing the knowledge discovery challenge in Spanish text documents",Performance Evaluation,Performance Evaluation
"this paper proposes a ∆-learning approach to distill discrimination and generalization knowledge by effectively decoupling, incrementally learning and adaptively fusing event representation",Theory Proposal,Theory Proposal
"In this paper, we proposed the multi-granularity lattice framework (MG lattice), a unified model comprehensively utilizes both internal information and external knowledge, to conduct the Chinese RE task.",Model Proposal,Model Proposal
"we propose A2N, an effective model (Section 2) which, conditioned on the query, uses a bi-linear attention on the graph neighborhood of an entity to generate an embedding representation of the entity.",Model Optimization,Model Optimization
"In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively.",Theory Proposal,Theory Proposal
"In this paper, we introduce a framework to infuse temporal awareness into such models by learning a pre-trained model to embed timexes.",Model Proposal,Model Proposal
"We consider a novel question answering (QA) task where the machine needs to read from large streaming data (long documents or videos) without knowing when the questions will be given, which is difficult to solve with existing QA methods due to their lack of scalability.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we introduce query-agnostic indexable representations of document phrases that can drastically speed up open-domain QA",Theory Proposal,Theory Proposal
"In this work, we propose neural variational language model (NVLM), which enables the sharing of grammar knowledge among different corpora.",Model Proposal,Model Proposal
"We present a new dataset with 1,390 examples from 7 application domains (e.g. a calendar or a file manager), each example consisting of a triplet: (a) the application’s initial state, (b) an instruction, to be carried out in the context of that state, and (c) the state of the application after carrying out the instruction",Dataset Creation,Dataset Creation
"We conduct the first large-scale systematic study of candidate pretraining tasks, comparing 19 different tasks both as alternatives and complements to language modeling",Resources,Resources
"In this work, we focus on complex question semantic parsing and propose a novel Hierarchical Semantic Parsing (HSP) method, which utilizes the decompositionality of complex questions for semantic parsing.",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks.",New Algorithm/ Method,New Algorithm/ Method
We demonstrate that the automatically curated corpus allows a bidirectional LSTM sentence encoder to yield high quality sentence embeddings and can serve as a supervised fine-tuning dataset for larger models such as BERT,Dataset Creation,Dataset Creation
"we introduce SParC (cross-domain Semantic Parsing in Context), an expert-labeled dataset which contains 4,298 coherent question sequences (12k+ questions paired with SQL queries) querying 200 complex databases in 138 different domains",Dataset Creation,Dataset Creation
We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges: 1) the mismatch between intents expressed in natural language (NL) and the implementation details in SQL; 2) the challenge in predicting columns caused by the large number of outof-domain words,Model Proposal,Model Proposal
"we experiment with spectral methods of signal representation and summarization as mechanisms for constructing such word-sequence embeddings in an unsupervised fashion. In particular, we explore an algorithm rooted in fluid-dynamics, known as higher-order Dynamic Mode Decomposition, which is designed to capture the eigenfrequencies, and hence the fundamental transition dynamics, of periodic and quasi-periodic systems.",New Algorithm/ Method,New Algorithm/ Method
"We propose SEMBLEU, a robust metric that extends BLEU (Papineni et al., 2002) to AMRs",Theory Proposal,Theory Proposal
"We implement our reranker in a competitive neural semantic parser and test on four semantic parsing (GEO, ATIS) and Python code generation (DJANGO, CONALA) tasks, improving the strong baseline parser by up to 5.7% absolute in BLEU (CONALA) and 2.9% in accuracy (DJANGO), outperforming the best published neural parser results on all four datasets.",Dataset Creation,Dataset Creation
" In this paper, we present an encoder-decoder semantic parser, where the structure of the DB schema is encoded with a graph neural network, and this representation is later used at both encoding and decoding time.",Theory Proposal,Theory Proposal
This paper presents a conservative estimate of human performance to serve as a target for the GLUE sentence understanding benchmark.,Model Proposal,Model Proposal
"In this paper, we present a single semantic parser that does very well across all of DM, PAS, PSD, EDS and AMR (2015 and 2017).",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we show that combination of different methods makes a positive impact",New Algorithm/ Method,New Algorithm/ Method
"we present two novel contributions. First, we present an analysis that spans the common components of a traditional NLP pipeline. We show that the order in which specific abstractions are encoded reflects the traditional hierarchy of these tasks. Second, we qualitatively analyze how individual sentences are processed by the BERT network, layer-by-layer. We show that while the pipeline order holds in aggregate, the model can allow individual decisions to depend on each other in arbitrary ways, deferring ambiguous decisions or revising incorrect ones based on higher-level information",Algorithm/Method Optimization,Algorithm/Method Optimization
"We present a model and methodology for learning paraphrastic sentence embeddings directly from bitext, removing the timeconsuming intermediate step of creating paraphrase corpora",New Algorithm/ Method,New Algorithm/ Method
"In this paper, we propose a second-order semantic dependency parser, which takes into consideration not only individual dependency edges but also interactions between pairs of edges",Theory Proposal,Theory Proposal
"we propose a new sarcasm dataset, Multimodal Sarcasm Detection Dataset (MUStARD1 ), compiled from popular TV shows.",Theory Proposal,Theory Proposal
"In this paper, we tackle these tasks in the context of complex arguments on a diverse set of topics.",Theory Proposal,New Algorithm/ Method
", we investigate two formalisms with deep sentiment representations that capture sentiment subtype expressions by latent variables and Gaussian mixture vectors, respectively",Performance Evaluation,Performance Evaluation
In this work we focus on Japanese and show the potential use of transfer learning techniques in text classification.,Theory Proposal,Theory Proposal
We analyze the nature of these cues and demonstrate that a range of models all exploit them,Performance Evaluation,Performance Evaluation
We propose a reason comparing network (RCN) to leverage reason information for stance comparison.,Theory Proposal,Theory Proposal
"we conduct a task of human motive detection. We manually annotate 1,600 review texts in restaurant and laptop domains from existing ABSA datasets with the six motives. The annotation results reveal that people are driven by different motives in different domains. Finally, we report the performance of baseline methods on this new dataset.",New Algorithm/ Method,New Algorithm/ Method
we propose a novel method to refine the embeddings of targets and aspects. Such pivotal embedding refinement utilizes a sparse coefficient vector to adjust the embeddings of target and aspect from the context.,Performance Evaluation,Performance Evaluation
"We address this task in an empirical manner by annotating 39 political debates from the last 50 years of US presidential campaigns, creating a new corpus of 29k argument components, labeled as premises and claims. We then propose two tasks: (1) identifying the argumentative components in such debates, and (2) classifying them as premises and claims.",Theory Proposal,Theory Proposal
This study investigates (i) span representation originally developed for other NLP tasks and (ii) a simple task-dependent extension for ASP. Our extensive experiments and analysis show that these representations yield high performance for ASP and provide some challenging types of instances to be parsed,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we present a fast and strong neural approach for general purpose text matching applications.",Model Proposal,Model Proposal
"We present a monolingual alignment system for long, sentence- or clause-level alignments, and demonstrate that systems designed for word- or short phrase-based alignment are illsuited for these longer alignments",Model Proposal,Algorithm/Method Optimization
"In this paper, we show that these two problems are actually complementary",Theory Proposal,Model Proposal
We present a latent variable model for predicting the relationship between a pair of text sequences,Model Proposal,Model Proposal
"We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017).",Model Proposal,Model Proposal
We present a supervised model for automatically identifying when one event is a subevent of another.,Model Proposal,Model Proposal
"In this paper, we show that commonsense inference still proves dicult for even stateof-the-art models, by presenting HellaSwag, a new challenge dataset.",Dataset Creation,Dataset Creation
we propose a novel framework to build a unified multi-domain enabled semantic parser trained only with weak supervision (denotations).,Theory Proposal,Theory Proposal
We introduce the use of Poincare embeddings ´ to improve existing state-of-the-art approaches to domain-specific taxonomy induction from text as a signal for both relocating wrong hyponym terms within a (pre-induced) taxonomy as well as for attaching disconnected terms in a taxonomy.,Theory Proposal,New Algorithm/ Method
"In this paper, we recast MNLI and JOCI as COPA-style plausibility tasks by sampling and constructing (p, h, h 0 ) triples from these two datasets. Each premise-hypothesis pair (p, h) is labeled with different levels of plausibility yp,h.",Dataset Creation,Dataset Creation
we propose a simple and effective method for fine-tuning distributional word vectors for LE. Our Generalized Lexical ENtailment model (GLEN) is decoupled from the word embedding model and applicable to any distributional vector space,New Algorithm/ Method,New Algorithm/ Method
"In this paper, we describe a simple re-implementation of BERT for commonsense reasoning.",Theory Proposal,Theory Proposal
". In this paper, we show that the performance of three language models on WSC273 consistently and robustly improves when finetuned on a similar pronoun disambiguation problem dataset (denoted WSCR).",Dataset Creation,Dataset Creation
"In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph.",Model Proposal,Model Proposal
We propose an end-to-end neural model with coreference alignment and conversation flow modeling.,Model Proposal,Model Proposal
We propose a cross-lingual QG model which uses the following training regime: (i) Unsupervised pretraining of language models in both primary and secondary languages and (ii) joint supervised training for QG in both languages.,Model Optimization,Model Optimization
"we propose a hierarchical reinforced sequence operation method, named Point-Then-Operate (PTO), which consists of a high-level agent that proposes operation positions and a lowlevel agent that alters the sentence",New Algorithm/ Method,New Algorithm/ Method
"We propose a new metric, PARENT, which aligns n-grams from the reference and generated texts to the semi-structured data before computing their precision and recall.",Theory Proposal,Theory Proposal
"In this work, we explore to what extent high quality training data is actually required for Extractive QA, and investigate the possibility of unsupervised Extractive QA.",Theory Proposal,Theory Proposal
", we propose MULTIQA, a BERTbased model, trained on multiple RC datasets, which leads to state-of-the-art performance on five RC datasets",Model Optimization,Model Optimization
"We propose a curriculum learning (CL) based Pointer-Generator framework for reading/sampling over large documents, enabling diverse training of the neural model based on the notion of alternating contextual difficulty",Model Optimization,Model Optimization
We propose Commonsense Auto-Generated Explanations (CAGE) as a framework for generating explanations for CQA.,Theory Proposal,Theory Proposal
"In this work, we address the interpretability of ML based question answering (QA) models on a combination of knowledge bases (KB) and text documents",Model Proposal,Model Proposal
"We measure this characteristic using modularity, a network measurement that measures the strength of clusters in a graph",Theory Proposal,Theory Proposal
"In this paper, we present the first work on cross-lingual generalisation of GR-LE relation",Theory Proposal,Theory Proposal
"In this paper, we extend these earlier experiments to cover 69 languages from 13 language families using a multilingual Bible corpus",Theory Proposal,Theory Proposal
The goal of this paper is to shed light on this matter so as to better understand the nature and extension of these limitations.,Theory Proposal,Theory Proposal
"We provide implication for other domainrelated works where better representation of
domain terms is important, especially when
the data set is highly imbalanced.",Theory Proposal,Theory Proposal
"we propose a novel methodology to automatically
verify the presence of therapeutic factors in
social networking websites by using Natural
Language Processing (NLP) techniques",New Algorithm/ Method,New Algorithm/ Method
"To achieve this task, natural language processing techniques were used to predict whether
each Tweet from a given set of Tweets contains a
mention of an ADR and extract any mentions of
ADRs",Theory Proposal,Theory Proposal
"we describe the development of
TCL, a lexicon for Turkish discourse connectives,
which follows the format of DiMLex",Theory Proposal,Theory Proposal
"This paper proposes a novel representation of
event structure by separating verbal semantics and the meaning of argument structure
constructions that verbs occur in.",New Algorithm/ Method,New Algorithm/ Method
"we propose that natural language generation
systems describing emotions should take into account how emotions are expressed non-verbally",New Algorithm/ Method,New Algorithm/ Method
"we show that some emotions are more
likely to be expressed via a certain channel, and
this channel is also influenced by the presence or
non-presence of a communication partner",Theory Proposal,Theory Proposal
"Using the Recursive feature elimination with
cross-validation (RFECV) algorithm, we perform feature selection experiments on an exhaustive set of nineteen features (belonging
to all the classes mentioned above) extracted
from Brown corpus text",New Algorithm/ Method,New Algorithm/ Method
"we take advantage of
these characteristics to identify the highlights
of pre-scheduled events from tweet streams
and we demonstrate a method to summarize
these highlights",Theory Proposal,Theory Proposal
"To incorporate sentiment score in predicting
a movie’s success",Performance Evaluation,Performance Evaluation
"we explore the viability
of models for the preemptive toxic detection task.",Performance Evaluation,Performance Evaluation
"we adapt a CRF layer as a a top module over the
outputs of the BERT-based model and demonstrate
that it improves performance even further.",Model Optimization,Model Optimization
we increase precision by filtering these name candidates with automatically learnt inflection patterns derived from name occurrences in large news article collections.,Algorithm/Method Optimization,Algorithm/Method Optimization
we discuss possible methods for improving sentiment classification for Slovak language by using state-of-the-art methods.,Algorithm/Method Optimization,Algorithm/Method Optimization
"Examines bias in ELMo and BERT, taking advantage of their context-sensitivity to give better visualizations",Theory Proposal,Theory Proposal
"We propose a multi-head natural
language inference (NLI) encoder which resolves
co-reference though heuristic interaction and efficiently addresses the redundancy in BERT by applying dropout to inputs directly",New Algorithm/ Method,New Algorithm/ Method
we propose an extractive question answering (QA) formulation of pronoun resolution task that overcomes this limitation and shows much lower gender bias (0.99) on their dataset.,Theory Proposal,Theory Proposal
"we aim to support the annotation of argument schemes by combining a recently developed annotation method for one of
the leading typologies of argument schemes (Section 4) and a popular online software tool for
annotating argumentative discourse, OVA",New Algorithm/ Method,New Algorithm/ Method
we present a robust English corpus and annotation schema that allows us to explore the less straightforward examples of term-definition structures in free and semi-structured text,Dataset Creation,Dataset Creation
"it is essential to include a
justification method in similar annotation tasks as
a suitable way of checking the guidelines and improving the training and evaluation processes of
automatic systems towards explainable AI",New Algorithm/ Method,New Algorithm/ Method
"We introduce two novel automated metrics:
Semantic Similarity and Response Echo Index and we show that they correlate well with
human judgment",New Algorithm/ Method,New Algorithm/ Method
we propose a novel method to select an appropriate response from response candidates generated by NCMs.,New Algorithm/ Method,New Algorithm/ Method
"we outline the approach and key components through which our conversational agent, Ruuh is able to accommodate a wide range of social needs",Theory Proposal,Theory Proposal
"We present de-lexical segmentation, a linguistically motivated alternative to greedy or other unsupervised methods, requiring language specific knowledge, but no direct supervision.",New Algorithm/ Method,New Algorithm/ Method
We explore the use of data mining and NLP techniques for understanding the variability of tones in a large corpus of Mandarin newscast speech,Theory Proposal,Theory Proposal
k we investigate using a subtle yet robust signal to resolve such ambiguity: linguistic alignment.,Performance Evaluation,Performance Evaluation
we conduct a detailed study with human annotators to confirm that our selection of semantic roles is effective in determining the underlying rhetorical structure of existing biomedical articles in an extensive dataset.,Theory Proposal,Theory Proposal
we show that filtering for transitivity within pairwise annotations is more effective than filtering based on annotation confidence measures for individual examples.,Algorithm/Method Optimization,Algorithm/Method Optimization
"we take the novel approach of applying, for aggregation, a gradual argumentation semantics to bipolar argumentation frameworks mined using stance detection",New Algorithm/ Method,New Algorithm/ Method
we describe the the DipInfo-UniTo realizer (hencefort UniTO realizer) participating to the shallow track of the Surface Realization Shared Task 2018,Theory Proposal,Theory Proposal
we show that the internal representations of RNNs trained on a variety of NLP tasks encode these syntactic features without explicit supervision,Theory Proposal,Theory Proposal
We propose an efficient gradient-based optimization method to manipulate discrete text structure at its one-hot representation,Algorithm/Method Optimization,Algorithm/Method Optimization
we propose a method for obtaining high quality word embeddings that capture domain specific semantics and are suitable for tasks on the specific domain,New Algorithm/ Method,New Algorithm/ Method
"addresses the linguistic phenomenon of null-instantiated frame elements, i.e., implicit semantic roles, and their
representation in FrameNet (FN)",Theory Proposal,Theory Proposal
We develop an unsupervised pipeline to extract schemas and apply our method to Reddit posts to detect schematic structures that are characteristic of different subreddits.,New Algorithm/ Method,New Algorithm/ Method
"We developed a machine-learning-based
method to detect video game players that
harass teammates or opponents in chat earlier
in the conversation",New Algorithm/ Method,New Algorithm/ Method
"The
aim of these models is to identify abusive language that directly targets certain individuals or
groups, particularly people belonging to protected
categories",Theory Proposal,Theory Proposal
"focuses on using exclusively text-based input in the detection, in an optimised architecture combining Convolutional Neural Networks and Long ShortTerm Memory-networks.",New Algorithm/ Method,New Algorithm/ Method
"I
show how gender should be explored in
multiplicity in computational research
through clustering techniques, and layout
how this is being achieved in a study in
progress on gender hostility on Stack
Overflow.",Theory Proposal,Theory Proposal
"aims to fill this gap by applying
the WEAT bias detection method to four sets
of word embeddings trained on corpora from
four different domains: news, social networking, biomedical and a gender-balanced corpus extracted from Wikipedia (GAP).",Performance Evaluation,Performance Evaluation
Demonstrates the effectiveness of the debiasing conceptor on both traditional and contextualized word embeddings.,Theory Proposal,Theory Proposal
"we propose to make use of the
recent popular BERT tool (Devlin et al., 2018).
BERT is a model trained for masked language
modeling (LM) word prediction and sentence prediction using the transformer network",Model Proposal,Model Proposal
"Our work is the
first successful attempt of using R-GCN to boost
the performance of BERT contextual embeddings
without the need to fine tune BERT",Model Optimization,Model Optimization
"we apply a variant of the Structured Prediction Energy Network (SPEN) (Belanger and McCallum, 2016) to the Dialogue State Tracking Challenge (DSTC) 2 datase",Applications,Applications
"We leverage the pretrained multilingual
BERT cased model to encode input sentences and apply additional word-level and
character-level LSTM layers before jointly
decoding lemmas and morphology tags using
simple sequence tagging layers",Model Optimization,Model Optimization
We apply convolutional neural networks to the task of shallow morpheme segmentation using low-resource datasets for 5 different languages,New Algorithm/ Method,New Algorithm/ Method
"we apply modern language modeling techniques to a large-vocabulary icon set commonly used in AAC applications, but for which we have no in-domain training data.",Applications,Applications
"we define a meaning representation label set by adapting the English
schema and taking into account the specific
characteristics of Vietnamese.",Theory Proposal,Theory Proposal
"we propose the addition of a set of speech acts, tense and aspect information, and parameters that help specify spatial location",Theory Proposal,Theory Proposal
"We
propose using a neural encoder-decoder model to
extract story events and present empirical results
with significant improvements over the baseline.",Model Proposal,Model Proposal
"we present the results of a full end-to-end
story generation pipeline as originally proposed by
Martin et al. (2018) (Figure 1), showing how all of
the sub-systems can be integrated.",Theory Proposal,Theory Proposal
"We define the task of scenario detection
and introduce a benchmark dataset of
annotated narrative texts, with segments
labeled according to the scripts they in-stantiate.",Dataset Creation,Dataset Creation
To prepare a data set to define a movie’s success,Dataset Creation,Dataset Creation
"we introduce the first
publicly-available Levantine Hate Speech and
Abusive (L-HSAB) Twitter dataset with the
objective to be a benchmark dataset for automatic detection of online Levantine toxic contents",Dataset Creation,Dataset Creation
"using a large data set of conversations among
Wikipedia contributors, we compile and make publicly available a new dataset with complete discussion threads and with semi-automatically generated
toxicity labels",Dataset Creation,Dataset Creation
"We train a neural network
with an objective to label sentences as grammatical or ungrammatical, using a “simulated
learner corpus”: a dataset with correct text
and with artificial errors, generated automatically",New Algorithm/ Method,New Algorithm/ Method
"We present the first gold-standard dataset for
Russian annotated with compositionality information of noun compounds.",Dataset Creation,Dataset Creation
"We release
a new gender-balanced dataset1 of 800 sentences pertaining to specific professions and
propose a methodology for using it as a test
bench to evaluate sentiment analysis models",Dataset Creation,Dataset Creation
we use Strictly k-Piecewise languages to generate datasets with various propertiesto compute the characteristics of the LDDs in these datasets using mutual information and analyze the impact of factors,Dataset Creation,Dataset Creation
we introduce a dataset of 230 synthesis procedures annotated by domain experts with labeled graphs that express the semantics of the synthesis sentences.,Dataset Creation,Dataset Creation
"create and organize a collection of
lemmas that would serve as a “hub” point for different resources",Resources,Resources
"presents the annotation
of formulaic sequences in the reference corpus of
spoken Slovenian in terms of syntactic structure,
pragmatic function and semantic relevance",New Algorithm/ Method,New Algorithm/ Method
"we present a data set of HindiEnglish code-mixed tweets labelled with semantic
roles. These labels provide us with information of the role played by an argument with respect to a
verb in a given sentence",Dataset Creation,Dataset Creation
"We developed detailed
and explicit guidelines for human annotators, and
tested these on corpus data",New Algorithm/ Method,New Algorithm/ Method
"a recorded dataset of 400 speeches discussing 200 controversial topics, along with mined claims for each topic",Dataset Creation,Dataset Creation
"We release CompSent-19, a new corpus consisting of 7,199 sentences containing item pairs (27% of the sentences are tagged as comparative and annotated with a preference);",Dataset Creation,Dataset Creation
"we propose the Restricted RNTN (r-RNTN) which uses only K < |V | recurrence matrices. Given that |V | words must be assigned K matrices, we map the most frequent K − 1 words to the first K − 1 matrices, and share the K-th matrix among the remaining words.",Theory Proposal,Theory Proposal
"We enhance tweet representation with a language model and distinguish the importance of different words with
Multi-Head Self-Attention",Model Proposal,Model Proposal
"We propose that a lattice-like architecture of the annotation categories can adequately handle all four issues, and at the same
time remain both intuitive for annotators and
faithful to typological insights",New Algorithm/ Method,New Algorithm/ Method
"presents an annotation scheme for modality that employs a dependency structure. Events and sources (here, conceivers) are represented as nodes and epistemic strength relations characterize the edges.",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel way to combine a neural
story generation model with an explicit, symbolic text planning component; furthermore,
we show that the design reduces the demand
on training data",New Algorithm/ Method,New Algorithm/ Method
"We present an ensemble-based system for eventto-sentence that allows for guided language generation and demonstrate that this outperforms a
baseline sequence-to-sequence approach.",New Algorithm/ Method,New Algorithm/ Method
We propose a hybrid system combining a rule-based approach and light ML techniques. We use multilingual lexical resources such as JRC-NAMES and BABELNET together with a named entity guesser to recognise names.,New Algorithm/ Method,New Algorithm/ Method
I present a novel neural network model based on the pre-trained BERT for the gendered pronoun resolution task,Model Proposal,Model Proposal
"The model presented here draws upon
the strengths of state-of-the-art language and
coreference resolution models, and introduces
a novel evidence-based deep learning architecture.",Model Proposal,Model Proposal
"we started experimenting with machine
learning approaches for automating part of the annotation process",Model Proposal,Model Proposal
"we achieve
these features in a simple architecture integrating
existing methods on top of SEQ2SEQ in order to
make it easily reproducible in existing dialogue
systems",New Algorithm/ Method,New Algorithm/ Method
Our models combine sparse sequence-to-sequence models with a two-headed attention mechanism that learns separate attention distributions for the lemma and inflectional tags,Model Proposal,Model Proposal
We propose a merging strategy inspired by Byte-Pair-Encoding that reduces the space of valid operations by merging frequent adjacent operations,New Algorithm/ Method,New Algorithm/ Method
We present various models to tackle each task and evaluate performance.,Model Proposal,Model Proposal
We explore the potential of a transfer learning approach to improve the performance of an argument mining model trained with a small volume of data annotated with the proposed scheme.,New Algorithm/ Method,New Algorithm/ Method
we propose a neural network to evaluate the probability of there being a relation between ACs and to rank ACs using TextRank on the basis of probability,Performance Evaluation,Performance Evaluation
"we first introduce a variant of GloVe, in which there is an explicit connection between word vectors and PMI weighted co-occurrence vectors. We then show how relation vectors can be naturally embedded into the resulting vector space.",New Algorithm/ Method,New Algorithm/ Method
"we propose an approach to explicitly obscure important author characteristics at training time, such that representations learned are invariant to these attributes",New Algorithm/ Method,New Algorithm/ Method
"Our approach relied on a text processing pipeline for tweets, and training traditional machine learning and deep learning models",Theory Proposal,Theory Proposal
aims to detect tweets with Adverse Drug Reaction (ADR) mentions we used ELMo embeddings which is a deep contextualized word representation able to capture both syntactic and semantic characteristics,New Algorithm/ Method,New Algorithm/ Method
"We train ULMFit and BERT models for Tasks 1 and 4, and show that these models are agnostic to the effects of undersampling and oversampling, given a highly imbalanced dataset",Performance Evaluation,Performance Evaluation
"We propose
an end-to-end framework to automatically generate a sequence of pictures that represent major
2
events in a story text.",New Algorithm/ Method,New Algorithm/ Method
"We develop a story generation model that
generates globally coherent stories about
daily activities.",New Algorithm/ Method,New Algorithm/ Method
"we present a system to monitor cyberbullying phenomena by
combining message classification and social
network analysis.",New Algorithm/ Method,New Algorithm/ Method
"We propose
a structured annotation scheme that labels claim
verifiability, stance, and sentiment on news outlets.",New Algorithm/ Method,New Algorithm/ Method
"The goal is to develop a resource and
methods for distinguishing compositional compounds, which meaning could be split into parts,
from non-compositional ones that have a solid
meaning, and for which we would like to have a
dedicated embedding",Resources,Resources
"we build a neural (NMT) machine system on the publicly available clean out-of-domain news corpus, and a phrase-based (PBMT) system trained on the same data in order to compare the two approaches in this specific scenario.",New Algorithm/ Method,New Algorithm/ Method
The paper presents a generic approach to the supervised sentiment analysis of social media content in foreign languages,New Algorithm/ Method,New Algorithm/ Method
"presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health.",New Algorithm/ Method,New Algorithm/ Method
"Introduces debiasing conceptors along with
a formal definition and mathematical relation
to the Word Embedding Association Test",Theory Proposal,Theory Proposal
"we
describe our BERT-based approach to solving
the problem of gender-balanced pronoun resolution. We are able to reach 92% F1 score and
a much lower gender bias on the benchmark
dataset shared by Google AI Language team.",New Algorithm/ Method,New Algorithm/ Method
we propose an approach to extend biased single-output genderblind NLP systems with gender-specific alternative reinflections.,New Algorithm/ Method,New Algorithm/ Method
"we present the currently available
language processing systems similar to emtsv for
the sake of comparison.",Theory Proposal,Theory Proposal
"we show that representing the concept of word complexity in a continuous manner
results in higher inter-annotator agreement than
using binary labels.",New Algorithm/ Method,New Algorithm/ Method
"our
aim is to create a system that is actually capable
of formulating relevant questions about the text it
processes.",New Algorithm/ Method,New Algorithm/ Method
"we focus on goal-oriented dialog systems that have a
clear message they need to convey, such as a price
or available times, and the role of computational
creativity in encapsulating their message in a creative form",New Algorithm/ Method,New Algorithm/ Method
"We propose an adversarial learning approach
for generating multi-turn dialogue responses.
Our proposed framework, hredGAN, is based
on conditional generative adversarial networks",New Algorithm/ Method,New Algorithm/ Method
"we propose a response
generation model that outputs diverse words while
preserving relevance in response to the input utterance",Model Proposal,Model Proposal
We present a hierarchical neural model for contextual morphological analysis with a shared encoder and independent decoders for each coarse-grained feature.,Model Proposal,Model Proposal
", we present our approach of treating contextual morphological analysis as the generation of the correct sequence of MSD tag dimensions.",New Algorithm/ Method,New Algorithm/ Method
We propose a model to perform morphosyntactic annotation for any language with a translation of the Bible.,Model Proposal,Model Proposal
we present artificial phonology experiments that show that phone embeddings learn paradigmatic relationships such as phonemic and allophonic distribution quite well,Model Proposal,Model Proposal
"This paper demonstrates that there are regular functions that are not weakly deterministic, and, because all attested processes so far studied are weakly deterministic, supports the subregular hypothesis.",Performance Evaluation,Performance Evaluation
We propose and test an annotation scheme that we use to conduct a pilot annotation experiment in which we enrich a subset of the SciDTB corpus with an additional layer of argumentative structures.,New Algorithm/ Method,New Algorithm/ Method
We present an experimental study of supervised classifiers and a strong rule-based baseline from prior work.,Theory Proposal,Theory Proposal
"we present a large-scale and indepth computational readability study for Arabic. Arabic, being a relatively low-resource and morphologically complex language, presents numerous challenges to the task of automatic readability assessment.",Theory Proposal,Theory Proposal
"we propose a new method to study social media
content by characterizing disease-related correlations of language, by leveraging available demographic and disease information on the community level.",New Algorithm/ Method,New Algorithm/ Method
we describe our methods to automatically classify Twitter posts conveying events of adverse drug reaction (ADR). B,New Algorithm/ Method,New Algorithm/ Method
The best-performed model on the test sets were trained on a merged corpus consisting of the datasets released by SMM4H 2017 and 2019,New Algorithm/ Method,New Algorithm/ Method
We also show the use of combining pretrained BERT embeddings with Glove embeddings fed to a BLSTM text classifier for sub-task-1 and sub-task-4.,Performance Evaluation,Performance Evaluation
"we propose an extension to
Abstract Meaning Representations (AMRs) to
encode scope information of quantifiers and
negation, in a way that overcomes the semantic gaps of the schema while maintaining its
cognitive simplicity.",New Algorithm/ Method,New Algorithm/ Method
"We propose two extensions of GKR that
clearly show this division and empirically test
one of the proposals on an NLI dataset with
hard compositional pairs.",New Algorithm/ Method,New Algorithm/ Method
"We present a method of generating inferences
from ULFs from a small set of interpretable inference rules by first defining general semantic predicates over ULF clauses and tree transformations
that correspond to natural semantic operations in
ULF.",New Algorithm/ Method,New Algorithm/ Method
"We describe
how ULF can be used to generate natural language inferences that are grounded in the semantic and syntactic structure through a small
set of rules defined over interpretable predicates and transformations on ULFs",Theory Proposal,Theory Proposal
"This paper presents a new task-oriented meaning representation called meta-semantics, that
is designed to detect patients with early symptoms of Alzheimer’s disease by analyzing their
language beyond a syntactic or semantic level",New Algorithm/ Method,New Algorithm/ Method
"This paper proposes using a Bidirectional
LSTM-CRF model in order to identify the
tense and aspect of verbs",Model Proposal,Model Proposal
"we describe new semantic representations for the lexical resource VerbNet that
provide this sort of information for thousands of verb senses and introduce a means for automatically translating text to these representations.",Theory Proposal,Theory Proposal
"we describe an approach to overcome this
by getting labelled persona data from a different task and leveraging those annotations to
perform persona based story generation.",Theory Proposal,Theory Proposal
"We propose a novel take on understanding
narratives in social media, focusing on learning “functional story schemas”, which consist
of sets of stereotypical functional structures.",New Algorithm/ Method,New Algorithm/ Method
"We introduce a novel
partitioning approach for characterizing user
polarization based on their distribution of participation across interest subreddits",New Algorithm/ Method,New Algorithm/ Method
"we describe a workflow for the
data-driven acquisition and semantic scaling
of a lexicon that covers lexical items from the
lower end of the German language register—
terms typically considered as rough, vulgar or
obscene.",New Algorithm/ Method,New Algorithm/ Method
"we propose an approach
for semi-automatically creating a data-to-text
(D2T) corpus for Russian that can be used
to learn a D2T natural language generation
model.",New Algorithm/ Method,New Algorithm/ Method
"we propose a new method to quantify bias in BERT embeddings (§2). Since BERT embeddings use a masked language modelling objective, we directly query the model to measure the bias for a particular token",New Algorithm/ Method,New Algorithm/ Method
Construction of a corpus with template sentences that can check the preservation of gender-neutrality in KR-EN translation,Dataset Creation,Dataset Creation
"we have developed a method of acquiring hedge annotations through crowdsourcing, by
framing the hedge identification task as a simple
word sense disambiguation problem.",New Algorithm/ Method,New Algorithm/ Method
"a demonstration that the generalized method
is comparable in reliability of annotations to
the original more restricted crowd-sourcing
method proposed by (Scholman and Demberg, 2017a);",Model Proposal,Model Proposal
"we present a discourse annotation
study of Italian data, which uses the annotation
scheme and discourse-analytic method, the QUDtree framework",New Algorithm/ Method,New Algorithm/ Method
"Does controlling for the homogeneity of the
group of annotators with respect to their
age, education level and native language contribute to higher agreement",New Algorithm/ Method,New Algorithm/ Method
"We propose a novel method for CMC based
on fine-tuning BERT by regarding the sequences of the questions and the answers as
independent inputs.",New Algorithm/ Method,New Algorithm/ Method
we contribute to the under-explored area of generating natural language explanations for general phenomena,Theory Proposal,Theory Proposal
"We introduce the use of multiple attention
mechanisms that selectively focus character and
word sequences in the sentence context.",New Algorithm/ Method,New Algorithm/ Method
We propose the input tier-based input strictly local (I-TISL) functions as a functional analogue of the generalized tierprojection mechanism of the IO-TSL languages,New Algorithm/ Method,New Algorithm/ Method
we adapt a graph-based approach to characterize the clusters (fuzzy types) of tone contour shapes observed in each tone n-gram category.,New Algorithm/ Method,New Algorithm/ Method
we will apply a hybrid approach for finding the correct splits of words and augmenting a morphological database,New Algorithm/ Method,New Algorithm/ Method
We propose an unsupervised approach for morphological segmentation of polysynthetic languages based on Adaptor Grammars,New Algorithm/ Method,New Algorithm/ Method
"We show that TSSL functions naturally describe rhythmic syncope while TIOSL functions cannot, and we argue that TSSL functions provide a more restricted characterization of rhythmic syncope than existing treatments within Optimality Theory.",Theory Proposal,Theory Proposal
"we have created a semantic graph that, together with named entity recognition and resolution (NER), should make it easier to establish connections between arguments in a given debate",New Algorithm/ Method,New Algorithm/ Method
We propose an attention mechanism to leverage lexicon information.,New Algorithm/ Method,New Algorithm/ Method
"We introduce a la carte embedding, a simple and general alternative to the usual word2vec-based approaches for building such representations that is based upon recent theoretical results for GloVe-like embeddings.",Model Proposal,Model Proposal
"We introduce a the DM NLP team’s system for NLPTEA 2018 shared task of Chinese Grammatical Error Diagnosis (CGED), which can be used to detect and correct grammatical errors in texts written by Chinese as a Foreign Language (CFL) learners.",New Algorithm/ Method,New Algorithm/ Method
"We describe an overview of the Dialogue Emotion Recognition Challenge, EmotionX, at the Sixth SocialNLP Workshop, which recognizes the emotion of each utterance in dialogues. This challenge offers the EmotionLines dataset as the experimental materials.",Theory Proposal,Theory Proposal
we propose a method to combine the breadth of generic embeddings with the specificity of domain specific embeddings,New Algorithm/ Method,New Algorithm/ Method
we propose a simple hyperparameter selection technique for active learning applied to semantic parsing,New Algorithm/ Method,New Algorithm/ Method
"we investigate whether SNACS
(Schneider et al., 2018b), an approach to semantic
disambiguation of adpositions and possessives, can
be adapted to cover syntactically core grammatical
relations (subjects and objects).",Theory Proposal,Theory Proposal
"we examine how narrative coherence is attained in the submissions
of NaNoGenMo 2018, an online text generation event where participants are challenged to
generate a 50,000 word novel.",Theory Proposal,Theory Proposal
"This study explores the relation between lexical concreteness and narrative text quality. We
present a methodology to quantitatively measure lexical concreteness of a text.",Theory Proposal,Theory Proposal
"we deploy a logistic regression
classifier to ascertain whether a given document belongs to the fiction or non-fiction
genre",Theory Proposal,Theory Proposal
"we will focus on the analysis of speech utterances in theatre scripts. Dialogues in theatre plays
are quite easy to collect (i.e. the characters are explicitly stated in the scripts) without the need of
lengthy and costly manual annotation.",Theory Proposal,Theory Proposal
"We evaluate our algorithm on
tweets collected around 2 episodes of a popular TV show, Game of Thrones, Season 7",Performance Evaluation,Performance Evaluation
"we
delineate and clarify the main challenges
and frontiers in the field, critically evaluate
their implications and discuss solutions",Theory Proposal,Theory Proposal
"We compare the effectiveness of end-to-end
character based models, with word + character embedding models, byte pair encoding and
subword models, to show which of the techniques perform better than pure word based
models.",Model Optimization,Model Optimization
"We also examine how preprocessing documents with byte pair encoding model pretrained on a large corpus, boost the performance of several word embedding based models massively.",Model Optimization,Model Optimization
"an investigation on the role
of populist themes and rhetoric in an Italian
Twitter corpus of hate speech against immigrants.",Theory Proposal,Theory Proposal
"contribution
of transfer learning technique to pronoun resolution systems is investigated and the gender
bias contained in classification models is evaluated.",Performance Evaluation,Performance Evaluation
Our work improves the snippetcontext baseline F1 score on Gendered Ambiguous Pronouns dataset from 66.9% to 80.3%.,Algorithm/Method Optimization,Algorithm/Method Optimization
"the development of a system-independent gender-awareness wrapper, and the building of a corpus for training and evaluating first-person-singular gender identification and reinflection in Arabic",New Algorithm/ Method,New Algorithm/ Method
A measure to evaluate and compare the performance of translation systems regarding the preservation of gender neutrality of pronouns,Performance Evaluation,Performance Evaluation
"we investigate RNN learning from the formal language
perspective using the WFA models, and we show
that adding more layers may not be sufficient if the
model has to deal with long-term dependencies.",Model Optimization,Model Optimization
"presents the annotation and evaluation of the Litkey Corpus, a longitudinal corpus of written texts in German from children in primary school between grades 2 to 4",Dataset Creation,Dataset Creation
"we explore corpus data of five Oceanic languages of Melanesia which are known to be mood-prominent (in the sense of Bhat, 1999). In order to find out more about tense, aspect, modality, and polarity, we tagged these categories in a subset of our corpora",Dataset Creation,Dataset Creation
we discover which linguistic phenomena are hard for humans to annotate and show that these do not always coincide with what is assumed to be difficult for automatic systems.,Theory Proposal,Theory Proposal
"we discuss whether the different distribution of discourse relations in each
setting reflects different strategies used to pursue a
communicative purpose (§6), and how these might
relate to audience design",Theory Proposal,Theory Proposal
"We found that the gold answer history contributed to the model performance most by
analyzing the effects of dialogue history",Model Optimization,Model Optimization
"We present the analysis of the application of
deep neural work for contextual resolution in dialogue, including both step-by-step and end-to-end
approaches",Applications,Applications
We provide a detailed analysis of the proposed models both on an internal benchmark and public dataset,Model Proposal,Model Proposal
"we propose and test the idea of performing cognate projection
to leverage high-resource training data for lowresource inflection generation.",New Algorithm/ Method,New Algorithm/ Method
We evaluate the effect of a variety of types of external embeddings for lemmatization and morphological tagging.,Performance Evaluation,Performance Evaluation
We evaluate the effect of combining annotated datasets from related languages for both tasks,Performance Evaluation,Performance Evaluation
"We analyze the dependencies among different morphological features to inform model choices, and find that adding POS information to the encoder significantly improves prediction accuracy by reducing errors across features, particularly Gender errors.",Model Optimization,Model Optimization
"We evaluate our proposed approach on 107 treebanks and achieve +14.76 (accuracy) average improvement over the shared task baseline (McCarthy et al., 2019) for morphological analysis.",Performance Evaluation,Performance Evaluation
"we examine whether a “CRFinspired” neural model without the hand-crafted features, can be applied to the task of argumentative unit segmentation at the clause level, and whether its performance is comparable to approaches exploiting such features",Model Proposal,Model Proposal
. We analyze challenges facing our computational methods and suggest future directions.,Theory Proposal,Theory Proposal
we investigate similarities between discourse and argumentation structures by aligning subtrees in a corpus containing both annotations,Theory Proposal,Theory Proposal
"In the face of the scarcity of argument lexicon, we explore several different types of lexicons to verify whether outside resources are useful for AM tasks.",Performance Evaluation,Performance Evaluation
we present and evaluate new attention-based architectures for the task of argumentative text segmentation.,New Algorithm/ Method,New Algorithm/ Method
we review the effectiveness of recently proposed contextualized word embedding approaches in regard to AM,Performance Evaluation,Performance Evaluation
"we run various discourse parsers (RST, PDTB) on the corpus, compare their results to the gold annotations (for RST) and then assess the contribution of automatically-derived discourse features for argumentation parsing",Performance Evaluation,Performance Evaluation
presents a first attempt at using Walton’s argumentation schemes for annotating arguments in Swedish political text and assessing the feasibility of using this particular set of schemes with two linguistically trained annotators.,New Algorithm/ Method,New Algorithm/ Method
"we study the possibility of combining short-term representations, stored in neural activations (hidden state), with medium-term representations encoded in a set of dynamical weights of the language model",Theory Proposal,Theory Proposal
we evaluate our approach which compares the use of “black-box” features (without ASR decoder information) and “glass-box” features which use internal information from the decoder,Performance Evaluation,Performance Evaluation
"We investigate the robustness of a classifier trained with adversarial examples, by studying its resilience to attacks and its accuracy on clean test data",Performance Evaluation,Performance Evaluation
"The solution presented
here features a bidirectional Long Shortterm Memory Network (bi-LSTM) for the
generation of character-level embeddings.",Theory Proposal,Theory Proposal
"we explore various aspects of sentiment detection
and their correlation to toxicity, and use our
results to implement a toxicity detection tool.",Theory Proposal,Theory Proposal
"we explore deep multimodal
fusion of text and photo for the task of hate
speech classification on social networks, where
hate speech posts frequently appear with images.",Theory Proposal,Theory Proposal
"we employ several wellestablished automated text analysis tools and
build on common practices for handling highly
imbalanced datasets and reducing sensitivity
to overfitting.",Dataset Creation,Dataset Creation
"The final model submitted is a multisource neural NER system with multilingual
BERT embeddings, trained on the concatenation of training data in various Slavic languages (as well as English)",Model Proposal,Model Proposal
"we use a
mixed model which combines multilingualcontextual and language-specific embeddings.",Model Proposal,Model Proposal
"Shows how heterogeneity in content and size of the ”target list” of gendered or racially marked terms interferes with debiasing, and how conceptors on contextual embeddings can be used to address such target list heterogeneity.",Theory Proposal,Theory Proposal
"For gender reinflection, we use a character-level neural MT (NMT) model in a single step (identify and reinflect, jointly), and as the second part of a twostep (identify then reinflect) system",Model Proposal,Model Proposal
"a “connective bank” consisting of 800 entries
including traditional connectives as well as
variations of connectives and alternative lexicalizations;",Dataset Creation,Dataset Creation
"we present a corpus annotated with
these relations and the analysis of these results where corpus contains 520 sentence pairs, annotated with these relations",Dataset Creation,Dataset Creation
"making
up for the scarcity of NLP resources in Turkish by
annotating a new corpus that has not been introduced to the UD project before, namely the TNC",Dataset Creation,Dataset Creation
"we describe three platforms that
constitute our annotation ecosystem, as background for a demonstration of their ability to work
in concert to provide easily usable means to adapt
NLP processes to specific domains",New Algorithm/ Method,New Algorithm/ Method
"we present
a repository of conversational datasets consisting of hundreds of millions of examples,
and a standardised evaluation procedure for
conversational response selection models using 1-of-100 accuracy.",Dataset Creation,Dataset Creation
"our model utilizes fine-tuning
to compensate for the training data scarcity, which
is essential because there is a limited amount of
domain-dependent and sentiment-rich dialogues",Model Proposal,Model Proposal
"We have developed a system based on LSTM neural networks inspired
by the excellent results obtained by deep learning classifiers",New Algorithm/ Method,New Algorithm/ Method
We study approaches based on machine learning and deep learning to extract adverse drug reaction mentions from highly informal texts in Twitter.,Theory Proposal,Model Proposal
This paper describes the system developed by team ASU-NLP for the Social Media Mining for Health Applications(SMM4H) shared task,New Algorithm/ Method,Model Proposal
"This paper describes the system that team MYTOMORROWS-TU DELFT developed for the 2019 Social Media Mining for Health Applications (SMM4H) Shared Task 3, for the end-to-end normalization of ADR tweet mentions to their corresponding MEDDRA codes.",New Algorithm/ Method,New Algorithm/ Method
We make an initial attempt in studying the effectiveness of transfer learning using ULMFit and BERT for the problems in the domain of health care pertaining to the shared tasks.,Theory Proposal,New Algorithm/ Method
"We employed a combination of three types of word representations as input to a LSTM model for detecting reportage of adverse drug reaction in tweets as part of the 2019 social media
mining for healthcare applications shared task.",Performance Evaluation,Performance Evaluation
"AMR concepts show a higher level of abstraction from surface forms, meaning that
AMR concepts bear less resemblance to the
word tokens in the original sentence.",Theory Proposal,Theory Proposal
"we consider neural network solution for multilingual named entity
recognition for Bulgarian, Czech, Polish and Russian languages for the BSNLP 2019 Shared Task
(Piskorski et al., 2019)",Theory Proposal,New Algorithm/ Method
"Present an approach to find one of the subtypes of gender bias, Gender Generalization",New Algorithm/ Method,Model Proposal
Provide a high-level definition of gender bias in text,Theory Proposal,Theory Proposal
"The main idea of our augmentation is to replace each name in the name-pronoun pair by a set of common placeholder names, in order to (1) diversify the idiosyncratic information embedded in individual names and leave only the contextual information",Theory Proposal,New Algorithm/ Method
"The main contribution of this study is providing progress on the recent detected problem which
is gender bias in MT",Theory Proposal,New Algorithm/ Method
aims to address such issues of interpretability by relating sequential neural networks to forms of computation that are more well understood.,Theory Proposal,Theory Proposal
"We address the nontrivial problem of evaluating the extractions
produced by systems against the reference tuples, and share our evaluation script",Theory Proposal,Theory Proposal
"we discuss how we tackle the challenges raised by harmonizing different lemmatization criteria in the LiLa: Linking Latin project,
which aims to make resources for Latin interoperable.1",Theory Proposal,Theory Proposal
"we first look at the use of discourse
connectives along two dimensions of variation and
show that there are systematic differences regarding the frequency of different forms of discourse
connectives",Theory Proposal,Theory Proposal
"While there is relevant
ongoing research on Semantic Role Labelling
(SRL) and on building tools for code-mixed
social media data, this is the first attempt at labelling semantic roles in Hindi-English codemixed data, to the best of our knowledge.",Dataset Creation,Dataset Creation
"We alleviated these problems
by developing WAT-SL 2.0, an open-source
web-based annotation tool for long-segment
labeling, hierarchically structured label sets
and built-ins for quality control.",Theory Proposal,Theory Proposal
"aims to 
create an annotated corpus where the annotation
contains all the features needed to generate questions concerning the text.",Dataset Creation,Dataset Creation
"we describe our system for
morphological analysis and lemmatization
in context, using a transformer-based
sequence to sequence model and a biaffine
attention based BiLSTM model",New Algorithm/ Method,New Algorithm/ Method
We use sequence-to-sequence networks trained on sequential phonetic encoding tasks to construct compositional phonological representations of words,New Algorithm/ Method,New Algorithm/ Method
we propose a three-way feature grouping: (i) features which access only the EAU span; (ii) features which access only the context of an EAU; (iii) features which access both EAU span and its context.,New Algorithm/ Method,New Algorithm/ Method
"to deploy a novel methodology for classifying different argumentative support (supporting evidences) in arguments, without considering the context",New Algorithm/ Method,New Algorithm/ Method
) the identification of the schemes for which available tools are readily available for use;,Theory Proposal,Theory Proposal
"This paper uses a novel framework to restore the elided elements in the sentence,
which is named Abstract Meaning Representation (AMR)(Banarescu et al., 2013). AMR represents the whole sentence meaning with concepts,
which are mainly abstracted from its corresponding words occurring in the sentence.",New Algorithm/ Method,New Algorithm/ Method
"Building a dataset for abusive language and
hate speech detection including detecting the
target, category, and level of hate speech in
Indonesian Twitter. We provide this research
dataset for public4
so that it can be used by
other researchers who are interested in doing
future work of this paper.",Dataset Creation,Dataset Creation
"Investigate what type of attention mechanism in deep learning architectures (contextual attention vs. self-attention) is better for
abusive language detection. We show that
contextual attention models outperform selfattention models on most cases (datasets and
architectures), and present a thorough error
analysis showing how contextual attention
works better than self-attention particularly
when it comes to modeling implicit abusive
content.",Algorithm/Method Optimization,Algorithm/Method Optimization
"Investigate whether stacked architectures are
better than simple architectures for abusive
language detection when using Biderectional
Long Short Term Memory (Bi-LSTM) networks. We show that stacked architectures are better than simple architectures
on all datasets. In addition, we discuss
the importance of pre-trained word embeddings for deep learning models.",Algorithm/Method Optimization,Algorithm/Method Optimization
"introduction of a novel
fine-grained hate speech typology that improves
on the common state-of-the-art used typologies,
which tend to disregard the existence of subtypes
of hate speech and either consider hate speech
recognition as a binary classification task, or take
into account only a few classes, such as ‘racism’
95
and ‘sexism’ (Waseem and Hovy, 2016) – despite
the fact that such broad distinctions unduly overgeneralize.",Algorithm/Method Optimization,Algorithm/Method Optimization
"This paper investigates the extent of the new
lexicon problem for different types of Ukrainian
corpora and further proposes and evaluates a
knowledge-light approach to extending lexical
coverage of morphological resources to neologisms (new words, meanings or usages) and new
single-word Named Entities (proper names) which
follow regular inflectional patterns",New Algorithm/ Method,Performance Evaluation
we pay special attention to the gapping resolution methods that were introduced within the shared task as well as an alternative test set that illustrates that our corpus is a diverse and representative subset of Russian language gapping sufficient for effective utilization of machine learning techniques.,New Algorithm/ Method,Algorithm/Method Optimization
"We provide an experimental evaluation of
models and methods for predicting compositionality of noun compounds. We show that
the methods from the previous work trained
on the proposed Russian-language resource
achieve the performance comparable with results on English corpora.",Performance Evaluation,Performance Evaluation
"describes the Second Shared Task on
multilingual NE recognition (NER), which aims
at addressing these problems in a systematic way.
The shared task was organized in the context of
the 7th Balto-Slavic Natural Language Processing
Workshop co-located with the ACL 2019 conference",Theory Proposal,Theory Proposal
"We propose a black-box approach for injecting the missing information to a pre-trained neural machine translation system, allowing to control the morphological variations in the generated translations without changing the underlying model or training data.",New Algorithm/ Method,New Algorithm/ Method
"we present an open-source, lightweight, easy-to-use graphical annotation tool that employs a statistical parser to create initial CCG derivations for sentences, and allows annotators to correct these annotations via lexical category constraints and span constraints",Resources,Resources
"we propose a corpus
generation strategy that only requires a machine translation system between English and
the target language in both directions, where
we filter the best translations by computing automatic translation metrics and the task performance score",New Algorithm/ Method,New Algorithm/ Method
"we present a new annotation
scheme for the Sejong part-of-speech tagged
corpus based on Universal Dependencies
style annotation. By using a new annotation
scheme, we can produce Sejong-style morphological analysis and part-of-speech tagging results which have been the de facto standard for
Korean language processing",Model Optimization,Model Optimization
"We formulate the problem
definition of context reconstruction in dialogue
into one detection problem and one ranking problem and present the difference between it and
traditional tasks such as pronoun and zero pronoun detection and mention candidate selection;",Theory Proposal,Theory Proposal
We improve upon the slot carryover model architecture in Naik et al. (2018) by introducing approaches for modeling slot interdependencies. We propose two neural network models based on pointer networks and transformer networks that can make joint predictions over slots.,Model Optimization,Model Optimization
"we computationally simulate two directions of verbal inflection in Japanese, Present 7→ Past and Past 7→ Present, with the rule-based computational model called Minimal Generalization Learner (MGL; Albright and Hayes, 2003) and experimentally evaluate the model with the bidirectional “wug” test where humans inflect novel verbs in two opposite directions.",Performance Evaluation,Performance Evaluation
"we propose Probabilistic FastText (PFT), which provides probabilistic characterlevel representations of words. The resulting word embeddings are highly expressive, yet straightforward and interpretable, with simple, efficient, and intuitive training procedures.",New Algorithm/ Method,New Algorithm/ Method
we transform external lexico-semantic relations into training examples which we use to learn an explicit retrofitting model (ER). The ER model allows us to learn a global specialization function and specialize the vectors of words unobserved in the training data as well.,New Algorithm/ Method,New Algorithm/ Method
"we introduce an extension by utilizing two independent encoders but sharing some partial weights which are responsible for extracting high-level representations of the input sentences.Besides, two different generative adversarial
networks (GANs), namely the local GAN
and global GAN, are proposed to enhance
the cross-language translation. With this
new approach, we achieve significant improvements on English-German, EnglishFrench and Chinese-to-English translation
tasks.",Model Optimization,Model Optimization
"We propose a novel triangular training architecture (TA-NMT) to effectively tackle the
data sparsity problem for rare languages in
NMT with an EM framework.Our method can exploit two additional bilingual datasets at both the model and data levels by introducing another rich language.Our method is a unified bidirectional EM algorithm, in which four translation models on
two low-resource pairs are trained jointly and
boost each other.",New Algorithm/ Method,New Algorithm/ Method
"We propose a unified model combining sentence-level and word-level attentions to
take advantage of both extractive and abstractive summarization approaches. We propose a novel inconsistency loss function to ensure our unified model to be mutually beneficial to both extractive and abstractive summarization. The unified model with
inconsistency loss achieves the best ROUGE
scores on CNN/Daily Mail dataset and outperforms recent state-of-the-art methods in
informativity and readability on human evaluation.",Model Proposal,Model Proposal
"We propose to introduce soft templates as additional input to improve the readability and stability of seq2seq summarization systems. Code and results can be found at http://www4.comp.polyu. edu.hk/˜cszqcao/. We extend the seq2seq framework to conduct template reranking and template-aware summary generation simultaneously. We fuse the popular IR-based and seq2seqbased summarization systems, which fully utilize the supervisions from both sides.",New Algorithm/ Method,New Algorithm/ Method
"We first to combine structural semantics and neural methods for TS, we propose an intermediate way for performing sentence splitting, presenting Direct Semantic Splitting (DSS), a simple and efficient algorithm based on a semantic parser which supports the direct decomposition of the sentence into its main semantic constituents.",Algorithm/Method Optimization,Algorithm/Method Optimization
We propose a method of combining Conditional Random Fields (CRFs) model with a post-processing layer using Google n-grams statistical information tailored to detect word selection and word order errors made by learners of Chinese as Foreign Language (CFL).,Model Optimization,Model Optimization
we report a short answer grading system in Chinese. We build a system based on standard machine learning approaches and test it with translated corpus from two publicly available corpus in English. The experiment results show similar results on two different corpus as in English.,New Algorithm/ Method,New Algorithm/ Method
"we present a qualitatively enhanced deep convolution recurrent neural network for computing the quality of a text in an automatic essay scoring task. The novelty of the work lies in the fact that instead of considering only the word and sentence representation of a text, we try to augment the different complex linguistic, cognitive and psychological features associated within a text document along with a hierarchical convolution recurrent neural network framework.",New Algorithm/ Method,New Algorithm/ Method
"we propose a new semi-supervised learning method with a feedback loop to leverage vast amounts of unlabeled data and feedback signals. In particular, we train two machine learning models iteratively. The main model, which is represented as M ain, performs the main task at runtime.",New Algorithm/ Method,New Algorithm/ Method
"We outline future directions in summarization to address all of these issues. By resolving the existing problems, we will make it easier for users of review-sites to make more informed decisions.",Model Optimization,Model Optimization
"We hypothesize that by training on higher information and more difficult training sentences, RNN language models can learn the language distribution more accurately and produce lower perplexities than models trained on similar-sized randomly sampled training sets",Theory Proposal,Theory Proposal
"We propose a learning-based framework to incorporate the scores of a set of lexical and semantic metrics as features, to capture the adequacy and fluency of captions at different linguistic levels. Our experimental results demonstrate that composite metrics draw upon the strengths of standalone measures to yield improved correlation and accuracy",Model Proposal,Model Proposal
"we propose a preordering method with a recursive neural network (RvNN). RvNN calculates reordering in a bottom-up manner (from the leaf nodes to the root) on a source syntax tree. Thus, preordering is performed considering the entire sub-trees.",New Algorithm/ Method,New Algorithm/ Method
"we aim to automatically generate description of medical images, to develop medical visual question answering system and to develop medical dialog agents that interact with patients to answer their queries based on their medical data.",Dataset Creation,Dataset Creation
"We review the existing methods which are revised to tackle complex entity mentions and categorize them as tokenlevel and sentence-level approaches. We then identify the research gap, and discuss some directions that we are exploring",Algorithm/Method Optimization,Algorithm/Method Optimization
"we attempt to contribute to LBD discipline outside of medical domain by automating crossdisciplinary knowledge discovery process. As a proof of concept, the proposed solution will be applied to different CS-related concepts.",Dataset Creation,Dataset Creation
"We compare our method with existing off-theshelf NER tools for social media content, and find that our systems outperforms the best baseline by 33.18 % (F1 score).",Algorithm/Method Optimization,Algorithm/Method Optimization
"We present ongoing work on data-driven parsing of German and French with Lexicalized Tree Adjoining Grammars. We use a supertagging approach combined with deep learning. We show the challenges of extracting LTAG supertags from the French Treebank, introduce the use of leftand right-sister-adjunction, present a neural architecture for the supertagger, and report experiments of n-best supertagging for French and German.",Model Proposal,Model Proposal
"we incorporate semantic supersensetags and syntactic supertag features into EN–FR and EN–DE factored NMT systems. In experiments on various test sets, we observe that such features (and particularly when combined) help the NMT model training to converge faster and improve the model quality according to the BLEU scores.",Performance Evaluation,Performance Evaluation
"we develop a novel pipeline for Semantic Abstractive Summarization (SAS). SAS, as introduced by Liu et al. (2015) first generates an AMR graph of an input story, through which it extracts a summary graph and finally, creates summary sentences from this summary graph. Compared to earlier approaches, we develop a more comprehensive method to generate the story AMR graph using state-ofthe-art co-reference resolution and Meta Nodes. Which we then use in a novel unsupervised algorithm based on how humans summarize a piece of text to extract the summary sub-graph. Our algorithm outperforms the state of the art SAS method by 1.7% F1 score in node prediction.",Resources,Resources
"we are focusing on biomedical document retrieval from literature for clinical decision support systems. We compare statistical and NLP based approaches of query reformulation for biomedical document retrieval. Also, we have modeled the biomedical document retrieval as a learning to rank problem. We report initial results for statistical and NLP based query reformulation approaches and learning to rank approach with future direction of research.",Model Optimization,Model Optimization
"we do not present direct quotes from any data, nor any identifying information. Anonymised data was collected from microblogging website Twitter - specifically, content containing self-classified suicidal ideation (i.e. text posts tagged with the word ’suicide) over the period of December 3, 2017 to January 31, 2018. The Twitter REST API2 was used for collection of tweets containing any of the following English words or phrases that are consistent with the vernacular of suicidal ideation (O’Dea et al., 2015",Dataset Creation,Dataset Creation
"we extracted 11,000 adjectives, 253 adverbs, 8483 verbs and sentiment annotation is being done by language experts. We discuss the methodology followed for the polarity annotations and validate the developed resource. This work aims at developing a benchmark corpus, as an extension to SentiWordNet, and baseline accuracy for a model where lexeme annotations are applied for sentiment predictions. The fundamental aim of this paper is to validate and study the possibility of utilizing machine learning algorithms, word-level sentiment annotations in the task of automated sentiment identification. Furthermore, accuracy is improved by annotating the bi-grams extracted from the target corpus.",New Algorithm/ Method,New Algorithm/ Method
"We investigate a new training paradigm for extractive summarization. Traditionally, human abstracts are used to derive goldstandard labels for extraction units. However, the labels are often inaccurate, because human abstracts and source documents cannot be easily aligned at the word level",Theory Proposal,Theory Proposal
"we capture using the HITS algorithm. We apply our proposed method to two tasks: machine translation and grammatical error correction. For Japanese-to-English translation, this method achieves a BLEU score that is 0.56 points more than that of a baseline. Furthermore, it outperforms the baseline method for English grammatical error correction, with an F0.5-measure that is 1.48 points higher",New Algorithm/ Method,New Algorithm/ Method
"we address the task of the generation of grammatical sentences in an isolated context given a partial bag-of-words which the generated sentence must contain. We view the task as a search problem (a problem of choice) involving combinations of smaller chunk based templates extracted from a training corpus to construct a complete sentence. To achieve that, we propose a fitness function which we use in conjunction with an evolutionary algorithm as the search procedure to arrive at a potentially grammatical sentence (modeled by the fitness score) which satisfies the input constraints.",Performance Evaluation,Performance Evaluation
"we develop an adversarial writing setting, where humans interact with trained models and try to break them. This annotation process yields a challenge set, which despite being easy for trivia players to answer, systematically stumps automated question answering systems. Diagnosing model errors on the evaluation data provides actionable insights to explore in developing robust and generalizable question answering systems",Resources,Resources
"we could predict a possible cognate from the given input. Our study shows that when language modelling smoothing methods are applied as the retrieval functions and used in conjunction with positional segmentation and error modelling gives better results than competing baselines, in both classification and prediction of cognates",Applications,Applications
we can demystify affect generation by reviewing psychological models which build on neuro-biological findings in regards to human emotion,Model Optimization,Model Optimization
"we show how to build an automatic spelling corrector for resourcescarce languages. We propose a sequenceto-sequence deep learning model which trains end-to-end. We perform experiments on synthetic datasets created for Indic languages, Hindi and Telugu, by incorporating the spelling mistakes committed at character level. A comparative evaluation shows that our model is competitive with the existing spell checking and correction techniques for Indic languages.",Model Proposal,Model Proposal
We reformulate the problem of encoding a multi-scale representation of a sequence in a language model by casting it in a continuous learning framework. We propose a hierarchical multi-scale language model in which short time-scale dependencies are encoded in the hidden state of a lower-level recurrent neural network while longer time-scale dependencies are encoded in the dynamic of the lower-level network by having a meta-learner update the weights of the lower-level neural network in an online meta-learning fashion. We use elastic weights consolidation as a higher-level to prevent catastrophic forgetting in our continuous learning framework,Model Optimization,Model Optimization
"we introduce restricted recurrent neural tensor networks (r-RNTN) which reserve distinct hidden layer weights for frequent vocabulary words while sharing a single set of weights for infrequent words. Perplexity evaluations show that for fixed hidden layer sizes, r-RNTNs improve language model performance over RNNs using only a small fraction of the parameters of unrestricted RNTNs. These results hold for r-RNTNs using Gated Recurrent Units and Long Short-Term Memory.",New Algorithm/ Method,New Algorithm/ Method
"We present a set of experiments to demonstrate that deep recurrent neural networks (RNNs) learn internal representations that capture soft hierarchical notions of syntax from highly varied supervision. We consider four syntax tasks at different depths of the parse tree; for each word, we predict its part of speech as well as the first (parent), second (grandparent) and third level (great-grandparent) constituent labels that appear above it. These predictions are made from representations produced at different depths in networks that are pretrained with one of four objectives: dependency parsing, semantic role labeling, machine translation, or language modeling. In every case, we find a correspondence between network depth and syntactic depth, suggesting that a soft syntactic hierarchy emerges. This effect is robust across all conditions, indicating that the models encode significant amounts of syntax even in the absence of an explicit syntactic training supervision",Model Proposal,Model Proposal
"we propose a novel approach to estimate WER, or e-WER, which does not require a gold-standard transcription of the test set. Our e-WER framework uses a comprehensive set of features: ASR recognised text, character recognition results to complement recognition output, and internal decoder features. We report results for the two features; black-box and glass-box using unseen 24 Arabic broadcast programs. Our system achieves 16.9% WER root mean squared error (RMSE) across 1,400 sentences. The estimated overall WER eWER was 25.3% for the three hours test set, while the actual WER was 28.5%",Theory Proposal,Theory Proposal
"we propose an approach to explicitly obscure important author characteristics at training time, such that representations learned are invariant to these attributes. Evaluating on two tasks, we show that this leads to increased privacy in the learned representations, as well as more robust models to varying evaluation conditions, including out-of-domain corpor",Theory Proposal,Theory Proposal
"We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier. We find that only a few manipulations are needed to greatly decrease the accuracy. Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the onehot input vectors. Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time. With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier.",Algorithm/Method Optimization,Algorithm/Method Optimization
We apply active learning to both traditional and “overnight” data collection approaches. We show that it is possible to obtain good training hyperparameters from seed data which is only a small fraction of the full dataset. We show that uncertainty sampling based on least confidence score is competitive in traditional data collection but not applicable for overnight collection. We evaluate several active learning strategies for overnight data collection and show that different example selected.,Dataset Creation,Dataset Creation
"we suggest to leverage the partition of articles into sections, in order to learn thematic similarity metric between sentences. We assume that a sentence is thematically closer to sentences within its section than to sentences from other sections. Based on this assumption, we use Wikipedia articles to automatically create a large dataset of weakly labeled sentence triplets, composed of a pivot sentence, one sentence from the same section and one from another section. We train a triplet network to embed sentences from the same section closer. To test the performance of the learned embeddings, we create and release a sentence clustering benchmark. We show that the triplet network learns useful thematic metrics, that significantly outperform state-of-theart semantic similarity methods and multipurpose embeddings on the task of thematic clustering of sentences. We also show that the learned embeddings perform well on the task of sentence semantic similarity prediction",Theory Proposal,Theory Proposal
"We use dependency triples automatically extracted from a Web-scale corpus to perform unsupervised semantic frame induction. We cast the frame induction problem as a triclustering problem that is a generalization of clustering for triadic data. Our replicable benchmarks demonstrate that the proposed graph-based approach, Triframes, shows state-of-the art results on this task on a FrameNet-derived dataset and performing on par with competitive methods on a verb class clustering task",Resources,Resources
We present a new architecture for named entity recognition. Our model employs multiple independent bidirectional LSTM units across the same input and promotes diversity among them by employing an inter-model regularization term. By distributing computation across multiple smaller LSTMs we find a reduction in the total number of parameters. We find our architecture achieves state-of-the-art performance on the CoNLL 2003 NER dataset.,Model Proposal,Model Proposal
"We observe that when they fail, they often make entity predictions that are incompatible with the type required by the relation. In response, we enhance each base factorization with two type-compatibility terms between entityrelation pairs, and combine the signals in a novel manner. Without explicit supervision from a type catalog, our proposed modification obtains up to 7% MRR gains over base models, and new state-of-the-art results on several datasets. Further analysis reveals that our models better represent the latent types of entities and their embeddings also predict supervised types better than the embeddings learned by baseline models",Performance Evaluation,Performance Evaluation
"We present a novel graph-based neural network model for relation extraction. Our model treats multiple pairs in a sentence simultaneously and considers interactions among them. All the entities in a sentence are placed as nodes in a fully-connected graph structure. The edges are represented with position-aware contexts around the entity pairs. In order to consider different relation paths between two entities, we construct up to l-length walks between each pair. The resulting walks are merged and iteratively used to update the edge representations into longer walks representations. We show that the model achieves performance comparable to the state-ofthe-art systems on the ACE 2005 dataset without using any external tools.",Model Proposal,Model Proposal
"We first point out that these tasks are related. Then, inspired by ranking relation instances and patterns computed by the HITS algorithm, and selecting cluster centroids using the K-means, LSA, or NMF method, we propose methods for selecting the initial seeds from an existing resource, or reducing the level of noise in the distantly labeled data. Experiments show that our proposed methods achieve a better performance than the baseline systems in both tasks",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose to improve the end-toend coreference resolution system by (1) using a biaffine attention model to get antecedent scores for each possible mention, and (2) jointly optimizing the mention detection accuracy and the mention clustering log-likelihood given the mention cluster labels. Our model achieves the stateof-the-art performance on the CoNLL2012 Shared Task English test set.",Dataset Creation,Dataset Creation
"We show that this update mechanism can be learned jointly with the semantic decoding and context modelling parts of the NBT model, eliminating the last rule-based module from this DST framework. We propose two different statistical update mechanisms and show that dialogue dynamics can be modelled with a very small number of additional model parameters. In our DST evaluation over three languages, we show that this model achieves competitive performance and provides a robust framework for building resource-light DST models.",Model Optimization,Model Optimization
"We study the role of linguistic context in predicting quantifiers (‘few’, ‘all’). We collect crowdsourced data from human participants and test various models in a local (single-sentence) and a global context (multi-sentence) condition. Models significantly out-perform humans in the former setting and are only slightly better in the latter. While human performance improves with more linguistic context (especially on proportional quantifiers), model performance suffers. Models are very effective in exploiting lexical and morpho-syntactic patterns; humans are better at genuinely understand",Model Optimization,Model Optimization
"We ask how to practically build a model for German named entity recognition (NER) that performs at the state of the art for both contemporary and historical texts, i.e., a big-data and a small-data scenario. The two best-performing model families are pitted against each other (linear-chain CRFs and BiLSTM) to observe the trade-off between expressiveness and data requirements. BiLSTM outperforms the CRF when large datasets are available and performs inferior for the smallest dataset.",Model Optimization,Model Optimization
"we analyze a novel dataset of more than one million code reviews for the Google Chromium project, from which we extract linguistic features of feedback that elicited responsive actions from coworkers. Using a manually-labeled subset of reviewer comments, we trained a highly accurate classifier to identify “acted-upon” comments (AUC = 0.85). Our results demonstrate the utility of our dataset, the feasibility of using NLP for this new task, and the potential of NLP to improve our understanding of how communications between colleagues can be authored to elicit positive, proactive responses",Dataset Creation,Dataset Creation
we describe a new multimodal dataset that consists of gaze measurements and spoken descriptions collected in parallel during an image inspection task. The task was performed by multiple participants on 100 general-domain images showing everyday objects and activities. We demonstrate the usefulness of the dataset by applying an existing visual-linguistic data fusion framework in order to label important image regions with appropriate linguistic labels,Dataset Creation,Dataset Creation
"we sketch 68 implicit morphological relations and 28 explicit semantic relations. A big and balanced dataset CA8 is then built for this task, including 17813 questions. Furthermore, we systematically explore the influences of vector representations, context features, and corpora on analogical reasoning. With the experiments, CA8 is proved to be a reliable benchmark for evaluating Chinese word embeddings.",Dataset Creation,Dataset Creation
"We therefore construct a significant new corpus on metaphor, with 5,605 manually annotated sentences in Chinese. We present an annotation scheme that contains annotations of linguistic metaphors, emotional categories (joy, anger, sadness, fear, love, disgust and surprise), and intensity. The annotation agreement analyses for multiple annotators are described. We also use the corpus to explore and analyze the emotionality of metaphors. To the best of our knowledge, this is the first relatively large metaphor corpus with an annotation of emotions in Chinese",Performance Evaluation,Performance Evaluation
we further develop automatic metrics that generalize a broad set of popular reference-based metrics and exhibit greatly improved correlations with human evaluations,Resources,Resources
"we propose a global encoding framework, which controls the information flow from the encoder to the decoder based on the global information of the source context. It consists of a convolutional gated unit to perform global encoding to improve the representations of the source-side information. Evaluations on the LCSTS and the English Gigaword both demonstrate that our model outperforms the baseline models, and the analysis shows that our model is capable of generating summary of higher quality and reducing repetition",Model Proposal,Model Proposal
"We herein present a language-modelbased evaluator for deletion-based sentence compression, and viewed this task as a series of deletion-and-evaluation operations using the evaluator. More specifically, the evaluator is a syntactic neural language model that is first built by learning the syntactic and structural collocation among words. Subsequently, a series of trial-and-error deletion operations are conducted on the source sentences via a reinforcement learning framework to obtain the best target compression. An empirical study shows that the proposed model can effectively generate more readable compression, comparable or superior to several strong baselines. Furthermore, we introduce a 200-sentence test set for a largescale dataset, setting a new baseline for the future research",Performance Evaluation,Performance Evaluation
"we seek to better understand how users react to trusted and deceptive news sources across two popular, and very different, social media platforms. To that end, (1) we develop a model to classify user reactions into one of nine types, such as answer, elaboration, and question, etc, and (2) we measure the speed and the type of reaction for trusted and deceptive news sources for 10.8M Twitter posts and 6.2M Reddit comments. We show that there are significant differences in the speed and the type of reactions between trusted and deceptive news sources on Twitter, but far smaller differences on Reddit",Model Proposal,Model Proposal
we model this task using CNN regression with an auxiliary ordinal regression objective. We demonstrate the effectiveness of our proposed approach using UK and US government petition datasets.1,Model Proposal,Model Proposal
"We introduce a new approach to tackle the problem of offensive language in online social media. Our approach uses unsupervised text style transfer to translate offensive sentences into non-offensive ones. We propose a new method for training encoderdecoders using non-parallel data that combines a collaborative classifier, attention and the cycle consistency loss. Experimental results on data from Twitter and Reddit show that our method outperforms a state-of-the-art text style transfer system in two out of three quantitative metrics and produces reliable non-offensive transferred sentences",New Algorithm/ Method,New Algorithm/ Method
"we address a research gap by exploring finer temporal granularity and using a more accessible language corpus. Twitter’s1 discourse is rather different from traditional English writing. So far, word embeddings trained on Twitter (Kulkarni et al., 2015; Mikolov et al., 2013) have considered it a static corpus, and have not used it to study short term changes in word connotations. It contributes with the following observations",Performance Evaluation,Performance Evaluation
"we make a move to build a dialogue system for automatic diagnosis. We first build a dataset collected from an online medical forum by extracting symptoms from both patients’ self-reports and conversational data between patients and doctors. Then we propose a taskoriented dialogue system framework to make the diagnosis for patients automatically, which can converse with patients to collect additional symptoms beyond their self-reports. Experimental results on our dataset show that additional symptoms extracted from conversation can greatly improve the accuracy for disease identification and our dialogue system is able to collect these symptoms automatically and make a better diagnosis",Theory Proposal,Theory Proposal
"we study transfer learning for multi-turn information seeking conversations in this paper. We first propose an efficient and effective multiturn conversation model based on convolutional neural networks. After that, we extend our model to adapt the knowledge learned from a resource-rich domain to enhance the performance. Finally, we deployed our model in an industrial chatbot called AliMe Assist 1 and observed a significant improvement over the existing online model.",Dataset Creation,Dataset Creation
"We present a novel multi-task modeling approach to learning multilingual distributed representations of text. Our system learns word and sentence embeddings jointly by training a multilingual skipgram model together with a cross-lingual sentence similarity model. Our architecture can transparently use both monolingual and sentence aligned bilingual corpora to learn multilingual embeddings, thus covering a vocabulary significantly larger than the vocabulary of the bilingual corpora alone. Our model shows competitive performance in a standard crosslingual document classification task. We also show the effectiveness of our method in a limited resource scenario",Model Proposal,Model Proposal
"We investigate the behavior of maps learned by machine translation methods. The maps translate words by projecting between word embedding spaces of different languages. We locally approximate these maps using linear maps, and find that they vary across the word embedding space. This demonstrates that the underlying maps are non-linear. Importantly, we show that the locally linear maps vary by an amount that is tightly correlated with the distance between the neighborhoods on which they are trained. Our results can be used to test non-linear methods, and to drive the design of more accurate maps for word translation",Theory Proposal,Theory Proposal
"We learn a joint multilingual sentence embedding and use the distance between sentences in different languages to filter noisy parallel data and to mine for parallel data in large news collections. We are able to improve a competitive baseline on the WMT’14 English to German task by 0.3 BLEU by filtering out 25% of the training data. The same approach is used to mine additional bitexts for the WMT’14 system and to obtain competitive results on the BUCC shared task to identify parallel sentences in comparable corpora. The approach is generic, it can be applied to many language pairs and it is independent of the architecture of the machine translation system",Resources,Resources
"we improve the existing SCRF methods by employing word-level and segment-level information simultaneously. First, word-level labels are utilized to derive the segment scores in SCRFs. Second, a CRF output layer and an SCRF output layer are integrated into an unified neural network and trained jointly. Experimental results on CoNLL 2003 named entity recognition (NER) shared task show that our model achieves state-of-the-art performance when no external knowledge is used",Algorithm/Method Optimization,Algorithm/Method Optimization
"we discuss the importance of external knowledge for performing Named Entity Recognition (NER). We present a novel modular framework that divides the knowledge into four categories according to the depth of knowledge they convey. Each category consists of a set of features automatically generated from different information sources, such as a knowledgebase, a list of names, or document-specific semantic annotations. Further, we show the effects on performance when incrementally adding deeper knowledge and discuss effectiveness/efficiency trade-of",Model Proposal,Model Proposal
"We consider the task of detecting contractual obligations and prohibitions. We show that a self-attention mechanism improves the performance of a BILSTM classifier, the previous state of the art for this task, by allowing it to focus on indicative tokens. We also introduce a hierarchical BILSTM, which converts each sentence to an embedding, and processes the sentence embeddings to classify each sentence. Apart from being faster to train, the hierarchical BILSTM outperforms the flat one, even when the latter considers surrounding sentences, because the hierarchical model has a broader discourse view.",Performance Evaluation,Performance Evaluation
"We present a paper abstract writing system based on an attentive neural sequenceto-sequence model that can take a title as input and automatically generate an abstract. We design a novel Writing-editing Network that can attend to both the title and the previously generated abstract drafts and then iteratively revise and polish the abstract. With two series of Turing tests, where the human judges are asked to distinguish the system-generated abstracts from human-written ones, our system passes Turing tests by junior domain experts at a rate up to 30% and by nonexpert at a rate up to 80%.",Model Proposal,Model Proposal
"We explore recently introduced definition modeling technique that provided the tool for evaluation of different distributed vector representations of words through modeling dictionary definitions of words. In this work, we study the problem of word ambiguities in definition modeling and propose a possible solution by employing latent variable modeling and soft attention mechanisms. Our quantitative and qualitative evaluation and analysis of the model shows that taking into account words ambiguity and polysemy leads to performance improveme",Model Optimization,Model Optimization
"we propose a Convolutional Neural Network (CNN) model for textbased multiple choice question answering where questions are based on a particular article. Given an article and a multiple choice question, our model assigns a score to each question-option tuple and chooses the final option accordingly. We test our model on Textbook Question Answering (TQA) and SciQ dataset. Our model outperforms several LSTM-based baseline models on the two datasets.",Dataset Creation,Dataset Creation
"we propose a novel method, tracking various semantic aspects with external neural memory chains while encouraging each to focus on a particular semantic aspect. Evaluated on the task of story ending prediction, our model demonstrates superior performance to a collection of competitive baselines, setting a new state of the art. 1",New Algorithm/ Method,New Algorithm/ Method
"we propose to inject structural representations in NNs by (i) learning an SVM model using Tree Kernels (TKs) on relatively few pairs of questions (few thousands) as gold standard (GS) training data is typically scarce, (ii) predicting labels on a very large corpus of question pairs, and (iii) pre-training NNs on such large corpus. The results on Quora and SemEval question similarity datasets show that NNs trained with our approach can learn more accurate models, especially after fine tuning on GS",Algorithm/Method Optimization,Algorithm/Method Optimization
"We offer a simple and effective method to seek a better balance between model confidence and length preference for Neural Machine Translation (NMT). Unlike the popular length normalization and coverage models, our model does not require training nor reranking the limited n-best outputs. Moreover, it is robust to large beam sizes, which is not well studied in previous work. On the Chinese-English and English-German translation tasks, our approach yields +0.4 ∼ 1.5 BLEU improvements over the state-of-the-art baselines.",Model Optimization,Model Optimization
"we propose an efficient method to dynamically sample the sentences in order to accelerate the NMT training. In this approach, a weight is assigned to each sentence based on the measured difference between the training costs of two iterations. Further, in each epoch, a certain percentage of sentences are dynamically sampled according to their weights. Empirical results based on the NIST Chinese-to-English and the WMT English-to-German tasks show that the proposed method can significantly accelerate the NMT training and improve the NMT performance.",New Algorithm/ Method,New Algorithm/ Method
"we propose to overcome this problem by replacing the source-language embedding layer of NMT with a bi-directional recurrent neural network that generates compositional representations of the input at any desired level of granularity. We test our approach in a low-resource setting with five languages from different morphological typologies, and under different composition assumptions. By training NMT to compose word representations from character trigrams, our approach consistently outperforms (from 1.71 to 2.48 BLEU points) NMT learning embeddings of statistically generated sub-word units.",Theory Proposal,Theory Proposal
"We explore strategies for incorporating target syntax into Neural Machine Translation. We specifically focus on syntax in ensembles containing multiple sentence representations. We formulate beam search over such ensembles using WFSTs, and describe a delayed SGD update training procedure that is especially effective for long representations like linearized syntax. Our approach gives state-of-the-art performance on a difficult Japanese-English task",Performance Evaluation,Performance Evaluation
"We empirically investigate learning from partial feedback in neural machine translation (NMT), when partial feedback is collected by asking users to highlight a correct chunk of a translation. We propose a simple and effective way of utilizing such feedback in NMT training. We demonstrate how the common machine translation problem of domain mismatch between training and deployment can be reduced solely based on chunk-level user feedback. We conduct a series of simulation experiments to test the effectiveness of the proposed method. Our results show that chunk-level feedback outperforms sentence based feedback by up to 2.61% BLEU absolute.",Theory Proposal,Theory Proposal
"We found such monotonicity forces the algorithm to sacrifice some decoding paths to explore new paths. As a result, the overall quality of the hypotheses selected by the algorithm is lower than expected. To mitigate this problem, we relax the monotonic constraint of the beam search by maintaining all found hypotheses in a single priority queue and using a universal score function for hypothesis selection. The proposed algorithm allows discarded hypotheses to be recovered in a later step. Despite its simplicity, we show that the proposed decoding algorithm enhances the quality of selected hypotheses and improve the translations even for highperformance models in English-Japanese translation task.",Theory Proposal,Theory Proposal
"we propose and evaluate models for classifying VNC usages as idiomatic or literal, based on a variety of approaches to forming distributed representations. Our results show that a model based on averaging word embeddings performs on par with, or better than, a previously-proposed approach based on skip-thoughts. Idiomatic usages of VNCs are known to exhibit lexico-syntactic fixedness. We further incorporate this information into our models, demonstrating that this rich linguistic knowledge is complementary to the information carried by distributed representations.",Model Optimization,Model Optimization
"we propose Pseudofit, a new method for specializing word embeddings according to semantic similarity without any external knowledge. Pseudofit exploits the notion of pseudo-sense for building several representations for each word and uses these representations for making the initial embeddings more generic. We illustrate the interest of Pseudofit for acquiring synonyms and study several variants of Pseudofit according to this perspective",New Algorithm/ Method,New Algorithm/ Method
we study the performance of both approaches on several hypernymy tasks and find that simple pattern-based methods consistently outperform distributional methods on common benchmark datasets. Our results show that pattern-based models provide important contextual constraints which are not yet captured in distributional methods.,Algorithm/Method Optimization,Algorithm/Method Optimization
"We explore novel strategies to address the coverage problem that change only the attention transformation. Our approach allocates fertilities to source words, used to bound the attention each word can receive. We experiment with various sparse and constrained attention transformations and propose a new one, constrained sparsemax, shown to be differentiable and sparse. Empirical evaluation is provided in three languages pairs.",Performance Evaluation,Performance Evaluation
"We show that the divergence in the tag distributions of the common named entities between the primary and assisting languages can reduce the effectiveness of multilingual learning. To alleviate this problem, we propose a metric based on symmetric KL divergence to filter out the highly divergent training instances in the assisting language. We empirically show that our data selection strategy improves NER performance in many languages, including those with very limited training data.",Theory Proposal,Theory Proposal
"we propose a neural Open IE approach with an encoder-decoder framework. Distinct from existing methods, the neural Open IE approach learns highly confident arguments and relation tuples bootstrapped from a state-of-the-art Open IE system. An empirical study on a large benchmark dataset shows that the neural Open IE system significantly outperforms several baselines, while maintaining comparable computational efficiency.",Algorithm/Method Optimization,Algorithm/Method Optimization
"we propose a novel Document Embedding Enhanced Bi-RNN model, called DEEB-RNN, to detect events in sentences. This model first learns event detection oriented embeddings of documents through a hierarchical and supervised attention based RNN, which pays word-level attention to event triggers and sentence-level attention to those sentences containing events. It then uses the learned document embedding to enhance another bidirectional RNN model to identify event triggers and their types in sentences. Through experiments on the ACE-2005 dataset, we demonstrate the effectiveness and merits of the proposed DEEB-RNN model via comparison with state-of-the-art methods",Model Proposal,Model Proposal
"We propose a method that can leverage unlabeled data to learn a matching model for response selection in retrieval-based chatbots. The method employs a sequence-tosequence architecture (Seq2Seq) model as a weak annotator to judge the matching degree of unlabeled pairs, and then performs learning with both the weak signals and the unlabeled data. Experimental results on two public data sets indicate that matching models get significant improvements when they are learned with the proposed method.",New Algorithm/ Method,New Algorithm/ Method
"We present a generative neural network model for slot filling based on a sequenceto-sequence (Seq2Seq) model together with a pointer network, in the situation where only sentence-level slot annotations are available in the spoken dialogue data. This model predicts slot values by jointly learning to copy a word which may be out-of-vocabulary (OOV) from an input utterance through a pointer network, or generate a word within the vocabulary through an attentional Seq2Seq model. Experimental results show the effectiveness of our slot filling model, especially at addressing the OOV problem. Additionally, we integrate the proposed model into a spoken language understanding system and achieve the state-of-the-art performance on the benchmark data.",Model Proposal,Model Proposal
"we propose a new transition-based discourse parser that makes use of memory networks to take discourse cohesion into account. The automatically captured discourse cohesion benefits discourse parsing, especially for long span scenarios. Experiments on the RST discourse treebank show that our method outperforms traditional featured based methods, and the memory based discourse cohesion can improve the overall parsing performance significantly 1 .",Theory Proposal,Theory Proposal
"we present SciDTB, a domainspecific discourse treebank annotated on scientific articles. Different from widelyused RST-DT and PDTB, SciDTB uses dependency trees to represent discourse structure, which is flexible and simplified to some extent but do not sacrifice structural integrity. We discuss the labeling framework, annotation workflow and some statistics about SciDTB. Furthermore, our treebank is made as a benchmark for evaluating discourse dependency parsers, on which we provide several baselines as fundamental work.",Model Proposal,Model Proposal
"we develop methods for predicting how much data is required to achieve a desired test accuracy by extrapolating results from systems trained on a small pilot training dataset. We model how accuracy varies as a function of training size on subsets of the pilot data, and use that model to predict how much training data would be required to achieve the desired accuracy. We introduce a new performance extrapolation task to evaluate how well different extrapolations predict system accuracy on larger training sets. We show that details of hyperparameter optimisation and the extrapolation models can have dramatic effects in a document classification task. We believe this is an important first step in developing methods for estimating the resources required to meet specific engineering performance targets.",Resources,Resources
"We investigate the influence that document context exerts on human acceptability judgements for English sentences, via two sets of experiments. The first compares ratings for sentences presented on their own with ratings for the same set of sentences given in their document contexts. The second assesses the accuracy with which two types of neural models — one that incorporates context during training and one that does not — predict these judgements. Our results indicate that: (1) context improves acceptability ratings for ill-formed sentences, but also reduces them for well-formed sentences; and (2) context helps unsupervised systems to model acceptability",Theory Proposal,Theory Proposal
"we propose a new similarity measure and two ad hoc experiments to shed light on this issue. In three cross-modal benchmarks we learn a large number of language-to-vision and visionto-language neural network mappings (up to five layers) using a rich diversity of image and text features and loss functions. Our results reveal that, surprisingly, the neighborhood structure of the predicted vectors consistently resembles more that of the input vectors than that of the target vectors. In a second experiment, we further show that untrained nets do not significantly disrupt the neighborhood (i.e., semantic) structure of the input vectors.",Theory Proposal,Theory Proposal
"We explore using a policy gradient method as a parser-agnostic alternative. In addition to directly optimizing for a tree-level metric such as F1, policy gradient has the potential to reduce exposure bias by allowing exploration during training; moreover, it does not require a dynamic oracle for supervision. On four constituency parsers in three languages, the method substantially outperforms static oracle likelihood training in almost all settings. For parsers where a dynamic oracle is available (including a novel oracle which we define for the transition system of Dyer et al. (2016)), policy gradient typically recaptures a substantial fraction of the performance gain afforded by the dynamic oracle.",Performance Evaluation,Performance Evaluation
"We propose a linear-time constituency parser with RNNs and dynamic programming using graph-structured stack and beam search, which runs in time O(nb2 ) where b is the beam size. We further speed this up to O(nb log b) by integrating cube pruning. Compared with chart parsing baselines, this linear-time parser is substantially faster for long sentences on the Penn Treebank and orders of magnitude faster for discourse parsing, and achieves the highest F1 accuracy on the Penn Treebank among single model end-to-end systems.",Model Proposal,Model Proposal
"We extend the LSTM-based syntactic parser of Dozat and Manning (2017) to train on and generate these graph structures. The resulting system on its own achieves stateof-the-art performance, beating the previous, substantially more complex stateof-the-art system by 0.6% labeled F1. Adding linguistically richer input representations pushes the margin even higher, allowing us to beat it by 1.9% labele",Performance Evaluation,Performance Evaluation
"We investigate the feasibility of recovering the original text written in an abugida after omitting subordinate diacritics and merging consonant letters with similar phonetic values. This is crucial for developing more efficient input methods by reducing the complexity in abugidas. Four abugidas in the southern Brahmic family, i.e., Thai, Burmese, Khmer, and Lao, were studied using a newswire 20, 000-sentence dataset",Theory Proposal,Theory Proposal
"we propose a novel task: automatic academic paper rating (AAPR), which automatically determine whether to accept academic papers. We build a new dataset for this task and propose a novel modularized hierarchical convolutional neural network to achieve automatic academic paper rating. Evaluation results show that the proposed model outperforms the baselines by a large margin",New Algorithm/ Method,New Algorithm/ Method
"we present an approach based on combining string kernels and word embeddings for automatic essay scoring. String kernels capture the similarity among strings based on counting common character ngrams, which are a low-level yet powerful type of feature, demonstrating state-of-theart results in various text classification tasks such as Arabic dialect identification or native language identification",Model Proposal,Model Proposal
"we aim to analyze structured time-series documents such as a collection of news articles and a series of scientific papers, wherein topics evolve along time depending on multiple topics in the past, and are also related to each other at each time.",Performance Evaluation,Performance Evaluation
" we propose a novel topic model PhraseCTM and a twostage method to find out the correlated topics at phrase level. In the first stage, we train PhraseCTM, which models the generation of words and phrases simultaneously by linking the phrases and component words within Markov Random Fields when they are semantically coheren",New Algorithm/ Method,New Algorithm/ Method
"we address the problem of finding a novel document descriptor based on the covariance matrix of the word vectors of a document. Our descriptor has a fixed length, which makes it easy to use in many supervised and unsupervised applications",Performance Evaluation,Performance Evaluation
"We report an empirical study on the task of negation scope extraction given the negation cue. Our key observation is that certain useful information such as features related to negation cue, long distance dependencies as well as some latent structural information can be exploited for such a task",Performance Evaluation,Performance Evaluation
We propose DEISTE (deep explorations of inter-sentence interactions for textual entailment) for this entailment task,Model Proposal,Model Proposal
"we focus on the task of pun location, which aims to identify the pun word in a given short text. We propose a sense-aware neural model to address this challenging task. Our model first obtains several WSD results for the text, and then leverages a bidirectional LSTM network to model each sequence of word senses.",Performance Evaluation,Performance Evaluation
"we report experiments with a rank-based metric for WE, which performs comparably to vector cosine in similarity estimation and outperforms it in the recently-introduced and challenging task of outlier detection, thus suggesting that rank-based measures can improve clustering quality",Performance Evaluation,Performance Evaluation
"We make three contributions to address this noise. First, we describe simple but effective adaptations to word embedding tools to maximize the informative content leveraged in each training sentence",Resources,Resources
"We hypothesize that taking into account global, corpuslevel information and generating a different noise distribution for each target word better satisfies the requirements of negative examples for each training word than the original frequency-based distribution",Theory Proposal,Theory Proposal
"We propose extending the continuous bag of words (CBOW) model (Mikolov et al., 2013a) to learn style-sensitive word vectors using a wider context window under the assumption that the style of all the words in an utterance is consistent",Dataset Creation,Dataset Creation
"we explore two approaches that transfer knowledge from documentlevel data, which is much less expensive to obtain, to improve the performance of aspect-level sentiment classification.",Performance Evaluation,Performance Evaluation
"We found that discourse relation, sentiment conflict and sentiment transition are effective indicators for humor recognition. On the perspective of using sentiment related features, sentiment association in discourse is more useful than counting the number of emotional words.",Theory Proposal,Theory Proposal
"we propose a double embeddings mechanism that is shown crucial for aspect extraction. The embedding layer is the very first layer, where all the information about each word is encoded.",Model Proposal,Model Proposal
"We propose a methodology to blend high quality but scarce labeled data with noisy but abundant weak labeled data during the training of neural networks. Experiments in the context of topic-dependent evidence detection with two forms of weak labeled data show the advantages of the blending scheme. In addition, we provide a manually annotated data set for the task of topicdependent evidence detection",New Algorithm/ Method,New Algorithm/ Method
"We propose a tri-modal architecture to predict Big Five personality trait scores from video clips with different channels for audio, text, and video data.",Model Proposal,Model Proposal
"We start by investigating previously suggested, but little evaluated, strategies for exploiting multiple treebanks based on concatenating training sets, with or without fine-tuning.",Theory Proposal,Theory Proposal
We generalize chart constraints to more expressive grammar formalisms and describe a neural tagger which predicts chart constraints at very high precision,Resources,Resources
we assess to what extent prominent sentence embedding methods exhibit select semantic properties,Resources,Resources
"We present the Supervised Directional Similarity Network (SDSN), a novel neural architecture for learning task-specific transformation functions on top of generalpurpose word embeddings",Model Proposal,Model Proposal
"We propose and assess methods for extracting one type of commonsense knowledge, object-property comparisons, from pretrained embeddings",Resources,Resources
We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge.,Theory Proposal,Theory Proposal
We propose the task of predicting simultaneous interpreter performance by building on existing methodology for quality estimation (QE) of machine translation output,Algorithm/Method Optimization,Algorithm/Method Optimization
"We experiment with a new approach where we combine resources from a pair of languages in the CoNLL 2009 shared task (Hajic et al. ˇ , 2009) to build a polyglot semantic role labeler. Notwithstanding the absence of parallel data, and the dissimilarity in annotations between languages, our approach results in an improvement in SRL performance on multiple languages over a monolingual baseline",Theory Proposal,Theory Proposal
we present a study to show how learning distributed representations of the logical forms from data annotated in different languages can be used for improving the performance of a monolingual semantic parser.,Model Proposal,Model Proposal
We propose a novel neural method to extract drug-drug interactions (DDIs) from texts using external drug molecular structure information,New Algorithm/ Method,New Algorithm/ Method
"we devise with these features can robustly cope with inputs 687 from diachronic corpora. We propose a new evaluation benchmark, based on the New York Times Archive, spanning more than 20 years, and the history collection historynet.com, spanning several centuries. Our experiments demonstrate that timeaware NED substantially outperforms some of the best standard NED tools",Theory Proposal,Theory Proposal
"We show experimentally that classification performance varies over time, and that performance can be improved by using a standard domain adaptation approach to adjust for changes in time.",Performance Evaluation,Performance Evaluation
We show how an adaptable language model can be used to generate personalized completions and how the model can use online updating to make predictions for users not seen during training. The personalized predictions are significantly better than a baseline that uses no user information,Resources,Resources
we focus on the problem of building assistive systems that can help users to write reviews.,Theory Proposal,Theory Proposal
We explore these two features of TS to build models tailored for specific grade levels. Our approach uses a standard sequenceto-sequence architecture where the original sequence is annotated with information about the target audience and/or the (predicted) type of simplification operation,Model Proposal,Model Proposal
"We show that while vanilla seq2seq models can reach high scores on the proposed benchmark (Narayan et al., 2017), they suffer from memorization of the training set which contains more than 89% of the unique simple sentences from the validation and test sets.",Performance Evaluation,Performance Evaluation
we supervise the learning of the representation of the source content with that of the summary,Theory Proposal,Theory Proposal
We present an alternative view to explain the success of LSTMs: the gates themselves are versatile recurrent models that provide more representational power than previously appreciated,Model Proposal,Model Proposal
"We consider the case of RNNs with finite precision whose computation time is linear in the input length. Under these limitations, we show that different RNN variants have different computational power.",Dataset Creation,Dataset Creation
we propose a new model to match a question-answer pair to a given passage. Our comatching approach explicitly treats the question and the candidate answer as two sequences and jointly matches them to the given passage,Model Proposal,Model Proposal
"we have performed various data analysis and analyzed a variety of top performing models presented for this task. Given the statistics we have aggregated, we have designed a new crowdsourcing scheme that creates a new SCT dataset, which overcomes some of the biases.",Model Optimization,Model Optimization
"we propose a Multi-sentiment-resource Enhanced Attention Network (MEAN) to alleviate the problem by integrating three kinds of sentiment linguistic knowledge (e.g., sentiment lexicon, negation words, intensity words) into the deep neural network via attention mechanisms",Model Proposal,Model Proposal
we address a sentiment classification task for a tweet analysis service as a case study and propose a pretraining strategy with unlabeled dialog data (tweet-reply pairs) via an encoder-decoder model.,Performance Evaluation,Performance Evaluation
"We analyze the ambiguity of hashtag usages and propose a novel neural networkbased model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection",Performance Evaluation,Performance Evaluation
"we explore the potential for generalizing classifiers between different targets, and propose a neural model that can apply what has been learned from a source target to a destination target",Theory Proposal,Theory Proposal
"we present SQUADRUN, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones",Dataset Creation,Dataset Creation
We propose a novel paradigm of grounding comparative adjectives within the realm of color descriptions.,New Algorithm/ Method,New Algorithm/ Method
